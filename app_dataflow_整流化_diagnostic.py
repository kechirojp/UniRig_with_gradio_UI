#!/usr/bin/env python3
"""
app.pyãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼æ•´æµåŒ–è¨ºæ–­ãƒ„ãƒ¼ãƒ«
å‘½åè¦å‰‡ã®å³æ ¼åŒ–ã¨åŸæµå‡¦ç†äº’æ›æ€§ç¢ºä¿ã®ãŸã‚ã®è¨ºæ–­

2025å¹´6æœˆ14æ—¥ä½œæˆ
"""

import os
import sys
from pathlib import Path

def analyze_current_dataflow():
    """ç¾åœ¨ã®app.pyãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼åˆ†æ"""
    
    print("=== app.pyãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼æ•´æµåŒ–è¨ºæ–­ ===")
    
    # 1. FixedDirectoryManagerã®å‘½åè¦å‰‡ç¢ºèª
    print("\n1. ğŸ” FixedDirectoryManagerå‘½åè¦å‰‡ç¢ºèª")
    
    # æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥ã®æ­£ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³
    correct_patterns = {
        "step0": {
            "preserved_file": "{model_name}.glb",           # âœ… ãƒ¢ãƒ‡ãƒ«åæ¥é ­ã®ã¿
            "metadata_json": "{model_name}_asset_metadata.json",  # âœ… ãƒ¢ãƒ‡ãƒ«åæ¥é ­ã®ã¿
            "textures_dir": "textures"                      # âœ… å®Œå…¨å›ºå®š
        },
        "step1": {
            "raw_data_npz": "raw_data.npz"                  # âœ… å®Œå…¨å›ºå®šï¼ˆåŸæµå‡¦ç†æœŸå¾…å€¤ï¼‰
        },
        "step2": {
            "skeleton_fbx": "{model_name}.fbx",             # âœ… ãƒ¢ãƒ‡ãƒ«åæ¥é ­ã®ã¿ï¼ˆåŸæµå‡¦ç†æœŸå¾…å€¤ï¼‰
            "skeleton_npz": "predict_skeleton.npz"          # âœ… å®Œå…¨å›ºå®šï¼ˆåŸæµå‡¦ç†æœŸå¾…å€¤ï¼‰
        },
        "step3": {
            "skinned_fbx": "{model_name}_skinned_unirig.fbx",  # âœ… ãƒ¢ãƒ‡ãƒ«åæ¥é ­ã®ã¿
            "skinning_npz": "{model_name}_skinning.npz"       # âœ… ãƒ¢ãƒ‡ãƒ«åæ¥é ­ã®ã¿
        },
        "step4": {
            "merged_fbx": "{model_name}_merged.fbx"         # âœ… ãƒ¢ãƒ‡ãƒ«åæ¥é ­ã®ã¿
        },
        "step5": {
            "final_fbx": "{model_name}_final.fbx",          # âœ… ãƒ¢ãƒ‡ãƒ«åæ¥é ­ã®ã¿
            "final_fbm_dir": "{model_name}_final.fbm"       # âœ… ãƒ¢ãƒ‡ãƒ«åæ¥é ­ã®ã¿
        }
    }
    
    print("âœ… æ­£ã—ã„å‘½åè¦å‰‡ãƒ‘ã‚¿ãƒ¼ãƒ³:")
    for step, files in correct_patterns.items():
        print(f"  {step}:")
        for key, pattern in files.items():
            print(f"    {key}: {pattern}")
    
    # 2. åŸæµå‡¦ç†äº’æ›æ€§ç¢ºèª
    print("\n2. ğŸ” åŸæµå‡¦ç†äº’æ›æ€§ç¢ºèª")
    
    critical_fixed_names = [
        "raw_data.npz",           # Step1â†’Step2,Step3å…¥åŠ›
        "predict_skeleton.npz",   # Step2â†’Step3å…¥åŠ›
        "inference_datalist.txt"  # Step3è¦ä»¶
    ]
    
    print("âš ï¸ å¤‰æ›´çµ¶å¯¾ç¦æ­¢ãƒ•ã‚¡ã‚¤ãƒ«å:")
    for filename in critical_fixed_names:
        print(f"  - {filename}")
    
    # 3. ãƒ•ã‚¡ã‚¤ãƒ«å—ã‘æ¸¡ã—æ•´åˆæ€§ç¢ºèª
    print("\n3. ğŸ” ã‚¹ãƒ†ãƒƒãƒ—é–“ãƒ•ã‚¡ã‚¤ãƒ«å—ã‘æ¸¡ã—æ•´åˆæ€§")
    
    dataflow_chain = [
        {
            "step": "Step0â†’Step1",
            "output": "{model_name}.glb",
            "input": "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«",
            "validation": "ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª"
        },
        {
            "step": "Step1â†’Step2",
            "output": "raw_data.npz",
            "input": "raw_data.npz",
            "validation": "NPZæ§‹é€ ç¢ºèª"
        },
        {
            "step": "Step2â†’Step3",
            "output": ["{model_name}.fbx", "predict_skeleton.npz"],
            "input": ["raw_data.npz", "predict_skeleton.npz", "{model_name}.fbx"],
            "validation": "ãƒ•ã‚¡ã‚¤ãƒ«ä¸‰ç‚¹ã‚»ãƒƒãƒˆç¢ºèª"
        },
        {
            "step": "Step3â†’Step4",
            "output": "{model_name}_skinned_unirig.fbx",
            "input": ["{model_name}.fbx", "{model_name}_skinned_unirig.fbx"],
            "validation": "FBXãƒšã‚¢ç¢ºèª"
        },
        {
            "step": "Step4â†’Step5",
            "output": "{model_name}_merged.fbx",
            "input": ["{model_name}_merged.fbx", "ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«"],
            "validation": "ãƒãƒ¼ã‚¸FBX+ã‚ªãƒªã‚¸ãƒŠãƒ«ç¢ºèª"
        }
    ]
    
    print("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ãƒã‚§ãƒ¼ãƒ³:")
    for flow in dataflow_chain:
        print(f"  {flow['step']}:")
        print(f"    å‡ºåŠ›: {flow['output']}")
        print(f"    å…¥åŠ›: {flow['input']}")
        print(f"    æ¤œè¨¼: {flow['validation']}")
    
    # 4. å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
    print("\n4. âš ï¸ å±é™ºãªæŸ”è»Ÿæ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆç¦æ­¢äº‹é …ï¼‰")
    
    dangerous_patterns = [
        "glob.glob('*extracted*.npz')",
        "find_file_with_pattern(pattern)",
        "dynamic_filename_generation()",
        "fallback_file_search()",
        "flexible_naming_scheme()"
    ]
    
    print("âŒ å®Ÿè£…ç¦æ­¢ãƒ‘ã‚¿ãƒ¼ãƒ³:")
    for pattern in dangerous_patterns:
        print(f"  - {pattern}")
    
    # 5. æ•´æµåŒ–è¦ä»¶
    print("\n5. ğŸ¯ æ•´æµåŒ–è¦ä»¶")
    
    requirements = [
        "ãƒ•ã‚¡ã‚¤ãƒ«åã¯{model_name}æ¥é ­ã¾ãŸã¯å®Œå…¨å›ºå®šã®ã¿",
        "åŸæµå‡¦ç†æœŸå¾…å€¤ã¨ã®100%ä¸€è‡´",
        "glob/å‹•çš„æ¤œç´¢ã®å®Œå…¨æ’é™¤",
        "ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã®ç¦æ­¢",
        "æ±ºã‚æ‰“ã¡ãƒ‘ã‚¹ç›´æ¥æŒ‡å®šã®å¾¹åº•"
    ]
    
    print("ğŸ“‹ å¿…é ˆè¦ä»¶:")
    for req in requirements:
        print(f"  âœ“ {req}")
    
    print("\n=== è¨ºæ–­å®Œäº† ===")
    print("æ¬¡ã®ä½œæ¥­: app.pyãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼æ•´æµåŒ–å®Ÿè£…")

if __name__ == "__main__":
    analyze_current_dataflow()
