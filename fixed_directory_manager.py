#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å›ºå®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç®¡ç†ã‚¯ãƒ©ã‚¹ - çµ±ä¸€å‘½åè¦å‰‡å¯¾å¿œï¼ˆæ•´æµå®Ÿè£…ï¼‰
2025å¹´6æœˆ14æ—¥æ”¹ä¿® - çµ±ä¸€å‘½åè¦å‰‡ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½å®Ÿè£…

ç›®çš„: çµ±ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‘½åè¦å‰‡ã«åŸºã¥ãäºˆæ¸¬å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«é…ç½®ã¨
     æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã®äº’æ›æ€§ä¿æŒ
"""

import logging
from pathlib import Path
from typing import Dict, Optional, Tuple, List
import shutil

class UnifiedNamingConvention:
    """çµ±ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‘½åè¦å‰‡ã®å®Ÿè£…"""
    
    NAMING_PATTERNS = {
        'step1': {
            'mesh_npz': '{model_name}_mesh.npz',
        },
        'step2': {
            'skeleton_fbx': '{model_name}_skeleton.fbx',
            'skeleton_npz': '{model_name}_skeleton.npz',
        },
        'step3': {
            'skinned_fbx': '{model_name}_skinned.fbx',
            'skinning_npz': '{model_name}_skinning.npz',
        },
        'step4': {
            'merged_fbx': '{model_name}_merged.fbx',
        },
        'step5': {
            'final_fbx': '{model_name}_final.fbx',     # æœ€çµ‚æˆæœç‰©ï¼ˆçµ±ä¸€ï¼‰
            # 'final_output': '{model_name}_final{ext}', # å‹•çš„æ‹¡å¼µå­å¯¾å¿œã¯åˆ¥é€”å‡¦ç†
        }
    }
    
    # ãƒ¬ã‚¬ã‚·ãƒ¼å‘½åãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
    LEGACY_PATTERNS = {
        'step1': {
            'mesh_npz': ['raw_data.npz'],
        },
        'step2': {
            'skeleton_fbx': ['{model_name}.fbx', 'skeleton.fbx', 'skeleton_model.fbx'],
            'skeleton_npz': ['predict_skeleton.npz'],
        },
        'step3': {
            'skinned_fbx': ['{model_name}_skinned.fbx', '{model_name}_skinned_unirig.fbx', 'result_fbx.fbx', 'skinned_model.fbx'],
            'skinning_npz': ['predict_skin.npz', '{model_name}_skinning.npz'],
        },
        'step4': {
            'merged_fbx': ['{model_name}_textured.fbx', '{model_name}_merged.fbx'],
        },
        'step5': {
            'rigged_fbx': ['{model_name}_final.fbx'],
            'final_fbx': ['{model_name}_final.fbx'],
            # 'final_output': ['{model_name}_final{ext}', '{model_name}_final.fbx', '{model_name}_rigged.fbx'],  # å‹•çš„æ‹¡å¼µå­å¯¾å¿œã¯åˆ¥é€”å‡¦ç†
        }
    }
    
    def get_unified_file_name(self, model_name: str, step: str, file_type: str, ext: str = None) -> str:
        """çµ±ä¸€å‘½åè¦å‰‡ã«åŸºã¥ããƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆï¼ˆå‹•çš„æ‹¡å¼µå­å¯¾å¿œï¼‰"""
        pattern = self.NAMING_PATTERNS.get(step, {}).get(file_type)
        if pattern:
            try:
                if '{ext}' in pattern and ext:
                    return pattern.format(model_name=model_name, ext=ext)
                else:
                    return pattern.format(model_name=model_name)
            except KeyError:
                # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤±æ•—æ™‚ã¯extãªã—ã§å†è©¦è¡Œ
                return pattern.format(model_name=model_name)
        else:
            raise ValueError(f"æœªå®šç¾©ã®çµ±ä¸€å‘½åãƒ‘ã‚¿ãƒ¼ãƒ³: {step}/{file_type}")
    
    def get_legacy_file_names(self, model_name: str, step: str, file_type: str, ext: str = None) -> List[str]:
        """ãƒ¬ã‚¬ã‚·ãƒ¼å‘½åãƒ‘ã‚¿ãƒ¼ãƒ³ãƒªã‚¹ãƒˆå–å¾—ï¼ˆå‹•çš„æ‹¡å¼µå­å¯¾å¿œï¼‰"""
        patterns = self.LEGACY_PATTERNS.get(step, {}).get(file_type, [])
        result = []
        for pattern in patterns:
            try:
                if '{ext}' in pattern and ext:
                    result.append(pattern.format(model_name=model_name, ext=ext))
                else:
                    result.append(pattern.format(model_name=model_name))
            except KeyError:
                # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤±æ•—æ™‚ã¯extãªã—ã§å†è©¦è¡Œ
                try:
                    result.append(pattern.format(model_name=model_name))
                except KeyError:
                    # ãã‚Œã§ã‚‚å¤±æ•—ã™ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    continue
        return result

class FixedDirectoryManager:
    """æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç®¡ç†ã‚¯ãƒ©ã‚¹ - çµ±ä¸€å‘½åè¦å‰‡å¯¾å¿œ"""
    
    def __init__(self, base_dir: Path, model_name: str, logger: Optional[logging.Logger] = None):
        """
        å›ºå®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç®¡ç†ã‚¯ãƒ©ã‚¹åˆæœŸåŒ–
        
        Args:
            base_dir: ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (/app/pipeline_work)
            model_name: ãƒ¢ãƒ‡ãƒ«å
            logger: ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        self.base_dir = Path(base_dir)
        self.model_name = model_name
        self.model_dir = self.base_dir / model_name
        self.logger = logger if logger else logging.getLogger(__name__)
        self.naming = UnifiedNamingConvention()
        
        # æ±ºã‚æ‰“ã¡ã‚¹ãƒ†ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå®šç¾© (å›ºå®šä»•æ§˜)
        self.step_dirs = {
            "step0": "00_asset_preservation",
            "step1": "01_extracted_mesh", 
            "step2": "02_skeleton",
            "step3": "03_skinning",
            "step4": "04_merge",
            "step5": "05_blender_integration"
        }
    
    def get_step_dir(self, step: str) -> Path:
        """ã‚¹ãƒ†ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹å–å¾—"""
        if step not in self.step_dirs:
            raise ValueError(f"æœªçŸ¥ã®ã‚¹ãƒ†ãƒƒãƒ—: {step}")
        return self.model_dir / self.step_dirs[step]
    
    def create_all_directories(self):
        """å…¨ã‚¹ãƒ†ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        try:
            # ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            self.model_dir.mkdir(parents=True, exist_ok=True)
            self.logger.info(f"ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {self.model_dir}")
            
            # å„ã‚¹ãƒ†ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            for step, dir_name in self.step_dirs.items():
                step_dir = self.model_dir / dir_name
                step_dir.mkdir(parents=True, exist_ok=True)
                self.logger.info(f"ã‚¹ãƒ†ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {step_dir}")
            
            return True
        except Exception as e:
            self.logger.error(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def setup_directories(self):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆcreate_all_directoriesã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼‰"""
        return self.create_all_directories()
    
    def get_unified_file_path(self, step: str, file_type: str, ext: str = None) -> Path:
        """çµ±ä¸€å‘½åè¦å‰‡ã«åŸºã¥ããƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹å–å¾—ï¼ˆå‹•çš„æ‹¡å¼µå­å¯¾å¿œï¼‰"""
        step_dir = self.get_step_dir(step)
        unified_name = self.naming.get_unified_file_name(self.model_name, step, file_type, ext)
        return step_dir / unified_name
    
    def find_file_with_fallback(self, step: str, file_type: str, ext: str = None) -> Optional[Path]:
        """çµ±ä¸€å‘½åè¦å‰‡ãƒ•ã‚¡ã‚¤ãƒ« + ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢ï¼ˆå‹•çš„æ‹¡å¼µå­å¯¾å¿œï¼‰"""
        step_dir = self.get_step_dir(step)
        
        # 1. çµ±ä¸€å‘½åè¦å‰‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
        unified_path = self.get_unified_file_path(step, file_type, ext)
        if unified_path.exists():
            self.logger.info(f"[OK] çµ±ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {unified_path}")
            return unified_path
        
        # 2. ãƒ¬ã‚¬ã‚·ãƒ¼å‘½åè¦å‰‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        legacy_names = self.naming.get_legacy_file_names(self.model_name, step, file_type, ext)
        for legacy_name in legacy_names:
            legacy_path = step_dir / legacy_name
            if legacy_path.exists():
                self.logger.warning(f"âš ï¸ ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨: {legacy_path}")
                return legacy_path
        
        self.logger.error(f"[FAIL] ãƒ•ã‚¡ã‚¤ãƒ«æœªç™ºè¦‹: {step}/{file_type} in {step_dir}")
        return None
    
    def ensure_unified_output(self, step: str, file_type: str, 
                             original_file: Path) -> Path:
        """åŸæµå‡¦ç†å‡ºåŠ›ã‚’çµ±ä¸€å‘½åè¦å‰‡ã«ãƒªãƒãƒ¼ãƒ /ã‚³ãƒ”ãƒ¼"""
        unified_path = self.get_unified_file_path(step, file_type)
        
        if original_file.exists() and original_file != unified_path:
            # çµ±ä¸€åã§ã®ã‚³ãƒ”ãƒ¼/ãƒªãƒãƒ¼ãƒ 
            unified_path.parent.mkdir(parents=True, exist_ok=True)
            shutil.copy2(original_file, unified_path)
            self.logger.info(f"ğŸ”„ çµ±ä¸€å‘½åè¦å‰‡é©ç”¨: {original_file} â†’ {unified_path}")
        
        return unified_path

    def validate_pipeline_integrity(self) -> Dict[str, bool]:
        """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œå…¨æ€§æ¤œè¨¼ (çµ±ä¸€å‘½åè¦å‰‡ + ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾å¿œ)"""
        validation_results = {}
        
        # Step1æ¤œè¨¼: ãƒ¡ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
        step1_mesh = self.find_file_with_fallback("step1", "mesh_npz")
        validation_results["step1_mesh"] = step1_mesh is not None
        
        # Step2æ¤œè¨¼: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
        step2_fbx = self.find_file_with_fallback("step2", "skeleton_fbx")
        step2_npz = self.find_file_with_fallback("step2", "skeleton_npz")
        validation_results["step2_fbx"] = step2_fbx is not None
        validation_results["step2_npz"] = step2_npz is not None
        
        # Step3æ¤œè¨¼: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXç¢ºèª
        step3_fbx = self.find_file_with_fallback("step3", "skinned_fbx")
        validation_results["step3_fbx"] = step3_fbx is not None
        
        # Step4æ¤œè¨¼: ãƒãƒ¼ã‚¸æ¸ˆã¿FBXç¢ºèª
        step4_fbx = self.find_file_with_fallback("step4", "merged_fbx")
        validation_results["step4_fbx"] = step4_fbx is not None
        
        # Step5æ¤œè¨¼: æœ€çµ‚å‡ºåŠ›ç¢ºèªï¼ˆå‹•çš„å½¢å¼å¯¾å¿œï¼‰
        step5_output = self.find_file_with_dynamic_extension("step5", "final_output")
        validation_results["step5_fbx"] = step5_output is not None
        
        return validation_results

    def get_pipeline_completion_status(self) -> Dict[str, bool]:
        """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†çŠ¶æ³ã®è©³ç´°å–å¾— (çµ±ä¸€å‘½åè¦å‰‡å¯¾å¿œ)"""
        validation = self.validate_pipeline_integrity()
        
        # å„ã‚¹ãƒ†ãƒƒãƒ—ã®å®Œäº†çŠ¶æ³ï¼ˆãƒ–ãƒ¼ãƒ«å€¤ã§è¿”ã™ï¼‰
        step0_completed, _, _ = self.check_step_completion("step0")  # ã‚¿ãƒ—ãƒ«ã‹ã‚‰æœ€åˆã®è¦ç´ ã‚’å–å¾—
        status = {
            "step0": step0_completed,
            "step1": validation["step1_mesh"],
            "step2": validation["step2_fbx"] and validation["step2_npz"],
            "step3": validation["step3_fbx"],
            "step4": validation["step4_fbx"],
            "step5": validation["step5_fbx"]
        }
        
        return status

    def get_user_download_files(self) -> Dict[str, Optional[Path]]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§"""
        download_files = {}
        
        # æœ€çµ‚æˆæœç‰©ï¼ˆæœ€å„ªå…ˆãƒ»å‹•çš„å½¢å¼å¯¾å¿œï¼‰
        final_output = self.find_file_with_dynamic_extension("step5", "final_output")
        if final_output:
            download_files["final_rigged_model"] = final_output
        
        # ä¸­é–“æˆæœç‰©ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
        skeleton_fbx = self.find_file_with_fallback("step2", "skeleton_fbx")
        if skeleton_fbx:
            download_files["skeleton_only"] = skeleton_fbx
        
        skinned_fbx = self.find_file_with_fallback("step3", "skinned_fbx")
        if skinned_fbx:
            download_files["skinned_model"] = skinned_fbx
        
        merged_fbx = self.find_file_with_fallback("step4", "merged_fbx")
        if merged_fbx:
            download_files["merged_model"] = merged_fbx
        
        return download_files

    def validate_step_inputs(self, step: str) -> Tuple[bool, str, Dict[str, Path]]:
        """
        ã‚¹ãƒ†ãƒƒãƒ—å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼
        
        Args:
            step: ã‚¹ãƒ†ãƒƒãƒ—å
            
        Returns:
            valid: æ¤œè¨¼çµæœ
            message: æ¤œè¨¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            available_files: åˆ©ç”¨å¯èƒ½ãƒ•ã‚¡ã‚¤ãƒ«è¾æ›¸
        """
        input_files = self.get_step_input_files(step)
        available_files = {}
        missing_files = []
        
        for key, path in input_files.items():
            if path.exists():
                available_files[key] = path
            else:
                missing_files.append(f"{key}: {path}")
        
        if missing_files:
            message = f"ä¸è¶³ãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(missing_files)}"
            return False, message, available_files
        else:
            return True, "å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼å®Œäº†", available_files
    
    def check_step_completion(self, step: str) -> Tuple[bool, List[str], List[str]]:
        """
        ã‚¹ãƒ†ãƒƒãƒ—å®Œäº†çŠ¶æ…‹ã‚’ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ã§åˆ¤å®š (JSONãªã—)
        
        Args:
            step: ã‚¹ãƒ†ãƒƒãƒ—å
            
        Returns:
            completed: å®Œäº†ãƒ•ãƒ©ã‚°
            existing_files: å­˜åœ¨ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ
            missing_files: ä¸è¶³ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ
        """
        expected = self.get_expected_files(step)
        existing_files = []
        missing_files = []
        
        for key, path in expected.items():
            if path.exists():
                existing_files.append(f"{key}: {path.name}")
            else:
                missing_files.append(f"{key}: {path.name}")
        
        completed = len(missing_files) == 0
        return completed, existing_files, missing_files
    
    def get_step_input_files(self, step: str) -> Dict[str, Path]:
        """
        ã‚¹ãƒ†ãƒƒãƒ—ã®å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾— (æ±ºã‚æ‰“ã¡ä¾å­˜é–¢ä¿‚)
        
        Args:
            step: ã‚¹ãƒ†ãƒƒãƒ—å
            
        Returns:
            å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«è¾æ›¸
        """
        input_files = {}
        
        if step == "step0":
            # Step0: å…ƒãƒ•ã‚¡ã‚¤ãƒ«ãŒå…¥åŠ›
            input_files["input_file"] = self.model_dir / f"{self.model_name}.glb"
        
        elif step == "step1":
            # Step1: å…ƒãƒ•ã‚¡ã‚¤ãƒ«ãŒå…¥åŠ›
            input_files["input_file"] = self.model_dir / f"{self.model_name}.glb"
        
        elif step == "step2":
            # Step2: Step1ã®å‡ºåŠ›ãŒå…¥åŠ›
            step1_files = self.get_expected_files("step1")
            input_files["raw_data_npz"] = step1_files["raw_data_npz"]
        
        elif step == "step3":
            # Step3: Step1ã¨Step2ã®å‡ºåŠ›ãŒå…¥åŠ›
            step1_files = self.get_expected_files("step1")
            step2_files = self.get_expected_files("step2")
            input_files["raw_data_npz"] = step1_files["raw_data_npz"]
            input_files["skeleton_fbx"] = step2_files["skeleton_fbx"]
            input_files["skeleton_npz"] = step2_files["skeleton_npz"]
        
        elif step == "step4":
            # Step4: Step2ã¨Step3ã®å‡ºåŠ›ãŒå…¥åŠ›
            step2_files = self.get_expected_files("step2")
            step3_files = self.get_expected_files("step3")
            input_files["skeleton_fbx"] = step2_files["skeleton_fbx"]
            input_files["skinned_fbx"] = step3_files["skinned_fbx"]
        
        elif step == "step5":
            # Step5: Step4ã®å‡ºåŠ›ã¨å…ƒãƒ•ã‚¡ã‚¤ãƒ«ãŒå…¥åŠ›
            step4_files = self.get_expected_files("step4")
            input_files["merged_fbx"] = step4_files["merged_fbx"]
            input_files["original_file"] = self.model_dir / f"{self.model_name}.glb"
        
        return input_files
    
    def get_expected_files(self, step: str) -> Dict[str, Path]:
        """å„ã‚¹ãƒ†ãƒƒãƒ—ã®æœŸå¾…å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«è¾æ›¸ã‚’å–å¾—"""
        step_dir = self.get_step_dir(step)
        
        if step == "step0":
            return {
                "asset_metadata_json": step_dir / f"{self.model_name}_asset_metadata.json",
                "asset_metadata_blender_json": step_dir / f"{self.model_name}_asset_metadata_blender.json",
                "textures_dir": step_dir / "textures",
                "original_file": step_dir / f"{self.model_name}.glb"
            }
        elif step == "step1":
            return {
                "raw_data_npz": step_dir / "raw_data.npz"
            }
        elif step == "step2":
            return {
                "skeleton_fbx": step_dir / f"{self.model_name}_skeleton.fbx",
                "skeleton_npz": step_dir / "predict_skeleton.npz",
                "mesh_for_skeleton": step_dir / "mesh_for_skeleton" / "raw_data.npz"  # Step2å°‚ç”¨ãƒ¡ãƒƒã‚·ãƒ¥
            }
        elif step == "step3":
            return {
                "skinned_fbx": step_dir / f"{self.model_name}_skinned.fbx",
                "skinning_npz": step_dir / "skinning_data.npz"
            }
        elif step == "step4":
            return {
                "merged_fbx": step_dir / f"{self.model_name}_merged.fbx"
            }
        elif step == "step5":
            # å‹•çš„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼å¯¾å¿œ: ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ã‚’æ¤œç´¢
            original_file = self.find_original_model_file()
            if original_file:
                original_ext = original_file.suffix.lower()
                final_output = step_dir / f"{self.model_name}_final{original_ext}"
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯FBX
                final_output = step_dir / f"{self.model_name}_final.fbx"
            
            return {
                "final_output": final_output,               # å‹•çš„å½¢å¼å¯¾å¿œ
                "final_fbx": step_dir / f"{self.model_name}_final.fbx",  # å¾Œæ–¹äº’æ›æ€§ç¶­æŒ
                "textures_dir": step_dir / f"{self.model_name}_final.fbm"
            }
        else:
            return {}
    
    def find_original_model_file(self) -> Optional[Path]:
        """
        ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        
        ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã®ãŸã‚ã«ã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ã—ã¾ã™ã€‚
        è¤‡æ•°ã®å ´æ‰€ã¨æ‹¡å¼µå­ã‚’å¯¾è±¡ã«æ¤œç´¢ã‚’è¡Œã„ã¾ã™ã€‚
        
        Returns:
            Optional[Path]: è¦‹ã¤ã‹ã£ãŸã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã€ã¾ãŸã¯ None
        """
        # æ¤œç´¢å¯¾è±¡ã®æ‹¡å¼µå­ï¼ˆã‚ˆã‚Šå…·ä½“çš„ãªé †åºã§ï¼‰
        supported_extensions = ['.glb', '.gltf', '.fbx', '.obj', '.vrm', '.dae', '.ply']
        
        # æ¤œç´¢å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆå„ªå…ˆåº¦é †ï¼‰
        search_paths = [
            # 1. Step0ã®ã‚¢ã‚»ãƒƒãƒˆä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            self.get_step_dir('step0'),
            # 2. ãƒ¢ãƒ‡ãƒ«å°‚ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            self.model_dir,
            # 3. ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç›´ä¸‹
            self.base_dir,
            # 4. dataset_inference_cleanï¼ˆä¸€æ™‚ä¿å­˜å ´æ‰€ï¼‰
            Path("/app/dataset_inference_clean"),
            # 5. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ«ãƒ¼ãƒˆ
            Path("/app")
        ]
        
        self.logger.info(f"ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢é–‹å§‹: {self.model_name}")
        
        # ãƒ¢ãƒ‡ãƒ«åã§ã®æ¤œç´¢
        for search_dir in search_paths:
            if not search_dir.exists():
                continue
                
            self.logger.debug(f"æ¤œç´¢ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {search_dir}")
            
            for ext in supported_extensions:
                # ãƒ¢ãƒ‡ãƒ«å + æ‹¡å¼µå­ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
                candidate = search_dir / f"{self.model_name}{ext}"
                if candidate.exists():
                    self.logger.info(f"[OK] ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {candidate}")
                    return candidate
        
        # ãƒ¢ãƒ‡ãƒ«åã§ã®æ¤œç´¢ãŒå¤±æ•—ã—ãŸå ´åˆã€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®3Dãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        for search_dir in search_paths:
            if not search_dir.exists():
                continue
                
            for ext in supported_extensions:
                # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®è©²å½“æ‹¡å¼µå­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
                for candidate in search_dir.glob(f"*{ext}"):
                    if candidate.is_file():
                        self.logger.info(f"[OK] 3Dãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {candidate}")
                        return candidate
        
        # æœ€å¾Œã®æ‰‹æ®µ: dataset_inference_cleanå†…ã®å…¨3Dãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
        dataset_dir = Path("/app/dataset_inference_clean")
        if dataset_dir.exists():
            for file_path in dataset_dir.iterdir():
                if file_path.is_file() and file_path.suffix.lower() in supported_extensions:
                    self.logger.info(f"[OK] datasetå†…3Dãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {file_path}")
                    return file_path
        
        self.logger.error(f"[FAIL] ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.model_name}")
        return None

    def get_original_file_extension(self) -> str:
        """
        ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ã‚’å–å¾—ï¼ˆã‚·ãƒ³ãƒ—ãƒ«å®Ÿè£…ï¼‰
        
        Returns:
            str: å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ï¼ˆä¾‹: '.glb', '.fbx', '.obj'ï¼‰
                è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ '.fbx' ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¨ã—ã¦è¿”ã™
        """
        # æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªæ–¹æ³•: ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ã—ã¦æ‹¡å¼µå­å–å¾—
        original_file = self.find_original_model_file()
        if original_file:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡æ‘˜é€šã‚Šï¼šãƒ•ã‚¡ã‚¤ãƒ«åã®æœ«å°¾ã‹ã‚‰æœ€åˆã®ãƒ”ãƒªã‚ªãƒ‰ã¾ã§
            ext = original_file.suffix.lower()
            self.logger.info(f"[OK] ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å½¢å¼å–å¾—: {ext}")
            return ext
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆFBXï¼‰
        self.logger.warning("ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ãŒç‰¹å®šã§ãã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¨ã—ã¦ .fbx ã‚’ä½¿ç”¨")
        return '.fbx'

    def get_step5_output_path_with_original_extension(self) -> Path:
        """
        Step5ã®æœ€çµ‚å‡ºåŠ›ãƒ‘ã‚¹ï¼ˆå…ƒãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’ç¶­æŒï¼‰
        
        Returns:
            Path: å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã®æœ€çµ‚å‡ºåŠ›ãƒ‘ã‚¹
        """
        original_ext = self.get_original_file_extension()
        step5_dir = self.get_step_dir('step5')
        return step5_dir / f"{self.model_name}_final{original_ext}"

    def find_file_with_dynamic_extension(self, step: str, file_type: str) -> Optional[Path]:
        """å‹•çš„æ‹¡å¼µå­å¯¾å¿œã®ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ï¼ˆStep5å°‚ç”¨ï¼‰"""
        if step == 'step5' and file_type in ['final_output', 'final_fbx']:
            # Step5ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§æ§˜ã€…ãªæ‹¡å¼µå­ã‚’æ¤œç´¢
            step_dir = self.get_step_dir(step)
            base_name = f"{self.model_name}_final"
            
            # ä¸€èˆ¬çš„ãª3Då½¢å¼ã‚’æ¤œç´¢
            supported_extensions = ['.glb', '.gltf', '.fbx', '.obj', '.dae', '.ply']
            
            for ext in supported_extensions:
                candidate_path = step_dir / f"{base_name}{ext}"
                if candidate_path.exists():
                    self.logger.info(f"[OK] å‹•çš„å½¢å¼ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {candidate_path}")
                    return candidate_path
        
        # final_outputãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯Noneã‚’è¿”ã™ï¼ˆã‚¨ãƒ©ãƒ¼ã‚’é¿ã‘ã‚‹ï¼‰
        return None
