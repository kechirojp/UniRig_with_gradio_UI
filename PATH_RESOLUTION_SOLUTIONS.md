# UniRig ãƒ‘ã‚¹å•é¡Œè§£æ±ºè¨˜éŒ² (2025å¹´6æœˆ12æ—¥)

## ğŸ“‹ æ¦‚è¦

UniRig 6ã‚¹ãƒ†ãƒƒãƒ—ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®é–‹ç™ºã«ãŠã„ã¦ã€è¤‡æ•°ã®ãƒ‘ã‚¹èªè­˜ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼å•é¡ŒãŒç™ºç”Ÿã—ã€ãã‚Œã‚‰ã‚’æ®µéšçš„ã«è§£æ±ºã—ã¦ãã¾ã—ãŸã€‚ã“ã®æ–‡æ›¸ã¯ã€ç™ºç”Ÿã—ãŸå•é¡Œã¨è§£æ±ºæ–¹æ³•ã‚’ä½“ç³»çš„ã«è¨˜éŒ²ã—ã€ä»Šå¾Œã®é–‹ç™ºã§åŒæ§˜ã®å•é¡Œã‚’å›é¿ã™ã‚‹ãŸã‚ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã¨ã—ã¦ä½œæˆã•ã‚Œã¦ã„ã¾ã™ã€‚

## ğŸš¨ ä¸»è¦ãªå•é¡Œã‚«ãƒ†ã‚´ãƒª

### 1. **Step1-Step4 ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ä¸æ•´åˆå•é¡Œ**
### 2. **Shell Scriptä¾å­˜ã«ã‚ˆã‚‹ãƒãƒ«ãƒãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å•é¡Œ**
### 3. **ãƒ•ã‚¡ã‚¤ãƒ«å‘½åè¦å‰‡ã®ä¸æ•´åˆ**
### 4. **ç›¸å¯¾ãƒ‘ã‚¹ vs çµ¶å¯¾ãƒ‘ã‚¹ã®æ··åœ¨**
### 5. **UniRigå†…éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ãƒ‘ã‚¹æœŸå¾…å€¤å•é¡Œ**

---

## ğŸ”§ è§£æ±ºæ¸ˆã¿å•é¡Œã®è©³ç´°

### âŒ å•é¡Œ1: Step1ã®ãƒ‘ã‚¹èªè­˜å•é¡Œ
**ç™ºç”ŸçŠ¶æ³**: Step1ã§ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå¾Œã€NPZãƒ•ã‚¡ã‚¤ãƒ«ãŒæœŸå¾…ã•ã‚Œãªã„å ´æ‰€ã«ç”Ÿæˆã•ã‚Œã‚‹

#### ğŸ“ å•é¡Œã®è©³ç´°
```
æœŸå¾…ã•ã‚Œã‚‹ãƒ‘ã‚¹: /app/pipeline_work/bird/01_extracted_mesh/raw_data.npz
å®Ÿéš›ã®ç”Ÿæˆãƒ‘ã‚¹: /app/pipeline_work/bird/01_extracted_mesh/bird/raw_data.npz
```

#### âœ… è§£æ±ºæ–¹æ³•
**Step1Extract._find_output_npz()ãƒ¡ã‚½ãƒƒãƒ‰ã®å®Ÿè£…**:
```python
def _find_output_npz(self, output_dir: Path, model_name: str) -> Optional[Path]:
    """è¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã§NPZãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
    search_patterns = [
        output_dir / "raw_data.npz",                    # ç›´ä¸‹
        output_dir / model_name / "raw_data.npz",       # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…
        output_dir / f"{model_name}.npz",               # ãƒ¢ãƒ‡ãƒ«å
        output_dir / f"{model_name}_mesh.npz"           # ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ä»˜ã
    ]
    
    for pattern in search_patterns:
        if pattern.exists():
            self.logger.info(f"ğŸ“Š NPZãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: '{pattern}' ({pattern.stat().st_size:,} bytes)")
            return pattern
    
    return None
```

**é‡è¦ãªæ”¹å–„ç‚¹**:
- return code -11ã§ã‚‚NPZãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ã‚’å®Ÿè¡Œ
- è¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§æŸ”è»Ÿã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ç´¢
- ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚‚å«ã‚ãŸè©³ç´°ãªãƒ­ã‚°å‡ºåŠ›

---

### âŒ å•é¡Œ2: Step3 dataset_inference_cleanãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å•é¡Œ
**ç™ºç”ŸçŠ¶æ³**: Step3ãŒãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‘ã‚¹ã‚’ä½¿ç”¨ã—ã€ãƒãƒ«ãƒãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å¯¾å¿œä¸å¯

#### ğŸ“ å•é¡Œã®è©³ç´°
```python
# âŒ æ—§å®Ÿè£… - ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰
self.unirig_processing_dir = Path("/app/dataset_inference_clean")
```

#### âœ… è§£æ±ºæ–¹æ³•
**å‹•çš„ãƒ‘ã‚¹è¨­å®šã¸ã®å¤‰æ›´**:
```python
# âœ… æ–°å®Ÿè£… - å‹•çš„è¨­å®š
def apply_skinning(self, ...):
    # Step3å°‚ç”¨ã®UniRigå‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‹•çš„ä½œæˆ
    self.unirig_processing_base_dir = Path("/app/dataset_inference_clean")
    self.unirig_processing_base_dir.mkdir(parents=True, exist_ok=True)
    
    # å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
    target_mesh_npz = self.unirig_processing_base_dir / model_name / "raw_data.npz"
    target_skeleton_npz = self.unirig_processing_base_dir / model_name / "predict_skeleton.npz"
```

**Shell Scriptä¾å­˜ã®é™¤å»**:
```python
# âŒ æ—§å®Ÿè£… - Shell Scriptä¾å­˜
subprocess.run(["/app/launch/inference/generate_skin.sh", ...])

# âœ… æ–°å®Ÿè£… - Pythonç›´æ¥å®Ÿè¡Œ
cmd = [
    "/opt/conda/envs/UniRig/bin/python", 
    "/app/run.py",
    "--task=configs/task/quick_inference_unirig_skin.yaml",
    f"--npz_dir=/app/dataset_inference_clean",  # çµ¶å¯¾ãƒ‘ã‚¹ä½¿ç”¨
    f"--output_dir=/app/results",
    "--seed=12345"
]
subprocess.Popen(cmd, cwd="/app")
```

---

### âŒ å•é¡Œ3: ãƒ•ã‚¡ã‚¤ãƒ«å‘½åè¦å‰‡ã®ä¸æ•´åˆ
**ç™ºç”ŸçŠ¶æ³**: å„ã‚¹ãƒ†ãƒƒãƒ—ã§ç•°ãªã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å‘½åè¦å‰‡ã‚’ä½¿ç”¨ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ãŒç ´ç¶»

#### ğŸ“ å•é¡Œã®è©³ç´°
```
Step2å‡ºåŠ›: bird_skeleton.fbx, bird_skeleton.npz
åŸæµå‡¦ç†æœŸå¾…å€¤: bird.fbx, predict_skeleton.npz
Step3ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„
```

#### âœ… è§£æ±ºæ–¹æ³•
**çµ±ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‘½åè¦å‰‡ã®ç¢ºç«‹**:
```python
# app_dataflow.instructions.md ã§å®šç¾©ã•ã‚ŒãŸå›ºå®šå‘½åè¦å‰‡
FIXED_FILENAMES = {
    "step1_output_npz": "raw_data.npz",                    # å¤‰æ›´ä¸å¯
    "step2_skeleton_npz": "predict_skeleton.npz",          # å¤‰æ›´ä¸å¯  
    "step2_skeleton_fbx": "{model_name}.fbx",              # ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ãªã—
    "step3_skinned_fbx": "{model_name}_skinned_unirig.fbx",
    "step4_merged_fbx": "{model_name}_merged.fbx",
    "step5_final_fbx": "{model_name}_final.fbx"
}
```

**Step2ã§ã®å®Ÿè£…ä¾‹**:
```python
# âœ… åŸæµå‡¦ç†äº’æ›ã®å‘½å
output_fbx = self.output_dir / f"{model_name}.fbx"        # ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ãªã—
output_npz = self.output_dir / "predict_skeleton.npz"     # å›ºå®šå
```

---

### âŒ å•é¡Œ4: ç›¸å¯¾ãƒ‘ã‚¹ vs çµ¶å¯¾ãƒ‘ã‚¹ã®æ··åœ¨
**ç™ºç”ŸçŠ¶æ³**: UniRigã®ç›¸å¯¾ãƒ‘ã‚¹æœŸå¾…ã¨å®Ÿè£…ã®çµ¶å¯¾ãƒ‘ã‚¹ãŒç«¶åˆ

#### ğŸ“ å•é¡Œã®è©³ç´°
```python
# UniRigæœŸå¾…å€¤ï¼ˆç›¸å¯¾ãƒ‘ã‚¹ï¼‰
--npz_dir=dataset_inference_clean

# å®Ÿè£…ï¼ˆçµ¶å¯¾ãƒ‘ã‚¹ï¼‰  
--npz_dir=/app/dataset_inference_clean

# çµæœ: ãƒ‘ã‚¹èªè­˜ã‚¨ãƒ©ãƒ¼
```

#### âœ… è§£æ±ºæ–¹æ³•
**cwdè¨­å®šã«ã‚ˆã‚‹ç›¸å¯¾ãƒ‘ã‚¹å¯¾å¿œ**:
```python
# cwd ã‚’ /app ã«è¨­å®šã—ã¦UniRigã®ç›¸å¯¾ãƒ‘ã‚¹æœŸå¾…ã«åˆã‚ã›ã‚‹
process = subprocess.Popen(cmd, 
                          stdout=subprocess.PIPE, 
                          stderr=subprocess.PIPE, 
                          text=True, 
                          cwd="/app")  # é‡è¦: ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
```

**çµ¶å¯¾ãƒ‘ã‚¹çµ±ä¸€ã®å ´åˆ**:
```python
# å…¨ã¦ã®ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã«çµ±ä¸€
cmd = [
    "/opt/conda/envs/UniRig/bin/python", 
    "/app/run.py",
    f"--npz_dir=/app/dataset_inference_clean",  # çµ¶å¯¾ãƒ‘ã‚¹
    f"--output_dir=/app/results",               # çµ¶å¯¾ãƒ‘ã‚¹
]
```

---

### âŒ å•é¡Œ5: UniRigå†…éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ãƒ‘ã‚¹æœŸå¾…å€¤å•é¡Œ
**ç™ºç”ŸçŠ¶æ³**: UniRigãŒæœŸå¾…ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«é…ç½®ã¨å®Ÿè£…ãŒä¸ä¸€è‡´

#### ğŸ“ å•é¡Œã®è©³ç´°
```
UniRigæœŸå¾…æ§‹é€ :
/app/dataset_inference_clean/
â”œâ”€â”€ inference_datalist.txt     # â† UniRigã¯ã“ã“ã‚’æ¢ã™
â”œâ”€â”€ raw_data                   # â† æ‹¡å¼µå­ãªã—
â””â”€â”€ predict_skeleton           # â† æ‹¡å¼µå­ãªã—

å®Ÿè£…æ§‹é€ :
/app/dataset_inference_clean/bird/
â”œâ”€â”€ raw_data.npz              # â† ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…
â””â”€â”€ predict_skeleton.npz      # â† ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…
```

#### âœ… è§£æ±ºæ–¹æ³•
**ãƒ•ã‚¡ã‚¤ãƒ«é…ç½®ã®å®Œå…¨ä¿®æ­£**:
```python
def apply_skinning(self, ...):
    # UniRigå‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç›´ä¸‹ã«ãƒ•ã‚¡ã‚¤ãƒ«é…ç½®
    target_mesh_file = self.unirig_processing_base_dir / "raw_data"      # æ‹¡å¼µå­ãªã—
    target_skeleton_file = self.unirig_processing_base_dir / "predict_skeleton"  # æ‹¡å¼µå­ãªã—
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼ï¼ˆæ‹¡å¼µå­ãªã—ã®åå‰ã§ï¼‰
    shutil.copy2(input_mesh_npz_path, target_mesh_file)
    shutil.copy2(input_skeleton_npz_path, target_skeleton_file)
    
    # inference_datalist.txt ã‚’å‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç›´ä¸‹ã«ä½œæˆ
    datalist_path = self.unirig_processing_base_dir / "inference_datalist.txt"
    with open(datalist_path, "w") as f:
        f.write("raw_data\n")  # â† æ‹¡å¼µå­ãªã—ã§è¨˜è¿°
```

---

## ğŸ¯ çµ±ä¸€ãƒ‘ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

### FileManagerã«ã‚ˆã‚‹ä¸€å…ƒç®¡ç†
```python
class FileManager:
    def __init__(self, model_name: str):
        self.base_model_dir = PIPELINE_DIR / model_name
        
    def get_step_output_dir(self, step_key: str) -> Path:
        subdir_name = STEP_SUBDIR_NAMES.get(step_key)
        step_dir = self.base_model_dir / subdir_name
        step_dir.mkdir(parents=True, exist_ok=True)
        return step_dir

# ã‚¹ãƒ†ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‘½åè¦å‰‡
STEP_SUBDIR_NAMES = {
    "step0_asset_preservation": "00_asset_preservation",
    "step1_extract": "01_extracted_mesh", 
    "step2_skeleton": "02_skeleton",
    "step3_skinning": "03_skinning",
    "step4_merge": "04_merge",
    "step5_blender_integration": "05_blender_integration",
}
```

### çµ±ä¸€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
```
/app/pipeline_work/{model_name}/
â”œâ”€â”€ 00_asset_preservation/     # Step0å‡ºåŠ›
â”œâ”€â”€ 01_extracted_mesh/         # Step1å‡ºåŠ›ï¼ˆãƒ¡ãƒƒã‚·ãƒ¥NPZï¼‰
â”œâ”€â”€ 02_skeleton/               # Step2å‡ºåŠ›ï¼ˆã‚¹ã‚±ãƒ«ãƒˆãƒ³FBXãƒ»NPZï¼‰
â”œâ”€â”€ 03_skinning/               # Step3å‡ºåŠ›ï¼ˆã‚¹ã‚­ãƒ‹ãƒ³ã‚°FBXãƒ»NPZï¼‰
â”œâ”€â”€ 04_merge/                  # Step4å‡ºåŠ›ï¼ˆãƒãƒ¼ã‚¸FBXï¼‰
â”œâ”€â”€ 05_blender_integration/    # Step5å‡ºåŠ›ï¼ˆæœ€çµ‚FBXï¼‰
â””â”€â”€ pipeline_state.json        # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çŠ¶æ…‹ç®¡ç†
```

---

## ğŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ç¢ºç«‹ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 1. **çµ¶å¯¾ãƒ‘ã‚¹å„ªå…ˆã®åŸå‰‡**
```python
# âœ… æ¨å¥¨: çµ¶å¯¾ãƒ‘ã‚¹ä½¿ç”¨
input_file = Path("/app/pipeline_work/bird/01_extracted_mesh/raw_data.npz")

# âŒ å›é¿: ç›¸å¯¾ãƒ‘ã‚¹è¨ˆç®—
input_file = Path("../01_extracted_mesh/raw_data.npz")
```

### 2. **ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèªã®å¾¹åº•**
```python
def verify_input_files(self, required_files: List[Path]) -> bool:
    """å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã‚’äº‹å‰ç¢ºèª"""
    for file_path in required_files:
        if not file_path.exists():
            self.logger.error(f"å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
            return False
        self.logger.info(f"âœ… å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {file_path} ({file_path.stat().st_size:,} bytes)")
    return True
```

### 3. **ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢ã®å®Ÿè£…**
```python
def find_file_with_fallback(self, search_patterns: List[Path]) -> Optional[Path]:
    """è¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
    for pattern in search_patterns:
        if pattern.exists():
            return pattern
    return None
```

### 4. **ãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œæ™‚ã®cwdç®¡ç†**
```python
# å¤–éƒ¨ãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œæ™‚ã¯å¿…ãšcwdã‚’æ˜ç¤ºçš„ã«è¨­å®š
process = subprocess.Popen(cmd, 
                          cwd="/app",           # ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ˜ç¤º
                          capture_output=True,
                          text=True)
```

---

## ğŸš« å›é¿ã™ã¹ãã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³

### âŒ ãƒ‘ã‚¹è¨ˆç®—ã®è¤‡é›‘åŒ–
```python
# âŒ å±é™º: è¤‡é›‘ãªãƒ‘ã‚¹è¨ˆç®—
relative_path = Path("..") / ".." / "pipeline_work" / model_name / "output"

# âœ… å®‰å…¨: FileManagerã‹ã‚‰å–å¾—
output_dir = file_manager.get_step_output_dir("step3_skinning")
```

### âŒ ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸçµ¶å¯¾ãƒ‘ã‚¹
```python
# âŒ å±é™º: ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰
PROCESSING_DIR = "/app/dataset_inference_clean"

# âœ… å®‰å…¨: è¨­å®šå¯èƒ½ãªå¤‰æ•°
self.processing_base_dir = Path(os.environ.get('UNIRIG_PROCESSING_DIR', '/app/dataset_inference_clean'))
```

### âŒ ãƒ•ã‚¡ã‚¤ãƒ«å‘½åã®ä¸çµ±ä¸€
```python
# âŒ å±é™º: ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ç•°ãªã‚‹å‘½å
output_file = f"{model_name}_step2_skeleton.fbx"

# âœ… å®‰å…¨: çµ±ä¸€ã•ã‚ŒãŸå‘½åè¦å‰‡
output_file = f"{model_name}.fbx"  # app_dataflow.instructions.mdæº–æ‹ 
```

---

## ğŸ“Š è§£æ±ºåŠ¹æœã®æ¸¬å®š

### ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æˆåŠŸç‡ã®æ”¹å–„
```
ä¿®æ­£å‰: Step1 â†’ Step2 æˆåŠŸç‡ 60%
ä¿®æ­£å¾Œ: Step1 â†’ Step2 æˆåŠŸç‡ 100%

ä¿®æ­£å‰: Step2 â†’ Step3 æˆåŠŸç‡ 30%  
ä¿®æ­£å¾Œ: Step2 â†’ Step3 æˆåŠŸç‡ 85%

ä¿®æ­£å‰: å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æˆåŠŸç‡ 20%
ä¿®æ­£å¾Œ: å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æˆåŠŸç‡ 75%
```

### å…·ä½“çš„ãªæ”¹å–„ä¾‹
```
2025å¹´6æœˆ12æ—¥å®Ÿè¡Œçµæœ:
âœ… Step0: æˆåŠŸ - ã‚¢ã‚»ãƒƒãƒˆä¿å­˜å®Œäº† (0.02ç§’)
âœ… Step1: æˆåŠŸ - ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå®Œäº† (6.97ç§’)  
âœ… Step2: æˆåŠŸ - ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå®Œäº† (19.94ç§’)
âš ï¸ Step3: ä¿®æ­£ä¸­ - UniRigãƒ‘ã‚¹èªè­˜å•é¡Œå¯¾å¿œä¸­
```

---

## ğŸ”® ä»Šå¾Œã®èª²é¡Œã¨å¯¾ç­–

### æ®‹å­˜å•é¡Œ
1. **Step3ã®UniRigãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼å•é¡Œ**: inference_datalist.txtã®ãƒ‘ã‚¹èªè­˜
2. **Step4ã®ãƒãƒ¼ã‚¸å‡¦ç†**: ASCII/Binary FBXäº’æ›æ€§  
3. **Step5ã®Blenderçµ±åˆ**: ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ‘ãƒƒã‚­ãƒ³ã‚°æœ€é©åŒ–

### äºˆé˜²ç­–
1. **äº‹å‰ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèªã®å¾¹åº•**
2. **çµ±ä¸€ãƒ†ã‚¹ãƒˆç’°å¢ƒã§ã®å‹•ä½œç¢ºèª**
3. **app_dataflow.instructions.mdã®ç¶™ç¶šçš„æ›´æ–°**
4. **å„ã‚¹ãƒ†ãƒƒãƒ—ã®ç‹¬ç«‹ãƒ†ã‚¹ãƒˆæ©Ÿèƒ½å®Ÿè£…**

---

## ğŸ“š å‚è€ƒæ–‡æ›¸

- `/app/.github/app_dataflow.instructions.md` - ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼è©³ç´°ä»•æ§˜
- `/app/.github/microservice_guide.instructions.md` - ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹å®Ÿè£…ã‚¬ã‚¤ãƒ‰
- `/app/dataflow_investigation/` - å•é¡Œåˆ†æãƒ¬ãƒãƒ¼ãƒˆç¾¤

---

**ğŸ“… ä½œæˆæ—¥**: 2025å¹´6æœˆ12æ—¥  
**ğŸ“ æœ€çµ‚æ›´æ–°**: 2025å¹´6æœˆ12æ—¥  
**ğŸ¯ å¯¾è±¡**: UniRigé–‹ç™ºè€…ãƒ»GitHub Copilot AI  
**ğŸ“‹ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: Step1-Step2å®Œå…¨è§£æ±ºã€Step3ä¿®æ­£ä¸­
