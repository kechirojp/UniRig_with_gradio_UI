# ğŸ“‹ åŸæµå‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ .txtãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ãƒ»å¾Œç¶šæ´»ç”¨ ãƒãƒ¼ãƒ¡ã‚¤ãƒ‰å›³

## ğŸ” åŸæµå‡¦ç†ã«ãŠã‘ã‚‹.txtãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆãƒ»æ´»ç”¨ãƒ•ãƒ­ãƒ¼

```mermaid
graph TB
    %% ========== Step 1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º ==========
    INPUT["ğŸ¯ å…¥åŠ›3Dãƒ¢ãƒ‡ãƒ«<br>giraffe.glb"]
    
    %% extract.shå®Ÿè¡Œ
    EXTRACT["âš™ï¸ launch/inference/extract.sh<br>python -m src.data.extract<br>--config configs/data/quick_inference.yaml<br>--target_count 50000"]
    
    %% Step1å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
    RAW_NPZ["ğŸ“¦ raw_data.npz<br>ãƒ¡ãƒƒã‚·ãƒ¥+ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿"]
    DATALIST_TXT["ğŸ“„ inference_datalist.txt<br>NPZãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ä¸€è¦§"]
    
    %% ========== Step 2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ ==========
    %% generate_skeleton.shå®Ÿè¡Œ  
    SKELETON_EXTRACT["âš™ï¸ ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå†å®Ÿè¡Œ<br>python -m src.data.extract<br>raw_data.npzæº–å‚™"]
    
    SKELETON_GEN["âš™ï¸ python run.py<br>--task configs/task/skeleton<br>--npz_dir tmp"]
    
    %% Step2å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
    SKELETON_NPZ["ğŸ“¦ predict_skeleton.npz<br>53ãƒœãƒ¼ãƒ³ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿"]
    SKELETON_FBX["ğŸ“¦ giraffe_skeleton.fbx<br>3Dã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ¢ãƒ‡ãƒ«"]
    SKELETON_PRED_TXT["ğŸ“„ skeleton_pred.txt<br>ã‚¹ã‚±ãƒ«ãƒˆãƒ³åº§æ¨™ãƒ»éšå±¤æƒ…å ±<br>53ã‚¸ãƒ§ã‚¤ãƒ³ãƒˆè©³ç´°ãƒ‡ãƒ¼ã‚¿"]
    BONES_TXT["ğŸ“„ model_name_bones.txt<br>ãƒœãƒ¼ãƒ³éšå±¤ãƒ†ã‚­ã‚¹ãƒˆ<br>è¦ªå­é–¢ä¿‚ãƒ»åå‰ä¸€è¦§"]
    
    %% ========== Step 3: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨ ==========
    %% generate_skin.shå®Ÿè¡Œ
    SKIN_EXTRACT["âš™ï¸ ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå†å®Ÿè¡Œ<br>bash launch/inference/extract.sh<br>ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿æº–å‚™"]
    
    SKIN_GEN["âš™ï¸ python run.py<br>--task configs/task/unirig_skin<br>--npz_dir dataset_inference_clean"]
    
    %% Step3å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
    SKINNED_FBX["ğŸ“¦ giraffe_skin.fbx<br>ã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«"]
    WEIGHTS_TXT["ğŸ“„ model_name_weights.txt<br>é ‚ç‚¹ã‚¦ã‚§ã‚¤ãƒˆæƒ…å ±<br>7702é ‚ç‚¹Ã—42ãƒœãƒ¼ãƒ³"]
    SKINNING_NPZ["ğŸ“¦ predict_skin.npz<br>ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿"]
    
    %% ========== Step 4: ãƒãƒ¼ã‚¸å‡¦ç† ==========
    MERGE["âš™ï¸ launch/inference/merge.sh<br>python -m src.inference.merge<br>--source skeleton.fbx<br>--target original.glb"]
    
    %% Step4å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
    FINAL_FBX["ğŸ“¦ giraffe_rigged.glb<br>æœ€çµ‚ãƒªã‚®ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«"]
    
    %% ========== ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼æ¥ç¶š ==========
    INPUT --> EXTRACT
    EXTRACT --> RAW_NPZ
    EXTRACT --> DATALIST_TXT
    
    %% Step2ãƒ•ãƒ­ãƒ¼
    RAW_NPZ --> SKELETON_EXTRACT
    SKELETON_EXTRACT --> SKELETON_GEN
    SKELETON_GEN --> SKELETON_NPZ
    SKELETON_GEN --> SKELETON_FBX
    SKELETON_GEN --> SKELETON_PRED_TXT
    SKELETON_GEN --> BONES_TXT
    
    %% Step3ãƒ•ãƒ­ãƒ¼ï¼ˆStep2å‡ºåŠ›ã‚’æ´»ç”¨ï¼‰
    RAW_NPZ --> SKIN_EXTRACT
    SKELETON_NPZ --> SKIN_GEN
    SKIN_EXTRACT --> SKIN_GEN
    SKIN_GEN --> SKINNED_FBX
    SKIN_GEN --> WEIGHTS_TXT
    SKIN_GEN --> SKINNING_NPZ
    
    %% Step4ãƒ•ãƒ­ãƒ¼
    SKELETON_FBX --> MERGE
    INPUT --> MERGE
    MERGE --> FINAL_FBX
    
    %% ========== .txtãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°åˆ†æ ==========
    classDef txtFile fill:#ffe6cc,stroke:#ff9933,color:#000
    classDef npzFile fill:#e6f3ff,stroke:#3399ff,color:#000
    classDef fbxFile fill:#e6ffe6,stroke:#66cc66,color:#000
    classDef process fill:#f0f0f0,stroke:#333,color:#000
    
    class DATALIST_TXT,SKELETON_PRED_TXT,BONES_TXT,WEIGHTS_TXT txtFile
    class RAW_NPZ,SKELETON_NPZ,SKINNING_NPZ npzFile
    class SKELETON_FBX,SKINNED_FBX,FINAL_FBX fbxFile
    class EXTRACT,SKELETON_EXTRACT,SKELETON_GEN,SKIN_EXTRACT,SKIN_GEN,MERGE process
```

## ğŸ“„ .txtãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°å†…å®¹ãƒ»æ´»ç”¨æ–¹æ³•

### ğŸ”¸ Step 1 å‡ºåŠ›: `inference_datalist.txt`
```mermaid
graph LR
    A["ğŸ“„ inference_datalist.txt"] --> B["ğŸ“‹ å†…å®¹: NPZãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ä¸€è¦§<br>/app/results/raw_data.npz"]
    B --> C["ğŸ¯ ç”¨é€”: å¾Œç¶šã‚¹ãƒ†ãƒƒãƒ—ã§ã®<br>NPZãƒ•ã‚¡ã‚¤ãƒ«å ´æ‰€ç‰¹å®š"]
    C --> D["âš™ï¸ æ´»ç”¨: generate_skeleton.sh<br>generate_skin.sh ãŒå‚ç…§"]
```

**å®Ÿéš›ã®å†…å®¹ä¾‹:**
```txt
/app/pipeline_work_fixed/01_extract/raw_data.npz
```

### ğŸ”¸ Step 2 å‡ºåŠ›: `skeleton_pred.txt`
```mermaid
graph LR
    A["ğŸ“„ skeleton_pred.txt"] --> B["ğŸ“‹ å†…å®¹: 53ã‚¸ãƒ§ã‚¤ãƒ³ãƒˆåº§æ¨™<br>X Y Z è¦ªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ åå‰"]
    B --> C["ğŸ¯ ç”¨é€”: ã‚¹ã‚±ãƒ«ãƒˆãƒ³æ§‹é€ ã®<br>è©³ç´°æƒ…å ±ä¿å­˜"]
    C --> D["âš™ï¸ æ´»ç”¨: ãƒ‡ãƒãƒƒã‚°ãƒ»æ¤œè¨¼<br>å¤–éƒ¨ãƒ„ãƒ¼ãƒ«é€£æº"]
```

**å®Ÿéš›ã®å†…å®¹ä¾‹:**
```txt
# Skeleton Prediction Data
# Number of joints: 53
# Class: articulationxl
# Format: joint_index x y z parent_index name
0 0.003906 -0.027344 0.035156 -1 bone_0
1 0.003906 -0.066406 0.050781 0 bone_1
2 0.003906 -0.152344 0.074219 1 bone_2
...ï¼ˆ53ãƒœãƒ¼ãƒ³åˆ†ï¼‰
```

### ğŸ”¸ Step 2 å‡ºåŠ›: `{model_name}_bones.txt`
```mermaid
graph LR
    A["ğŸ“„ giraffe_bones.txt"] --> B["ğŸ“‹ å†…å®¹: ãƒœãƒ¼ãƒ³éšå±¤æƒ…å ±<br>è¦ªå­é–¢ä¿‚ãƒ»åå‰ä¸€è¦§"]
    B --> C["ğŸ¯ ç”¨é€”: ãƒœãƒ¼ãƒ³æ§‹é€ ã®<br>å¯èª­å½¢å¼ã§ã®ä¿å­˜"]
    C --> D["âš™ï¸ æ´»ç”¨: ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³åˆ¶ä½œ<br>ãƒªã‚®ãƒ³ã‚°æ¤œè¨¼"]
```

**å®Ÿéš›ã®å†…å®¹ä¾‹:**
```txt
# Bone Hierarchy for giraffe
# Total bones: 53
Bone  0: bone_0 (root)
Bone  1: bone_1 (parent: bone_0)
Bone  2: bone_2 (parent: bone_1)
...ï¼ˆ53ãƒœãƒ¼ãƒ³åˆ†ã®éšå±¤æƒ…å ±ï¼‰
```

### ğŸ”¸ Step 3 å‡ºåŠ›: `{model_name}_weights.txt`
```mermaid
graph LR
    A["ğŸ“„ giraffe_weights.txt"] --> B["ğŸ“‹ å†…å®¹: é ‚ç‚¹ã‚¦ã‚§ã‚¤ãƒˆæƒ…å ±<br>7702é ‚ç‚¹Ã—æœ€å¤§4ãƒœãƒ¼ãƒ³å½±éŸ¿"]
    B --> C["ğŸ¯ ç”¨é€”: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆ<br>è©³ç´°ãƒ‡ãƒ¼ã‚¿ä¿å­˜"]
    C --> D["âš™ï¸ æ´»ç”¨: ã‚¦ã‚§ã‚¤ãƒˆãƒšã‚¤ãƒ³ãƒˆèª¿æ•´<br>ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å“è³ªæ¤œè¨¼"]
```

**å®Ÿéš›ã®å†…å®¹ä¾‹:**
```txt
# Skinning Weight Information
# Vertex count: 7702
# Bone count: 42
# Max influences per vertex: 4
vertex_0000: bone_19=0.261 bone_21=0.252 bone_40=0.250 bone_33=0.237
vertex_0001: bone_36=0.255 bone_00=0.254 bone_17=0.253 bone_18=0.237
...ï¼ˆ7702é ‚ç‚¹åˆ†ã®ã‚¦ã‚§ã‚¤ãƒˆæƒ…å ±ï¼‰
```

## ğŸ”„ .txtãƒ•ã‚¡ã‚¤ãƒ«ã®å¾Œç¶šã‚¹ãƒ†ãƒƒãƒ—ã§ã®æ´»ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³

```mermaid
flowchart TD
    %% .txtãƒ•ã‚¡ã‚¤ãƒ«æ´»ç”¨ãƒ•ãƒ­ãƒ¼
    subgraph TXT_USAGE[".txtãƒ•ã‚¡ã‚¤ãƒ«æ´»ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³"]
        direction TB
        
        %% å†…éƒ¨æ´»ç”¨
        subgraph INTERNAL["ğŸ”§ å†…éƒ¨å‡¦ç†æ´»ç”¨"]
            DATALIST_READ["ğŸ“„ datalist.txtèª­ã¿è¾¼ã¿<br>â†’ NPZãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹å–å¾—"]
            SKELETON_DEBUG["ğŸ“„ skeleton_pred.txt<br>â†’ ãƒ‡ãƒãƒƒã‚°ãƒ»æ¤œè¨¼"]
            WEIGHTS_VERIFY["ğŸ“„ weights.txt<br>â†’ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å“è³ªæ¤œè¨¼"]
        end
        
        %% å¤–éƒ¨ãƒ„ãƒ¼ãƒ«é€£æº
        subgraph EXTERNAL["ğŸŒ å¤–éƒ¨ãƒ„ãƒ¼ãƒ«é€£æº"]
            BLENDER_IMPORT["ğŸ“„ bones.txt<br>â†’ Blenderæ‰‹å‹•ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"]
            MAYA_EXPORT["ğŸ“„ skeleton_pred.txt<br>â†’ Maya/3ds Maxé€£æº"]
            CUSTOM_TOOLS["ğŸ“„ weights.txt<br>â†’ ã‚«ã‚¹ã‚¿ãƒ ãƒ„ãƒ¼ãƒ«é–‹ç™º"]
        end
        
        %% å“è³ªä¿è¨¼
        subgraph QA["âœ… å“è³ªä¿è¨¼"]
            BONE_COUNT["ğŸ“„ bones.txt<br>â†’ ãƒœãƒ¼ãƒ³æ•°æ¤œè¨¼"]
            WEIGHT_ANALYSIS["ğŸ“„ weights.txt<br>â†’ ã‚¦ã‚§ã‚¤ãƒˆåˆ†å¸ƒåˆ†æ"]
            HIERARCHY_CHECK["ğŸ“„ skeleton_pred.txt<br>â†’ éšå±¤æ§‹é€ ãƒã‚§ãƒƒã‚¯"]
        end
    end
    
    %% æ¥ç¶šé–¢ä¿‚
    DATALIST_READ --> SKELETON_DEBUG
    SKELETON_DEBUG --> WEIGHTS_VERIFY
    
    BLENDER_IMPORT --> BONE_COUNT
    MAYA_EXPORT --> HIERARCHY_CHECK
    CUSTOM_TOOLS --> WEIGHT_ANALYSIS
```

## ğŸ“Š .txtãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã‚¿ã‚¤ãƒŸãƒ³ã‚°ãƒ»å®¹é‡ãƒ»ç”¨é€”ä¸€è¦§

| ã‚¹ãƒ†ãƒƒãƒ— | ãƒ•ã‚¡ã‚¤ãƒ«å | ç”Ÿæˆã‚¿ã‚¤ãƒŸãƒ³ã‚° | å…¸å‹çš„ã‚µã‚¤ã‚º | ä¸»è¦ç”¨é€” |
|---------|------------|---------------|-------------|----------|
| **Step 1** | `inference_datalist.txt` | extract.shå®Œäº†æ™‚ | ~100B | NPZãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ç®¡ç† |
| **Step 2** | `skeleton_pred.txt` | ARWriter.write_on_batch_end() | ~5KB | ã‚¹ã‚±ãƒ«ãƒˆãƒ³åº§æ¨™è©³ç´° |
| **Step 2** | `{model_name}_bones.txt` | ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå®Œäº†æ™‚ | ~2KB | ãƒœãƒ¼ãƒ³éšå±¤æƒ…å ± |
| **Step 3** | `{model_name}_weights.txt` | SkinWriter.write_on_batch_end() | ~500KB | é ‚ç‚¹ã‚¦ã‚§ã‚¤ãƒˆè©³ç´° |

## ğŸ¯ é‡è¦ãªæŠ€è¡“çš„æ´å¯Ÿ

### 1. **ãƒ•ã‚¡ã‚¤ãƒ«é–“ä¾å­˜é–¢ä¿‚**
- `datalist.txt` â†’ å…¨å¾Œç¶šã‚¹ãƒ†ãƒƒãƒ—ã§ã®NPZãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹
- `skeleton_pred.txt` â†’ å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã¨ã®ãƒ‡ãƒ¼ã‚¿äº¤æ›
- `weights.txt` â†’ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å“è³ªã®è©³ç´°æ¤œè¨¼

### 2. **å‘½åè¦å‰‡ã®ä¸€è²«æ€§**
```bash
# å›ºå®šå‘½åãƒ‘ã‚¿ãƒ¼ãƒ³
inference_datalist.txt          # å¸¸ã«å›ºå®šå
skeleton_pred.txt              # å¸¸ã«å›ºå®šå  
{model_name}_bones.txt         # ãƒ¢ãƒ‡ãƒ«åãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹
{model_name}_weights.txt       # ãƒ¢ãƒ‡ãƒ«åãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹
```

### 3. **å¾Œç¶šã‚¹ãƒ†ãƒƒãƒ—ã§ã®å®Ÿéš›ã®å‚ç…§æ–¹æ³•**
```python
# datalist.txt ã®æ´»ç”¨ä¾‹
with open("inference_datalist.txt", "r") as f:
    npz_path = f.read().strip()
    
# skeleton_pred.txt ã®æ´»ç”¨ä¾‹
skeleton_data = []
with open("skeleton_pred.txt", "r") as f:
    for line in f:
        if line.startswith("#"): continue
        joint_data = line.strip().split()
        skeleton_data.append({
            "index": int(joint_data[0]),
            "position": [float(joint_data[1]), float(joint_data[2]), float(joint_data[3])],
            "parent": int(joint_data[4]) if joint_data[4] != "-1" else None,
            "name": joint_data[5]
        })

# weights.txt ã®æ´»ç”¨ä¾‹  
vertex_weights = {}
with open(f"{model_name}_weights.txt", "r") as f:
    for line in f:
        if line.startswith("vertex_"):
            vertex_id = line.split(":")[0]
            weights = line.split(":")[1].strip().split()
            vertex_weights[vertex_id] = {
                bone.split("=")[0]: float(bone.split("=")[1]) 
                for bone in weights
            }
```

---

**ğŸ“ æ³¨è¨˜**: ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯`README_ORIGINAL.md`ãŠã‚ˆã³åŸæµå‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆ`launch/inference/*.sh`ï¼‰ã®è©³ç´°åˆ†æã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚å®Ÿéš›ã®.txtãƒ•ã‚¡ã‚¤ãƒ«ã‚µãƒ³ãƒ—ãƒ«ã¯`pipeline_work_fixed/`é…ä¸‹ã§ç¢ºèªæ¸ˆã¿ã§ã™ã€‚
