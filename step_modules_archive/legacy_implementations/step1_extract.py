"""
Step 1 Module - ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º
ç‹¬ç«‹ã—ãŸå®Ÿè¡Œæ©Ÿèƒ½ã¨ã—ã¦ã€3Dãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º

è²¬å‹™: 3Dãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« â†’ ãƒ¡ãƒƒã‚·ãƒ¥NPZãƒ•ã‚¡ã‚¤ãƒ«
å…¥åŠ›: 3Dãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (.glb, .fbx, .obj, .vrmç­‰)
å‡ºåŠ›: ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (.npz)
"""

import os
import sys
import logging
import subprocess
import yaml # Not strictly used in current logic, but kept for potential future config use
from pathlib import Path
from typing import Tuple, Dict, Optional, Any
import json
import numpy as np # Not strictly used in current logic, but kept for potential future npz handling
import time
import shutil

# UniRigå®Ÿè¡Œãƒ‘ã‚¹è¨­å®š
sys.path.append('/app')

# Default logger setup if no logger is provided
logger = logging.getLogger(__name__)
if not logger.hasHandlers():
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

class Step1Extract:
    """Step 1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""
    
    def __init__(self, output_dir: Path, logger_instance: Optional[logging.Logger] = None):
        self.output_dir = output_dir # This is the step-specific output dir, e.g., /app/pipeline_work/model_name/01_extracted_mesh/
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.logger = logger_instance if logger_instance else logging.getLogger(__name__)
    
    def _find_output_npz(self, output_dir: Path, model_name: str) -> Optional[Path]:
        """
        ç”Ÿæˆã•ã‚ŒãŸNPZãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã§æ¤œç´¢
        
        Args:
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            model_name: ãƒ¢ãƒ‡ãƒ«å
            
        Returns:
            è¦‹ã¤ã‹ã£ãŸNPZãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯Noneï¼‰
        """
        search_patterns = [
            output_dir / "raw_data.npz",                    # ç›´æ¥å‡ºåŠ›
            output_dir / model_name / "raw_data.npz",       # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…
            output_dir / f"{model_name}.npz",               # ãƒ¢ãƒ‡ãƒ«å.npz
            output_dir / f"{model_name}_mesh.npz"           # ãƒ¢ãƒ‡ãƒ«å_mesh.npz
        ]
        
        for npz_path in search_patterns:
            if npz_path.exists():
                self.logger.info(f"NPZãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {npz_path}")
                return npz_path
        
        self.logger.warning(f"NPZãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³: {[str(p) for p in search_patterns]}")
        return None

    def extract_mesh(self, input_file_path: Path, model_name: str, preserve_textures_in_step1: bool = False) -> Tuple[bool, str, Dict[str, Any]]:
        """
        å®Ÿéš›ã®ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºã®å®Ÿè¡Œ (UniRig src.data.extractä½¿ç”¨)
        
        Args:
            input_file_path: å…¥åŠ›3Dãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (çµ¶å¯¾ãƒ‘ã‚¹)
            model_name: ãƒ¢ãƒ‡ãƒ«åï¼ˆå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨ï¼‰
            preserve_textures_in_step1: ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ãƒ†ã‚¯ã‚¹ãƒãƒ£æƒ…å ±ã‚’åˆ¥é€”ä¿å­˜ã™ã‚‹ã‹ã€‚
                                     Step0ã§ã‚¢ã‚»ãƒƒãƒˆä¿å­˜ãŒè¡Œã‚ã‚Œã‚‹ãŸã‚ã€é€šå¸¸ã¯Falseã€‚
            
        Returns:
            (success, logs, output_files dict)
        """
        logs = ""
        try:
            self.logger.info(f"Step 1 é–‹å§‹: å…¥åŠ› '{input_file_path}', ãƒ¢ãƒ‡ãƒ«å '{model_name}'")
            
            if not input_file_path.exists():
                error_msg = f"[FAIL] å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_file_path}"
                self.logger.error(error_msg)
                return False, error_msg, {}
            
            # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã®ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼ (src.data.extract ãŒç‰¹å®šã®å ´æ‰€ã‚’æœŸå¾…ã™ã‚‹å ´åˆãŒã‚ã‚‹ãŸã‚)
            # ã¾ãŸã€å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã«ãƒ¢ãƒ‡ãƒ«åã‚’å«ã‚ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒãƒƒã‚°æ™‚ã®è­˜åˆ¥ã‚’å®¹æ˜“ã«ã™ã‚‹
            persistent_input_file = self.output_dir / f"{model_name}{input_file_path.suffix}"
            if not persistent_input_file.exists() or persistent_input_file.stat().st_mtime < input_file_path.stat().st_mtime:
                shutil.copy2(input_file_path, persistent_input_file)
                logs += f"ğŸ“‹ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ« '{input_file_path.name}' ã‚’ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼: '{persistent_input_file}'\\n"
            else:
                logs += f"ğŸ“‹ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ« '{persistent_input_file.name}' ã¯ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚\\n"

            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹å®šç¾© (UniRigã®ã‚³ã‚¢ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒæœŸå¾…ã™ã‚‹å›ºå®šå)
            # ã“ã‚Œã‚‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ self.output_dir (ä¾‹: /app/pipeline_work/model_name/01_extracted_mesh/) ã«ç”Ÿæˆã•ã‚Œã‚‹
            output_npz_path = self.output_dir / "raw_data.npz"
            output_datalist_path = self.output_dir / "inference_datalist.txt"
            
            # UniRigã® src.data.extract ã‚¹ã‚¯ãƒªãƒ—ãƒˆç”¨ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            # ã“ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¯ãƒªãƒã‚¸ãƒˆãƒªã®å›ºå®šãƒ‘ã‚¹ã«ã‚ã‚‹ã¨ä»®å®š
            config_file_path = Path("/app/configs/data/quick_inference.yaml") # æŒ‡ç¤ºæ›¸ã«åŸºã¥ãä¿®æ­£
            if not config_file_path.exists():
                # Fallback or default config if specific one not found
                # For now, let's assume it must exist or try a more generic one if specified in docs.
                # Based on original script, it was /app/configs/extract_config.yaml
                # The original instructions mention configs/data/quick_inference.yaml for extract.sh
                # Let's stick to quick_inference.yaml as per the more detailed original script context.
                alt_config_path = Path("/app/configs/extract_config.yaml")
                if alt_config_path.exists():
                    config_file_path = alt_config_path
                    logs += f"âš ï¸ ãƒ¡ã‚¤ãƒ³è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« {config_file_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ä»£æ›¿ {alt_config_path} ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\\n"
                else:
                    error_msg = f"[FAIL] è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_file_path} ãŠã‚ˆã³ {alt_config_path}"
                    self.logger.error(error_msg)
                    return False, error_msg, {}
            
            logs += f"ğŸ” ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºé–‹å§‹: '{persistent_input_file.name}' ã‚’ä½¿ç”¨\\n"
            logs += f"âš™ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: '{config_file_path}'\\n"
            logs += f"[FILE] å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º): '{self.output_dir}'\\n"
            
            # UniRig src.data.extract å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰ï¼ˆå…¨å¿…é ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æä¾›ï¼‰
            cmd = [
                sys.executable, "-m", "src.data.extract",
                "--config", str(config_file_path),
                "--require_suffix", ".glb,.fbx,.obj,.vrm",     # å—ã‘å…¥ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­
                "--faces_target_count", "8000",             # ç›®æ¨™é¢æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
                "--num_runs", "1",                          # å®Ÿè¡Œå›æ•°ï¼ˆå˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ï¼‰
                "--force_override", "true",                 # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ä¸Šæ›¸ãè¨±å¯
                "--id", "0",                                # ãƒ—ãƒ­ã‚»ã‚¹IDï¼ˆå˜ä¸€å®Ÿè¡Œï¼‰
                "--time", str(int(time.time())),           # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
                "--input", str(persistent_input_file),      # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
                "--output_dir", str(self.output_dir)        # ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            ]
            
            logs += f"ğŸš€ å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: {' '.join(cmd)}\\n"
            
            env = os.environ.copy()
            env['PYTHONPATH'] = f"/app:{env.get('PYTHONPATH', '')}"
            # env['GRADIO'] = '1' # GRADIOç’°å¢ƒå¤‰æ•°ã¯src.data.extractã«å½±éŸ¿ã—ãªã„å¯èƒ½æ€§ãŒé«˜ã„ã®ã§ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
            
            start_time = time.time()
            result = subprocess.run(
                cmd,
                cwd="/app", # UniRigã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ /app ã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹ã‚’æœŸå¾…ã™ã‚‹ã“ã¨ãŒã‚ã‚‹
                env=env,
                capture_output=True,
                text=True,
                timeout=300 # 5åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            )
            execution_time = time.time() - start_time
            logs += f"â±ï¸ æŠ½å‡ºã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’\\n"
            
            # ğŸ”§ Critical Fix: return codeã«é–¢ä¿‚ãªãNPZãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ã‚’å®Ÿè¡Œ
            # return code -11ã§ã‚‚raw_data.npzãŒç”Ÿæˆã•ã‚Œã‚‹å ´åˆãŒã‚ã‚‹ãŸã‚
            actual_npz_path = self._find_output_npz(self.output_dir, model_name)
            
            if result.returncode == 0:
                logs += "[OK] UniRigæŠ½å‡ºãƒ—ãƒ­ã‚»ã‚¹æ­£å¸¸çµ‚äº†\\n"
            else:
                logs += f"âš ï¸ UniRigæŠ½å‡ºãƒ—ãƒ­ã‚»ã‚¹çµ‚äº† (return code: {result.returncode})\\n"
                logs += f"STDOUT: {result.stdout}\\n"
                logs += f"STDERR: {result.stderr}\\n"
            
            # NPZãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã¯æˆåŠŸã¨ã—ã¦å‡¦ç†
            if actual_npz_path:
                file_size = actual_npz_path.stat().st_size
                logs += f"ğŸ“Š NPZãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: '{actual_npz_path}' ({file_size:,} bytes)\\n"
                
                # inference_datalist.txtç”Ÿæˆï¼ˆåŸæµå‡¦ç†äº’æ›æ€§ã®ãŸã‚ï¼‰
                datalist_content = str(actual_npz_path)
                with open(output_datalist_path, 'w', encoding='utf-8') as f:
                    f.write(datalist_content)
                logs += f"ğŸ“„ inference_datalist.txtç”Ÿæˆ: '{output_datalist_path}'\\n"
                
                output_files: Dict[str, Any] = {
                    "extracted_npz": str(actual_npz_path), # Step2ãŒæœŸå¾…ã™ã‚‹ã‚­ãƒ¼å
                    "datalist_txt": str(output_datalist_path),  # åŸæµå‡¦ç†äº’æ›
                    "model_name": model_name,
                    "persistent_input_path_in_step_dir": str(persistent_input_file) # ã“ã®ã‚¹ãƒ†ãƒƒãƒ—å†…ã§ä½¿ç”¨ã—ãŸå…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
                }
                if output_datalist_path.exists():
                    logs += f"ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆç”Ÿæˆ: '{output_datalist_path.name}'\\n"
                    output_files["datalist"] = str(output_datalist_path)
                else:
                    logs += f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« '{output_datalist_path.name}' ã¯ç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\\n"
                    output_files["datalist"] = None

                # ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜å‡¦ç† (Step0ãŒä¸»æ‹…å½“ã ãŒã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¾ãŸã¯è¿½åŠ æƒ…å ±ã¨ã—ã¦)
                if preserve_textures_in_step1:
                    texture_info = self._preserve_texture_metadata_in_step1(persistent_input_file, model_name)
                    output_files.update(texture_info)
                    logs += f"ğŸ¨ (Step1) ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜è©¦è¡Œå®Œäº†ã€‚çµæœ: {texture_info.get('texture_metadata')}\\n"
                
                logs += "[OK] Step 1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå®Œäº†\\n"
                return True, logs, output_files
            else:
                error_msg = f"[FAIL] NPZãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³:\\n"
                error_msg += f"- {self.output_dir / 'raw_data.npz'}\\n"
                error_msg += f"- {self.output_dir / model_name / 'raw_data.npz'}\\n"
                error_msg += f"- {self.output_dir / f'{model_name}.npz'}\\n"
                if result.returncode != 0:
                    error_msg += f"Return code: {result.returncode}\\n"
                    error_msg += f"STDOUT:\\n{result.stdout}\\nSTDERR:\\n{result.stderr}"
                logs += error_msg
                self.logger.error(error_msg)
                return False, logs, {}
                
        except subprocess.TimeoutExpired:
            error_msg = "[FAIL] ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå‡¦ç†ãŒ5åˆ†ã‚’è¶…éã—ã¾ã—ãŸ"
            logs += error_msg + "\\n"
            self.logger.error(error_msg)
            return False, logs, {}
        except Exception as e:
            error_msg = f"[FAIL] Step 1 å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {type(e).__name__} - {e}"
            logs += error_msg + "\\n"
            self.logger.error(error_msg, exc_info=True)
            return False, logs, {}
    
    def _preserve_texture_metadata_in_step1(self, source_model_file: Path, model_name: str) -> Dict[str, Optional[str]]:
        """
        ã“ã®ã‚¹ãƒ†ãƒƒãƒ—å†…ã§ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹ï¼ˆä¸»ã«Step0ã®è£œå®Œã¾ãŸã¯ãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰ã€‚
        Step0ãŒã‚¢ã‚»ãƒƒãƒˆä¿å­˜ã®ä¸»æ‹…å½“ã€‚
        """
        try:
            # ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (self.output_dir å†…)
            step1_texture_metadata_dir = self.output_dir / "step1_texture_info"
            step1_texture_metadata_dir.mkdir(exist_ok=True)
            
            metadata_file_path = step1_texture_metadata_dir / f"{model_name}_step1_texture_metadata.json"
            
            metadata = {
                "model_name": model_name,
                "source_model_in_step1_dir": str(source_model_file),
                "preserved_at_step1": time.time(),
                "info": "This metadata is a supplementary record from Step1. Primary asset preservation is handled by Step0."
                # ã“ã“ã«Blenderãªã©ã‚’ä½¿ã£ã¦å®Ÿéš›ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¿½åŠ å¯èƒ½
            }
            
            with open(metadata_file_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"(Step1) ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {metadata_file_path}")
            return {
                "step1_texture_metadata": str(metadata_file_path),
                "step1_texture_info_dir": str(step1_texture_metadata_dir)
            }
        except Exception as e:
            self.logger.warning(f"(Step1) ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return {"step1_texture_metadata": None, "step1_texture_info_dir": None}

def execute_step1(
    input_file_path: Path, 
    model_name: str, 
    step_output_dir: Path, 
    logger_instance: logging.Logger,
    preserve_textures_in_step1: bool = False
) -> Tuple[bool, str, Dict[str, Any]]:
    """
    Step 1: 3Dãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¾ã™ã€‚

    Args:
        input_file_path: å…¥åŠ›3Dãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (çµ¶å¯¾ãƒ‘ã‚¹)
        model_name: ãƒ¢ãƒ‡ãƒ«å
        step_output_dir: ã“ã®ã‚¹ãƒ†ãƒƒãƒ—å°‚ç”¨ã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ (çµ¶å¯¾ãƒ‘ã‚¹)
        logger_instance: app.pyã‹ã‚‰æ¸¡ã•ã‚Œã‚‹ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        preserve_textures_in_step1: Step1å†…ã§è¿½åŠ ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜ã‚’è¡Œã†ã‹

    Returns:
        success: æˆåŠŸãƒ•ãƒ©ã‚° (True/False)
        logs: å®Ÿè¡Œãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        output_files: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«è¾æ›¸
    """
    try:
        extractor = Step1Extract(output_dir=step_output_dir, logger_instance=logger_instance)
        return extractor.extract_mesh(input_file_path, model_name, preserve_textures_in_step1)
    except Exception as e:
        error_message = f"Step 1 å®Ÿè¡Œæº–å‚™ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {type(e).__name__} - {e}"
        logger_instance.error(error_message, exc_info=True)
        return False, error_message, {}

if __name__ == '__main__':
    # --- Step1å˜ä½“ãƒ†ã‚¹ãƒˆ ---
    # å®Ÿéš›ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã¯app.pyã‹ã‚‰å‘¼ã³å‡ºã•ã‚Œã¾ã™
    
    import json
    
    test_logger = logging.getLogger("Step1Extract_Test")
    test_logger.setLevel(logging.INFO)
    test_handler = logging.StreamHandler(sys.stdout)
    test_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
    test_logger.addHandler(test_handler)
    test_logger.propagate = False

    test_model_name = "test_bird_step1"
    pipeline_base_dir = Path("/app/pipeline_work")
    step_output_dir = pipeline_base_dir / test_model_name / "01_extracted_mesh"
    
    # ãƒ†ã‚¹ãƒˆç”¨å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ« (å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦)
    test_input_file = Path("/app/examples/bird.glb")
    
    if not test_input_file.exists():
        test_logger.error(f"ãƒ†ã‚¹ãƒˆç”¨å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {test_input_file}")
        test_logger.error("å®Ÿéš›ã®Step1-Step2é€£æºãƒ†ã‚¹ãƒˆã«ã¯app.pyã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„")
        exit(1)

    test_logger.info(f"--- Step1Extract å˜ä½“ãƒ†ã‚¹ãƒˆé–‹å§‹ ---")
    test_logger.info(f"å…¥åŠ›: {test_input_file}")
    test_logger.info(f"å‡ºåŠ›: {step_output_dir}")

    success, logs, files = execute_step1(
        input_file_path=test_input_file,
        model_name=test_model_name,
        step_output_dir=step_output_dir,
        logger_instance=test_logger,
        preserve_textures_in_step1=False
    )
    
    test_logger.info(f"çµæœ: {'æˆåŠŸ' if success else 'å¤±æ•—'}")
    if success:
        test_logger.info(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {json.dumps(files, indent=2)}")
    else:
        test_logger.error(f"ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°: {logs}")

    test_logger.info("--- Step1Extract å˜ä½“ãƒ†ã‚¹ãƒˆå®Œäº† ---")
