#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced Safe Texture Restoration: Priority 1å®Ÿè£…
å®Œå…¨ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿æŒã‚’ä¿è¨¼ã™ã‚‹å¼·åŒ–ç‰ˆSafe FBX-to-Blend Texture Flow

ğŸ¯ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå„ªå…ˆäº‹é …ã«åŸºã¥ãå®Ÿè£…:
- Priority 1: Safe FBX-to-Blend Texture Flow (RECOMMENDED)
- ãƒ†ã‚¯ã‚¹ãƒãƒ£å“è³ªå‘ä¸Šï¼ˆç›®æ¨™: 7.5MBä»¥ä¸Šï¼‰
- 100%ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿æŒç‡ã®å®Ÿç¾
"""

import os
import json
import subprocess
import traceback
from pathlib import Path
from typing import Dict, List, Optional, Tuple

class EnhancedSafeTextureRestoration:
    """
    å¼·åŒ–ç‰ˆSafe Texture Restoration
    
    ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå„ªå…ˆäº‹é …ã«åŸºã¥ã6æ®µéš+è¿½åŠ å¼·åŒ–ã«ã‚ˆã‚‹
    å®Œå…¨ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿æŒãƒ•ãƒ­ãƒ¼å®Ÿè£…
    """
    
    def __init__(self, working_dir: str, model_name: str, use_subprocess: bool = True):
        self.working_dir = Path(working_dir)
        self.model_name = model_name
        self.use_subprocess = use_subprocess
        
        # Safe Flow directory structure
        self.safe_dir = self.working_dir / "safe_enhanced_flow" / model_name
        self.safe_dir.mkdir(parents=True, exist_ok=True)
        
        # Enhanced stage paths
        self.stage1_workspace = self.safe_dir / "stage1_enhanced_import.blend"
        self.stage2_analyzed = self.safe_dir / "stage2_enhanced_analysis.json"
        self.stage3_reconstructed = self.safe_dir / "stage3_enhanced_reconstruction.blend"
        self.stage4_validated = self.safe_dir / "stage4_enhanced_validation.blend"
        self.stage5_pre_export = self.safe_dir / "stage5_enhanced_pre_export.blend"
        self.stage6_final_fbx = self.safe_dir / f"{model_name}_enhanced_final_textured.fbx"
        
        # Texture quality enhancement directories
        self.texture_backup_dir = self.safe_dir / "texture_backup"
        self.texture_backup_dir.mkdir(exist_ok=True)
        
        # Path references to existing pipeline
        self.skinning_dir = self.working_dir / "03_skinning_output" / model_name
        self.mesh_dir = self.working_dir / "01_extracted_mesh" / model_name
        self.textures_dir = self.mesh_dir / "textures"
        
        print(f"ğŸš€ Enhanced Safe Texture Restoration initialized for {model_name}")
        print(f"ğŸ“ Working directory: {self.safe_dir}")
    
    def execute_enhanced_restoration(self, skinned_fbx_path: Optional[str] = None) -> Tuple[bool, str, Dict]:
        """
        å¼·åŒ–ç‰ˆå®Œå…¨å¾©å…ƒå®Ÿè¡Œ
        
        Priority 1: Safe FBX-to-Blend Texture Flowã®å¼·åŒ–ç‰ˆå®Ÿè£…
        6æ®µéš + è¿½åŠ å“è³ªå‘ä¸Šå‡¦ç†
        """
        print("ğŸš€ Enhanced Safe Texture Restoration - PRIORITY 1 IMPLEMENTATION")
        print("=" * 80)
        
        # Custom skinned FBX path if provided
        if skinned_fbx_path:
            self.custom_skinned_fbx_path = skinned_fbx_path
        
        try:
            # Stage 1: Enhanced FBX Import (0-15%)
            print("ğŸ“¥ Stage 1: Enhanced FBX Import with Texture Preservation")
            if not self.stage1_enhanced_fbx_import():
                return False, "", {"error": "Stage 1 failed"}
            
            # Stage 2: Deep Texture Analysis (15-30%)
            print("ğŸ” Stage 2: Deep Texture Analysis & Backup")
            texture_analysis = self.stage2_deep_texture_analysis()
            if not texture_analysis:
                return False, "", {"error": "Stage 2 failed"}
            
            # Stage 3: Advanced Material Reconstruction (30-50%)
            print("ğŸ¨ Stage 3: Advanced Material Reconstruction")
            if not self.stage3_advanced_material_reconstruction(texture_analysis):
                return False, "", {"error": "Stage 3 failed"}
            
            # Stage 4: Comprehensive Validation (50-65%)
            print("ğŸ”— Stage 4: Comprehensive Material & UV Validation")
            if not self.stage4_comprehensive_validation():
                return False, "", {"error": "Stage 4 failed"}
            
            # Stage 5: Pre-Export Optimization (65-80%)
            print("âš¡ Stage 5: Pre-Export Texture Optimization")
            if not self.stage5_pre_export_optimization():
                return False, "", {"error": "Stage 5 failed"}
            
            # Stage 6: Enhanced FBX Export (80-95%)
            print("ğŸ“¤ Stage 6: Enhanced FBX Export with Guaranteed Embedding")
            if not self.stage6_enhanced_fbx_export():
                return False, "", {"error": "Stage 6 failed"}
            
            # Stage 7: Quality Assurance (95-100%)
            print("ğŸ” Stage 7: Final Quality Assurance & Validation")
            quality_report = self.stage7_quality_assurance()
            
            print("\nâœ… Enhanced Safe Texture Restoration completed successfully!")
            print(f"ğŸ“ Final FBX: {self.stage6_final_fbx}")
            print(f"ğŸ“Š Quality Score: {quality_report.get('quality_score', 'UNKNOWN')}")
            print(f"ğŸ“ File Size: {quality_report.get('file_size_mb', 0):.2f} MB")
            
            return True, str(self.stage6_final_fbx), quality_report
            
        except Exception as e:
            error_msg = f"Enhanced restoration failed: {str(e)}"
            print(f"âŒ {error_msg}")
            traceback.print_exc()
            return False, "", {"error": error_msg}
    
    def stage1_enhanced_fbx_import(self) -> bool:
        """
        Stage 1: ã‚¹ã‚­ãƒ³FBXã®å¼·åŒ–ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        æ—¢å­˜ãƒ†ã‚¯ã‚¹ãƒãƒ£æƒ…å ±ã®äº‹å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å«ã‚€
        """
        print("ğŸ“¥ Stage 1: Enhanced FBX Import")
        
        # Find skinned FBX
        if hasattr(self, 'custom_skinned_fbx_path') and self.custom_skinned_fbx_path:
            skinned_fbx = self.custom_skinned_fbx_path
        else:
            skinned_fbx = self.skinning_dir / "skinned_model.fbx"
        
        if not os.path.exists(skinned_fbx):
            print(f"âŒ Skinned FBX not found: {skinned_fbx}")
            return False
        
        print(f"ğŸ“‚ Importing: {skinned_fbx}")
        
        # Enhanced import script with texture preservation
        skinned_fbx_str = str(skinned_fbx).replace('\\', '/')
        stage1_blend_str = str(self.stage1_workspace).replace('\\', '/')
        
        script_content = f'''
import bpy
import os

def enhanced_fbx_import():
    try:
        # Ultra-clean workspace
        bpy.ops.wm.read_factory_settings(use_empty=True)
        
        # Import with enhanced settings for texture preservation
        bpy.ops.import_scene.fbx(
            filepath="{skinned_fbx_str}",
            use_image_search=True,  # Search for textures
            use_anim=True,
            ignore_leaf_bones=False,
            use_custom_normals=True,
            use_custom_props=True,
            # Enhanced texture handling
            decal_offset=0.0,
            use_prepost_rot=True
        )
        
        # Analyze and preserve existing texture references
        print(f"ğŸ“Š Enhanced Analysis:")
        print(f"  Objects: {{len(bpy.data.objects)}}")
        print(f"  Meshes: {{len([o for o in bpy.data.objects if o.type == 'MESH'])}}")
        print(f"  Armatures: {{len([o for o in bpy.data.objects if o.type == 'ARMATURE'])}}")
        print(f"  Materials: {{len(bpy.data.materials)}}")
        print(f"  Images: {{len(bpy.data.images)}}")
        
        # Ensure view layer update
        bpy.context.view_layer.update()
        
        # Save enhanced workspace
        bpy.ops.wm.save_as_mainfile(filepath="{stage1_blend_str}")
        print(f"âœ… Stage 1 Enhanced: Workspace saved with {{len(bpy.data.objects)}} objects")
        return True
        
    except Exception as e:
        print(f"âŒ Stage 1 Enhanced error: {{e}}")
        import traceback
        traceback.print_exc()
        return False

result = enhanced_fbx_import()
if result:
    print("Stage1EnhancedSuccess")
else:
    print("Stage1EnhancedFailed")
'''
        
        try:
            result = subprocess.run([
                "blender", "--background", "--python-expr", script_content
            ], capture_output=True, text=True, timeout=240)
            
            if "Stage1EnhancedSuccess" in result.stdout:
                print("âœ… Stage 1 Enhanced: FBX import successful")
                return True
            else:
                print("âŒ Stage 1 Enhanced: FBX import failed")
                print("Stdout:", result.stdout[-1000:])  # Last 1000 chars
                print("Stderr:", result.stderr[-500:])   # Last 500 chars
                return False
                
        except Exception as e:
            print(f"âŒ Stage 1 Enhanced: Subprocess error: {e}")
            return False
    
    def stage2_deep_texture_analysis(self) -> Dict:
        """
        Stage 2: æ·±åº¦ãƒ†ã‚¯ã‚¹ãƒãƒ£åˆ†æã¨å®Œå…¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        
        æ—¢å­˜ã®YAMLãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã«åŠ ãˆã¦ã€è¿½åŠ ã®è©³ç´°åˆ†æã‚’å®Ÿè¡Œ
        """
        print("ğŸ” Stage 2: Deep Texture Analysis")
        
        # Load existing YAML manifest
        yaml_manifest_path = self.mesh_dir / "material_manifest.yaml"
        
        if not yaml_manifest_path.exists():
            print(f"âŒ YAML manifest not found: {yaml_manifest_path}")
            return None
        
        try:
            import yaml
            with open(yaml_manifest_path, 'r', encoding='utf-8') as f:
                yaml_data = yaml.safe_load(f)
            
            print(f"ğŸ“‹ YAML Manifest loaded: {len(yaml_data.get('materials', []))} materials")
            
            # Enhanced texture backup
            texture_backup_info = self._backup_texture_files(yaml_data)
            
            # Comprehensive analysis
            enhanced_analysis = {
                'yaml_manifest': yaml_data,
                'texture_backup': texture_backup_info,
                'analysis_timestamp': str(Path().absolute()),
                'source_textures': self._analyze_source_textures(),
                'texture_metrics': self._calculate_texture_metrics()
            }
            
            # Save enhanced analysis
            with open(self.stage2_analyzed, 'w', encoding='utf-8') as f:
                json.dump(enhanced_analysis, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… Stage 2 Enhanced: Deep analysis saved")
            print(f"ğŸ“Š Texture files backed up: {len(texture_backup_info.get('backed_up_files', []))}")
            
            return enhanced_analysis
            
        except Exception as e:
            print(f"âŒ Stage 2 Enhanced error: {e}")
            traceback.print_exc()
            return None
    
    def _backup_texture_files(self, yaml_data: Dict) -> Dict:
        """ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ•ã‚¡ã‚¤ãƒ«ã®å®Œå…¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        backup_info = {
            'backed_up_files': [],
            'total_size_mb': 0,
            'backup_dir': str(self.texture_backup_dir)
        }
        
        # Copy all texture files to backup directory
        if self.textures_dir.exists():
            for texture_file in self.textures_dir.glob("*"):
                if texture_file.is_file() and texture_file.suffix.lower() in ['.png', '.jpg', '.jpeg', '.tga']:
                    backup_path = self.texture_backup_dir / texture_file.name
                    import shutil
                    shutil.copy2(texture_file, backup_path)
                    
                    file_size = texture_file.stat().st_size
                    backup_info['backed_up_files'].append({
                        'name': texture_file.name,
                        'size_bytes': file_size,
                        'backup_path': str(backup_path)
                    })
                    backup_info['total_size_mb'] += file_size / (1024 * 1024)
        
        print(f"ğŸ“¦ Texture backup: {len(backup_info['backed_up_files'])} files, {backup_info['total_size_mb']:.2f}MB")
        return backup_info
    
    def _analyze_source_textures(self) -> Dict:
        """å…ƒãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°åˆ†æ"""
        source_analysis = {
            'texture_files': [],
            'total_files': 0,
            'total_size_mb': 0
        }
        
        if self.textures_dir.exists():
            for texture_file in self.textures_dir.glob("*"):
                if texture_file.is_file():
                    file_info = {
                        'name': texture_file.name,
                        'size_bytes': texture_file.stat().st_size,
                        'size_mb': texture_file.stat().st_size / (1024 * 1024),
                        'type': texture_file.suffix.lower()
                    }
                    source_analysis['texture_files'].append(file_info)
                    source_analysis['total_size_mb'] += file_info['size_mb']
            
            source_analysis['total_files'] = len(source_analysis['texture_files'])
        
        return source_analysis
    
    def _calculate_texture_metrics(self) -> Dict:
        """ãƒ†ã‚¯ã‚¹ãƒãƒ£å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—"""
        metrics = {
            'expected_final_size_mb': 0,
            'quality_threshold_mb': 7.5,
            'compression_factor': 0.85  # æœŸå¾…åœ§ç¸®ç‡
        }
        
        # Calculate expected final size
        source_analysis = self._analyze_source_textures()
        base_texture_size = source_analysis.get('total_size_mb', 0)
        rigging_overhead = 1.5  # MB for rigging data
        
        metrics['expected_final_size_mb'] = (base_texture_size * metrics['compression_factor']) + rigging_overhead
        metrics['minimum_acceptable_mb'] = max(7.5, base_texture_size * 0.6)
        
        return metrics
    
    def stage3_advanced_material_reconstruction(self, texture_analysis: Dict) -> bool:
        """
        Stage 3: é«˜åº¦ãƒãƒ†ãƒªã‚¢ãƒ«å†æ§‹ç¯‰
        
        YAMLãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚’ä½¿ç”¨ã—ãŸ
        å®Œå…¨ãªBlenderãƒãƒ†ãƒªã‚¢ãƒ«å†æ§‹ç¯‰
        """
        print("ğŸ¨ Stage 3: Advanced Material Reconstruction")
        
        stage1_blend_str = str(self.stage1_workspace).replace('\\', '/')
        stage3_blend_str = str(self.stage3_reconstructed).replace('\\', '/')
        texture_backup_str = str(self.texture_backup_dir).replace('\\', '/')
        
        # Pass texture analysis as JSON string
        texture_analysis_json = json.dumps(texture_analysis).replace('"', '\\"')
        
        script_content = f'''
import bpy
import json
import os

def advanced_material_reconstruction():
    try:
        # Load workspace
        bpy.ops.wm.open_mainfile(filepath="{stage1_blend_str}")
        
        # Parse texture analysis
        texture_analysis = json.loads("""{texture_analysis_json}""")
        yaml_data = texture_analysis['yaml_manifest']
        
        print("ğŸ¨ Advanced Material Reconstruction starting...")
        
        # Enhanced material creation
        materials_created = 0
        textures_connected = 0
        
        for mat_data in yaml_data.get('materials', []):
            mat_name = mat_data['name']
            
            # Create or get material
            material = bpy.data.materials.get(mat_name)
            if not material:
                material = bpy.data.materials.new(name=mat_name)
                materials_created += 1
            
            # Enable nodes
            material.use_nodes = True
            nodes = material.node_tree.nodes
            links = material.node_tree.links
            
            # Clear existing nodes
            nodes.clear()
            
            # Create enhanced node setup
            principled = nodes.new(type='ShaderNodeBsdfPrincipled')
            principled.location = (0, 0)
            
            output = nodes.new(type='ShaderNodeOutputMaterial')
            output.location = (300, 0)
            
            # Connect Principled to Output
            links.new(principled.outputs['BSDF'], output.inputs['Surface'])
            
            # Process textures with enhanced connection logic
            texture_maps = mat_data.get('texture_maps', {{}})
            y_offset = 300
            
            for tex_type, tex_info in texture_maps.items():
                if tex_info and tex_info.get('file_name'):
                    tex_file_name = tex_info['file_name']
                    tex_file_path = os.path.join("{texture_backup_str}", tex_file_name)
                    
                    if os.path.exists(tex_file_path):
                        # Create texture node
                        tex_node = nodes.new(type='ShaderNodeTexImage')
                        tex_node.location = (-400, y_offset)
                        y_offset -= 250
                        
                        # Load image
                        try:
                            image = bpy.data.images.load(tex_file_path)
                            tex_node.image = image
                            
                            # Enhanced connection logic
                            if tex_type == 'baseColorTexture':
                                links.new(tex_node.outputs['Color'], principled.inputs['Base Color'])
                                print(f"   âœ… Connected Base Color: {{tex_file_name}}")
                                textures_connected += 1
                                
                            elif tex_type == 'normalTexture':
                                # Create Normal Map node
                                normal_map = nodes.new(type='ShaderNodeNormalMap')
                                normal_map.location = (-200, y_offset + 100)
                                links.new(tex_node.outputs['Color'], normal_map.inputs['Color'])
                                links.new(normal_map.outputs['Normal'], principled.inputs['Normal'])
                                # Set correct colorspace
                                image.colorspace_settings.name = 'Non-Color'
                                print(f"   âœ… Connected Normal Map: {{tex_file_name}}")
                                textures_connected += 1
                                
                            elif tex_type == 'metallicRoughnessTexture':
                                # Enhanced Metallic/Roughness handling
                                separate_node = nodes.new(type='ShaderNodeSeparateColor')
                                separate_node.location = (-200, y_offset)
                                links.new(tex_node.outputs['Color'], separate_node.inputs['Color'])
                                # Blue=Metallic, Green=Roughness (glTF standard)
                                links.new(separate_node.outputs['Blue'], principled.inputs['Metallic'])
                                links.new(separate_node.outputs['Green'], principled.inputs['Roughness'])
                                # Set correct colorspace
                                image.colorspace_settings.name = 'Non-Color'
                                print(f"   âœ… Connected Metallic/Roughness: {{tex_file_name}}")
                                textures_connected += 1
                            
                        except Exception as e:
                            print(f"   âŒ Failed to load texture {{tex_file_name}}: {{e}}")
                    else:
                        print(f"   âš ï¸ Texture file not found: {{tex_file_path}}")
        
        # Assign materials to meshes
        mesh_assignments = 0
        for obj in bpy.data.objects:
            if obj.type == 'MESH':
                # Clear existing materials
                obj.data.materials.clear()
                
                # Assign first available material (enhanced logic can be added)
                if bpy.data.materials:
                    for material in bpy.data.materials:
                        obj.data.materials.append(material)
                        mesh_assignments += 1
                        break
        
        print(f"ğŸ¨ Advanced reconstruction complete:")
        print(f"   Materials created: {{materials_created}}")
        print(f"   Textures connected: {{textures_connected}}")
        print(f"   Mesh assignments: {{mesh_assignments}}")
        
        # Save reconstructed workspace
        bpy.ops.wm.save_as_mainfile(filepath="{stage3_blend_str}")
        return True
        
    except Exception as e:
        print(f"âŒ Stage 3 Advanced error: {{e}}")
        import traceback
        traceback.print_exc()
        return False

result = advanced_material_reconstruction()
if result:
    print("Stage3AdvancedSuccess")
else:
    print("Stage3AdvancedFailed")
'''
        
        try:
            result = subprocess.run([
                "blender", "--background", "--python-expr", script_content
            ], capture_output=True, text=True, timeout=300)
            
            if "Stage3AdvancedSuccess" in result.stdout:
                print("âœ… Stage 3 Advanced: Material reconstruction successful")
                # Extract statistics from output
                output_lines = result.stdout.split('\n')
                for line in output_lines:
                    if 'Materials created:' in line or 'Textures connected:' in line:
                        print(f"  ğŸ“Š {line.strip()}")
                return True
            else:
                print("âŒ Stage 3 Advanced: Material reconstruction failed")
                print("Stdout:", result.stdout[-1000:])
                return False
                
        except Exception as e:
            print(f"âŒ Stage 3 Advanced: Subprocess error: {e}")
            return False
    
    def stage4_comprehensive_validation(self) -> bool:
        """
        Stage 4: åŒ…æ‹¬çš„æ¤œè¨¼
        
        ãƒãƒ†ãƒªã‚¢ãƒ«æ¥ç¶šã€UVåº§æ¨™ã€ãƒ¡ãƒƒã‚·ãƒ¥å‰²ã‚Šå½“ã¦ã®å®Œå…¨æ¤œè¨¼
        """
        print("ğŸ”— Stage 4: Comprehensive Material & UV Validation")
        
        stage3_blend_str = str(self.stage3_reconstructed).replace('\\', '/')
        stage4_blend_str = str(self.stage4_validated).replace('\\', '/')
        
        script_content = f'''
import bpy

def comprehensive_validation():
    try:
        # Load reconstructed workspace
        bpy.ops.wm.open_mainfile(filepath="{stage3_blend_str}")
        
        print("ğŸ”— Comprehensive Validation starting...")
        
        validation_passed = True
        materials_validated = 0
        connections_validated = 0
        uv_maps_validated = 0
        
        # Material and connection validation
        for mat in bpy.data.materials:
            materials_validated += 1
            print(f"ğŸ¨ Validating material: {{mat.name}}")
            
            if not mat.use_nodes:
                print(f"   âŒ Material {{mat.name}} does not use nodes")
                validation_passed = False
                continue
            
            # Find Principled BSDF
            principled = None
            texture_nodes = []
            
            for node in mat.node_tree.nodes:
                if node.type == 'BSDF_PRINCIPLED':
                    principled = node
                elif node.type == 'TEX_IMAGE' and node.image:
                    texture_nodes.append(node)
            
            if not principled:
                print(f"   âŒ No Principled BSDF found")
                validation_passed = False
                continue
            
            print(f"   ğŸ“ Found {{len(texture_nodes)}} texture nodes")
            
            # Enhanced connection validation
            critical_connections = 0
            base_color_connected = bool(principled.inputs['Base Color'].links)
            normal_connected = bool(principled.inputs['Normal'].links)
            roughness_connected = bool(principled.inputs['Roughness'].links)
            metallic_connected = bool(principled.inputs['Metallic'].links)
            
            if base_color_connected:
                critical_connections += 1
                connections_validated += 1
            if normal_connected:
                critical_connections += 1
                connections_validated += 1
            if roughness_connected:
                critical_connections += 1
                connections_validated += 1
            if metallic_connected:
                critical_connections += 1
                connections_validated += 1
            
            print(f"   ğŸ”— Critical connections: {{critical_connections}}/4")
            print(f"   ğŸ”— Base Color: {{'âœ…' if base_color_connected else 'âŒ'}}")
            print(f"   ğŸ”— Normal: {{'âœ…' if normal_connected else 'âŒ'}}")
            print(f"   ğŸ”— Roughness: {{'âœ…' if roughness_connected else 'âŒ'}}")
            print(f"   ğŸ”— Metallic: {{'âœ…' if metallic_connected else 'âŒ'}}")
            
            if critical_connections < 2:  # At least 2 connections required
                print(f"   âš ï¸ Insufficient connections ({{critical_connections}} < 2)")
                # Don't fail validation for this, but note it
        
        # UV coordinate validation
        for obj in bpy.data.objects:
            if obj.type == 'MESH':
                mesh = obj.data
                if mesh.uv_layers:
                    uv_maps_validated += 1
                    print(f"   âœ… {{obj.name}} has {{len(mesh.uv_layers)}} UV map(s)")
                else:
                    print(f"   âš ï¸ {{obj.name}} has no UV maps")
        
        # Material assignment validation
        mesh_with_materials = 0
        for obj in bpy.data.objects:
            if obj.type == 'MESH':
                if obj.data.materials:
                    mesh_with_materials += 1
                    print(f"   âœ… {{obj.name}} has {{len(obj.data.materials)}} material(s)")
                else:
                    print(f"   âŒ {{obj.name}} has no materials")
                    validation_passed = False
        
        print(f"ğŸ”— Comprehensive validation results:")
        print(f"   Materials validated: {{materials_validated}}")
        print(f"   Connections validated: {{connections_validated}}")
        print(f"   UV maps validated: {{uv_maps_validated}}")
        print(f"   Meshes with materials: {{mesh_with_materials}}")
        
        # Save validated workspace
        if validation_passed or mesh_with_materials > 0:  # Continue if we have some materials
            bpy.ops.wm.save_as_mainfile(filepath="{stage4_blend_str}")
            print("âœ… Validation completed - workspace saved")
            return True
        else:
            print("âŒ Critical validation failures")
            return False
        
    except Exception as e:
        print(f"âŒ Stage 4 Comprehensive error: {{e}}")
        import traceback
        traceback.print_exc()
        return False

result = comprehensive_validation()
if result:
    print("Stage4ComprehensiveSuccess")
else:
    print("Stage4ComprehensiveFailed")
'''
        
        try:
            result = subprocess.run([
                "blender", "--background", "--python-expr", script_content
            ], capture_output=True, text=True, timeout=240)
            
            if "Stage4ComprehensiveSuccess" in result.stdout:
                print("âœ… Stage 4 Comprehensive: Validation successful")
                # Extract validation statistics
                output_lines = result.stdout.split('\n')
                for line in output_lines:
                    if 'validated:' in line or 'with materials:' in line:
                        print(f"  ğŸ“Š {line.strip()}")
                return True
            else:
                print("âŒ Stage 4 Comprehensive: Validation failed")
                print("Stdout:", result.stdout[-1000:])
                return False
                
        except Exception as e:
            print(f"âŒ Stage 4 Comprehensive: Subprocess error: {e}")
            return False
    
    def stage5_pre_export_optimization(self) -> bool:
        """
        Stage 5: ãƒ—ãƒªã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæœ€é©åŒ–
        
        FBXã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå‰ã®é›†ä¸­çš„ãƒ†ã‚¯ã‚¹ãƒãƒ£æœ€é©åŒ–
        """
        print("âš¡ Stage 5: Pre-Export Texture Optimization")
        
        stage4_blend_str = str(self.stage4_validated).replace('\\', '/')
        stage5_blend_str = str(self.stage5_pre_export).replace('\\', '/')
        
        script_content = f'''
import bpy
import os

def pre_export_optimization():
    try:
        # Load validated workspace
        bpy.ops.wm.open_mainfile(filepath="{stage4_blend_str}")
        
        print("âš¡ Pre-Export Optimization starting...")
        
        # 1. Force pack ALL textures
        packed_count = 0
        total_packed_size = 0
        
        for img in bpy.data.images:
            if img.name not in ['Render Result', 'Viewer Node']:
                try:
                    if not (hasattr(img, 'packed_file') and img.packed_file):
                        img.pack()
                        packed_count += 1
                        print(f"ğŸ“¦ Packed: {{img.name}} ({{img.size[0]}}x{{img.size[1]}})")
                    else:
                        print(f"âœ… Already packed: {{img.name}}")
                    
                    # Calculate packed size
                    if hasattr(img, 'packed_file') and img.packed_file:
                        total_packed_size += len(img.packed_file.data)
                        
                except Exception as e:
                    print(f"âŒ Failed to pack {{img.name}}: {{e}}")
        
        total_packed_mb = total_packed_size / (1024 * 1024)
        print(f"ğŸ“¦ Total packed: {{packed_count}} textures, {{total_packed_mb:.2f}}MB")
        
        # 2. Material node optimization for FBX compatibility
        materials_optimized = 0
        for mat in bpy.data.materials:
            if mat.use_nodes:
                # Ensure proper material setup for FBX export
                nodes = mat.node_tree.nodes
                links = mat.node_tree.links
                
                # Find Principled BSDF
                principled = None
                for node in nodes:
                    if node.type == 'BSDF_PRINCIPLED':
                        principled = node
                        break
                
                if principled:
                    materials_optimized += 1
                    
                    # Ensure texture nodes have proper colorspace settings
                    for node in nodes:
                        if node.type == 'TEX_IMAGE' and node.image:
                            # Set appropriate colorspace based on usage
                            connected_to_normal = any(
                                link.to_socket.name == 'Color' and link.to_node.type == 'NORMAL_MAP'
                                for link in node.outputs['Color'].links
                            )
                            connected_to_roughness = any(
                                link.to_socket.name in ['Roughness', 'Metallic']
                                for link in node.outputs['Color'].links
                            )
                            
                            if connected_to_normal or connected_to_roughness:
                                node.image.colorspace_settings.name = 'Non-Color'
                            else:
                                node.image.colorspace_settings.name = 'sRGB'
        
        print(f"ğŸ¨ Materials optimized: {{materials_optimized}}")
        
        # 3. UV coordinate validation and optimization
        uv_objects_processed = 0
        for obj in bpy.data.objects:
            if obj.type == 'MESH' and obj.data.uv_layers:
                # Ensure UV coordinates are properly set
                bpy.context.view_layer.objects.active = obj
                uv_objects_processed += 1
        
        print(f"ğŸ—ºï¸ UV objects processed: {{uv_objects_processed}}")
        
        # 4. Scene optimization
        bpy.context.view_layer.update()
        
        # 5. Save pre-export optimized workspace
        bpy.ops.wm.save_as_mainfile(filepath="{stage5_blend_str}")
        
        print("âš¡ Pre-Export Optimization completed successfully")
        return True
        
    except Exception as e:
        print(f"âŒ Stage 5 Pre-Export error: {{e}}")
        import traceback
        traceback.print_exc()
        return False

result = pre_export_optimization()
if result:
    print("Stage5PreExportSuccess")
else:
    print("Stage5PreExportFailed")
'''
        
        try:
            result = subprocess.run([
                "blender", "--background", "--python-expr", script_content
            ], capture_output=True, text=True, timeout=240)
            
            if "Stage5PreExportSuccess" in result.stdout:
                print("âœ… Stage 5 Pre-Export: Optimization successful")
                # Extract optimization statistics
                output_lines = result.stdout.split('\n')
                for line in output_lines:
                    if 'Total packed:' in line or 'Materials optimized:' in line:
                        print(f"  ğŸ“Š {line.strip()}")
                return True
            else:
                print("âŒ Stage 5 Pre-Export: Optimization failed")
                print("Stdout:", result.stdout[-1000:])
                return False
                
        except Exception as e:
            print(f"âŒ Stage 5 Pre-Export: Subprocess error: {e}")
            return False
    
    def stage6_enhanced_fbx_export(self) -> bool:
        """
        Stage 6: å¼·åŒ–FBXã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        
        æœ€å¤§é™ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿æŒã‚’ä¿è¨¼ã™ã‚‹FBXã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        """
        print("ğŸ“¤ Stage 6: Enhanced FBX Export with Guaranteed Embedding")
        
        stage5_blend_str = str(self.stage5_pre_export).replace('\\', '/')
        final_fbx_str = str(self.stage6_final_fbx).replace('\\', '/')
        
        script_content = f'''
import bpy
import os

def enhanced_fbx_export():
    try:
        # Load pre-export optimized workspace
        bpy.ops.wm.open_mainfile(filepath="{stage5_blend_str}")
        
        print("ğŸ“¤ Enhanced FBX Export starting...")
        
        # Final pre-export checks
        texture_count = 0
        packed_textures = 0
        total_texture_size = 0
        
        for img in bpy.data.images:
            if img.name not in ['Render Result', 'Viewer Node']:
                texture_count += 1
                if hasattr(img, 'packed_file') and img.packed_file:
                    packed_textures += 1
                    total_texture_size += len(img.packed_file.data)
                    print(f"âœ… Ready for export: {{img.name}} ({{len(img.packed_file.data) // 1024}}KB)")
                else:
                    print(f"âš ï¸ Not packed: {{img.name}}")
        
        texture_size_mb = total_texture_size / (1024 * 1024)
        print(f"ğŸ“Š Export readiness: {{packed_textures}}/{{texture_count}} textures, {{texture_size_mb:.2f}}MB")
        
        # Ensure output directory exists
        output_dir = os.path.dirname("{final_fbx_str}")
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)
        
        # Enhanced FBX export with maximum texture preservation
        print("ğŸ“¤ Executing enhanced FBX export...")
        bpy.ops.export_scene.fbx(
            filepath="{final_fbx_str}",
            # Object selection - export everything
            use_selection=False,
            object_types={{'MESH', 'ARMATURE', 'LIGHT', 'CAMERA'}},
            
            # CRITICAL: Enhanced texture embedding settings
            path_mode='COPY',              # Copy texture files
            embed_textures=True,           # Force embed in FBX
            
            # Transform settings
            axis_forward='-Z',
            axis_up='Y',
            global_scale=1.0,
            apply_unit_scale=True,
            apply_scale_options='FBX_SCALE_NONE',
            
            # Geometry settings
            use_mesh_modifiers=True,
            use_mesh_edges=True,
            use_triangles=False,           # Keep quads where possible
            use_custom_props=True,
            
            # Material settings (ENHANCED)
            use_tspace=True,               # Tangent space for normal maps
            mesh_smooth_type='FACE',       # Face smoothing
            colors_type='SRGB',           # sRGB color space
            prioritize_active_color=False,
            
            # Animation settings
            use_anim=True,
            add_leaf_bones=True,
            use_armature_deform_only=True,
            bake_anim=False,
            
            # Advanced settings for maximum compatibility
            use_metadata=True,
            batch_mode='OFF',
            
            # Experimental: Force binary format for better texture embedding
            use_ascii=False
        )
        
        # Verify export success
        if os.path.exists("{final_fbx_str}"):
            file_size = os.path.getsize("{final_fbx_str}")
            file_size_mb = file_size / (1024 * 1024)
            
            print(f"âœ… Enhanced FBX exported successfully!")
            print(f"ğŸ“Š Final size: {{file_size_mb:.2f}} MB")
            
            # Enhanced quality assessment
            if file_size_mb >= 8.0:
                print("ğŸ‰ EXCELLENT: File size indicates outstanding texture embedding")
            elif file_size_mb >= 7.0:
                print("âœ… GOOD: File size indicates successful texture embedding")
            elif file_size_mb >= 5.0:
                print("âš ï¸ ACCEPTABLE: File size indicates partial texture embedding")
            else:
                print("âŒ POOR: File size indicates potential texture loss")
            
            return True
        else:
            print("âŒ Enhanced FBX file not created")
            return False
        
    except Exception as e:
        print(f"âŒ Stage 6 Enhanced error: {{e}}")
        import traceback
        traceback.print_exc()
        return False

result = enhanced_fbx_export()
if result:
    print("Stage6EnhancedSuccess")
else:
    print("Stage6EnhancedFailed")
'''
        
        try:
            result = subprocess.run([
                "blender", "--background", "--python-expr", script_content
            ], capture_output=True, text=True, timeout=360)  # Extended timeout for export
            
            if "Stage6EnhancedSuccess" in result.stdout:
                print("âœ… Stage 6 Enhanced: FBX export successful")
                # Extract export statistics
                output_lines = result.stdout.split('\n')
                for line in output_lines:
                    if 'Final size:' in line or 'texture embedding' in line:
                        print(f"  ğŸ“Š {line.strip()}")
                return True
            else:
                print("âŒ Stage 6 Enhanced: FBX export failed")
                print("Stdout:", result.stdout[-1500:])
                return False
                
        except Exception as e:
            print(f"âŒ Stage 6 Enhanced: Subprocess error: {e}")
            return False
    
    def stage7_quality_assurance(self) -> Dict:
        """
        Stage 7: æœ€çµ‚å“è³ªä¿è¨¼
        
        ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå„ªå…ˆäº‹é …ã«åŸºã¥ãå“è³ªæŒ‡æ¨™ã®åŒ…æ‹¬çš„æ¤œè¨¼
        """
        print("ğŸ” Stage 7: Final Quality Assurance & Validation")
        
        if not self.stage6_final_fbx.exists():
            return {"error": "Final FBX does not exist", "quality_score": "FAILED"}
        
        file_size = self.stage6_final_fbx.stat().st_size
        file_size_mb = file_size / (1024 * 1024)
        
        # Load texture analysis for comparison
        texture_analysis = {}
        if self.stage2_analyzed.exists():
            try:
                with open(self.stage2_analyzed, 'r', encoding='utf-8') as f:
                    texture_analysis = json.load(f)
            except:
                pass
        
        # Enhanced quality scoring based on project requirements
        quality_score = "POOR"
        texture_preservation_rate = 0
        
        expected_size = texture_analysis.get('texture_metrics', {}).get('expected_final_size_mb', 7.5)
        minimum_acceptable = texture_analysis.get('texture_metrics', {}).get('minimum_acceptable_mb', 7.5)
        
        if file_size_mb >= expected_size:
            quality_score = "EXCELLENT"
            texture_preservation_rate = 1.0
        elif file_size_mb >= minimum_acceptable:
            quality_score = "GOOD"
            texture_preservation_rate = 0.85
        elif file_size_mb >= 5.0:
            quality_score = "ACCEPTABLE"
            texture_preservation_rate = 0.65
        elif file_size_mb >= 3.0:
            quality_score = "POOR"
            texture_preservation_rate = 0.35
        else:
            quality_score = "FAILED"
            texture_preservation_rate = 0.1
        
        # Comprehensive quality report
        quality_report = {
            "enhanced_safe_restoration": True,
            "priority_1_implementation": True,
            "final_fbx_path": str(self.stage6_final_fbx),
            "file_size_bytes": file_size,
            "file_size_mb": round(file_size_mb, 2),
            "quality_score": quality_score,
            "texture_preservation_rate": texture_preservation_rate,
            "expected_size_mb": expected_size,
            "minimum_acceptable_mb": minimum_acceptable,
            "meets_project_requirements": file_size_mb >= 7.5,  # Project requirement
            "texture_analysis": texture_analysis.get('texture_metrics', {}),
            "recommendations": []
        }
        
        # Generate recommendations
        if file_size_mb < 7.5:
            quality_report["recommendations"].append(
                f"File size {file_size_mb:.2f}MB below project requirement (7.5MB+) - investigate texture embedding"
            )
        
        if texture_preservation_rate < 0.8:
            quality_report["recommendations"].append(
                f"Texture preservation rate {texture_preservation_rate:.0%} below target - review material reconstruction"
            )
        
        # Save quality report
        quality_report_path = self.safe_dir / "stage7_quality_report.json"
        with open(quality_report_path, 'w', encoding='utf-8') as f:
            json.dump(quality_report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“Š Enhanced Quality Assessment:")
        print(f"  ğŸ“ File Size: {file_size_mb:.2f} MB")
        print(f"  ğŸ¯ Quality Score: {quality_score}")
        print(f"  ğŸ“ˆ Texture Preservation: {texture_preservation_rate:.0%}")
        print(f"  âœ… Meets Requirements: {'YES' if quality_report['meets_project_requirements'] else 'NO'}")
        
        return quality_report


# Test function for standalone execution
def test_enhanced_safe_texture_restoration():
    """Enhanced Safe Texture Restorationã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª Testing Enhanced Safe Texture Restoration - PRIORITY 1")
    print("=" * 80)
    
    # Initialize enhanced system
    enhanced_system = EnhancedSafeTextureRestoration(
        working_dir="/app/pipeline_work",
        model_name="bird",
        use_subprocess=True
    )
    
    # Execute enhanced restoration
    success, final_fbx, quality_report = enhanced_system.execute_enhanced_restoration()
    
    if success:
        print("\nğŸ‰ Enhanced Safe Texture Restoration completed successfully!")
        print(f"ğŸ“ Final FBX: {final_fbx}")
        print(f"ğŸ“Š Quality: {quality_report.get('quality_score', 'UNKNOWN')}")
        print(f"ğŸ“ Size: {quality_report.get('file_size_mb', 0):.2f} MB")
        print(f"ğŸ¯ Meets Requirements: {'YES' if quality_report.get('meets_project_requirements', False) else 'NO'}")
        
        # Display recommendations if any
        recommendations = quality_report.get('recommendations', [])
        if recommendations:
            print("\nğŸ’¡ Recommendations:")
            for rec in recommendations:
                print(f"  â€¢ {rec}")
    else:
        print("\nâŒ Enhanced Safe Texture Restoration failed")
        print(f"âŒ Error: {quality_report.get('error', 'Unknown error')}")
    
    return success, final_fbx, quality_report


if __name__ == "__main__":
    test_enhanced_safe_texture_restoration()
