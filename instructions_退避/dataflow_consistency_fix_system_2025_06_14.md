---
applyTo: '**'
---

# UniRigæ±ºã‚æ‰“ã¡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼æ•´åˆæ€§ä¿®æ­£ã‚·ã‚¹ãƒ†ãƒ  - 2025å¹´6æœˆ14æ—¥

## ğŸ¯ æœ€é‡è¦èª²é¡Œ: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼é½Ÿé½¬ã®å®Œå…¨è§£æ±º

**ç›®æ¨™**: `.github/unirig_original_dataflow.instructions.md`ã§ç‰¹å®šã•ã‚ŒãŸå…¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼é½Ÿé½¬ã‚’è§£æ±ºã—ã€æ±ºã‚æ‰“ã¡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã‚’ç¢ºç«‹

## ğŸš¨ ç™ºè¦‹ã•ã‚ŒãŸé‡å¤§ãªé½Ÿé½¬ã¨ä¿®æ­£æ–¹é‡

### 1. ğŸ”¥ Step2å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åé½Ÿé½¬ã®ä¿®æ­£ (æœ€é«˜å„ªå…ˆ)

#### å•é¡Œ: `skeleton.fbx` vs `{model_name}.fbx`
```yaml
# ç¾åœ¨ã®å•é¡Œè¨­å®š
# /app/configs/task/quick_inference_skeleton_articulationxl_ar_256.yaml
export_fbx: skeleton  # âŒ "skeleton.fbx"ã¨ã—ã¦å‡ºåŠ›ã•ã‚Œã‚‹
```

#### æ±ºå®šçš„è§£æ±ºç­–:
```yaml
# ä¿®æ­£å¾Œã®è¨­å®š
export_fbx: "{model_name}"  # âœ… "{model_name}.fbx"ã¨ã—ã¦å‡ºåŠ›ã•ã‚Œã‚‹
```

### 2. ğŸ”¥ Step3è¨­å®šé‡è¤‡å®šç¾©ã®é™¤å» (æœ€é«˜å„ªå…ˆ)

#### å•é¡Œ: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å†…ã®é‡è¤‡writerå®šç¾©
```yaml
# ç¾åœ¨ã®å•é¡Œ - /app/configs/task/quick_inference_unirig_skin.yaml
writer:                    # 1å›ç›®ã®å®šç¾©
  export_npz: "{model_name}_skinning"
  export_fbx: "{model_name}_skinned_unirig"

# ...ä¸­ç•¥...

writer:                    # 2å›ç›®ã®å®šç¾©ï¼ˆé‡è¤‡ï¼‰
  export_npz: predict_skin
  export_fbx: result_fbx
```

#### æ±ºå®šçš„è§£æ±ºç­–:
```yaml
# å˜ä¸€writerå®šç¾©ï¼ˆçµ±ä¸€å‘½åè¦å‰‡æº–æ‹ ï¼‰
writer:
  export_npz: "{model_name}_skinning"
  export_fbx: "{model_name}_skinned_unirig"
```

### 3. ğŸ”¥ generate_skin.shã®npz_dirãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¿®æ­£ (é«˜å„ªå…ˆ)

#### å•é¡Œ: å›ºå®šå€¤ã®å¼·åˆ¶
```bash
# ç¾åœ¨ã®å•é¡Œ
if [ -n "$npz_dir" ]; then
    cmd="$cmd --npz_dir=dataset_inference_clean"  # å›ºå®šå€¤å¼·åˆ¶
fi
```

#### æ±ºå®šçš„è§£æ±ºç­–:
```bash
# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å€¤ã‚’æ­£ã—ãä½¿ç”¨
if [ -n "$npz_dir" ]; then
    cmd="$cmd --npz_dir=$npz_dir"  # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šå€¤ã‚’ä½¿ç”¨
fi
```

## ğŸ› ï¸ å®Ÿè£…ã™ã‚‹ä¿®æ­£ã‚·ã‚¹ãƒ†ãƒ 

### Phase 1: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¿®æ­£

#### quick_inference_skeleton_articulationxl_ar_256.yamlä¿®æ­£
```yaml
# æ±ºã‚æ‰“ã¡ãƒ•ã‚¡ã‚¤ãƒ«åä¿®æ­£
task: inference
writer:
  export_fbx: "{model_name}"      # âœ… ä¿®æ­£: skeleton â†’ {model_name}
  export_npz: predict_skeleton    # âœ… ç¶­æŒ: åŸæµå‡¦ç†æœŸå¾…å€¤
```

#### quick_inference_unirig_skin.yamlä¿®æ­£
```yaml
# é‡è¤‡å®šç¾©ã®å®Œå…¨é™¤å»
task: inference
writer:
  export_npz: "{model_name}_skinning"      # âœ… çµ±ä¸€å‘½åè¦å‰‡
  export_fbx: "{model_name}_skinned_unirig" # âœ… çµ±ä¸€å‘½åè¦å‰‡
# é‡è¤‡writerå®šç¾©ã‚’å®Œå…¨å‰Šé™¤
```

### Phase 2: ã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¿®æ­£

#### generate_skeleton.shä¿®æ­£
```bash
# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å‡¦ç†ã®æ”¹å–„
output_dir=${output_dir:-"results"}
model_name=${model_name:-"unknown"}

# Stage 2ã§ã®--model_nameãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¿½åŠ 
cmd="$cmd --model_name=$model_name"
```

#### generate_skin.shä¿®æ­£
```bash
# npz_dirãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ­£ã—ã„å‡¦ç†
if [ -n "$npz_dir" ]; then
    cmd="$cmd --npz_dir=$npz_dir"     # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šå€¤ä½¿ç”¨
else
    cmd="$cmd --npz_dir=dataset_inference_clean"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®ã¿
fi
```

#### merge.shä¿®æ­£
```bash
# --model_nameãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¿½åŠ ï¼ˆçµ±ä¸€å‘½åè¦å‰‡å¯¾å¿œï¼‰
model_name=""
while [[ "$#" -gt 0 ]]; do
    case $1 in
        --model_name) model_name="$2"; shift ;;
        # ...existing cases...
    esac
    shift
done

# model_nameã‚’src.inference.mergeã«æ¸¡ã™
cmd="$cmd --model_name=$model_name"
```

## ğŸ“ æ±ºã‚æ‰“ã¡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ä»•æ§˜

### ç¢ºå®šãƒ•ã‚¡ã‚¤ãƒ«å‘½åè¦å‰‡
```python
UNIFIED_DATAFLOW_SPECIFICATION = {
    # Step1å‡ºåŠ›ï¼ˆå›ºå®šï¼‰
    "mesh_output": "raw_data.npz",
    
    # Step2å‡ºåŠ›ï¼ˆæ±ºã‚æ‰“ã¡ä¿®æ­£æ¸ˆã¿ï¼‰
    "skeleton_fbx": "{model_name}.fbx",      # âœ… ä¿®æ­£æ¸ˆã¿
    "skeleton_npz": "predict_skeleton.npz",   # âœ… åŸæµå‡¦ç†æœŸå¾…å€¤
    
    # Step3å‡ºåŠ›ï¼ˆæ±ºã‚æ‰“ã¡ä¿®æ­£æ¸ˆã¿ï¼‰
    "skinned_fbx": "{model_name}_skinned_unirig.fbx", # âœ… çµ±ä¸€å‘½å
    "skinned_npz": "{model_name}_skinning.npz",       # âœ… çµ±ä¸€å‘½å
    
    # Step4å‡ºåŠ›ï¼ˆæ±ºã‚æ‰“ã¡ï¼‰
    "merged_fbx": "{model_name}_merged.fbx",   # âœ… çµ±ä¸€å‘½å
    
    # Step5å‡ºåŠ›ï¼ˆæ±ºã‚æ‰“ã¡ï¼‰
    "final_fbx": "{model_name}_final.fbx"     # âœ… çµ±ä¸€å‘½å
}
```

### ç¢ºå®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
```
æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ :
/app/pipeline_work/{model_name}/
â”œâ”€â”€ 01_extracted_mesh/
â”‚   â””â”€â”€ raw_data.npz                           # Step1å‡ºåŠ›
â”œâ”€â”€ 02_skeleton/
â”‚   â”œâ”€â”€ {model_name}.fbx                       # âœ… ä¿®æ­£æ¸ˆã¿
â”‚   â””â”€â”€ predict_skeleton.npz                   # åŸæµå‡¦ç†æœŸå¾…å€¤
â”œâ”€â”€ 03_skinning/
â”‚   â”œâ”€â”€ {model_name}_skinned_unirig.fbx        # âœ… ä¿®æ­£æ¸ˆã¿
â”‚   â””â”€â”€ {model_name}_skinning.npz              # âœ… ä¿®æ­£æ¸ˆã¿
â”œâ”€â”€ 04_merge/
â”‚   â””â”€â”€ {model_name}_merged.fbx                # çµ±ä¸€å‘½å
â””â”€â”€ 05_blender_integration/
    â””â”€â”€ {model_name}_final.fbx                 # çµ±ä¸€å‘½å

# åŸæµå‡¦ç†äº’æ›ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
/app/dataset_inference_clean/{model_name}/
â”œâ”€â”€ raw_data.npz                               # Step1ã‹ã‚‰ã‚³ãƒ”ãƒ¼
â”œâ”€â”€ predict_skeleton.npz                       # Step2ã‹ã‚‰ã‚³ãƒ”ãƒ¼
â”œâ”€â”€ {model_name}.fbx                           # Step2ã‹ã‚‰ã‚³ãƒ”ãƒ¼
â””â”€â”€ inference_datalist.txt                    # æ–°è¦ä½œæˆ
```

## ğŸ”§ å®Ÿè£…æ‰‹é †

### 1. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¿®æ­£å®Ÿè¡Œ
```python
def fix_config_files():
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®é½Ÿé½¬ä¿®æ­£"""
    
    # Step2è¨­å®šä¿®æ­£
    skeleton_config = "/app/configs/task/quick_inference_skeleton_articulationxl_ar_256.yaml"
    fix_skeleton_config(skeleton_config)
    
    # Step3è¨­å®šä¿®æ­£
    skin_config = "/app/configs/task/quick_inference_unirig_skin.yaml"
    fix_skin_config(skin_config)
```

### 2. ã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¿®æ­£å®Ÿè¡Œ
```python
def fix_shell_scripts():
    """ã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®é½Ÿé½¬ä¿®æ­£"""
    
    # generate_skeleton.shä¿®æ­£
    fix_generate_skeleton_script()
    
    # generate_skin.shä¿®æ­£
    fix_generate_skin_script()
    
    # merge.shä¿®æ­£
    fix_merge_script()
```

### 3. step_modulesçµ±åˆç¢ºèª
```python
def verify_dataflow_integrity():
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼æ•´åˆæ€§ã®å®Œå…¨ç¢ºèª"""
    
    checks = [
        verify_file_naming_consistency(),
        verify_directory_structure(),
        verify_original_flow_compatibility(),
        verify_unified_naming_convention()
    ]
    
    return all(checks)
```

## ğŸ“Š ä¿®æ­£å®Œäº†å¾Œã®æ¤œè¨¼é …ç›®

### âœ… ç¢ºèªãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ
- [ ] Step2ãŒ`{model_name}.fbx`ã‚’å‡ºåŠ›ã™ã‚‹
- [ ] Step3è¨­å®šã®é‡è¤‡å®šç¾©ãŒé™¤å»ã•ã‚Œã¦ã„ã‚‹
- [ ] `generate_skin.sh`ã®npz_dirãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒæ­£ã—ãå‡¦ç†ã•ã‚Œã‚‹
- [ ] å…¨ã‚¹ãƒ†ãƒƒãƒ—ãŒçµ±ä¸€å‘½åè¦å‰‡ã«å¾“ã†
- [ ] åŸæµå‡¦ç†ã¨ã®100%äº’æ›æ€§ãŒä¿ãŸã‚Œã‚‹
- [ ] Step1â†’Step2â†’Step3â†’Step4ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ãŒæ±ºã‚æ‰“ã¡ã§å‹•ä½œã™ã‚‹

### ğŸ§ª ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ
```python
def test_unified_dataflow():
    """æ±ºã‚æ‰“ã¡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã®å®Œå…¨ãƒ†ã‚¹ãƒˆ"""
    
    # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«å
    model_name = "test_bird"
    
    # Step1â†’Step2â†’Step3â†’Step4ã®é †æ¬¡å®Ÿè¡Œ
    step1_success = execute_step1(model_name)
    assert step1_success
    
    step2_success = execute_step2(model_name)
    assert step2_success
    assert Path(f"pipeline_work/{model_name}/02_skeleton/{model_name}.fbx").exists()
    
    step3_success = execute_step3(model_name)
    assert step3_success
    assert Path(f"pipeline_work/{model_name}/03_skinning/{model_name}_skinned_unirig.fbx").exists()
    
    step4_success = execute_step4(model_name)
    assert step4_success
    assert Path(f"pipeline_work/{model_name}/04_merge/{model_name}_merged.fbx").exists()
```

## ğŸš¨ é‡è¦ãªæ³¨æ„äº‹é …

### ä¿®æ­£ä½œæ¥­ã®æ³¨æ„ç‚¹
1. **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¿…é ˆ**: å…¨ä¿®æ­£å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ
2. **æ®µéšçš„ä¿®æ­£**: ä¸€ã¤ãšã¤ä¿®æ­£ã—ã¦å‹•ä½œç¢ºèª
3. **äº’æ›æ€§ç¢ºèª**: å„ä¿®æ­£å¾Œã«åŸæµå‡¦ç†ã¨ã®äº’æ›æ€§ç¢ºèª
4. **ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ**: ä¿®æ­£å®Œäº†å¾Œã®ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

### å¤±æ•—æ™‚ã®å¾©æ—§è¨ˆç”»
```python
BACKUP_FILES = [
    "configs/task/quick_inference_skeleton_articulationxl_ar_256.yaml",
    "configs/task/quick_inference_unirig_skin.yaml",
    "launch/inference/generate_skeleton.sh",
    "launch/inference/generate_skin.sh",
    "launch/inference/merge.sh"
]

def create_backups():
    """ä¿®æ­£å‰ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ"""
    for file_path in BACKUP_FILES:
        shutil.copy2(file_path, f"{file_path}.backup_{timestamp}")

def restore_backups():
    """å•é¡Œç™ºç”Ÿæ™‚ã®å¾©æ—§"""
    for file_path in BACKUP_FILES:
        backup_file = f"{file_path}.backup_{timestamp}"
        if Path(backup_file).exists():
            shutil.copy2(backup_file, file_path)
```

---

## ğŸ¯ æœŸå¾…ã•ã‚Œã‚‹æˆæœ

### ä¿®æ­£å®Œäº†å¾Œã®çŠ¶æ…‹
- âœ… å…¨ãƒ•ã‚¡ã‚¤ãƒ«å‘½åãŒæ±ºã‚æ‰“ã¡ã§äºˆæ¸¬å¯èƒ½
- âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®é‡è¤‡ãƒ»çŸ›ç›¾ãŒå®Œå…¨é™¤å»
- âœ… ã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒæ­£ã—ãå‡¦ç†ã•ã‚Œã‚‹
- âœ… åŸæµå‡¦ç†ã¨ã®100%äº’æ›æ€§ç¶­æŒ
- âœ… Step1â†’Step2â†’Step3â†’Step4â†’Step5ã®å®Œå…¨è‡ªå‹•åŒ–

### ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ä¿¡é ¼æ€§ã®å‘ä¸Š
- ğŸš« ãƒ•ã‚¡ã‚¤ãƒ«åã®ä¸æ•´åˆã«ã‚ˆã‚‹ã‚¨ãƒ©ãƒ¼é™¤å»
- ğŸš« è¨­å®šã®é‡è¤‡ãƒ»çŸ›ç›¾ã«ã‚ˆã‚‹ã‚¨ãƒ©ãƒ¼é™¤å»
- ğŸš« ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼ã®é™¤å»
- âœ… æ±ºã‚æ‰“ã¡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã«ã‚ˆã‚‹ç¢ºå®Ÿæ€§ä¿è¨¼

---

**ğŸ“… ä½œæˆæ—¥**: 2025å¹´6æœˆ14æ—¥  
**ğŸ¯ å¯¾è±¡**: UniRigé–‹ç™ºãƒãƒ¼ãƒ ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼æ•´åˆæ€§ç¢ºä¿ï¼‰  
**ğŸ“ é‡è¦åº¦**: æœ€é«˜ï¼ˆæ±ºã‚æ‰“ã¡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼å®Ÿç¾ã«å¿…é ˆï¼‰  
**ğŸ”„ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: ä¿®æ­£è¨ˆç”»ç­–å®šå®Œäº†ã€å®Ÿè£…æº–å‚™å®Œäº†

**âš ï¸ é‡è¦**: ã“ã®ä¿®æ­£ã‚·ã‚¹ãƒ†ãƒ ã¯ã€UniRigã®æ±ºã‚æ‰“ã¡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼å®Ÿç¾ã®ãŸã‚ã®æœ€é‡è¦ä½œæ¥­ã§ã™ã€‚ã™ã¹ã¦ã®é½Ÿé½¬ã‚’è§£æ±ºã—ã€ç¢ºå®Ÿãªãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã‚’ç¢ºç«‹ã—ã¾ã™ã€‚
