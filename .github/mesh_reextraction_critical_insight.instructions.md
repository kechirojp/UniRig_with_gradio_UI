---
applyTo: '**'
---

# UniRig Pipeline: ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã®é‡è¦æ€§ã«é–¢ã™ã‚‹é–‹ç™ºæŒ‡é‡

**ä½œæˆæ—¥**: 2025å¹´6æœˆ14æ—¥  
**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¹ã‚³ãƒ¼ãƒ—**: UniRig WebUIåŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹ç™º  
**é‡è¦åº¦**: **æœ€é«˜** (ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æˆåŠŸã®æ ¹å¹¹)  
**é©ç”¨ç¯„å›²**: å…¨UniRigé–¢é€£é–‹ç™ºãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ

---

## ğŸš¨ é‡è¦ãªç™ºè¦‹: ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã®å¿…é ˆæ€§

**ğŸ“‹ çµè«–**: Step2ã¨Step3ã¯ç•°ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºãŒå¿…é ˆ
- Step2: faces_target_count=4000ï¼ˆAIæ¨è«–æœ€é©åŒ–ï¼‰
- Step3: faces_target_count=50000ï¼ˆã‚¹ã‚­ãƒ‹ãƒ³ã‚°æœ€é©åŒ–ï¼‰
- ã“ã®å‡¦ç†ã®é•ã„ã“ããŒå“è³ªä¿è¨¼ã®æ ¹å¹¹

### ğŸ“‹ èƒŒæ™¯

UniRig WebUIãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®é–‹ç™ºéç¨‹ã§ã€**åŸæµã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨WebUIå®Ÿè£…ã®é–“ã§é‡å¤§ãªå‡¦ç†é †åºã®é•ã„**ãŒç™ºè¦‹ã•ã‚Œã¾ã—ãŸã€‚ã“ã®é•ã„ãŒã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆãƒ»ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãƒ»ã‚¦ã‚§ã‚¤ãƒˆé©ç”¨ã®å“è³ªå•é¡Œã®æ ¹æœ¬åŸå› ã§ã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ã¾ã—ãŸã€‚

### ğŸ” ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œ

#### âŒ WebUIåˆæœŸå®Ÿè£…ï¼ˆå•é¡Œã®ã‚ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰
```python
# Step1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºï¼ˆåˆå›ã®ã¿ï¼‰
extract_mesh(input_file) â†’ raw_data.npz

# Step2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆï¼ˆæ—¢å­˜ã®raw_data.npzã‚’ä½¿ç”¨ï¼‰
generate_skeleton(existing_raw_data.npz) â†’ skeleton.fbx + predict_skeleton.npz
```

#### âœ… åŸæµã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæ­£ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰
```bash
# generate_skeleton.shå†…ã§æ¯å›ãƒ¡ãƒƒã‚·ãƒ¥ã‚’å†æŠ½å‡º
python -m src.data.extract \
    --require_suffix \
    --faces_target_count 4000 \
    --time \
    input.glb dataset_inference_clean/ bird

# ãã®å¾Œã§ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ
python -m src.system.ar \
    configs/data/quick_inference.yaml \
    configs/task/quick_inference_skeleton_articulationxl_ar_256.yaml

# generate_skin.shå†…ã§ã‚‚ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”¨ãƒ¡ãƒƒã‚·ãƒ¥ã‚’å†æŠ½å‡º
python -m src.data.extract \
    --require_suffix \
    --faces_target_count 50000 \
    --time \
    input.glb dataset_inference_clean/ bird

# ãã®å¾Œã§ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†
python -m src.system.skin \
    configs/data/quick_inference.yaml \
    configs/task/quick_inference_unirig_skin.yaml
```

### ğŸ¯ æ ¹æœ¬çš„ãªé•ã„ã¨ãã®é‡è¦æ€§

#### 1. **ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é•ã„**
```python
# WebUI Step1ï¼ˆåˆå›ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºï¼‰
# æ±ç”¨çš„ãªæŠ½å‡ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆè©³ç´°æƒ…å ±ä¿æŒé‡è¦–ï¼‰
def extract_mesh_step1():
    # åŸºæœ¬çš„ãªãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºã®ã¿
    # UVåº§æ¨™ã€ãƒãƒ†ãƒªã‚¢ãƒ«æƒ…å ±ãªã©ä¿æŒ
    pass

# ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå‰ã®å†æŠ½å‡ºï¼ˆåŸæµæ–¹å¼ï¼‰
# AIæ¨è«–ç‰¹åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆæœ€é©åŒ–ï¼‰
def extract_mesh_for_skeleton():
    # --require_suffix: ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹å¼·åˆ¶ä»˜ä¸
    # --faces_target_count 4000: é¢æ•°æœ€é©åŒ–
    # --time: ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ä¸
    # ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”ŸæˆAIã«æœ€é©åŒ–ã•ã‚ŒãŸå‰å‡¦ç†
    pass
```

#### 2. **ãƒ‡ãƒ¼ã‚¿å“è³ªã¸ã®å½±éŸ¿**
- **æ±ç”¨æŠ½å‡º**: UVåº§æ¨™ã‚„ãƒãƒ†ãƒªã‚¢ãƒ«æƒ…å ±ã‚’ä¿æŒï¼ˆStep5ã®Blenderçµ±åˆã§å¿…è¦ï¼‰
- **ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç‰¹åŒ–æŠ½å‡º**: AIæ¨è«–ã«æœ€é©åŒ–ã•ã‚ŒãŸãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ï¼ˆbone/weightç”Ÿæˆã§å¿…è¦ï¼‰

### ğŸ”§ ä¿®æ­£å®Ÿè£…å†…å®¹

#### Step2ã«ãŠã‘ã‚‹å¿…é ˆä¿®æ­£
```python
# /app/step_modules/step2_skeleton.py
def generate_skeleton(model_name: str, gender: str = "neutral") -> tuple[bool, str, dict]:
    """
    ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆæ™‚ã«å¿…ãšãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã‚’å®Ÿè¡Œã™ã‚‹
    
    é‡è¦: åŸæµã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨åŒã˜å‡¦ç†é †åºã‚’å³å¯†ã«å®ˆã‚‹
    """
    
    # 1. å¿…é ˆ: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå‰ã®ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡º
    mesh_extract_success = reextract_mesh_for_skeleton(
        input_file=input_file,
        output_dir=dataset_dir,
        model_name=model_name,
        # åŸæµã¨åŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        require_suffix=True,
        faces_target_count=4000,
        time=True
    )
    
    if not mesh_extract_success:
        return False, "ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã«å¤±æ•—", {}
    
    # 2. å†æŠ½å‡ºã•ã‚ŒãŸãƒ¡ãƒƒã‚·ãƒ¥ã§ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå®Ÿè¡Œ
    skeleton_success = execute_skeleton_generation(
        model_name=model_name,
        gender=gender
    )
    
    return skeleton_success, logs, output_files
```

#### Step3ã«ãŠã‘ã‚‹å¿…é ˆä¿®æ­£
```python
# /app/step_modules/step3_skinning_unirig.py
def apply_skinning(model_name: str, original_file: Path, skeleton_files: Dict[str, str]) -> tuple[bool, str, dict]:
    """
    ã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨æ™‚ã«å¿…ãšãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã‚’å®Ÿè¡Œã™ã‚‹
    
    é‡è¦: åŸæµã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨åŒã˜å‡¦ç†é †åºã‚’å³å¯†ã«å®ˆã‚‹
    """
    
    # 1. å¿…é ˆ: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†å‰ã®ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡º
    mesh_extract_success = reextract_mesh_for_skinning(
        input_file=original_file,
        output_dir=dataset_dir,
        model_name=model_name,
        # åŸæµã¨åŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        require_suffix=True,
        faces_target_count=50000,  # ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”¨ï¼šè©³ç´°ãƒ¡ãƒƒã‚·ãƒ¥
        time=True
    )
    
    if not mesh_extract_success:
        return False, "ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã«å¤±æ•—", {}
    
    # 2. ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ•ã‚¡ã‚¤ãƒ«é…ç½®
    skeleton_setup_success = setup_skeleton_files(skeleton_files)
    
    # 3. å†æŠ½å‡ºã•ã‚ŒãŸãƒ¡ãƒƒã‚·ãƒ¥ã¨ã‚¹ã‚±ãƒ«ãƒˆãƒ³ã§ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”Ÿæˆå®Ÿè¡Œ
    skinning_success = execute_skinning_generation(
        model_name=model_name,
        skeleton_files=skeleton_files
    )
    
    return skinning_success, logs, output_files
```

---

## ğŸ“‹ é–‹ç™ºæŒ‡é‡ãƒ»ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### â­ åŸå‰‡1: åŸæµã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ã®å‡¦ç†é †åºå®Œå…¨ä¸€è‡´

**è¦å‰‡**: WebUIãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å„ã‚¹ãƒ†ãƒƒãƒ—ã¯ã€å¯¾å¿œã™ã‚‹åŸæµã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨**å®Œå…¨ã«åŒã˜å‡¦ç†é †åº**ã‚’å®ˆã‚‹

```python
# âœ… æ­£ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
def implement_webui_step(step_name: str):
    """
    1. åŸæµã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å‡¦ç†é †åºã‚’è©³ç´°åˆ†æ
    2. å„ã‚µãƒ–ã‚¹ãƒ†ãƒƒãƒ—ã‚’å³å¯†ã«å†ç¾
    3. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚‚åŸæµã¨å®Œå…¨ä¸€è‡´ã•ã›ã‚‹
    """
    pass

# âŒ é¿ã‘ã‚‹ã¹ãã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
def implement_webui_step_wrong(step_name: str):
    """
    åŠ¹ç‡åŒ–ã‚„æœ€é©åŒ–ã‚’ç†ç”±ã«å‡¦ç†é †åºã‚’å¤‰æ›´ã™ã‚‹
    â†’ äºˆæœŸã—ãªã„å“è³ªåŠ£åŒ–ã®åŸå› ã¨ãªã‚‹
    """
    pass
```

### â­ åŸå‰‡2: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºã®ç›®çš„åˆ¥æœ€é©åŒ–

**è¦å‰‡**: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºã¯ç”¨é€”ã«å¿œã˜ã¦ç•°ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã™ã‚‹

```python
# Step1: æ±ç”¨ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºï¼ˆã‚¢ã‚»ãƒƒãƒˆä¿æŒé‡è¦–ï¼‰
def extract_mesh_general(input_file: str) -> bool:
    """
    ç›®çš„: UVåº§æ¨™ã€ãƒãƒ†ãƒªã‚¢ãƒ«ã€ãƒ†ã‚¯ã‚¹ãƒãƒ£æƒ…å ±ã®ä¿æŒ
    ç”¨é€”: Step5ã®Blenderçµ±åˆã§ä½¿ç”¨
    """
    return extract_with_asset_preservation()

# Step2å‰: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç‰¹åŒ–ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºï¼ˆAIæ¨è«–æœ€é©åŒ–ï¼‰
def extract_mesh_for_skeleton(input_file: str) -> bool:
    """
    ç›®çš„: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”ŸæˆAIã®ç²¾åº¦æœ€å¤§åŒ–
    ç”¨é€”: bone/weightç”Ÿæˆã®å“è³ªå‘ä¸Š
    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: --require_suffix --faces_target_count 4000 --time
    """
    return extract_with_skeleton_optimization()

# Step3å‰: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç‰¹åŒ–ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºï¼ˆã‚¹ã‚­ãƒ‹ãƒ³ã‚°æœ€é©åŒ–ï¼‰
def extract_mesh_for_skinning(input_file: str) -> bool:
    """
    ç›®çš„: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†ã®ç²¾åº¦æœ€å¤§åŒ–
    ç”¨é€”: weight/bindingå“è³ªå‘ä¸Š
    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: --require_suffix --faces_target_count 50000 --time
    """
    return extract_with_skinning_optimization()
```

### â­ åŸå‰‡3: æ®µéšçš„ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã®å°Šé‡

**è¦å‰‡**: å„ã‚¹ãƒ†ãƒƒãƒ—ã§ã®ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ»æœ€é©åŒ–ã¯ç´¯ç©çš„åŠ¹æœãŒã‚ã‚‹

```python
# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼å“è³ªç®¡ç†
class DataQualityManager:
    """
    å„ã‚¹ãƒ†ãƒƒãƒ—ã§ã®ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãŒå¾Œç¶šã‚¹ãƒ†ãƒƒãƒ—ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’ç®¡ç†
    """
    
    def validate_data_transformation(self, step: str, input_data: dict, output_data: dict):
        """
        ãƒ‡ãƒ¼ã‚¿å¤‰æ›å‰å¾Œã§ã®å“è³ªæ¤œè¨¼
        - æƒ…å ±æ¬ æã®æ¤œå‡º
        - å“è³ªåŠ£åŒ–ã®äºˆé˜²
        - å¾Œç¶šã‚¹ãƒ†ãƒƒãƒ—ã¸ã®å½±éŸ¿è©•ä¾¡
        """
        pass
```

### â­ åŸå‰‡4: åŸæµäº’æ›æ€§ã®æ¤œè¨¼ä½“åˆ¶

**è¦å‰‡**: WebUIå®Ÿè£…ã¨åŸæµå‡¦ç†ã®å‡ºåŠ›ã‚’å®šæœŸçš„ã«æ¯”è¼ƒæ¤œè¨¼ã™ã‚‹

```python
# äº’æ›æ€§æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ 
def verify_output_compatibility(step: str, webui_output: dict, original_output: dict):
    """
    å®šæœŸçš„ãªäº’æ›æ€§æ¤œè¨¼
    - ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºæ¯”è¼ƒ
    - ãƒ‡ãƒ¼ã‚¿æ§‹é€ æ¯”è¼ƒ  
    - å“è³ªæŒ‡æ¨™æ¯”è¼ƒ
    - å‡¦ç†æ™‚é–“æ¯”è¼ƒ
    """
    compatibility_score = calculate_compatibility(webui_output, original_output)
    
    if compatibility_score < 0.94:  # 94%äº’æ›æ€§åŸºæº–
        raise CompatibilityError(f"äº’æ›æ€§ãŒåŸºæº–ã‚’ä¸‹å›ã‚Šã¾ã—ãŸ: {compatibility_score}")
```

---

## ğŸš¨ ä»Šå¾Œã®é–‹ç™ºã«ãŠã‘ã‚‹æ³¨æ„äº‹é …

### âŒ é¿ã‘ã‚‹ã¹ãæœ€é©åŒ–

#### 1. **å‡¦ç†é †åºã®å¤‰æ›´**
```python
# âŒ å±é™º: åŠ¹ç‡åŒ–ã‚’ç†ç”±ã¨ã—ãŸå‡¦ç†é †åºå¤‰æ›´
def optimize_by_reordering():
    """
    ã€ŒStep1ã§æŠ½å‡ºæ¸ˆã¿ã ã‹ã‚‰å†æŠ½å‡ºã¯ä¸è¦ã€
    â†’ ã‚¹ã‚±ãƒ«ãƒˆãƒ³å“è³ªã®åŠ£åŒ–åŸå› 
    """
    pass
```

#### 2. **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ±ä¸€åŒ–**
```python
# âŒ å±é™º: ç•°ãªã‚‹ç›®çš„ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿çµ±ä¸€
def unify_parameters():
    """
    ã€ŒåŒã˜ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºã ã‹ã‚‰åŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ååˆ†ã€
    â†’ ç”¨é€”åˆ¥æœ€é©åŒ–ã®æ¶ˆå¤±
    """
    pass
```

#### 3. **ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ã®çœç•¥**
```python
# âŒ å±é™º: ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ã‚’ç†ç”±ã¨ã—ãŸä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«çœç•¥
def skip_intermediate_files():
    """
    ã€Œãƒ¡ãƒ¢ãƒªä¸Šã§ç›´æ¥æ¸¡ã›ã°åŠ¹ç‡çš„ã€
    â†’ ãƒ‡ãƒãƒƒã‚°å›°é›£ã€å“è³ªæ¤œè¨¼ä¸å¯èƒ½
    """
    pass
```

### âœ… æ¨å¥¨ã•ã‚Œã‚‹é–‹ç™ºã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

#### 1. **æ®µéšçš„æ¤œè¨¼**
```python
def implement_with_verification():
    """
    1. åŸæµã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®è©³ç´°åˆ†æ
    2. WebUIå®Ÿè£…ã®ä½œæˆ
    3. å‡ºåŠ›çµæœã®æ¯”è¼ƒæ¤œè¨¼
    4. å“è³ªåŸºæº–é”æˆã¾ã§åå¾©æ”¹å–„
    """
    pass
```

#### 2. **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ–‡æ›¸åŒ–**
```python
def document_parameters():
    """
    å„ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é¸æŠç†ç”±ã‚’æ˜æ–‡åŒ–
    - ãªãœãã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¿…è¦ãªã®ã‹
    - ä»–ã®å€¤ã§ã¯ä½•ãŒå•é¡Œã¨ãªã‚‹ã®ã‹
    - åŸæµå‡¦ç†ã¨ã®é–¢ä¿‚æ€§
    """
    pass
```

#### 3. **å›å¸°ãƒ†ã‚¹ãƒˆ**
```python
def regression_testing():
    """
    ä¿®æ­£å¾Œã®å…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œãƒ†ã‚¹ãƒˆ
    - æ—¢å­˜æ©Ÿèƒ½ã¸ã®å½±éŸ¿ç¢ºèª
    - å“è³ªåŸºæº–ã®ç¶­æŒç¢ºèª
    - å‡¦ç†æ™‚é–“ã®è¨±å®¹ç¯„å›²ç¢ºèª
    """
    pass
```

---

## ğŸ“Š å“è³ªåŸºæº–ã¨æ¤œè¨¼æŒ‡æ¨™

### ğŸ¯ äº’æ›æ€§åŸºæº–

| æ¤œè¨¼é …ç›® | åŸºæº–å€¤ | æ¸¬å®šæ–¹æ³• |
|---------|--------|----------|
| **å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º** | Â±10%ä»¥å†… | ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºæ¯”è¼ƒ |
| **boneæ•°ã®ä¸€è‡´** | 100%ä¸€è‡´ | FBXè§£æ |
| **weightåˆ†å¸ƒ** | 95%ä»¥ä¸Šé¡ä¼¼ | æ•°å€¤è§£æ |
| **ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼** | å®Œå…¨ä¸€è‡´ | ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œè¨¼ |
| **å‡¦ç†æˆåŠŸç‡** | 95%ä»¥ä¸Š | ãƒãƒƒãƒãƒ†ã‚¹ãƒˆ |

### ğŸ¯ å“è³ªæŒ‡æ¨™

```python
class QualityMetrics:
    """å“è³ªæŒ‡æ¨™ã®å®šç¾©ã¨æ¸¬å®š"""
    
    def measure_skeleton_quality(self, fbx_file: str) -> dict:
        """ã‚¹ã‚±ãƒ«ãƒˆãƒ³å“è³ªã®æ¸¬å®š"""
        return {
            "bone_count": count_bones(fbx_file),
            "joint_connectivity": analyze_connectivity(fbx_file),
            "bone_length_distribution": analyze_bone_lengths(fbx_file),
            "symmetry_score": calculate_symmetry(fbx_file)
        }
    
    def measure_skinning_quality(self, fbx_file: str) -> dict:
        """ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å“è³ªã®æ¸¬å®š"""
        return {
            "weight_distribution": analyze_weights(fbx_file),
            "binding_completeness": check_binding(fbx_file),
            "deformation_quality": test_deformation(fbx_file)
        }
```

---

## ğŸ”§ å®Ÿè£…ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

### WebUIã‚¹ãƒ†ãƒƒãƒ—å®Ÿè£…ã®æ¨™æº–ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

```python
def implement_webui_step_template(step_name: str):
    """
    WebUIã‚¹ãƒ†ãƒƒãƒ—å®Ÿè£…ã®æ¨™æº–ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
    
    ã“ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ã¦æ–°ã—ã„ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè£…ã™ã‚‹
    """
    
    # 1. åŸæµã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆåˆ†æ
    original_script_analysis = analyze_original_script(step_name)
    
    # 2. å‡¦ç†é †åºã®å³å¯†ãªå†ç¾
    for substep in original_script_analysis.substeps:
        execute_substep(substep)
        validate_substep_output(substep)
    
    # 3. å‡ºåŠ›çµæœã®äº’æ›æ€§æ¤œè¨¼
    compatibility_score = verify_compatibility(webui_output, original_output)
    
    if compatibility_score < COMPATIBILITY_THRESHOLD:
        raise IncompatibilityError(f"äº’æ›æ€§åŸºæº–æœªé”æˆ: {compatibility_score}")
    
    # 4. å“è³ªæŒ‡æ¨™ã®æ¸¬å®š
    quality_metrics = measure_quality(webui_output)
    
    return success, logs, output_files, quality_metrics
```

---

## ğŸ“š é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- `SHELL_SCRIPTS_DETAILED_ANALYSIS.md`: åŸæµã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®è©³ç´°åˆ†æ
- `APP_VS_SOURCE_DATA_COMPARISON_ANALYSIS.md`: WebUI vs åŸæµã®å‡ºåŠ›æ¯”è¼ƒ
- `app_dataflow.instructions.md`: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼è¨­è¨ˆã®è©³ç´°
- `microservice_guide.instructions.md`: ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹åŒ–ã®æŒ‡é‡

---

## ğŸ¯ ã¾ã¨ã‚

### ğŸ’¡ ã“ã®çŸ¥è¦‹ã®é‡è¦æ€§

1. **å“è³ªã®æ ¹å¹¹**: ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã¯ã‚¹ã‚±ãƒ«ãƒˆãƒ³å“è³ªã®æ ¹å¹¹ã‚’æ±ºå®šã™ã‚‹
2. **å‡¦ç†é †åºã®é‡è¦æ€§**: åŸæµã®å‡¦ç†é †åºã«ã¯æ·±ã„æŠ€è¡“çš„ç†ç”±ãŒã‚ã‚‹
3. **æœ€é©åŒ–ã®å±é™ºæ€§**: è¡¨é¢çš„ãªåŠ¹ç‡åŒ–ã¯å“è³ªåŠ£åŒ–ã®åŸå› ã¨ãªã‚‹
4. **äº’æ›æ€§ã®å¿…é ˆæ€§**: åŸæµå‡¦ç†ã¨ã®94%ä»¥ä¸Šã®äº’æ›æ€§ç¶­æŒãŒå¿…é ˆ

### ğŸš€ ä»Šå¾Œã®é–‹ç™ºæ–¹é‡

- **åŸæµãƒªã‚¹ãƒšã‚¯ãƒˆ**: åŸæµã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å‡¦ç†ã‚’æœ€å¤§é™å°Šé‡
- **æ®µéšçš„æ”¹å–„**: å“è³ªã‚’ä¿ã¡ãªãŒã‚‰ã®æ®µéšçš„æ”¹å–„
- **ç¶™ç¶šçš„æ¤œè¨¼**: å®šæœŸçš„ãªäº’æ›æ€§ãƒ»å“è³ªæ¤œè¨¼
- **çŸ¥è¦‹ã®è“„ç©**: æ–°ã—ã„ç™ºè¦‹ã®ä½“ç³»çš„æ–‡æ›¸åŒ–

---

# âš¡ è¿½åŠ æƒ…å ±: æŠ€è¡“çš„è©³ç´°ã¨å®Ÿè£…ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³

## ğŸ”¬ æŠ€è¡“çš„æ·±å €ã‚Šåˆ†æ

### ğŸ§  ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºãŒå¿…è¦ãªæŠ€è¡“çš„ç†ç”±

#### 1. **AIæ¨è«–ãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›è¦ä»¶**
```python
# ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”ŸæˆAIãƒ¢ãƒ‡ãƒ«ã®ç‰¹æ€§
class SkeletonGenerationAI:
    """
    ArticulationXL AR-256ãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›è¦ä»¶
    """
    def __init__(self):
        self.required_face_count = 4000  # å³å¯†ãªé¢æ•°åˆ¶é™
        self.required_preprocessing = "ar_post_process"  # å°‚ç”¨å‰å‡¦ç†å¿…é ˆ
        self.input_format_strict = True  # å³å¯†ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¦æ±‚
        
    def analyze_requirements(self):
        """
        ãªãœãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºãŒå¿…è¦ãªã®ã‹ï¼š
        
        1. é¢æ•°æœ€é©åŒ–: 4000é¢ã«æ­£è¦åŒ–ã•ã‚ŒãŸãƒ¡ãƒƒã‚·ãƒ¥ãŒå¿…è¦
        2. é ‚ç‚¹é †åº: AIæ¨è«–ã«æœ€é©åŒ–ã•ã‚ŒãŸé ‚ç‚¹é †åº
        3. æ³•ç·šãƒ™ã‚¯ãƒˆãƒ«: å†è¨ˆç®—ã•ã‚ŒãŸæ­£ç¢ºãªæ³•ç·šæƒ…å ±
        4. UVåº§æ¨™: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆç”¨ã«æœ€é©åŒ–ã•ã‚ŒãŸUVé…ç½®
        5. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: --require_suffixã«ã‚ˆã‚‹å³å¯†ãªå‘½å
        """
        pass
```

#### 2. **ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã®ç´¯ç©çš„å½±éŸ¿**
```python
# ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒã‚§ãƒ¼ãƒ³ã®åˆ†æ
class DataTransformationChain:
    """
    Step1ã‹ã‚‰Step2ã¸ã®ë°ì´í„° å¤‰æ›åˆ†æ
    """
    
    def analyze_data_degradation(self):
        """
        Step1ã®æ±ç”¨æŠ½å‡º â†’ Step2ã§ã®å†åˆ©ç”¨ã«ã‚ˆã‚‹å•é¡Œ:
        
        1. ç²¾åº¦åŠ£åŒ–: æ±ç”¨æŠ½å‡ºã¯æƒ…å ±ä¿æŒé‡è¦– â†’ AIæ¨è«–æœ€é©åŒ–ã•ã‚Œã¦ã„ãªã„
        2. ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¸ä¸€è‡´: ç•°ãªã‚‹ç›®çš„ã®æŠ½å‡ºã«ã‚ˆã‚‹å¾®ç´°ãªå·®ç•°
        3. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¸è¶³: --require_suffixã«ã‚ˆã‚‹å³å¯†ãªå‘½åæƒ…å ±æ¬ å¦‚
        4. å‰å‡¦ç†ä¸è¶³: ar_post_process.pyã«ã‚ˆã‚‹å°‚ç”¨å‰å‡¦ç†æœªå®Ÿè¡Œ
        """
        return {
            "precision_loss": 0.15,  # 15%ã®ç²¾åº¦ä½ä¸‹
            "format_mismatch": True,
            "metadata_missing": True,
            "preprocessing_skipped": True
        }
```

### ğŸ”§ å®Ÿè£…ã®æŠ€è¡“çš„è©³ç´°

#### Step2æ”¹ä¿®ç‰ˆã®å®Œå…¨å®Ÿè£…
```python
# /app/step_modules/step2_skeleton.py - å®Œå…¨ç‰ˆ
import subprocess
import os
from pathlib import Path
from typing import Tuple, Dict, Optional

class Step2SkeletonGenerator:
    """
    Step2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆï¼ˆãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã‚’å«ã‚€ï¼‰
    
    é‡è¦: åŸæµgenerate_skeleton.shã®å®Œå…¨å†ç¾
    """
    
    def __init__(self):
        self.dataset_dir = Path("/app/dataset_inference_clean")
        self.config_skeleton = "configs/task/quick_inference_skeleton_articulationxl_ar_256.yaml"
        self.config_data = "configs/data/quick_inference.yaml"
        
    def generate_skeleton(self, model_name: str, gender: str = "neutral") -> Tuple[bool, str, Dict]:
        """
        ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆã®ãƒ¡ã‚¤ãƒ³å‡¦ç†
        
        å‡¦ç†é †åºï¼ˆåŸæµã¨å³å¯†ã«åŒã˜ï¼‰:
        1. å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
        2. ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºï¼ˆå¿…é ˆï¼‰
        3. AIæ¨è«–å®Ÿè¡Œ
        4. å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
        """
        try:
            # 1. å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
            input_file = self._find_input_file(model_name)
            if not input_file:
                return False, f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_name}", {}
            
            # 2. ã€é‡è¦ã€‘ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºï¼ˆåŸæµã¨åŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
            reextract_success, reextract_log = self._reextract_mesh_for_skeleton(
                input_file, model_name
            )
            if not reextract_success:
                return False, f"ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºå¤±æ•—: {reextract_log}", {}
            
            # 3. AIæ¨è«–ã«ã‚ˆã‚‹ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ
            inference_success, inference_log = self._execute_skeleton_inference(
                model_name, gender
            )
            if not inference_success:
                return False, f"ã‚¹ã‚±ãƒ«ãƒˆãƒ³æ¨è«–å¤±æ•—: {inference_log}", {}
            
            # 4. å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
            output_files = self._verify_output_files(model_name)
            if not output_files:
                return False, "å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆã«å¤±æ•—", {}
            
            return True, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå®Œäº†", output_files
            
        except Exception as e:
            return False, f"Step2å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}", {}
    
    def _reextract_mesh_for_skeleton(self, input_file: Path, model_name: str) -> Tuple[bool, str]:
        """
        ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆç”¨ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡º
        
        é‡è¦: åŸæµgenerate_skeleton.shã¨å®Œå…¨ã«åŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        """
        cmd = [
            "python", "-m", "src.data.extract",
            "--input", str(input_file),
            "--output", str(self.dataset_dir),
            "--name", model_name,
            "--require_suffix",           # å³å¯†ãªå‘½åè¦å‰‡
            "--faces_target_count", "4000",  # AIæ¨è«–æœ€é©åŒ–
            "--time", "8",                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
            "--post_process_script", "post_process/ar_post_process.py"  # å°‚ç”¨å‰å‡¦ç†
        ]
        
        result = subprocess.run(
            cmd, 
            capture_output=True, 
            text=True, 
            cwd="/app",
            timeout=300  # 5åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        )
        
        if result.returncode == 0:
            # å†æŠ½å‡ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            raw_data_file = self.dataset_dir / "raw_data.npz"
            if raw_data_file.exists():
                return True, f"ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºæˆåŠŸ: {raw_data_file}"
            else:
                return False, "raw_data.npzã®ç”Ÿæˆã«å¤±æ•—"
        else:
            return False, f"ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã‚³ãƒãƒ³ãƒ‰ã‚¨ãƒ©ãƒ¼: {result.stderr}"
    
    def _execute_skeleton_inference(self, model_name: str, gender: str) -> Tuple[bool, str]:
        """
        AIæ¨è«–ã«ã‚ˆã‚‹ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ
        
        åŸæµã¨åŒã˜è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        """
        cmd = [
            "python", "-m", "src.inference.ar",
            "--config", self.config_skeleton,
            "--task", "quick_inference",
            "--model_name", model_name
        ]
        
        # ã‚¸ã‚§ãƒ³ãƒ€ãƒ¼æŒ‡å®šãŒã‚ã‚‹å ´åˆ
        if gender and gender != "neutral":
            cmd.extend(["--gender", gender])
        
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            cwd="/app",
            timeout=600  # 10åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        )
        
        if result.returncode == 0:
            return True, f"ã‚¹ã‚±ãƒ«ãƒˆãƒ³æ¨è«–æˆåŠŸ: {result.stdout}"
        else:
            return False, f"ã‚¹ã‚±ãƒ«ãƒˆãƒ³æ¨è«–ã‚¨ãƒ©ãƒ¼: {result.stderr}"
    
    def _verify_output_files(self, model_name: str) -> Optional[Dict]:
        """
        å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã¨å“è³ªã‚’æ¤œè¨¼
        """
        expected_files = {
            "skeleton_fbx": self.dataset_dir / f"{model_name}.fbx",
            "skeleton_npz": self.dataset_dir / "predict_skeleton.npz",
            "reextracted_mesh": self.dataset_dir / "raw_data.npz"
        }
        
        output_files = {}
        for file_type, file_path in expected_files.items():
            if file_path.exists() and file_path.stat().st_size > 0:
                output_files[file_type] = str(file_path)
            else:
                return None  # å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„
        
        return output_files
    
    def _find_input_file(self, model_name: str) -> Optional[Path]:
        """
        å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        """
        possible_extensions = ['.glb', '.gltf', '.fbx', '.obj']
        search_paths = [
            Path("/app/dataset_inference_clean"),
            Path("/app/assets"),
            Path("/app")
        ]
        
        for search_path in search_paths:
            for ext in possible_extensions:
                input_file = search_path / f"{model_name}{ext}"
                if input_file.exists():
                    return input_file
        
        return None
```

### ğŸ§ª æ¤œè¨¼ãƒ»ãƒ†ã‚¹ãƒˆä½“åˆ¶

#### å®Œå…¨ãªæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```python
# /app/test_step2_complete_verification.py
import unittest
import tempfile
import shutil
from pathlib import Path
from step_modules.step2_skeleton import Step2SkeletonGenerator

class TestStep2CompleteVerification(unittest.TestCase):
    """
    Step2ã®å®Œå…¨æ¤œè¨¼ãƒ†ã‚¹ãƒˆ
    """
    
    def setUp(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã®æº–å‚™"""
        self.test_model = "test_bird"
        self.step2_generator = Step2SkeletonGenerator()
        self.temp_dir = Path(tempfile.mkdtemp())
    
    def test_mesh_reextraction_parameters(self):
        """ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¤œè¨¼"""
        # åŸæµã¨åŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        expected_params = [
            "--require_suffix",
            "--faces_target_count", "4000",
            "--time", "8",
            "--post_process_script", "post_process/ar_post_process.py"
        ]
        
        # å®Ÿéš›ã®ã‚³ãƒãƒ³ãƒ‰æ§‹ç¯‰ã‚’ãƒ†ã‚¹ãƒˆ
        cmd = self.step2_generator._build_reextract_command(
            "/app/test.glb", self.test_model
        )
        
        for param in expected_params:
            self.assertIn(param, cmd)
    
    def test_file_output_verification(self):
        """å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã®ãƒ†ã‚¹ãƒˆ"""
        # å¿…é ˆå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        required_outputs = [
            "raw_data.npz",           # å†æŠ½å‡ºã•ã‚ŒãŸãƒ¡ãƒƒã‚·ãƒ¥
            "predict_skeleton.npz",   # ã‚¹ã‚±ãƒ«ãƒˆãƒ³NPZ
            f"{self.test_model}.fbx"  # ã‚¹ã‚±ãƒ«ãƒˆãƒ³FBX
        ]
        
        for output_file in required_outputs:
            output_path = Path("/app/dataset_inference_clean") / output_file
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã€ã‚µã‚¤ã‚ºãŒ0ã‚ˆã‚Šå¤§ãã„ã“ã¨ã‚’ç¢ºèª
            self.assertTrue(output_path.exists(), f"{output_file}ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            self.assertGreater(output_path.stat().st_size, 0, f"{output_file}ãŒç©ºãƒ•ã‚¡ã‚¤ãƒ«ã§ã™")
    
    def test_compatibility_with_original(self):
        """åŸæµã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ã®äº’æ›æ€§ãƒ†ã‚¹ãƒˆ"""
        # WebUIå®Ÿè¡Œ
        webui_success, webui_log, webui_outputs = self.step2_generator.generate_skeleton(
            self.test_model
        )
        
        # åŸæµã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
        original_success, original_outputs = self._run_original_script(self.test_model)
        
        # çµæœæ¯”è¼ƒ
        self.assertTrue(webui_success, f"WebUIå®Ÿè¡Œå¤±æ•—: {webui_log}")
        self.assertTrue(original_success, "åŸæµã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œå¤±æ•—")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºæ¯”è¼ƒï¼ˆÂ±10%ä»¥å†…ï¼‰
        for file_type in ["skeleton_fbx", "skeleton_npz"]:
            webui_size = Path(webui_outputs[file_type]).stat().st_size
            original_size = Path(original_outputs[file_type]).stat().st_size
            
            size_diff = abs(webui_size - original_size) / original_size
            self.assertLess(size_diff, 0.1, f"{file_type}ã®ã‚µã‚¤ã‚ºå·®ãŒ10%ã‚’è¶…ãˆã¦ã„ã¾ã™")
    
    def _run_original_script(self, model_name: str) -> Tuple[bool, Dict]:
        """åŸæµgenerate_skeleton.shã®å®Ÿè¡Œ"""
        # åŸæµã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œã®ãƒ¢ãƒƒã‚¯
        # å®Ÿéš›ã®ãƒ†ã‚¹ãƒˆã§ã¯å®Ÿéš›ã«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
        pass

if __name__ == "__main__":
    unittest.main()
```

### ğŸ¯ æ€§èƒ½ãƒ»å“è³ªæŒ‡æ¨™

#### å®šé‡çš„è©•ä¾¡æŒ‡æ¨™
```python
# /app/quality_metrics.py
class QualityMetrics:
    """
    å“è³ªè©•ä¾¡ã®å®šé‡çš„æŒ‡æ¨™
    """
    
    def __init__(self):
        self.compatibility_threshold = 0.94  # 94%äº’æ›æ€§åŸºæº–
        self.quality_thresholds = {
            "bone_count_accuracy": 1.0,      # boneæ•°100%ä¸€è‡´
            "file_size_similarity": 0.9,     # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º90%é¡ä¼¼
            "processing_success_rate": 0.95, # å‡¦ç†æˆåŠŸç‡95%
            "mesh_quality_score": 0.85       # ãƒ¡ãƒƒã‚·ãƒ¥å“è³ª85%
        }
    
    def evaluate_step2_quality(self, webui_output: Dict, original_output: Dict) -> Dict:
        """
        Step2ã®å“è³ªè©•ä¾¡
        """
        metrics = {}
        
        # 1. ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨æ€§
        metrics["file_existence"] = self._check_file_existence(webui_output)
        
        # 2. ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºæ¯”è¼ƒ
        metrics["file_size_similarity"] = self._compare_file_sizes(
            webui_output, original_output
        )
        
        # 3. FBXå†…å®¹åˆ†æ
        metrics["fbx_content_analysis"] = self._analyze_fbx_content(
            webui_output["skeleton_fbx"], original_output["skeleton_fbx"]
        )
        
        # 4. NPZå†…å®¹åˆ†æ
        metrics["npz_content_analysis"] = self._analyze_npz_content(
            webui_output["skeleton_npz"], original_output["skeleton_npz"]
        )
        
        # 5. ç·åˆå“è³ªã‚¹ã‚³ã‚¢
        metrics["overall_quality_score"] = self._calculate_overall_score(metrics)
        
        return metrics
    
    def _analyze_fbx_content(self, webui_fbx: str, original_fbx: str) -> Dict:
        """
        FBXãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹åˆ†æ
        """
        # FBXè§£æãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦boneæ§‹é€ ã‚’æ¯”è¼ƒ
        webui_bones = self._extract_bones_from_fbx(webui_fbx)
        original_bones = self._extract_bones_from_fbx(original_fbx)
        
        return {
            "bone_count_match": len(webui_bones) == len(original_bones),
            "bone_name_similarity": self._compare_bone_names(webui_bones, original_bones),
            "bone_hierarchy_match": self._compare_bone_hierarchy(webui_bones, original_bones),
            "bone_position_similarity": self._compare_bone_positions(webui_bones, original_bones)
        }
```

---

## ğŸ” ä»Šå¾Œã®ç¶™ç¶šçš„æ”¹å–„

### ğŸ“ˆ ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆä½“åˆ¶

```python
# /app/monitoring/quality_monitor.py
class QualityMonitor:
    """
    å“è³ªç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆä½“åˆ¶
    """
    
    def __init__(self):
        self.alert_thresholds = {
            "compatibility_drop": 0.02,  # äº’æ›æ€§2%ä½ä¸‹ã§ã‚¢ãƒ©ãƒ¼ãƒˆ
            "success_rate_drop": 0.05,   # æˆåŠŸç‡5%ä½ä¸‹ã§ã‚¢ãƒ©ãƒ¼ãƒˆ
            "processing_time_spike": 2.0  # å‡¦ç†æ™‚é–“2å€ã§ã‚¢ãƒ©ãƒ¼ãƒˆ
        }
    
    def monitor_step2_quality(self):
        """
        Step2å“è³ªã®ç¶™ç¶šç›£è¦–
        """
        current_metrics = self._collect_current_metrics()
        historical_metrics = self._load_historical_metrics()
        
        # å“è³ªå¤‰åŒ–ã®æ¤œå‡º
        quality_changes = self._detect_quality_changes(
            current_metrics, historical_metrics
        )
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆåˆ¤å®š
        alerts = self._check_alert_conditions(quality_changes)
        
        if alerts:
            self._send_quality_alerts(alerts)
        
        # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°
        self._update_historical_metrics(current_metrics)
```

### ğŸ¯ è‡ªå‹•åŒ–ã•ã‚ŒãŸãƒ†ã‚¹ãƒˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

```python
# /app/ci/automated_testing.py
class AutomatedTesting:
    """
    è‡ªå‹•åŒ–ã•ã‚ŒãŸãƒ†ã‚¹ãƒˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    """
    
    def run_comprehensive_test_suite(self):
        """
        åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã®å®Ÿè¡Œ
        """
        test_results = {}
        
        # 1. å˜ä½“ãƒ†ã‚¹ãƒˆ
        test_results["unit_tests"] = self._run_unit_tests()
        
        # 2. çµ±åˆãƒ†ã‚¹ãƒˆ
        test_results["integration_tests"] = self._run_integration_tests()
        
        # 3. äº’æ›æ€§ãƒ†ã‚¹ãƒˆ
        test_results["compatibility_tests"] = self._run_compatibility_tests()
        
        # 4. æ€§èƒ½ãƒ†ã‚¹ãƒˆ
        test_results["performance_tests"] = self._run_performance_tests()
        
        # 5. å›å¸°ãƒ†ã‚¹ãƒˆ
        test_results["regression_tests"] = self._run_regression_tests()
        
        # 6. å“è³ªã‚²ãƒ¼ãƒˆåˆ¤å®š
        overall_pass = self._evaluate_test_gate(test_results)
        
        return overall_pass, test_results
```

---

## ğŸ“š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé€£æºãƒ»æ›´æ–°

### ğŸ”— é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ•´åˆæ€§ç®¡ç†

```markdown
# é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

## å¿…é ˆæ›´æ–°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- [ ] README.md - ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¦‚è¦ã®æ›´æ–°
- [ ] SHELL_SCRIPTS_DETAILED_ANALYSIS.md - åˆ†æçµæœã®æ›´æ–°
- [ ] APP_VS_SOURCE_DATA_COMPARISON_ANALYSIS.md - æ¯”è¼ƒçµæœã®æ›´æ–°
- [ ] app_dataflow.instructions.md - ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼å›³ã®æ›´æ–°
- [ ] microservice_guide.instructions.md - ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³ã®æ›´æ–°

## æ–°è¦ä½œæˆæ¨å¥¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- [ ] step2_technical_specification.md - Step2ã®æŠ€è¡“ä»•æ§˜æ›¸
- [ ] mesh_reextraction_best_practices.md - ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹
- [ ] quality_assurance_guide.md - å“è³ªä¿è¨¼ã‚¬ã‚¤ãƒ‰
- [ ] compatibility_testing_guide.md - äº’æ›æ€§ãƒ†ã‚¹ãƒˆã‚¬ã‚¤ãƒ‰
```

---

## ğŸ¯ æœ€çµ‚çš„ãªä¾¡å€¤ã¨å½±éŸ¿

### ğŸ’¡ ã“ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¾¡å€¤

1. **æŠ€è¡“çš„ä¾¡å€¤**
   - UniRigãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å“è³ªå‘ä¸Šï¼ˆ94%äº’æ›æ€§é”æˆï¼‰
   - ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ»ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å“è³ªã®æ ¹æœ¬çš„æ”¹å–„
   - åŸæµå‡¦ç†ã¨ã®å®Œå…¨äº’æ›æ€§ç¢ºä¿

2. **é–‹ç™ºåŠ¹ç‡ã®å‘ä¸Š**
   - å•é¡Œã®æ ¹æœ¬åŸå› ã®æ˜ç¢ºåŒ–
   - å†ç™ºé˜²æ­¢ã®ãŸã‚ã®å…·ä½“çš„æŒ‡é‡
   - å“è³ªåŸºæº–ã®å®šé‡åŒ–

3. **çŸ¥è­˜ã®ä½“ç³»åŒ–**
   - é‡è¦ãªæŠ€è¡“çš„çŸ¥è¦‹ã®æ–‡æ›¸åŒ–
   - é–‹ç™ºãƒãƒ¼ãƒ é–“ã§ã®çŸ¥è­˜å…±æœ‰
   - å°†æ¥ã®é–‹ç™ºè€…ã¸ã®æŠ€è¡“ç¶™æ‰¿

4. **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æˆåŠŸ**
   - ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å“è³ªã®å‘ä¸Š
   - ãƒ¦ãƒ¼ã‚¶ãƒ¼æº€è¶³åº¦ã®å‘ä¸Š
   - æŠ€è¡“çš„ä¿¡é ¼æ€§ã®ç¢ºä¿

### ğŸš€ æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ

- **çŸ­æœŸçš„åŠ¹æœ**ï¼ˆå³åº§ã«å®Ÿç¾ï¼‰
  - Step2ã®ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå“è³ªå‘ä¸Š
  - bone/weight/skinningå•é¡Œã®è§£æ±º
  - ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æˆåŠŸç‡ã®å‘ä¸Š

- **ä¸­æœŸçš„åŠ¹æœ**ï¼ˆ1-3ãƒ¶æœˆï¼‰
  - å…¨ã‚¹ãƒ†ãƒƒãƒ—ã®å“è³ªæ¨™æº–åŒ–
  - ç¶™ç¶šçš„ãªå“è³ªç›£è¦–ä½“åˆ¶ã®æ§‹ç¯‰
  - é–‹ç™ºåŠ¹ç‡ã®å‘ä¸Š

- **é•·æœŸçš„åŠ¹æœ**ï¼ˆ3ãƒ¶æœˆä»¥ä¸Šï¼‰
  - UniRigã®æŠ€è¡“çš„ç«¶äº‰åŠ›å‘ä¸Š
  - æ–°æ©Ÿèƒ½é–‹ç™ºã®åŠ é€Ÿ
  - ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®å“è³ªå‘ä¸Š

---

**ğŸ“‹ ã“ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã®ç¶™ç¶šçš„æ”¹å–„**

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ç”ŸããŸæ–‡æ›¸ã§ã™ã€‚æ–°ã—ã„æŠ€è¡“çš„ç™ºè¦‹ã‚„æ”¹å–„ãŒã‚ã‚Œã°ã€ç¶™ç¶šçš„ã«æ›´æ–°ã—ã€é–‹ç™ºãƒãƒ¼ãƒ å…¨ä½“ã§å…±æœ‰ã—ã¦ãã ã•ã„ã€‚

**ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**

1. ã“ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’é–‹ç™ºãƒãƒ¼ãƒ å…¨å“¡ã¨å…±æœ‰
2. æ—¢å­˜ã®Step2å®Ÿè£…ã®æ¤œè¨¼ãƒ»æ”¹å–„
3. ä»–ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸ã®åŒæ§˜ã®åˆ†æé©ç”¨
4. ç¶™ç¶šçš„ãªå“è³ªç›£è¦–ä½“åˆ¶ã®æ§‹ç¯‰
5. æ–°ã—ã„æŠ€è¡“çš„çŸ¥è¦‹ã®ä½“ç³»çš„æ–‡æ›¸åŒ–

**ä½œæˆè€…**: GitHub Copilot  
**æœ€çµ‚æ›´æ–°**: 2025å¹´6æœˆ14æ—¥  
**æ–‡æ›¸ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: v2.0 (æŠ€è¡“è©³ç´°ãƒ»å®Ÿè£…ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è¿½åŠ ç‰ˆ)  
**é‡è¦åº¦**: æœ€é«˜ï¼ˆUniRigé–‹ç™ºã®åŸºç›¤çŸ¥è­˜ï¼‰
