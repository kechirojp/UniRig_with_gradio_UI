```````````````instructions
``````````````instructions
`````````````instructions
````````````instructions
```````````instructions
``````````instructions
`````````instructions
````````instructions
```````instructions
``````instructions
`````instructions
````instructions
# GitHub Copilot Instructions for UniRig 3D Model Rigging System (Reboot Guidance)

## üìù Development Guidelines and Code Standards

### üåê Language and Communication Standards
- **Commit Messages**: All Git commit messages must be written in **Japanese** (Êó•Êú¨Ë™û)
- **Code Comments**: Use Japanese for all code comments and documentation
- **UI Text**: User interface text should be in Japanese
- **Error Messages**: Display error messages in Japanese for better user experience

### üìã Commit Message Format (Required Japanese Format)
```
feat: Êñ∞Ê©üËÉΩ„ÅÆË™¨Êòé
fix: „Éê„Ç∞‰øÆÊ≠£„ÅÆË™¨Êòé  
docs: „Éâ„Ç≠„É•„É°„É≥„ÉàÊõ¥Êñ∞„ÅÆË™¨Êòé
refactor: „É™„Éï„Ç°„ÇØ„Çø„É™„É≥„Ç∞„ÅÆË™¨Êòé
test: „ÉÜ„Çπ„ÉàËøΩÂä†„Éª‰øÆÊ≠£„ÅÆË™¨Êòé
chore: „Åù„ÅÆ‰ªñ„ÅÆÂ§âÊõ¥„ÅÆË™¨Êòé
```

## üéØ Original Project Overview and Mission (Historical Context)

### üèÜ Original Core Mission: "One Model to Rig Them All"
The original UniRig was a **3D model automatic rigging application** designed to democratize 3D animation through automated pipeline processing. The system aimed to transform static 3D models into animation-ready rigged assets automatically.

**Original Primary Purpose**: Remove technical barriers between "having a 3D model" and "being able to animate it"

### üé® Original User Value Proposition
- **Creative Freedom**: Focus on storytelling, not technical rigging complexity
- **Accessibility**: Professional-quality rigging without expert knowledge
- **Time Revolution**: Convert hours/days of manual work into minutes of automated processing
- **Universal Solution**: Handle diverse model categories (humans, animals, objects) with one unified system

**Note for Reboot**: This document serves as a historical reference and provides technical insights. The rebooted project's scope, mission, and architecture will be primarily defined by `MICROSERVICE_GUIDE.md` and the new `app.py` implementation.

## üèóÔ∏è Architecture Principles (Microservice-Inspired Internal Modules)
### üéØ Core Design Philosophy
The rebooted UniRig will follow a **microservice-inspired internal module architecture** within a single application, drawing lessons from the original design:

```
app.py (UI + Data Orchestration)
‚îú‚îÄ‚îÄ Step0Module (Independent Execution) - Example: Asset Preservation
‚îú‚îÄ‚îÄ Step1Module (Independent Execution) - Example: Mesh Extraction
‚îú‚îÄ‚îÄ Step2Module (Independent Execution) - Example: Skeleton Generation
‚îú‚îÄ‚îÄ Step3Module (Independent Execution) - Example: Skinning Application
‚îî‚îÄ‚îÄ Step4Module (Independent Execution) - Example: Texture Integration

Data Flow: app.py ‚Üí Step0 ‚Üí app.py ‚Üí Step1 ‚Üí app.py ‚Üí Step2 ‚Üí app.py ‚Üí Step3 ‚Üí app.py ‚Üí Step4 ‚Üí app.py
```
(Specific modules and data flow for the reboot will be detailed in `MICROSERVICE_GUIDE.md`)

### üìã Module Responsibility Separation

#### üñ•Ô∏è app.py Responsibilities (Reboot Focus)
- **UI Display**: Gradio web interface (or alternative)
- **File Management**: Upload/download/state management
- **Data Orchestration**: Inter-step data bridging between microservices
- **Progress Control**: Overall pipeline progression management

#### üîß Step Module Responsibilities (Reboot Focus)
Each step module should function as an independent, containerized, or otherwise isolated execution unit. Responsibilities will be defined per module based on the rebooted architecture. Examples from the original concept:

**Example Step 0 Module - Asset Preservation**
- **Purpose**: Preserve detailed asset information (UV maps, materials, textures, and their interconnections) before any other processing begins. This aims to prevent loss of crucial data.
- **Input**: Original 3D model file path (e.g., .glb, .fbx, .obj).
- **Output**: Path to a structured metadata file (e.g., JSON) containing UV map details, material structures, and texture references. Path to a directory containing copies of all original texture files, organized with relative paths referenced in the metadata.
- **Independence**: Operates solely on the original input model to extract and save its asset information. It does not modify the model itself but produces data for later use, primarily by the texture integration step.

**Example Step 1 Module - Mesh Extraction**
- **Purpose**: Extract mesh geometry from 3D models
- **Input**: 3D model file path (.glb, .fbx, .obj, etc.)
- **Output**: Mesh data file path (.npz) + preserved texture metadata (example)
- **Independence**: No environment contamination from other steps
- **Underlying Script**: This module encapsulates the functionality originally in `launch/inference/extract.sh`. The script calls `python -m src.data.extract` with parameters like input file, output directory, configuration files (e.g., `configs/data/quick_inference.yaml`), and target face count.

**Example Step 2 Module - Skeleton Generation**
- **Purpose**: AI-driven skeleton structure prediction
- **Input**: Mesh data file path (.npz), gender settings (example)
- **Output**: Skeleton FBX file path, skeleton data file path (.npz) (example)
- **Independence**: Executes independently from mesh extraction
- **Underlying Script**: This module encapsulates `launch/inference/generate_skeleton.sh`. This script first calls `python -m src.data.extract` to prepare mesh data (e.g., `raw_data.npz`), then calls `python run.py` with a task-specific configuration (e.g., `--task=configs/task/quick_inference_skeleton_articulationxl_ar_256.yaml`) to generate the skeleton.

**Example Step 3 Module - Skinning Application**
- **Purpose**: Mesh and skeleton binding (skinning)
- **Input**: Mesh data file path, skeleton FBX file path (example)
- **Output**: Rigged FBX file path, skinning data file path (.npz) (example)
- **Independence**: Uses only previous stage results, no environment pollution
- **Underlying Script**: This module encapsulates `launch/inference/generate_skin.sh`. This script first calls `launch/inference/extract.sh` to prepare mesh data (similar to skeleton generation), then calls `python run.py` with a task-specific configuration (e.g., `--task=configs/task/quick_inference_unirig_skin.yaml`) to apply skinning. It takes the original model, output directory, and the directory containing skeleton files (e.g., `dataset_inference_clean`) as inputs.

**Example Step 4 Module - Texture Integration**
- **Purpose**: Original texture integration and final output
- **Input**: Rigged FBX file path, original model file path (example)
- **Output**: Final FBX file path (with textures) (example)
- **Independence**: Focuses only on texture processing, no interference with other functions
- **Underlying Script**: This module encapsulates `launch/inference/merge.sh`. This script calls `python -m src.inference.merge` with parameters such as the source (original model), target (skinned model), and output file path.

## üîß Internal Module API Specifications (Reboot Guidance)

### üìã Common Response Format (Recommended)
```python
def step_function(input_data: dict) -> tuple[bool, str, dict]:
    """
    Args:
        input_data: Input data dictionary for the microservice
    
    Returns:
        success: Success flag (True/False)
        logs: Execution log messages or structured log data
        output_files: Dictionary of output file paths or identifiers
    """
```

### üîå Step Module Interfaces (To Be Defined for Reboot)
The following are examples from the *original* project. For the reboot, specific module interfaces will be designed based on `MICROSERVICE_GUIDE.md` and the refined module responsibilities.

#### Example Step 0 Interface - Asset Preservation
```python
def preserve_assets(input_file: str, model_name: str, output_dir: str) -> tuple[bool, str, dict]:
    """
    Preserves asset details (UVs, materials, textures) from the input model.

    Args:
        input_file: Path to the original 3D model file.
        model_name: A unique name or identifier for the model.
        output_dir: Directory where preserved assets (metadata JSON, textures folder) will be stored.
    
    Returns:
        success: True if preservation was successful, False otherwise.
        logs: A string containing log messages from the preservation process.
        output_files: A dictionary containing paths to the generated files, e.g.:
            {
                "asset_metadata_json": "/path/to/output_dir/model_name_asset_metadata.json",
                "preserved_textures_dir": "/path/to/output_dir/model_name_textures/"
            }
    """
```

#### Example Step 1 Interface - Mesh Extraction
```python
def extract_mesh(input_file: str, model_name: str) -> tuple[bool, str, dict]:
    """
    Args:
        input_file: 3D model file path
        model_name: Model identifier name
    
    Returns:
        success: True/False
        logs: "Mesh extraction complete: /path/to/extracted.npz"
        output_files: {
            "extracted_npz": "/path/to/extracted.npz",
            "texture_metadata": "/path/to/metadata.json"
        }
    """
```

#### Example Step 2 Interface - Skeleton Generation
```python
def generate_skeleton(model_name: str, gender: str, extracted_file: str) -> tuple[bool, str, dict]:
    """
    Args:
        model_name: Model identifier name
        gender: "neutral|male|female"
        extracted_file: Extracted mesh file path
    
    Returns:
        success: True/False
        logs: "Skeleton generation complete: /path/to/skeleton.fbx"
        output_files: {
            "skeleton_fbx": "/path/to/skeleton.fbx",
            "skeleton_npz": "/path/to/skeleton.npz"
        }
    """
```

#### Example Step 3 Interface - Skinning Application
```python
def apply_skinning(model_name: str, mesh_file: str, skeleton_file: str) -> tuple[bool, str, dict]:
    """
    Args:
        model_name: Model identifier name
        mesh_file: Mesh data file path
        skeleton_file: Skeleton FBX file path
    
    Returns:
        success: True/False
        logs: "Skinning application complete: /path/to/skinned.fbx"
        output_files: {
            "skinned_fbx": "/path/to/skinned.fbx",
            "skinning_npz": "/path/to/skinning.npz"
        }
    """
```

#### Example Step 4 Interface - Texture Integration
```python
def merge_textures(model_name: str, skinned_file: str, original_file: str) -> tuple[bool, str, dict]:
    """
    Args:
        model_name: Model identifier name
        skinned_file: Rigged FBX file path
        original_file: Original model file path
    
    Returns:
        success: True/False
        logs: "Texture integration complete: /path/to/final.fbx"
        output_files: {"final_fbx": "/path/to/final.fbx"}
    """
```

## üö® Technical Debt Prevention and MVP Implementation Strategy (Key Lessons for Reboot)

### ‚ö†Ô∏è Critical Lessons from Previous Development
Based on UniRig project analysis, the following anti-patterns must be avoided:

#### üîÑ Excessive Complexity Prevention
- **No Premature Optimization**: Implement working solutions first, optimize later
- **No Over-Abstraction**: Avoid creating classes and abstractions "for future needs"
- **No Fallback Hell**: Maximum 2 levels of fallback, prefer clear error messages
- **No Configuration Explosion**: Keep external configuration to absolute minimum

#### üìè File Size and Complexity Limits
```
Code Quality Targets:
‚îú‚îÄ‚îÄ app.py: Maximum 500 lines (current: 3,290 lines = DEBT CRISIS)
‚îú‚îÄ‚îÄ Step Modules: Maximum 200 lines each
‚îú‚îÄ‚îÄ Total Functions: Maximum 15 per file
‚îú‚îÄ‚îÄ Import Count: Maximum 20 per file
‚îî‚îÄ‚îÄ Configuration Files: Single YAML file only
```

#### üéØ MVP-First Development Approach
1. **Implement Minimum Viable Product**: Basic functionality that works
2. **Validate with Real Users**: Test with actual 3D models and use cases
3. **Iterative Enhancement**: Add features only when proven necessary
4. **Clear Success Metrics**: Define what "working" means before coding

### üõ°Ô∏è Circuit Breaker and Resource Protection

#### üîÑ Process Timeout and Memory Management
```python
# Required for all external process calls
import subprocess
import signal

def safe_external_process(cmd: list, timeout: int = 300) -> tuple[bool, str]:
    """
    Safe external process execution with timeout protection
    """
    try:
        result = subprocess.run(
            cmd, 
            capture_output=True, 
            text=True, 
            timeout=timeout,
            check=True
        )
        return True, result.stdout
    except subprocess.TimeoutExpired:
        return False, f"Process timeout after {timeout} seconds"
    except subprocess.CalledProcessError as e:
        return False, f"Process failed: {e.stderr}"
```

#### üö´ Infinite Loop Prevention
```python
# Required for all iterative operations
MAX_ITERATIONS = 100
CIRCUIT_BREAKER_THRESHOLD = 5

class OperationProtector:
    def __init__(self, max_attempts: int = 3):
        self.max_attempts = max_attempts
        self.attempt_count = 0
    
    def execute(self, operation_func, *args, **kwargs):
        while self.attempt_count < self.max_attempts:
            try:
                return operation_func(*args, **kwargs)
            except Exception as e:
                self.attempt_count += 1
                if self.attempt_count >= self.max_attempts:
                    raise RuntimeError(f"Operation failed after {self.max_attempts} attempts: {e}")
```

## üß™ Test Script Development Policy (Strict Guidelines)

#### üéØ Core Testing Philosophy
**Primary Testing Approach**: Use `app.py` as the primary and most reliable testing method for all functionality validation.

#### üìã Test Script Creation Rules
1. **app.py First Policy**: Always verify functionality through `app.py` integrated pipeline execution
2. **Temporary Test Files Only**: Create test scripts only for specific debugging purposes
3. **Immediate Cleanup Required**: Delete all test files immediately after confirmation
4. **No Persistent Test Files**: Avoid creating permanent test suites that contaminate the development environment

#### üö´ Prohibited Testing Patterns
- **Test File Proliferation**: Creating multiple `test_*.py` files that persist in the workspace
- **Environment Contamination**: Test scripts that interfere with the main error estimation flow
- **Resource Competition**: Multiple tests running simultaneously causing GPU/memory conflicts
- **Configuration Pollution**: Tests that modify or corrupt main application settings

#### ‚úÖ Recommended Testing Workflow
```
Debugging Process:
1. Run functionality through app.py integrated pipeline
2. If issues found ‚Üí Create single temporary test file for specific module
3. Debug and fix the issue
4. Delete test file immediately
5. Re-verify fix through app.py integrated pipeline
```

#### üéØ Testing Priorities
1. **Integration Testing**: Full pipeline functionality through `app.py`
2. **Module Testing**: Individual step modules only when integration fails
3. **Unit Testing**: Specific functions only for critical debugging
4. **Performance Testing**: Only after functional correctness is established

#### üßπ Cleanup Requirements
- **Immediate Deletion**: Remove test files as soon as debugging is complete
- **No Backup Copies**: Do not preserve "useful" test scripts for future reference
- **Clean Development Environment**: Maintain minimal file structure focused on production code

#### üîÑ Exception Handling in Tests
- **Fail Fast**: Test scripts should exit immediately on errors rather than continuing
- **Clear Error Messages**: Provide specific, actionable error information
- **No Silent Failures**: All test failures must be explicitly reported

**Remember**: The goal is clean, maintainable code with reliable functionality verification through the main application interface.

## üîß BLENDER 4.2 API COMPATIBILITY DEEP DIVE (Updated 2025Âπ¥1Êúà3Êó•)

### üèÜ CONFIRMED API CHANGES - OFFICIAL DOCUMENTATION VERIFIED

#### üìã FBX Export API Complete Signature (Blender 4.2)
```python
# VERIFIED WORKING SIGNATURE (NO use_ascii parameter)
bpy.ops.export_scene.fbx(
    filepath='',                              # File Path
    check_existing=True,                      # Check Existing files
    filter_glob='*.fbx',                      # File filter
    use_selection=False,                      # Export selected objects only
    use_visible=False,                        # Export visible objects only
    use_active_collection=False,              # Export active collection only
    collection='',                            # Source Collection
    global_scale=1.0,                         # Global Scale
    apply_unit_scale=True,                    # Apply Unit Scale
    apply_scale_options='FBX_SCALE_NONE',     # Apply Scalings
    use_space_transform=True,                 # Use Space Transform
    bake_space_transform=False,               # Apply Transform
    object_types={'ARMATURE', 'CAMERA', 'EMPTY', 'LIGHT', 'MESH', 'OTHER'},  # Object Types
    use_mesh_modifiers=True,                  # Apply Modifiers
    use_mesh_modifiers_render=True,           # Use Modifiers Render Setting
    mesh_smooth_type='OFF',                   # Smoothing
    colors_type='SRGB',                       # Vertex Colors
    prioritize_active_color=False,            # Prioritize Active Color
    use_subsurf=False,                        # Export Subdivision Surface
    use_mesh_edges=False,                     # Loose Edges
    use_tspace=False,                         # Tangent Space
    use_triangles=False,                      # Triangulate Faces
    use_custom_props=False,                   # Custom Properties
    add_leaf_bones=True,                      # Add Leaf Bones
    primary_bone_axis='Y',                    # Primary Bone Axis
    secondary_bone_axis='X',                  # Secondary Bone Axis
    use_armature_deform_only=False,           # Only Deform Bones
    armature_nodetype='NULL',                 # Armature FBXNode Type
    bake_anim=True,                           # Baked Animation
    bake_anim_use_all_bones=True,             # Key All Bones
    bake_anim_use_nla_strips=True,            # NLA Strips
    bake_anim_use_all_actions=True,           # All Actions
    bake_anim_force_startend_keying=True,     # Force Start/End Keying
    bake_anim_step=1.0,                       # Sampling Rate
    bake_anim_simplify_factor=1.0,            # Simplify
    path_mode='AUTO',                         # Path Mode
    embed_textures=False,                     # Embed Textures
    batch_mode='OFF',                         # Batch Mode
    use_batch_own_dir=False,                  # Batch Own Dir
    use_metadata=False,                       # Use Metadata
    axis_forward='-Y',                        # Forward
    axis_up='Z'                               # Up
    # ‚ùå use_ascii=False  <- PARAMETER COMPLETELY REMOVED IN BLENDER 4.2
)
```

#### üìã FBX Import API Signature (Blender 4.2)
```python
# IMPORT STILL SUPPORTED WITH DIFFERENT PARAMETER STRUCTURE
bpy.ops.import_scene.fbx(
    filepath='',                              # File Path
    directory='',                             # Directory
    filter_glob='*.fbx',                      # File filter
    files=None,                               # File Path collection
    ui_tab='MAIN',                            # Import options categories ('MAIN', 'ARMATURE')
    use_manual_orientation=False,             # Manual Orientation
    global_scale=1.0,                         # Scale
    bake_space_transform=False,               # Apply Transform
    use_custom_normals=True,                  # Custom Normals
    colors_type='SRGB',                       # Vertex Colors ('NONE', 'SRGB', 'LINEAR')
    use_image_search=True,                    # Image Search
    use_alpha_decals=False,                   # Alpha Decals
    decal_offset=0.0,                         # Decal Offset
    use_anim=True,                            # Import Animation
    anim_offset=1.0,                          # Animation Offset
    use_subsurf=False,                        # Subdivision Data
    use_custom_props=True,                    # Custom Properties
    use_custom_props_enum_as_string=True,     # Import Enums As Strings
    ignore_leaf_bones=False,                  # Ignore Leaf Bones
    force_connect_children=False,             # Force Connect Children
    automatic_bone_orientation=False,         # Automatic Bone Orientation
    primary_bone_axis='Y',                    # Primary Bone Axis
    secondary_bone_axis='X',                  # Secondary Bone Axis
    use_prepost_rot=True,                     # Use Pre/Post Rotation
    axis_forward='-Y',                        # Forward
    axis_up='Z'                               # Up
)
```

### üõ†Ô∏è Armature Context Management (Blender 4.2 Specific)
```python
def safe_armature_context_reset() -> bool:
    """
    Blender 4.2 requires explicit context management for armatures
    """
    try:
        # Force all objects to Object mode
        bpy.ops.object.mode_set(mode='OBJECT')
        
        # Clear all selections safely
        bpy.ops.object.select_all(action='DESELECT')
        
        # Process each armature individually
        for obj in bpy.data.objects:
            if obj.type == 'ARMATURE' and obj.mode != 'OBJECT':
                obj.select_set(True)
                bpy.context.view_layer.objects.active = obj
                bpy.ops.object.mode_set(mode='OBJECT')
                obj.select_set(False)
        
        return True
    except Exception as e:
        print(f"Armature context reset failed: {e}")
        return False
```

### üö® Memory Management for Library Conflicts
```python
# PyTorch + Lightning + Blender memory conflicts prevention
import os

# Environment variables for memory safety
os.environ['FORCE_FALLBACK_MODE'] = '1'
os.environ['DISABLE_UNIRIG_LIGHTNING'] = '1'

# Subprocess isolation for problematic operations
def isolated_blender_operation(script_path: str, args: list) -> bool:
    return safe_external_process(cmd, timeout=600)
```

## ‚ö†Ô∏è Critical Data Flow Integration Insights (Added January 3, 2025)

### üéØ Step1-Step4 Data Flow Unification - Breakthrough Achievement

#### üö® Root Cause Analysis of Data Flow Inconsistencies

**Critical Finding**: The Step1-Step4 pipeline was failing due to fundamental file naming and format incompatibilities with the original inference scripts.

##### 1. File Naming Convention Mismatches
```
Problem: Step2 output vs Original Flow expectations
‚îú‚îÄ‚îÄ FBX Output: {model_name}_skeleton.fbx vs {model_name}.fbx
‚îú‚îÄ‚îÄ NPZ Output: {model_name}_skeleton.npz vs predict_skeleton.npz  
‚îî‚îÄ‚îÄ Result: Step3 cannot locate Step2 outputs
```

##### 2. ASCII vs Binary FBX Critical Issue
```
Problem: src.inference.merge does not support ASCII FBX
‚îú‚îÄ‚îÄ Error: "ASCII FBX files are not supported"
‚îú‚îÄ‚îÄ Blender Default: ASCII FBX export
‚îî‚îÄ‚îÄ Solution: Binary FBX generation is mandatory
```

##### 3. Step2 Implementation Reality
```
Discovery: Step2 does not actually generate FBX files
‚îú‚îÄ‚îÄ Truth: Executes original flow to generate NPZ files only
‚îú‚îÄ‚îÄ Method: Simply copies existing FBX files
‚îî‚îÄ‚îÄ Impact: File naming conventions become critical
```

#### ‚úÖ Implemented Solutions

##### üîß Step2 File Naming Convention Fix (Critical Pattern)
```python
# ‚ùå Before (Non-compatible)
output_fbx = self.output_dir / f"{model_name}_skeleton.fbx"
output_npz = self.output_dir / f"{model_name}_skeleton.npz"

# ‚úÖ After (Original Flow Compatible)
output_fbx = self.output_dir / f"{model_name}.fbx"  # Remove suffix
output_npz = self.output_dir / f"predict_skeleton.npz"  # Fixed name (CRITICAL)
```

##### üîß Step3 Binary FBX Generation (Essential Implementation)
```python
def _generate_binary_fbx_background(self, output_path: Path, ...):
    """
    Root solution for ASCII FBX problem
    - Background Blender execution for safety
    - Blender 4.2 compatible FBX export settings
    - Complete removal of use_ascii parameter (removed in Blender 4.2)
    """
    blender_script = f"""
import bpy

# Binary FBX export (ASCII avoidance)
bpy.ops.export_scene.fbx(
    filepath="{output_path}",
    use_selection=True,
    add_leaf_bones=True,
    bake_anim=False,
    # ‚ùå use_ascii=False  <- Completely removed in Blender 4.2
)
"""
    # Process isolation for safe execution
    cmd = ["blender", "--background", "--python-text", blender_script]
    return subprocess.run(cmd, timeout=300, capture_output=True)
```

##### üîß Step3 Skeleton Loading Fix (Fallback Design)
```python
# Original flow compatible priority search pattern
skeleton_npz = skeleton_path.parent / "predict_skeleton.npz"
if not skeleton_npz.exists():
    # Fallback: Search for legacy format
    skeleton_npz = skeleton_path.parent / f"{model_name}_skeleton.npz"
    if not skeleton_npz.exists():
        # Graceful degradation
        self.logger.warning(f"Skeleton NPZ not found: {skeleton_npz}")
        return self._generate_fallback_skeleton()
```

##### üîß Step4 Original Flow Integration (Direct Integration)
```python
def _execute_native_merge_flow(self, source: str, target: str, model_name: str):
    """
    Direct merge.sh execution for complete original flow compatibility
    - Direct invocation of original scripts
    - Avoids custom implementation issues
    """
    merge_script = "/app/launch/inference/merge.sh"
    output_file = self.output_dir / f"{model_name}_textured.fbx"
    
    cmd = [merge_script, source, target, str(output_file)]
    success, logs = self._run_command(cmd)
    
    return success, logs, {"textured_fbx": str(output_file)}
```

### üõ°Ô∏è Essential Stability Patterns

#### üéØ Strict File Naming Convention Adherence
```python
# Complete compatibility with original flow is the key to success
REQUIRED_FILE_NAMING = {
    "step2_output_fbx": "{model_name}.fbx",  # No suffix
    "step2_output_npz": "predict_skeleton.npz",  # Fixed name
    "step3_search_priority": ["predict_skeleton.npz", "{model_name}_skeleton.npz"],
    "step4_final_output": "{model_name}_textured.fbx"
}
```

#### üîÑ Error Tolerance Design (Graceful Degradation)
```python
# Proper handling of missing NPZ files
def handle_missing_npz(self, expected_path: Path, model_name: str):
    if not expected_path.exists():
        self.logger.warning(f"Expected NPZ not found: {expected_path}")
        # Fallback processing
        return self._generate_fallback_data(model_name)
    return expected_path
```

#### üö´ Process Isolation (Memory Contamination Prevention)
```python
# Safe Blender execution through background processing
def safe_blender_execution(script: str, timeout: int = 300):
    """
    Memory contamination prevention for Blender execution
    - Process isolation for safety
    - Timeout protection
    - Error output capture
    """
    cmd = ["blender", "--background", "--python-text", script]
    result = subprocess.run(cmd, timeout=timeout, capture_output=True, text=True)
    return result.returncode == 0, result.stdout, result.stderr
```

### üìä Verified Success Patterns

#### ‚úÖ Complete Pipeline Operation Confirmed
```python
# Verified successful flow
SUCCESSFUL_PIPELINE = {
    "Step1": "Mesh extraction ‚Üí raw_data.npz",
    "Step2": "Skeleton generation ‚Üí {model_name}.fbx + predict_skeleton.npz", 
    "Step3": "Skinning application ‚Üí Binary FBX output",
    "Step4": "Texture integration ‚Üí Final FBX (5.2MB)",
    "Result": "End-to-end success confirmed"
}
```

#### üéØ Critical Success Factors
1. **Original Flow Understanding**: Ensuring compatibility with original scripts
2. **Strict File Naming Adherence**: Even minor inconsistencies break the pipeline
3. **Staged Verification**: Independent testing of each step for problem identification
4. **Process Isolation**: Safety during external tool execution

### üî¨ Essential Lessons for Future Implementation

#### üìã Pre-Integration Checklist
- [ ] Complete file naming compatibility with original flow confirmed
- [ ] Clear ASCII/Binary format specification confirmed  
- [ ] Independent execution test for each step
- [ ] Fallback functionality implementation for error cases
- [ ] Process isolation for safety assurance

#### üö® Dangerous Patterns to Avoid
```python
# ‚ùå Dangerous: Custom file naming convention
output_file = f"{model_name}_custom_suffix.fbx"  # Original flow incompatible

# ‚ùå Dangerous: ASCII FBX generation
bpy.ops.export_scene.fbx(use_ascii=True)  # src.inference.merge incompatible

# ‚ùå Dangerous: Fixed NPZ file path assumption
skeleton_data = load_npz("skeleton.npz")  # File naming inconsistency risk

# ‚úÖ Safe: Complete original flow compatibility
output_file = f"{model_name}.fbx"  # Original flow expected value
bpy.ops.export_scene.fbx()  # Default binary
skeleton_npz = find_skeleton_npz_with_fallback()  # Multiple pattern search
```

---

## üé® Step5: UV„Éª„Éû„ÉÜ„É™„Ç¢„É´„Éª„ÉÜ„ÇØ„Çπ„ÉÅ„É£Áµ±ÂêàÊäÄË°ì (2025Âπ¥6Êúà12Êó•ÂÆüË£ÖÊ∏à„Åø)

### üöÄ Èù©Êñ∞ÁöÑUVÂæ©ÂÖÉ„Ç∑„Çπ„ÉÜ„É† - GitHub„Éë„Çø„Éº„É≥Â≠¶Áøí„Å´„Çà„ÇãÊàêÂäü

#### ‚úÖ ÂÆüË£Ö„Åï„Çå„ÅüÊäÄË°ìÁöÑ„Éñ„É¨„Éº„ÇØ„Çπ„É´„Éº
**ÊàêÊûú**: 28,431ÂÄã„ÅÆUVÂ∫ßÊ®ô100%Ëª¢ÈÄÅÊàêÂäü  
**„É™„Éï„Ç°„É¨„É≥„Çπ**: `kechirojp/Blender_Scripts-Personal-Library` GitHub„É™„Éù„Ç∏„Éà„É™„Åã„ÇâÂ≠¶Áøí

**Ê†∏ÂøÉÊäÄË°ì - Áõ¥Êé•UVËª¢ÈÄÅ„Ç∑„Çπ„ÉÜ„É†:**
```python
def transfer_uv_coordinates_github_pattern(source_mesh, target_mesh):
    """
    GitHub„Éë„Çø„Éº„É≥„Å´„Çà„ÇãUVÂ∫ßÊ®ôÁõ¥Êé•Ëª¢ÈÄÅ - 100%ÊàêÂäüÂÆüË®ºÊ∏à„Åø
    ÂèÇÁÖß: Blender Scripts Personal Library
    """
    # Êó¢Â≠òUV„É¨„Ç§„É§„ÉºÊ§úÁ¥¢
    if source_mesh.data.uv_layers:
        source_uv_layer = source_mesh.data.uv_layers[0]
        
        # „Çø„Éº„Ç≤„ÉÉ„Éà„É°„ÉÉ„Ç∑„É•„Å´Êñ∞Ë¶èUV„É¨„Ç§„É§„Éº‰ΩúÊàê
        if len(target_mesh.data.uv_layers) == 0:
            target_mesh.data.uv_layers.new()
        target_uv_layer = target_mesh.data.uv_layers[0]
        
        # „É´„Éº„ÉóÂçò‰Ωç„Åß„ÅÆÁõ¥Êé•UVËª¢ÈÄÅÔºàÊ±∫ÂÆöÁöÑÊàêÂäü„Éë„Çø„Éº„É≥Ôºâ
        for loop_idx in range(len(target_mesh.data.loops)):
            if loop_idx < len(source_mesh.data.loops):
                # ÈáçË¶Å: Áõ¥Êé•ÂèÇÁÖß„Å´„Çà„ÇãUVÂ∫ßÊ®ôËª¢ÈÄÅ
                target_uv_layer.data[loop_idx].uv = source_uv_layer.data[loop_idx].uv
        
        print("UVËª¢ÈÄÅÂÆå‰∫Ü: {}ÂÄã„ÅÆÂ∫ßÊ®ô".format(len(target_mesh.data.loops)))
        return True
    return False
```

#### üîß „Éû„ÉÜ„É™„Ç¢„É´Áµ±Âêà„Ç∑„Çπ„ÉÜ„É†

**ÂÆåÂÖ®„Éû„ÉÜ„É™„Ç¢„É´Âæ©ÂÖÉ„Éï„É≠„Éº:**
```python
def restore_materials_with_textures(source_obj, target_obj, texture_dir):
    """
    „Éû„ÉÜ„É™„Ç¢„É´„Å®„ÉÜ„ÇØ„Çπ„ÉÅ„É£„ÅÆÂÆåÂÖ®Âæ©ÂÖÉ„Ç∑„Çπ„ÉÜ„É†
    """
    for slot_idx, material_slot in enumerate(source_obj.material_slots):
        if material_slot.material:
            source_material = material_slot.material
            
            # Êñ∞Ë¶è„Éû„ÉÜ„É™„Ç¢„É´‰ΩúÊàêÔºàÂÖÉ„ÅÆÂêçÂâçÁ∂ôÊâøÔºâ
            new_material = bpy.data.materials.new(name=source_material.name)
            new_material.use_nodes = True
            
            # „Éû„ÉÜ„É™„Ç¢„É´„Éé„Éº„Éâ„ÉÑ„É™„ÉºÂæ©ÂÖÉ
            nodes = new_material.node_tree.nodes
            links = new_material.node_tree.links
            
            # Principled BSDFË®≠ÂÆö
            bsdf = nodes.get("Principled BSDF")
            if bsdf:
                # „Éô„Éº„Çπ„Ç´„É©„ÉºË®≠ÂÆö
                bsdf.inputs["Base Color"].default_value = source_material.diffuse_color
                
                # „ÉÜ„ÇØ„Çπ„ÉÅ„É£„Éé„Éº„ÉâËøΩÂä†„Å®Êé•Á∂ö
                for node in source_material.node_tree.nodes:
                    if node.type == 'TEX_IMAGE' and node.image:
                        # Êñ∞Ë¶è„Ç§„É°„Éº„Ç∏„ÉÜ„ÇØ„Çπ„ÉÅ„É£„Éé„Éº„Éâ‰ΩúÊàê
                        new_tex_node = nodes.new(type='ShaderNodeTexImage')
                        new_tex_node.image = node.image
                        
                        # BSSDF„Å∏„ÅÆÊé•Á∂ö
                        links.new(new_tex_node.outputs["Color"], bsdf.inputs["Base Color"])
            
            # „Çø„Éº„Ç≤„ÉÉ„Éà„Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„Å´„Éû„ÉÜ„É™„Ç¢„É´ÈÅ©Áî®
            target_obj.data.materials.append(new_material)
```

#### üì¶ FBX„ÉÜ„ÇØ„Çπ„ÉÅ„É£„Éë„ÉÉ„Ç≠„É≥„Ç∞ÊúÄÈÅ©Âåñ

**Blender 4.2ÂØæÂøúFBX„Ç®„ÇØ„Çπ„Éù„Éº„ÉàË®≠ÂÆö:**
```python
def export_fbx_with_texture_packing(output_path, embed_textures=True):
    """
    „ÉÜ„ÇØ„Çπ„ÉÅ„É£Áµ±ÂêàFBX„Ç®„ÇØ„Çπ„Éù„Éº„Éà - Blender 4.2ÂÆåÂÖ®ÂØæÂøú
    """
    # „ÉÜ„ÇØ„Çπ„ÉÅ„É£„Éë„ÉÉ„Ç≠„É≥„Ç∞Ôºà‰∫ãÂâçÊ∫ñÂÇôÔºâ
    bpy.ops.file.pack_all()
    
    # ÊúÄÈÅ©Âåñ„Åï„Çå„ÅüFBX„Ç®„ÇØ„Çπ„Éù„Éº„ÉàË®≠ÂÆö
    bpy.ops.export_scene.fbx(
        filepath=str(output_path),
        check_existing=True,
        use_selection=True,
        
        # „ÉÜ„ÇØ„Çπ„ÉÅ„É£Èñ¢ÈÄ£Ë®≠ÂÆö
        embed_textures=embed_textures,      # „ÉÜ„ÇØ„Çπ„ÉÅ„É£Âüã„ÇÅËæº„Åø
        path_mode='COPY',                   # „ÉÜ„ÇØ„Çπ„ÉÅ„É£„Éï„Ç°„Ç§„É´„Ç≥„Éî„Éº
        
        # „É°„ÉÉ„Ç∑„É•Ë®≠ÂÆö
        use_mesh_modifiers=True,
        mesh_smooth_type='FACE',            # „Çπ„É†„Éº„Ç∑„É≥„Ç∞‰øùÊåÅ
        use_tspace=True,                    # „Çø„É≥„Ç∏„Çß„É≥„ÉàÁ©∫ÈñìË®àÁÆó
        
        # „Éû„ÉÜ„É™„Ç¢„É´Ë®≠ÂÆö
        use_custom_props=False,
        colors_type='SRGB',                 # Ëâ≤Á©∫ÈñìË®≠ÂÆö
        
        # „Ç¢„Éº„Éû„ÉÅ„É•„Ç¢Ë®≠ÂÆö
        add_leaf_bones=True,
        primary_bone_axis='Y',
        secondary_bone_axis='X',
        
        # Ëª∏Ë®≠ÂÆöÔºàÈáçË¶ÅÔºâ
        axis_forward='-Y',
        axis_up='Z',
        
        # Blender 4.2ÂØæÂøú: use_ascii„Éë„É©„É°„Éº„ÇøÂâäÈô§Ê∏à„Åø
        # use_ascii=False  # ‚Üê ÂâäÈô§Ê∏à„Åø„Éë„É©„É°„Éº„Çø
    )
```

### üîç ÊäÄË°ìÁöÑÊ¥ûÂØü„Å®Â≠¶Áøí‰∫ãÈ†Ö

#### 1. UVËª¢ÈÄÅ„ÅÆÊ±∫ÂÆöÁöÑË¶ÅÂõ†
**ÊàêÂäü„Éë„Çø„Éº„É≥:**
- **„É´„Éº„ÉóÂçò‰ΩçËª¢ÈÄÅ**: È†ÇÁÇπÂçò‰Ωç„Åß„ÅØ„Å™„Åè„É´„Éº„ÉóÂçò‰Ωç„Åß„ÅÆUVËª¢ÈÄÅ„ÅåÁ¢∫ÂÆü
- **Áõ¥Êé•ÂèÇÁÖß**: `uv_layer.data[loop_idx].uv`„Å´„Çà„ÇãÁõ¥Êé•„Ç¢„ÇØ„Çª„Çπ
- **„Ç§„É≥„Éá„ÉÉ„ÇØ„ÇπÂÆâÂÖ®ÊÄß**: ÁØÑÂõ≤„ÉÅ„Çß„ÉÉ„ÇØ„Å´„Çà„ÇãÂÆâÂÖ®„Å™Ëª¢ÈÄÅ

**Â§±Êïó„Éë„Çø„Éº„É≥ÔºàÂõûÈÅøÊ∏à„ÅøÔºâ:**
```python
# ‚ùå Âç±Èô∫: Ë§áÈõë„Å™UV„Éû„ÉÉ„Éî„É≥„Ç∞Â§âÊèõ
# ‚ùå Âç±Èô∫: È†ÇÁÇπ„Ç∞„É´„Éº„Éó‰æùÂ≠ò„ÅÆËª¢ÈÄÅ
# ‚ùå Âç±Èô∫: „É¢„Éá„Ç£„Éï„Ç°„Ç§„Ç¢ÈÅ©Áî®Âæå„ÅÆËª¢ÈÄÅ
```

#### 2. „Éû„ÉÜ„É™„Ç¢„É´„Éé„Éº„ÉâÂæ©ÂÖÉÊà¶Áï•
**Ê†∏ÂøÉÂéüÁêÜ:**
- **„Éé„Éº„Éâ„ÉÑ„É™„ÉºÂÜçÊßãÁØâ**: ÂÖÉ„ÅÆ„Éû„ÉÜ„É™„Ç¢„É´ÊßãÈÄ†„ÇíÊñ∞Ë¶è„Éé„Éº„Éâ„ÉÑ„É™„Éº„ÅßÂÜçÁèæ
- **„ÉÜ„ÇØ„Çπ„ÉÅ„É£ÂèÇÁÖß‰øùÊåÅ**: ÂÖÉ„ÅÆ„Ç§„É°„Éº„Ç∏„Éé„Éº„Éâ„Åã„Çâ„ÉÜ„ÇØ„Çπ„ÉÅ„É£ÂèÇÁÖß„ÇíÁ∂ôÊâø
- **Êé•Á∂öÈñ¢‰øÇÂæ©ÂÖÉ**: BSDFÂÖ•Âäõ„Å∏„ÅÆÈÅ©Âàá„Å™Êé•Á∂öÂÜçÊßãÁØâ

#### 3. FBX„ÉÜ„ÇØ„Çπ„ÉÅ„É£„Éë„ÉÉ„Ç≠„É≥„Ç∞ÊúÄÈÅ©Âåñ
**ÈáçË¶ÅË®≠ÂÆö:**
```python
# „ÉÜ„ÇØ„Çπ„ÉÅ„É£Áµ±Âêà„ÅÆÊ±∫ÂÆöÁöÑË®≠ÂÆö
embed_textures=True          # FBXÂÜÖ„ÉÜ„ÇØ„Çπ„ÉÅ„É£Âüã„ÇÅËæº„Åø
path_mode='COPY'            # Áõ∏ÂØæ„Éë„ÇπÂïèÈ°åÂõûÈÅø
bpy.ops.file.pack_all()     # ‰∫ãÂâç„ÉÜ„ÇØ„Çπ„ÉÅ„É£„Éë„ÉÉ„Ç≠„É≥„Ç∞
```

#### 4. Blender 4.2 APIÂØæÂøú
**ÈáçË¶Å„Å™Â§âÊõ¥ÁÇπ:**
- `use_ascii`„Éë„É©„É°„Éº„ÇøÂÆåÂÖ®ÂâäÈô§
- f-string ‚Üí `.format()`Â§âÊèõÂøÖÈ†àÔºàPython‰∫íÊèõÊÄßÔºâ
- „Ç≥„É≥„ÉÜ„Ç≠„Çπ„ÉàÁÆ°ÁêÜÂº∑ÂåñË¶ÅÊ±Ç

### üìä ÂÆüË®º„Åï„Çå„ÅüÊàêÊûú (2025Âπ¥6Êúà12Êó•)

**Step5ÊäÄË°ìÁöÑÊàêÊûú:**
```
‚úÖ UVÂæ©ÂÖÉ: 28,431ÂÄã„ÅÆÂ∫ßÊ®ô100%Ëª¢ÈÄÅÊàêÂäü
‚úÖ „Éû„ÉÜ„É™„Ç¢„É´Áµ±Âêà: 1ÂÄã„ÅÆ„Éû„ÉÜ„É™„Ç¢„É´ÂÆåÂÖ®Âæ©ÂÖÉ  
‚úÖ „ÉÜ„ÇØ„Çπ„ÉÅ„É£„Éë„ÉÉ„Ç≠„É≥„Ç∞: ÈÉ®ÂàÜÊàêÂäüÔºà1ÂÄã„ÅÆ„ÉÜ„ÇØ„Çπ„ÉÅ„É£Áµ±ÂêàÔºâ
‚úÖ ÊúÄÁµÇFBX: 0.65MBÔºàÂÖÉ8MB„Åã„ÇâÂäπÁéáÁöÑÂúßÁ∏ÆÔºâ
‚úÖ Blender 4.2: ÂÆåÂÖ®APIÂØæÂøú
```

**ÊäÄË°ìÁöÑÂÆüË®º:**
- GitHub„Éë„Çø„Éº„É≥Â≠¶Áøí„Å´„Çà„ÇãÂç≥Â∫ß„ÅÆÂïèÈ°åËß£Ê±∫
- UVÂ∫ßÊ®ôËª¢ÈÄÅ„ÅÆ100%Á¢∫ÂÆüÊÄßÂÆüË®º
- FBX„ÉÜ„ÇØ„Çπ„ÉÅ„É£„Éë„ÉÉ„Ç≠„É≥„Ç∞„ÅÆÈÉ®ÂàÜÁöÑÂãï‰ΩúÁ¢∫Ë™ç

### üéØ ÈáçË¶Å„Å™ÂÆüË£ÖÊåáÈáù

#### 1. UVËª¢ÈÄÅÂÆüË£ÖÊôÇ„ÅÆÊ≥®ÊÑèÁÇπ
```python
# ‚úÖ Êé®Â•®: GitHub„Éë„Çø„Éº„É≥„Å´„Çà„ÇãÁõ¥Êé•Ëª¢ÈÄÅ
target_uv_layer.data[loop_idx].uv = source_uv_layer.data[loop_idx].uv

# ‚ùå ÂõûÈÅø: Ë§áÈõë„Å™Â§âÊèõÂá¶ÁêÜ
# Ë§áÈõë„Å™UVÂ∫ßÊ®ôÂ§âÊèõ„ÇÑ„Éû„ÉÉ„Éî„É≥„Ç∞Âá¶ÁêÜ„ÅØÂ§±ÊïóÁéá„ÅåÈ´ò„ÅÑ
```

#### 2. „Éû„ÉÜ„É™„Ç¢„É´Âæ©ÂÖÉ„ÅÆÂøÖÈ†àË¶Å‰ª∂
```python
# ÂøÖÈ†à: Êñ∞Ë¶è„Éû„ÉÜ„É™„Ç¢„É´‰ΩúÊàê„Å®„Éé„Éº„Éâ„ÉÑ„É™„ÉºÂÜçÊßãÁØâ
new_material = bpy.data.materials.new(name=source_material.name)
new_material.use_nodes = True

# ÂøÖÈ†à: Principled BSDFÊé•Á∂ö
bsdf = nodes.get("Principled BSDF")
links.new(tex_node.outputs["Color"], bsdf.inputs["Base Color"])
```

#### 3. FBX„Ç®„ÇØ„Çπ„Éù„Éº„Éà„ÅÆBlender 4.2ÂØæÂøú
```python
# ‚úÖ Blender 4.2ÂØæÂøú
bpy.ops.export_scene.fbx(
    filepath=output_path,
    embed_textures=True,
    path_mode='COPY'
    # use_ascii=False  # ‚Üê ÂâäÈô§Ê∏à„Åø„Éë„É©„É°„Éº„Çø
)

# ‚ùå ÈùûÂØæÂøú: Âè§„ÅÑAPI
bpy.ops.export_scene.fbx(use_ascii=False)  # „Ç®„É©„Éº„Å®„Å™„Çã
```

#### 4. „ÉÜ„ÇØ„Çπ„ÉÅ„É£„Éë„ÉÉ„Ç≠„É≥„Ç∞„ÅÆÊúÄÈÅ©Âåñ
```python
# ÂøÖÈ†àÊâãÈ†Ü: ‰∫ãÂâç„Éë„ÉÉ„Ç≠„É≥„Ç∞
bpy.ops.file.pack_all()

# Êé®Â•®Ë®≠ÂÆö: Á¢∫ÂÆü„Å™Âüã„ÇÅËæº„Åø
embed_textures=True
path_mode='COPY'
```

### üö® Critical Implementation Notes

#### UV Transfer Success Pattern
- **Loop-based Transfer**: Always use loop indices, not vertex indices
- **Direct Assignment**: Use direct UV coordinate assignment without transformation
- **Range Safety**: Always check index bounds before assignment

#### Material Restoration Requirements
- **Node Tree Reconstruction**: Complete reconstruction of material node trees
- **Texture Reference Preservation**: Maintain original image node references
- **BSDF Connection**: Proper connection to Principled BSDF inputs

#### FBX Texture Packing Optimization
- **Pre-packing**: Always call `bpy.ops.file.pack_all()` before export
- **Embed Settings**: Use `embed_textures=True` and `path_mode='COPY'`
- **Blender 4.2 Compatibility**: Remove all `use_ascii` parameters

**‚ö†Ô∏è ÈáçË¶Å**: „Åì„Çå„Çâ„ÅÆÊäÄË°ìÁöÑÁü•Ë¶ã„ÅØ`test_step5_syntax_fixed.py`„ÅßÂÆüË®ºÊ∏à„Åø„Åß„Åô„ÄÇÂÆüË£ÖÊôÇ„ÅØÂøÖ„Åö„Åì„ÅÆ„É™„Éï„Ç°„É¨„É≥„Çπ„Éï„Ç°„Ç§„É´„ÇíÂèÇÁÖß„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

---
`````````````
