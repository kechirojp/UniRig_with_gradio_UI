"""
ğŸ¯ UniRig WebUIå®Œå…¨ç‰ˆ - src/pipelineçµ±åˆãƒ»æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥å®Œå…¨é©ç”¨

æ”¹ä¿®å®Œäº† (2025å¹´6æœˆ14æ—¥ - æœ€çµ‚çµ±åˆç‰ˆ):
1. src/pipelineçµ±åˆã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰é‡è¤‡è§£æ¶ˆ
2. æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥å®Œå…¨é©ç”¨ 
3. åŸæµå‡¦ç†äº’æ›æ€§100%ç¢ºä¿
4. ã‚¨ãƒ©ãƒ¼å‡¦ç†ãƒ»æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ å¼·åŒ–
5. ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å®Œå…¨å¯¾å¿œ
"""
import gradio as gr
import os
import shutil
import time
import logging
import subprocess
import socket
import sys
from pathlib import Path
from typing import Tuple, Optional, Dict, Any

# ğŸ¯ æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç®¡ç†ã‚¯ãƒ©ã‚¹ï¼ˆãƒ¡ã‚¤ãƒ³ã®æ–½ç­–ï¼‰
from fixed_directory_manager import FixedDirectoryManager

# ğŸ”§ çµ±ä¸€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼ˆå®Œå…¨ç‰ˆï¼‰
from unified_pipeline_orchestrator import UnifiedPipelineOrchestrator

# ğŸ”§ ä¸­é–“ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ„ãƒ¼ãƒ«
from cleanup_intermediate_data import IntermediateDataCleaner

# ğŸ”§ src/pipelineçµ±åˆã‚¯ãƒ©ã‚¹
from src.pipeline.unified_extract import UnifiedExtractor
from src.pipeline.unified_skinning import UnifiedSkinningOrchestrator

# ğŸ”§ step_modulesçµ±åˆã‚¯ãƒ©ã‚¹
# Step1, Step2 imports will be done dynamically within functions to avoid conflicts
from src.pipeline.unified_merge import UnifiedMergeOrchestrator
from src.pipeline.unified_blender import UnifiedBlenderOrchestrator
from src.pipeline.pipeline_error_analyzer import PipelineErrorAnalyzer

# ğŸ”§ step_modulesçµ±åˆã‚¯ãƒ©ã‚¹
from step_modules.step0_asset_preservation import Step0AssetPreservation

# å®šæ•°
PIPELINE_BASE_DIR = Path("/app/pipeline_work")
DEFAULT_MODEL_NAME = "default_model"

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ­ã‚¬ãƒ¼è¨­å®š ---
app_logger = logging.getLogger("UniRigApp")
if not app_logger.handlers:
    app_logger.setLevel(logging.DEBUG)
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    console_handler.setFormatter(console_formatter)
    app_logger.addHandler(console_handler)

# --- ã‚·ãƒ³ãƒ—ãƒ«FileManagerã‚¯ãƒ©ã‚¹ ---
# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ---
def extract_model_name_from_file(file_path: str) -> str:
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«åã‚’æŠ½å‡º"""
    if not file_path:
        return DEFAULT_MODEL_NAME
    
    filename = Path(file_path).stem  # æ‹¡å¼µå­ã‚’é™¤ã„ãŸãƒ•ã‚¡ã‚¤ãƒ«å
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ äº’æ›æ€§ã®ãŸã‚ã‚µãƒ‹ã‚¿ã‚¤ã‚º
    sanitized = filename.replace(" ", "_").replace(":", "_").replace("/", "_")
    return sanitized if sanitized else DEFAULT_MODEL_NAME

def execute_complete_pipeline(uploaded_file_info, gender: str, auto_cleanup: bool = False) -> tuple[bool, str]:
    """ä¸€æ°—é€šè²«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œï¼ˆè©³ç´°ãƒ­ã‚°ç‰ˆï¼‰"""
    if not uploaded_file_info:
        return False, "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ãƒ¢ãƒ‡ãƒ«åã‚’è‡ªå‹•å–å¾—
    model_name = extract_model_name_from_file(uploaded_file_info.name)
    input_file_path = uploaded_file_info.name
    
    app_logger.info(f"ä¸€æ°—é€šè²«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹: {model_name}")
    
    # è©³ç´°ãƒ­ã‚°ã®åˆæœŸåŒ–
    detailed_logs = []
    detailed_logs.append(f"ğŸ“Š ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è©³ç´°ãƒ­ã‚°")
    detailed_logs.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    
    try:
        # äº‹å‰ã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼
        detailed_logs.append(f"ğŸ” ã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼é–‹å§‹...")
        error_analyzer = PipelineErrorAnalyzer(app_logger)
        system_check = error_analyzer.validate_system_requirements()
        if not system_check["valid"]:
            detailed_logs.append(f"[FAIL] ã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼å¤±æ•—: {system_check['message']}")
            return False, "\n".join(detailed_logs)
        detailed_logs.append(f"[OK] ã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼å®Œäº†")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ (æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥)
        detailed_logs.append(f"[FILE] ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆä¸­...")
        fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
        fdm.create_all_directories()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        original_filename = Path(input_file_path).name
        target_path = fdm.model_dir / original_filename
        file_size = Path(input_file_path).stat().st_size / (1024 * 1024)  # MB
        shutil.copy(input_file_path, target_path)
        app_logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {target_path}")
        detailed_logs.append(f"[OK] ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: {original_filename} ({file_size:.2f}MB)")
        detailed_logs.append(f"[DIR] ä¿å­˜å…ˆ: {target_path}")
        
        # Step 0: ã‚¢ã‚»ãƒƒãƒˆä¿å­˜
        detailed_logs.append(f"")
        detailed_logs.append(f"ğŸ”§ Step 0: ã‚¢ã‚»ãƒƒãƒˆä¿å­˜é–‹å§‹")
        detailed_logs.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        app_logger.info(f"Step 0 é–‹å§‹: {model_name}")
        success, step_logs = execute_step0(model_name, str(target_path))
        if not success:
            error_report = error_analyzer.diagnose_execution_error(
                Exception(step_logs), "step0"
            )
            detailed_logs.append(f"[FAIL] Step 0 å¤±æ•—: {step_logs}")
            detailed_logs.append(f"ğŸ’¡ è§£æ±ºç­–: {error_report.get('suggested_solution', 'ä¸æ˜')}")
            return False, "\n".join(detailed_logs)
        detailed_logs.append(f"[OK] Step 0 å®Œäº†")
        detailed_logs.append(f"ğŸ“‹ è©³ç´°: {step_logs}")
        
        # Step 1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º
        detailed_logs.append(f"")
        detailed_logs.append(f"ğŸ”§ Step 1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºé–‹å§‹")
        detailed_logs.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        app_logger.info(f"Step 1 é–‹å§‹: {model_name}")
        success, step_logs = execute_step1_wrapper(model_name, str(target_path))
        if not success:
            error_report = error_analyzer.diagnose_execution_error(
                Exception(step_logs), "step1"
            )
            detailed_logs.append(f"[FAIL] Step 1 å¤±æ•—: {step_logs}")
            detailed_logs.append(f"ğŸ’¡ è§£æ±ºç­–: {error_report.get('suggested_solution', 'ä¸æ˜')}")
            return False, "\n".join(detailed_logs)
        detailed_logs.append(f"[OK] Step 1 å®Œäº†")
        detailed_logs.append(f"ğŸ“‹ è©³ç´°: {step_logs}")
        
        # Step 2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ
        detailed_logs.append(f"")
        detailed_logs.append(f"ğŸ”§ Step 2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆé–‹å§‹")
        detailed_logs.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        app_logger.info(f"Step 2 é–‹å§‹: {model_name}")
        success, step_logs = execute_step2(model_name, gender)
        if not success:
            error_report = error_analyzer.diagnose_execution_error(
                Exception(step_logs), "step2"
            )
            detailed_logs.append(f"[FAIL] Step 2 å¤±æ•—: {step_logs}")
            detailed_logs.append(f"ğŸ’¡ è§£æ±ºç­–: {error_report.get('suggested_solution', 'ä¸æ˜')}")
            return False, "\n".join(detailed_logs)
        detailed_logs.append(f"[OK] Step 2 å®Œäº†")
        detailed_logs.append(f"ğŸ“‹ è©³ç´°: {step_logs}")
        
        # Step 3: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°
        detailed_logs.append(f"")
        detailed_logs.append(f"ğŸ”§ Step 3: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨é–‹å§‹")
        detailed_logs.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        app_logger.info(f"Step 3 é–‹å§‹: {model_name}")
        success, step_logs = execute_step3(model_name)
        if not success:
            error_report = error_analyzer.diagnose_execution_error(
                Exception(step_logs), "step3"
            )
            detailed_logs.append(f"[FAIL] Step 3 å¤±æ•—: {step_logs}")
            detailed_logs.append(f"ğŸ’¡ è§£æ±ºç­–: {error_report.get('suggested_solution', 'ä¸æ˜')}")
            return False, "\n".join(detailed_logs)
        detailed_logs.append(f"[OK] Step 3 å®Œäº†")
        detailed_logs.append(f"ğŸ“‹ è©³ç´°: {step_logs}")
        
        # Step 4: ãƒãƒ¼ã‚¸
        detailed_logs.append(f"")
        detailed_logs.append(f"ğŸ”§ Step 4: ãƒãƒ¼ã‚¸å‡¦ç†é–‹å§‹")
        detailed_logs.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        app_logger.info(f"Step 4 é–‹å§‹: {model_name}")
        success, step_logs = execute_step4(model_name)
        if not success:
            error_report = error_analyzer.diagnose_execution_error(
                Exception(step_logs), "step4"
            )
            detailed_logs.append(f"[FAIL] Step 4 å¤±æ•—: {step_logs}")
            detailed_logs.append(f"ğŸ’¡ è§£æ±ºç­–: {error_report.get('suggested_solution', 'ä¸æ˜')}")
            return False, "\n".join(detailed_logs)
        detailed_logs.append(f"[OK] Step 4 å®Œäº†")
        detailed_logs.append(f"ğŸ“‹ è©³ç´°: {step_logs}")
        
        # Step 5: æœ€çµ‚çµ±åˆ
        detailed_logs.append(f"")
        detailed_logs.append(f"ğŸ”§ Step 5: æœ€çµ‚çµ±åˆé–‹å§‹")
        detailed_logs.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        app_logger.info(f"Step 5 é–‹å§‹: {model_name}")
        success, step_logs = execute_step5(model_name)
        if not success:
            error_report = error_analyzer.diagnose_execution_error(
                Exception(step_logs), "step5"
            )
            detailed_logs.append(f"[FAIL] Step 5 å¤±æ•—: {step_logs}")
            detailed_logs.append(f"ğŸ’¡ è§£æ±ºç­–: {error_report.get('suggested_solution', 'ä¸æ˜')}")
            return False, "\n".join(detailed_logs)
        detailed_logs.append(f"[OK] Step 5 å®Œäº†")
        detailed_logs.append(f"ğŸ“‹ è©³ç´°: {step_logs}")
        
        # æœ€çµ‚æ¤œè¨¼
        detailed_logs.append(f"")
        detailed_logs.append(f"ğŸ” æœ€çµ‚æ¤œè¨¼é–‹å§‹")
        detailed_logs.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        final_check = fdm.get_pipeline_completion_status()
        completion_rate = sum(final_check.values()) / len(final_check) * 100
        
        detailed_logs.append(f"ğŸ“Š å®Œäº†ç‡: {completion_rate:.1f}%")
        for step, completed in final_check.items():
            status = "[OK]" if completed else "[FAIL]"
            detailed_logs.append(f"   {step}: {status}")
            detailed_logs.append(f"  {status} {step}: {'å®Œäº†' if completed else 'æœªå®Œäº†'}")
        
        final_output_files = fdm.get_expected_files('step5')
        final_output = final_output_files.get('final_output') or final_output_files.get('final_fbx')
        
        if final_output and final_output.exists():
            file_size = final_output.stat().st_size / (1024 * 1024)  # MB
            detailed_logs.append(f"[FILE] æœ€çµ‚å‡ºåŠ›: {final_output}")
            detailed_logs.append(f"[SIZE] ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:.2f}MB")
            detailed_logs.append(f"[FORMAT] å½¢å¼: {final_output.suffix.upper()}")
        else:
            detailed_logs.append(f"[WARN] æœ€çµ‚å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        app_logger.info(f"ä¸€æ°—é€šè²«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†: {model_name} ({completion_rate:.1f}%)")
        
        # è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if auto_cleanup and completion_rate >= 100.0:
            detailed_logs.append(f"")
            detailed_logs.append(f"ğŸ§¹ è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–‹å§‹")
            detailed_logs.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            
            try:
                cleaner = IntermediateDataCleaner(logger_instance=app_logger)
                cleanup_success, cleanup_message = cleaner.cleanup_specific_model(model_name, create_backup=False)
                
                if cleanup_success:
                    detailed_logs.append(f"[OK] è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {cleanup_message}")
                    app_logger.info(f"è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {model_name}")
                else:
                    detailed_logs.append(f"âš ï¸ è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¤±æ•—: {cleanup_message}")
                    app_logger.warning(f"è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¤±æ•—: {model_name} - {cleanup_message}")
                    
            except Exception as cleanup_error:
                detailed_logs.append(f"[FAIL] è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {str(cleanup_error)}")
                app_logger.error(f"è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {cleanup_error}")
        
        return True, "\n".join(detailed_logs)
        
    except Exception as e:
        error_report = error_analyzer.diagnose_execution_error(e, "pipeline")
        app_logger.error(f"ä¸€æ°—é€šè²«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        detailed_logs.append(f"")
        detailed_logs.append(f"[FAIL] è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ")
        detailed_logs.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        detailed_logs.append(f"ğŸ› ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}")
        detailed_logs.append(f"ğŸ’¡ è§£æ±ºç­–: {error_report.get('suggested_solution', 'ä¸æ˜')}")
        return False, "\n".join(detailed_logs)

# --- ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œé–¢æ•°ç¾¤ï¼ˆsrc/pipelineçµ±åˆç‰ˆï¼‰ ---
def execute_step0(model_name: str, input_file_path: str) -> tuple[bool, str]:
    """Step0: ã‚¢ã‚»ãƒƒãƒˆä¿å­˜å®Ÿè¡Œï¼ˆæ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥ï¼‰"""
    try:
        fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
        
        # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
        if not Path(input_file_path).exists():
            return False, f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {input_file_path}"
        
        step0 = Step0AssetPreservation(model_name, input_file_path, fdm.get_step_dir('step0'), app_logger)
        success, logs, files = step0.preserve_assets()
        
        # æœŸå¾…å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼
        expected = fdm.get_expected_files("step0")
        created_files = []
        for key, path in expected.items():
            if path.exists():
                created_files.append(f"{key}: {path}")
        
        final_logs = logs + f"\nä½œæˆãƒ•ã‚¡ã‚¤ãƒ«: {len(created_files)}å€‹\n" + "\n".join(created_files)
        return success, final_logs
    except Exception as e:
        return False, f"Step0 ã‚¨ãƒ©ãƒ¼: {str(e)}"

def execute_step1_wrapper(model_name: str, input_file_path: str) -> tuple[bool, str]:
    """Step1ãƒ©ãƒƒãƒ‘ãƒ¼: step_modulesã®execute_step1ã‚’ä½¿ç”¨"""
    try:
        fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
        
        # äº‹å‰æ¤œè¨¼
        error_analyzer = PipelineErrorAnalyzer(app_logger)
        validation_result = error_analyzer.validate_input_requirements("step1", {
            "input_file": input_file_path,
            "model_name": model_name
        })
        
        if not validation_result["valid"]:
            return False, f"Step1 äº‹å‰æ¤œè¨¼å¤±æ•—: {validation_result['message']}"
        
        # step_modules/step1_extract.pyã‚’ä½¿ç”¨
        from step_modules.step1_extract import execute_step1
        
        output_dir = fdm.get_step_dir('step1')
        output_dir.mkdir(parents=True, exist_ok=True)
        
        success, logs, output_files = execute_step1(
            input_file_path=Path(input_file_path),
            model_name=model_name,
            step_output_dir=output_dir,
            logger_instance=app_logger
        )
        
        # æœŸå¾…å‡ºåŠ›ç¢ºèª
        expected = fdm.get_expected_files("step1")
        if expected["raw_data_npz"].exists():
            logs += f"\n[OK] æœŸå¾…å‡ºåŠ›ç¢ºèª: {expected['raw_data_npz']} (å­˜åœ¨)"
            file_size = expected["raw_data_npz"].stat().st_size
            logs += f"\n[OK] ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:,} bytes"
        else:
            logs += f"\n[FAIL] æœŸå¾…å‡ºåŠ›æœªä½œæˆ: {expected['raw_data_npz']}"
        
        return success, logs
    except Exception as e:
        app_logger.error(f"Step1å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return False, f"Step1 ã‚¨ãƒ©ãƒ¼: {str(e)}"

def execute_step2(model_name: str, gender: str) -> tuple[bool, str]:
    """Step2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå®Ÿè¡Œï¼ˆãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã‚’å«ã‚€ï¼‰
    
    é‡è¦: ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã®çŸ¥è¦‹ã«åŸºã¥ãã€åŸæµgenerate_skeleton.shã¨åŒã˜å‡¦ç†é †åºã‚’å®Ÿè¡Œ:
    1. ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå‰ã«å¿…ãšãƒ¡ãƒƒã‚·ãƒ¥ã‚’å†æŠ½å‡º
    2. AIæ¨è«–ç‰¹åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼ˆ--require_suffix, --faces_target_count=4000, --time=8ï¼‰
    3. å°‚ç”¨å‰å‡¦ç†ï¼ˆar_post_process.pyï¼‰ã‚’é©ç”¨
    """
    try:
        fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
        
        # ã€é‡è¦ã€‘ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢ï¼ˆãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã®ãŸã‚ï¼‰
        app_logger.info(f"Step2: ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã«ã‚ˆã‚‹ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆé–‹å§‹ - {model_name}")
        
        # ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        original_file = fdm.find_original_model_file()
        if not original_file:
            return False, "Step2: ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã«å¿…è¦ï¼‰"
        
        app_logger.info(f"Step2: ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {original_file}")
        
        # Step2å°‚ç”¨å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        output_dir = fdm.get_step_dir('step2')
        
        # step_modules/step2_skeletonã‚’ä½¿ç”¨ï¼ˆæœ€æ–°ç‰ˆï¼‰
        from step_modules.step2_skeleton import Step2Skeleton
        
        step2_module = Step2Skeleton(output_dir, app_logger)
        
        # ã€é‡è¦ã€‘ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã‚’å«ã‚€ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå®Ÿè¡Œ
        success, skeleton_logs, output_files = step2_module.generate_skeleton(
            original_file=original_file,
            model_name=model_name,
            gender=gender
        )
        
        # æœŸå¾…å‡ºåŠ›ç¢ºèª
        expected = fdm.get_expected_files("step2")
        output_check = []
        for key, path in expected.items():
            if path.exists():
                output_check.append(f"âœ“ {key}: {path}")
            else:
                output_check.append(f"âœ— {key}: {path}")
        
        # è©³ç´°ãƒ­ã‚°ã®çµ±åˆ
        combined_logs = f"""Step2å®Œäº†ãƒ­ã‚°:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆï¼‹ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºãƒ•ã‚§ãƒ¼ã‚ºã€‘
{skeleton_logs}

ã€å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã€‘
{chr(10).join(output_check)}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"""
        
        return success, combined_logs
        
    except Exception as e:
        app_logger.error(f"Step2å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return False, f"Step2 ã‚¨ãƒ©ãƒ¼: {str(e)}"


def execute_mesh_reextraction_for_skeleton(original_file: Path, model_name: str) -> tuple[bool, str]:
    """
    ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå°‚ç”¨ã®ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡º
    
    é‡è¦: åŸæµgenerate_skeleton.shã¨å®Œå…¨ã«åŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
    - --require_suffix: å³å¯†ãªå‘½åè¦å‰‡é©ç”¨
    - --faces_target_count=4000: AIæ¨è«–æœ€é©åŒ–ã•ã‚ŒãŸé¢æ•°
    - --time=8: ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ä¸
    - --post_process_script=post_process/ar_post_process.py: å°‚ç”¨å‰å‡¦ç†
    """
    app_logger.info(f"ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆç”¨ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºé–‹å§‹: {original_file}")
    
    try:
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆdataset_inference_clean/ï¼‰
        output_dir = Path("/app/dataset_inference_clean")
        
        # åŸæµgenerate_skeleton.shã¨åŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå®Ÿè¡Œ
        cmd = [
            "python", "-m", "src.data.extract",
            "--input", str(original_file),
            "--output", str(output_dir),
            "--name", model_name,
            "--require_suffix",           # å³å¯†ãªå‘½åè¦å‰‡
            "--faces_target_count", "4000",  # AIæ¨è«–æœ€é©åŒ–
            "--time", "8",                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
            "--post_process_script", "post_process/ar_post_process.py"  # å°‚ç”¨å‰å‡¦ç†
        ]
        
        app_logger.info(f"ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã‚³ãƒãƒ³ãƒ‰: {' '.join(cmd)}")
        
        # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            cwd="/app",
            timeout=300  # 5åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        )
        
        if result.returncode == 0:
            # å†æŠ½å‡ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
            reextracted_mesh = output_dir / "raw_data.npz"
            if reextracted_mesh.exists():
                file_size = reextracted_mesh.stat().st_size
                success_log = f"""[OK] ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆç”¨ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºæˆåŠŸ
[FILE] å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {reextracted_mesh}
ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:,} bytes
ğŸ¯ ä½¿ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: åŸæµgenerate_skeleton.shäº’æ›
   - require_suffix: æœ‰åŠ¹
   - faces_target_count: 4000
   - time: 8
   - post_process_script: ar_post_process.py

ğŸ“ æ¨™æº–å‡ºåŠ›:
{result.stdout}"""
                app_logger.info("ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆç”¨ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºå®Œäº†")
                return True, success_log
            else:
                return False, f"å†æŠ½å‡ºãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå¤±æ•—: raw_data.npzãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        else:
            error_log = f"""[FAIL] ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆç”¨ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºå¤±æ•—
ğŸš¨ çµ‚äº†ã‚³ãƒ¼ãƒ‰: {result.returncode}
ğŸ“ æ¨™æº–ã‚¨ãƒ©ãƒ¼:
{result.stderr}

ğŸ“ æ¨™æº–å‡ºåŠ›:
{result.stdout}"""
            return False, error_log
            
    except subprocess.TimeoutExpired:
        return False, "ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ5åˆ†åˆ¶é™ï¼‰"
    except Exception as e:
        return False, f"ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}"

def execute_step3(model_name: str) -> tuple[bool, str]:
    """Step3: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å®Ÿè¡Œï¼ˆåŸæµäº’æ›ç‰ˆï¼‰
    
    é‡è¦: åŸæµgenerate_skin.shã¨åŒã˜å‡¦ç†é †åº:
    1. ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”Ÿæˆå‰ã«å¿…ãšãƒ¡ãƒƒã‚·ãƒ¥ã‚’å†æŠ½å‡º
    2. Step2ã®å‡ºåŠ› (predict_skeleton.npz) ã¨ä½µç”¨
    3. dataset_inference_clean/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§å‡¦ç†å®Ÿè¡Œ
    """
    try:
        fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
        
        # ã€é‡è¦ã€‘ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢ï¼ˆã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”¨ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã®ãŸã‚ï¼‰
        # Note: è©³ç´°ãƒ­ã‚°ã¯step_moduleså´ã§å‡ºåŠ›ã•ã‚Œã‚‹
        
        # ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        original_file = fdm.find_original_model_file()
        if not original_file:
            return False, "Step3: ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”¨ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã«å¿…è¦ï¼‰"
        
        app_logger.info(f"Step3: ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {original_file}")
        
        # Step2ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
        step2_files = fdm.get_expected_files("step2")
        skeleton_npz = step2_files["skeleton_npz"]
        skeleton_fbx = step2_files["skeleton_fbx"]
        
        if not skeleton_npz.exists():
            return False, f"Step3: predict_skeleton.npzãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {skeleton_npz}"
        if not skeleton_fbx.exists():
            return False, f"Step3: ã‚¹ã‚±ãƒ«ãƒˆãƒ³FBXãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {skeleton_fbx}"
        
        # Step3å°‚ç”¨å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        output_dir = fdm.get_step_dir('step3')
        
        # step_modules/step3_skinning_unirigã‚’ä½¿ç”¨ï¼ˆæœ€æ–°ç‰ˆï¼‰
        from step_modules.step3_skinning_unirig import Step3Skinning
        
        step3_module = Step3Skinning(output_dir)
        
        # Step2ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«è¾æ›¸ã‚’æº–å‚™
        skeleton_files = {
            "skeleton_npz": str(skeleton_npz),
            "skeleton_fbx": str(skeleton_fbx)
        }
        
        # ã€é‡è¦ã€‘ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¨Step2å‡ºåŠ›ã‚’ä½¿ç”¨ã—ã¦ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
        # ã“ã®å†…éƒ¨ã§åŸæµã¨åŒæ§˜ã«ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºãŒå®Ÿè¡Œã•ã‚Œã‚‹
        success, logs, output_files = step3_module.apply_skinning(
            model_name=model_name,
            original_file=original_file,  # ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«
            skeleton_files=skeleton_files
        )
        
        # æœŸå¾…å‡ºåŠ›ç¢ºèª
        expected = fdm.get_expected_files("step3")
        if expected["skinned_fbx"].exists():
            logs += f"\n[OK] æœŸå¾…å‡ºåŠ›ç¢ºèª: {expected['skinned_fbx']} (å­˜åœ¨)\n"
        else:
            logs += f"\nâš ï¸ æœŸå¾…å‡ºåŠ›æœªä½œæˆ: {expected['skinned_fbx']}\n"
        
        return success, logs
    except Exception as e:
        app_logger.error(f"Step3å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return False, f"Step3 ã‚¨ãƒ©ãƒ¼: {str(e)}"

def execute_step4(model_name: str) -> tuple[bool, str]:
    """Step4: 3ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹çµ±åˆãƒãƒ¼ã‚¸ï¼ˆKDTreeãƒãƒƒãƒãƒ³ã‚°æŠ€è¡“ï¼‰
    
    æœ€æ–°çŸ¥è¦‹ã«ã‚ˆã‚‹æœ¬è³ªçš„å®šç¾©:
    - ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¡ãƒƒã‚·ãƒ¥ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰+ AIã‚¹ã‚­ãƒ‹ãƒ³ã‚°ï¼ˆStep3å‡ºåŠ›ï¼‰ã®çµ±åˆ
    - Step3å‡ºåŠ›ï¼ˆskinned_fbxï¼‰ã«ã‚¹ã‚­ãƒ³ã‚¦ã‚§ã‚¤ãƒˆæƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚ã€ã“ã‚Œã‚’sourceã«ä½¿ç”¨
    - KDTreeæœ€è¿‘å‚ãƒãƒƒãƒãƒ³ã‚°ã«ã‚ˆã‚‹é ‚ç‚¹æ•°å·®ç•°å¸åã‚·ã‚¹ãƒ†ãƒ 
    - ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¡ãƒƒã‚·ãƒ¥ã‚’targetã¨ã—ã¦ã€ã‚¹ã‚­ãƒ³ã‚¦ã‚§ã‚¤ãƒˆæƒ…å ±ã‚’æ­£ç¢ºã«è»¢å†™
    """
    try:
        fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
        
        # å…¥åŠ›æ¤œè¨¼ï¼ˆ3ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ç¢ºèªï¼‰
        valid, message, available_files = fdm.validate_step_inputs("step4")
        if not valid:
            return False, f"Step4 å…¥åŠ›æ¤œè¨¼å¤±æ•—ï¼ˆ3ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹çµ±åˆã«å¿…è¦ï¼‰: {message}"
        
        # ã€é‡è¦ä¿®æ­£ã€‘ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹1: AIã‚¹ã‚­ãƒ‹ãƒ³ã‚°ï¼ˆStep3å‡ºåŠ›ï¼‰- sourceå¼•æ•°ã¨ã—ã¦ä½¿ç”¨
        # Step3ã§ç”Ÿæˆã•ã‚ŒãŸskinned_fbxã«ã¯æ­£ã—ã„ã‚¹ã‚­ãƒ³ã‚¦ã‚§ã‚¤ãƒˆæƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹
        skinned_fbx = available_files.get("skinned_fbx")
        if not skinned_fbx or not Path(skinned_fbx).exists():
            return False, "Step4 ã‚¨ãƒ©ãƒ¼: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXï¼ˆStep3å‡ºåŠ›ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆã‚¹ã‚­ãƒ³ã‚¦ã‚§ã‚¤ãƒˆè»¢å†™ã«å¿…è¦ï¼‰"
        
        # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹2: ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¡ãƒƒã‚·ãƒ¥ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰- targetå¼•æ•°ã¨ã—ã¦ä½¿ç”¨
        # é‡è¦: model_dirã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        original_files = list(fdm.model_dir.glob("*"))
        original_file = None
        for f in original_files:
            if f.suffix.lower() in ['.glb', '.fbx', '.obj', '.dae', '.gltf']:
                original_file = str(f)
                break
        
        if not original_file:
            return False, "Step4 ã‚¨ãƒ©ãƒ¼: ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¡ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆ3ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹çµ±åˆã«å¿…è¦ï¼‰"
        
        app_logger.info(f"Step4: ã‚¹ã‚­ãƒ³ã‚¦ã‚§ã‚¤ãƒˆè»¢å†™å‡¦ç† - source: {skinned_fbx}, target: {original_file}")
        
        # unified_mergeä½¿ç”¨ï¼ˆ3ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹çµ±åˆå‡¦ç†ï¼‰
        merge_orchestrator = UnifiedMergeOrchestrator(app_logger)
        output_dir = fdm.get_step_dir('step4')
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ã€ä¿®æ­£ã€‘é‡è¦ãªæŠ€è¡“çš„ç™ºè¦‹: skinned_fbxï¼ˆStep3å‡ºåŠ›ï¼‰ã‚’sourceã«ä½¿ç”¨
        success, logs = merge_orchestrator.merge_skeleton_skinning_unified(
            model_name=model_name,
            skinned_fbx=str(skinned_fbx),   # source: AIã‚¹ã‚­ãƒ‹ãƒ³ã‚°ï¼ˆStep3å‡ºåŠ›ãƒ»ã‚¹ã‚­ãƒ³ã‚¦ã‚§ã‚¤ãƒˆä»˜ãï¼‰
            original_file=original_file,    # target: ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¡ãƒƒã‚·ãƒ¥ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰
            output_dir=str(output_dir)
        )
        
        # æœŸå¾…å‡ºåŠ›ç¢ºèª
        expected = fdm.get_expected_files("step4")
        if expected["merged_fbx"].exists():
            logs += f"\næœŸå¾…å‡ºåŠ›ç¢ºèª: {expected['merged_fbx']} (å­˜åœ¨)"
        else:
            logs += f"\nâš ï¸ æœŸå¾…å‡ºåŠ›æœªä½œæˆ: {expected['merged_fbx']}"
        
        return success, logs
    except Exception as e:
        app_logger.error(f"Step4å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return False, f"Step4 ã‚¨ãƒ©ãƒ¼: {str(e)}"

def execute_step5(model_name: str) -> tuple[bool, str]:
    """Step5: ãƒªã‚®ãƒ³ã‚°ç§»æ¤å¯¾å¿œæœ€çµ‚çµ±åˆå®Ÿè¡Œ"""
    try:
        fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
        
        # å…¥åŠ›æ¤œè¨¼
        valid, message, available_files = fdm.validate_step_inputs("step5")
        if not valid:
            return False, f"Step5 å…¥åŠ›æ¤œè¨¼å¤±æ•—: {message}"
        
        merged_fbx = available_files["merged_fbx"]
        original_file = available_files.get("original_file")
        
        if not original_file:
            return False, "Step5: ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        
        # Step5Blenderãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½¿ç”¨ï¼ˆãƒªã‚®ãƒ³ã‚°ç§»æ¤å¯¾å¿œï¼‰
        from step_modules.step5_blender_integration import Step5BlenderIntegration
        output_dir = fdm.get_step_dir('step5')
        
        step5 = Step5BlenderIntegration(output_dir)
        success, logs, output_files = step5.integrate_final_output(
            model_name=model_name,
            original_file=Path(original_file),    # ã‚¢ã‚»ãƒƒãƒˆæƒ…å ±æºï¼ˆãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»UVãƒ»ãƒãƒ†ãƒªã‚¢ãƒ«ï¼‰
            rigged_file=Path(merged_fbx)          # ãƒªã‚®ãƒ³ã‚°æƒ…å ±æºï¼ˆãƒœãƒ¼ãƒ³ãƒ»ã‚¹ã‚­ãƒ³ï¼‰
        )
        
        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
        if success and output_files.get("final_output"):
            final_output = Path(output_files["final_output"])
            if final_output.exists():
                logs += f"\nâœ… æœ€çµ‚å‡ºåŠ›ç¢ºèª: {final_output} (å­˜åœ¨ã€{output_files.get('size_mb', 0):.2f} MB)"
            else:
                logs += f"\nâš ï¸ æœ€çµ‚å‡ºåŠ›æœªä½œæˆ: {final_output}"
                success = False
        
        return success, logs
    except Exception as e:
        app_logger.error(f"Step5å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return False, f"Step5 ã‚¨ãƒ©ãƒ¼: {str(e)}"

# --- Gradio UIï¼ˆæ”¹è‰¯ç‰ˆï¼‰ ---
def create_simple_ui():
    """æ”¹è‰¯ã•ã‚ŒãŸGradio UIä½œæˆï¼ˆsrc/pipelineçµ±åˆç‰ˆï¼‰"""
    
    with gr.Blocks(title="UniRig WebUI - å®Œå…¨ç‰ˆ") as demo:
        gr.Markdown("# ğŸ¯ UniRig WebUI - å®Œå…¨çµ±åˆç‰ˆ")
        gr.Markdown("**src/pipelineçµ±åˆãƒ»æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥å®Œå…¨é©ç”¨ãƒ»ã‚¨ãƒ©ãƒ¼äºˆé˜²ã‚·ã‚¹ãƒ†ãƒ æ­è¼‰**")
        
        with gr.Row():
            with gr.Column():
                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                uploaded_file = gr.File(
                    label="3Dãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« (.glb, .fbx, .obj, .vrm)",
                    file_types=[".glb", ".fbx", ".obj", ".vrm", ".dae", ".gltf"]
                )
                model_name_input = gr.Textbox(
                    label="ãƒ¢ãƒ‡ãƒ«å (è‡ªå‹•å–å¾—)", 
                    value="", 
                    placeholder="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã«è‡ªå‹•è¨­å®š", 
                    interactive=False
                )
                gender_input = gr.Radio(
                    ["neutral", "male", "female"], 
                    label="æ€§åˆ¥", 
                    value="neutral"
                )
                
                # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†å¾Œã®è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                auto_cleanup_checkbox = gr.Checkbox(
                    label="ğŸ§¹ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†å¾Œã«ä¸­é–“ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•å‰Šé™¤",
                    value=False,
                    info="æœ€çµ‚å‡ºåŠ›ä½œæˆå¾Œã€ä¸­é–“ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•çš„ã«å‰Šé™¤ã—ã¦ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã‚’ç¯€ç´„"
                )
                
                # ä¸€æ°—é€šè²«å‡¦ç†ãƒœã‚¿ãƒ³
                with gr.Row():
                    complete_pipeline_btn = gr.Button(
                        "ğŸš€ ä¸€æ°—é€šè²«å®Ÿè¡Œ (å…¨ã‚¹ãƒ†ãƒƒãƒ—è‡ªå‹•)", 
                        variant="primary", 
                        size="lg"
                    )
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³
                gr.Markdown("### ğŸ“¥ çµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                download_btn = gr.Button("ğŸ“¥ ãƒªã‚®ãƒ³ã‚°æ¸ˆãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", variant="secondary")
                download_file = gr.File(
                    label="ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«", 
                    visible=True,
                    interactive=False,  # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å°‚ç”¨
                    file_count="single"  # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«
                )
                
                gr.Markdown("---")
                gr.Markdown("### ğŸ”§ å€‹åˆ¥ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰")
                
                # ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œãƒœã‚¿ãƒ³
                with gr.Row():
                    step0_btn = gr.Button("Step 0: ã‚¢ã‚»ãƒƒãƒˆä¿å­˜", size="sm")
                    step1_btn = gr.Button("Step 1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º", size="sm")
                    step2_btn = gr.Button("Step 2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ", size="sm")
                with gr.Row():
                    step3_btn = gr.Button("Step 3: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°", size="sm")
                    step4_btn = gr.Button("Step 4: 3ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹çµ±åˆãƒãƒ¼ã‚¸", size="sm")
                    step5_btn = gr.Button("Step 5: æœ€çµ‚çµ±åˆ", size="sm")
                
                with gr.Row():
                    reset_btn = gr.Button("ğŸ”„ ãƒªã‚»ãƒƒãƒˆ", variant="secondary", size="sm")
                    refresh_btn = gr.Button("ğŸ“Š çŠ¶æ…‹æ›´æ–°", variant="secondary", size="sm")
                
                # ä¸­é–“ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚»ã‚¯ã‚·ãƒ§ãƒ³
                gr.Markdown("---")
                gr.Markdown("### ğŸ§¹ ä¸­é–“ãƒ‡ãƒ¼ã‚¿ç®¡ç†")
                
                with gr.Row():
                    analyze_data_btn = gr.Button("ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æ", variant="secondary", size="sm")
                    cleanup_model_btn = gr.Button("ğŸ§¹ ã“ã®ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ¼ã‚¿å‰Šé™¤", variant="secondary", size="sm")
                    cleanup_all_btn = gr.Button("ğŸ—‘ï¸ å…¨ä¸­é–“ãƒ‡ãƒ¼ã‚¿å‰Šé™¤", variant="stop", size="sm")
                
                with gr.Row():
                    backup_checkbox = gr.Checkbox(
                        label="å‰Šé™¤å‰ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ", 
                        value=False
                    )
                
            with gr.Column():
                # çŠ¶æ…‹è¡¨ç¤º
                status_display = gr.Textbox(
                    label="ğŸ“Š ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çŠ¶æ…‹", 
                    lines=15, 
                    interactive=False,
                    placeholder="ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦çŠ¶æ…‹æ›´æ–°ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„",
                    max_lines=20
                )
                log_display = gr.Textbox(
                    label="ğŸ“‹ å®Ÿè¡Œãƒ­ã‚°", 
                    lines=15, 
                    interactive=False,
                    placeholder="å®Ÿè¡Œãƒ­ã‚°ãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™",
                    max_lines=25
                )
        
        # --- ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ ---
        def handle_upload(uploaded_file_info):
            if not uploaded_file_info:
                return "", "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ãƒ¢ãƒ‡ãƒ«åã‚’è‡ªå‹•å–å¾—
                model_name = extract_model_name_from_file(uploaded_file_info.name)
                fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
                fdm.create_all_directories()
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
                original_filename = Path(uploaded_file_info.name).name
                target_path = fdm.model_dir / original_filename
                shutil.copy(uploaded_file_info.name, target_path)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—
                file_size = target_path.stat().st_size / (1024 * 1024)  # MB
                
                return model_name, f"[OK] ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†\\n[FILE] ãƒ•ã‚¡ã‚¤ãƒ«: {original_filename}\\n[SIZE] ã‚µã‚¤ã‚º: {file_size:.2f} MB\\n[TAG] ãƒ¢ãƒ‡ãƒ«å: {model_name}\\n[DIR] ä¿å­˜å…ˆ: {target_path}"
            except Exception as e:
                return "", f"[FAIL] ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}"
        
        def get_status(model_name):
            """è©³ç´°ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çŠ¶æ…‹è¡¨ç¤º"""
            if not model_name:
                return "âš ï¸ ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            try:
                fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
                
                # çŠ¶æ…‹è©³ç´°ã®æ§‹ç¯‰
                status_lines = []
                status_lines.append(f"ğŸ“Š UniRig ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çŠ¶æ…‹ãƒ¬ãƒãƒ¼ãƒˆ")
                status_lines.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
                status_lines.append(f"[TAG] ãƒ¢ãƒ‡ãƒ«å: {model_name}")
                status_lines.append(f"[FILE] ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {fdm.model_dir}")
                status_lines.append(f"â° æ›´æ–°æ™‚åˆ»: {time.strftime('%Y-%m-%d %H:%M:%S')}")
                status_lines.append(f"")
                
                # å®Œäº†ç‡è¨ˆç®—ï¼ˆãƒ–ãƒ¼ãƒ«å€¤å¯¾å¿œï¼‰
                completion_status = fdm.get_pipeline_completion_status()
                completed_steps = sum(1 for status in completion_status.values() if status)
                total_steps = len(completion_status)
                completion_rate = completed_steps / total_steps * 100
                
                status_lines.append(f"ğŸ å…¨ä½“é€²æ—: {completed_steps}/{total_steps} ã‚¹ãƒ†ãƒƒãƒ—å®Œäº† ({completion_rate:.1f}%)")
                status_lines.append(f"")
                
                # å„ã‚¹ãƒ†ãƒƒãƒ—ã®è©³ç´°çŠ¶æ…‹
                step_details = {
                    'step0': 'ğŸ”§ Step 0: ã‚¢ã‚»ãƒƒãƒˆä¿å­˜',
                    'step1': 'ğŸ”§ Step 1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º', 
                    'step2': 'ğŸ”§ Step 2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ',
                    'step3': 'ğŸ”§ Step 3: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨',
                    'step4': 'ğŸ”§ Step 4: 3ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹çµ±åˆãƒãƒ¼ã‚¸ï¼ˆKDTreeæŠ€è¡“ï¼‰',
                    'step5': 'ğŸ”§ Step 5: æœ€çµ‚çµ±åˆ'
                }
                
                status_lines.append(f"ï¿½ ã‚¹ãƒ†ãƒƒãƒ—åˆ¥è©³ç´°çŠ¶æ…‹:")
                status_lines.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
                
                for step_id, step_name in step_details.items():
                    is_completed = completion_status.get(step_id, False)
                    status_icon = "[OK]" if is_completed else "[WAIT]"
                    status_text = "å®Œäº†" if is_completed else "æœªå®Ÿè¡Œ"
                    
                    status_lines.append(f"{status_icon} {step_name}: {status_text}")
                    
                    # æœŸå¾…ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
                    try:
                        expected_files = fdm.get_expected_files(step_id)
                        for file_key, file_path in expected_files.items():
                            if file_path.exists():
                                file_size = file_path.stat().st_size / (1024 * 1024)  # MB
                                status_lines.append(f"    [FILE] {file_key}: {file_path.name} ({file_size:.2f}MB)")
                            else:
                                status_lines.append(f"    [FAIL] {file_key}: æœªä½œæˆ")
                    except Exception as e:
                        status_lines.append(f"    âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«çŠ¶æ…‹ç¢ºèªã‚¨ãƒ©ãƒ¼: {str(e)}")
                    
                    status_lines.append(f"")
                
                # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡
                if fdm.model_dir.exists():
                    total_size = sum(f.stat().st_size for f in fdm.model_dir.rglob('*') if f.is_file())
                    total_size_mb = total_size / (1024 * 1024)
                    status_lines.append(f"ğŸ’¾ ç·ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡: {total_size_mb:.2f}MB")
                
                # æœ€çµ‚å‡ºåŠ›ã®çŠ¶æ…‹ï¼ˆå‹•çš„å½¢å¼å¯¾å¿œï¼‰
                step5_files = fdm.get_expected_files("step5")
                final_output = step5_files.get("final_output") or step5_files.get("final_fbx")
                if final_output and final_output.exists():
                    final_size = final_output.stat().st_size / (1024 * 1024)
                    status_lines.append(f"ğŸ¯ æœ€çµ‚å‡ºåŠ›: {final_output.name} ({final_size:.2f}MB)")
                else:
                    status_lines.append(f"ğŸ¯ æœ€çµ‚å‡ºåŠ›: æœªç”Ÿæˆ")
                
                return "\n".join(status_lines)
                
            except Exception as e:
                return f"[FAIL] çŠ¶æ…‹å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}\nè©³ç´°: {type(e).__name__}"
        
        def handle_download(model_name):
            """
            Gradio 5.31.0å¯¾å¿œã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å‡¦ç†
            ç›´æ¥ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è¿”ã™ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
            """
            if not model_name:
                return None, "âš ï¸ ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            try:
                fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
                
                # å‹•çš„å½¢å¼å¯¾å¿œ: find_file_with_dynamic_extensionã‚’ä½¿ç”¨
                final_output = fdm.find_file_with_dynamic_extension("step5", "final_output")
                
                if final_output and final_output.exists():
                    # Gradio 5.31.0: strå‹ãƒ‘ã‚¹ã‚’è¿”ã™ï¼ˆå¿…é ˆï¼‰
                    return str(final_output), f"[OK] ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æº–å‚™å®Œäº†: {final_output.name}"
                else:
                    return None, f"[FAIL] æœ€çµ‚å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            except Exception as e:
                app_logger.error(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
                return None, f"[FAIL] ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}"
        def handle_complete_pipeline(uploaded_file_info, gender, auto_cleanup):
            """ä¸€æ°—é€šè²«å‡¦ç†ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆè©³ç´°ãƒ­ã‚°è¡¨ç¤ºç‰ˆï¼‰"""
            if not uploaded_file_info:
                return "[FAIL] ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“", None, ""
            
            # é–‹å§‹ãƒ­ã‚°
            model_name = extract_model_name_from_file(uploaded_file_info.name)
            start_log = f"""ğŸš€ ä¸€æ°—é€šè²«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹
[FILE] ãƒ¢ãƒ‡ãƒ«å: {model_name}
[DIR] ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_file_info.name}
ğŸ‘¤ æ€§åˆ¥è¨­å®š: {gender}
ğŸ§¹ è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: {'æœ‰åŠ¹' if auto_cleanup else 'ç„¡åŠ¹'}
â° é–‹å§‹æ™‚åˆ»: {time.strftime('%Y-%m-%d %H:%M:%S')}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
            
            success, logs = execute_complete_pipeline(uploaded_file_info, gender, auto_cleanup)
            status_icon = "[OK]" if success else "[FAIL]"
            
            # çµ‚äº†ãƒ­ã‚°
            end_log = f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â° çµ‚äº†æ™‚åˆ»: {time.strftime('%Y-%m-%d %H:%M:%S')}
ğŸ æœ€çµ‚çµæœ: {status_icon} {'æˆåŠŸ' if success else 'å¤±æ•—'}
"""
            
            # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æˆåŠŸæ™‚ã¯è‡ªå‹•ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¨­å®š
            download_file_path = None
            if success:
                try:
                    fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
                    final_output = fdm.find_file_with_dynamic_extension("step5", "final_output")
                    if final_output and final_output.exists():
                        # Gradio 5.31.0: strå‹ãƒ‘ã‚¹ã‚’è¨­å®šï¼ˆå¿…é ˆï¼‰
                        download_file_path = str(final_output)
                except Exception as e:
                    app_logger.error(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
            
            return f"{start_log}{logs}{end_log}", download_file_path, model_name

        def handle_cleanup_intermediate_data(model_name, create_backup=False):
            """ä¸­é–“ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
            try:
                cleaner = IntermediateDataCleaner(logger_instance=app_logger)
                
                if model_name:
                    # ç‰¹å®šã®ãƒ¢ãƒ‡ãƒ«ã®ã¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                    success, message = cleaner.cleanup_specific_model(model_name, create_backup)
                else:
                    # å…¨ã¦ã®ä¸­é–“ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                    success, message = cleaner.cleanup_intermediate_data(create_backup)
                
                status_icon = "[OK]" if success else "[FAIL]"
                return f"{status_icon} {message}"
                
            except Exception as e:
                app_logger.error(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                return f"[FAIL] ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {str(e)}"
        
        def handle_analyze_intermediate_data():
            """ä¸­é–“ãƒ‡ãƒ¼ã‚¿åˆ†æãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
            try:
                cleaner = IntermediateDataCleaner(logger_instance=app_logger)
                analysis = cleaner.analyze_intermediate_data()
                
                if not analysis["pipeline_dir_exists"]:
                    return "[OK] ä¸­é–“ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯å­˜åœ¨ã—ã¾ã›ã‚“"
                
                analysis_lines = []
                analysis_lines.append("ğŸ” ä¸­é–“ãƒ‡ãƒ¼ã‚¿åˆ†æçµæœ")
                analysis_lines.append("=" * 50)
                analysis_lines.append(f"[DIR] ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {PIPELINE_BASE_DIR}")
                analysis_lines.append(f"[SIZE] ç·ã‚µã‚¤ã‚º: {analysis['total_size_mb']:.2f}MB")
                analysis_lines.append(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {analysis['file_count']:,}å€‹")
                analysis_lines.append(f"[FILE] ãƒ¢ãƒ‡ãƒ«æ•°: {len(analysis['model_directories'])}å€‹")
                
                if analysis["model_directories"]:
                    analysis_lines.append("")
                    analysis_lines.append("ğŸ“‹ ãƒ¢ãƒ‡ãƒ«ä¸€è¦§:")
                    for model in analysis["model_directories"]:
                        steps = analysis["step_directories"].get(model["name"], [])
                        analysis_lines.append(f"  â€¢ {model['name']} (ã‚¹ãƒ†ãƒƒãƒ—: {', '.join(steps)})")
                        analysis_lines.append(f"    æœ€çµ‚æ›´æ–°: {model['last_modified']}")
                
                return "\n".join(analysis_lines)
                
            except Exception as e:
                app_logger.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                return f"[FAIL] åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"
        
        def handle_step0(uploaded_file_info, model_name):
            """Step0å®Ÿè¡Œãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
            if not uploaded_file_info or not model_name:
                return "[FAIL] ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            start_log = f"""ğŸ”§ Step 0: ã‚¢ã‚»ãƒƒãƒˆä¿å­˜é–‹å§‹
[FILE] ãƒ¢ãƒ‡ãƒ«å: {model_name}
[DIR] ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_file_info.name}
â° é–‹å§‹æ™‚åˆ»: {time.strftime('%Y-%m-%d %H:%M:%S')}

"""
            success, logs = execute_step0(model_name, uploaded_file_info.name)
            status_icon = "[OK]" if success else "[FAIL]"
            
            return f"{start_log}{logs}\n\nğŸ Step 0 çµæœ: {status_icon} {'æˆåŠŸ' if success else 'å¤±æ•—'}"
        
        def handle_step1(uploaded_file_info, model_name):
            """Step1å®Ÿè¡Œãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
            if not uploaded_file_info or not model_name:
                return "[FAIL] ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            start_log = f"""ğŸ”§ Step 1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºé–‹å§‹
[FILE] ãƒ¢ãƒ‡ãƒ«å: {model_name}
[DIR] ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_file_info.name}
â° é–‹å§‹æ™‚åˆ»: {time.strftime('%Y-%m-%d %H:%M:%S')}

"""
            success, logs = execute_step1_wrapper(model_name, uploaded_file_info.name)
            status_icon = "[OK]" if success else "[FAIL]"
            
            return f"{start_log}{logs}\n\nğŸ Step 1 çµæœ: {status_icon} {'æˆåŠŸ' if success else 'å¤±æ•—'}"
        
        def handle_step2(model_name, gender):
            """Step2å®Ÿè¡Œãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
            if not model_name:
                return "[FAIL] ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            start_log = f"""ğŸ”§ Step 2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆé–‹å§‹
[FILE] ãƒ¢ãƒ‡ãƒ«å: {model_name}
ğŸ‘¤ æ€§åˆ¥è¨­å®š: {gender}
â° é–‹å§‹æ™‚åˆ»: {time.strftime('%Y-%m-%d %H:%M:%S')}

"""
            success, logs = execute_step2(model_name, gender)
            status_icon = "[OK]" if success else "[FAIL]"
            
            return f"{start_log}{logs}\n\nğŸ Step 2 çµæœ: {status_icon} {'æˆåŠŸ' if success else 'å¤±æ•—'}"
        
        def handle_step3(model_name):
            """Step3å®Ÿè¡Œãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
            if not model_name:
                return "[FAIL] ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            start_log = f"""ğŸ”§ Step 3: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨é–‹å§‹
[FILE] ãƒ¢ãƒ‡ãƒ«å: {model_name}
â° é–‹å§‹æ™‚åˆ»: {time.strftime('%Y-%m-%d %H:%M:%S')}

"""
            success, logs = execute_step3(model_name)
            status_icon = "[OK]" if success else "[FAIL]"
            
            return f"{start_log}{logs}\n\nğŸ Step 3 çµæœ: {status_icon} {'æˆåŠŸ' if success else 'å¤±æ•—'}"
        
        def handle_step4(model_name):
            """Step4å®Ÿè¡Œãƒãƒ³ãƒ‰ãƒ©ãƒ¼ - 3ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹çµ±åˆãƒãƒ¼ã‚¸"""
            if not model_name:
                return "[FAIL] ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            start_log = f"""ğŸ”§ Step 4: ãƒãƒ¼ã‚¸å‡¦ç†é–‹å§‹
[FILE] ãƒ¢ãƒ‡ãƒ«å: {model_name}
â° é–‹å§‹æ™‚åˆ»: {time.strftime('%Y-%m-%d %H:%M:%S')}

"""
            success, logs = execute_step4(model_name)
            status_icon = "[OK]" if success else "[FAIL]"
            
            return f"{start_log}{logs}\n\nğŸ Step 4 çµæœ: {status_icon} {'æˆåŠŸ' if success else 'å¤±æ•—'}"
        
        def handle_step5(uploaded_file_info, model_name):
            """Step5å®Ÿè¡Œãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
            if not uploaded_file_info or not model_name:
                return "[FAIL] ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            start_log = f"""ğŸ”§ Step 5: æœ€çµ‚çµ±åˆé–‹å§‹
[FILE] ãƒ¢ãƒ‡ãƒ«å: {model_name}
[DIR] ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_file_info.name}
â° é–‹å§‹æ™‚åˆ»: {time.strftime('%Y-%m-%d %H:%M:%S')}

"""
            success, logs = execute_step5(model_name)
            status_icon = "[OK]" if success else "[FAIL]"
            
            return f"{start_log}{logs}\n\nğŸ Step 5 çµæœ: {status_icon} {'æˆåŠŸ' if success else 'å¤±æ•—'}"
        
        def handle_reset(model_name):
            """ãƒªã‚»ãƒƒãƒˆå®Ÿè¡Œãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
            if not model_name:
                return "[FAIL] ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            try:
                fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
                if fdm.model_dir.exists():
                    shutil.rmtree(fdm.model_dir)
                    fdm.create_all_directories()
                return f"ğŸ”„ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ: {model_name}"
            except Exception as e:
                return f"[FAIL] ãƒªã‚»ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}"
        
        # ã‚¤ãƒ™ãƒ³ãƒˆæ¥ç¶š
        uploaded_file.change(handle_upload, [uploaded_file], [model_name_input, log_display])
        complete_pipeline_btn.click(handle_complete_pipeline, [uploaded_file, gender_input, auto_cleanup_checkbox], [log_display, download_file, model_name_input])
        download_btn.click(handle_download, [model_name_input], [download_file, log_display])
        
        step0_btn.click(handle_step0, [uploaded_file, model_name_input], log_display)
        step1_btn.click(handle_step1, [uploaded_file, model_name_input], log_display)
        step2_btn.click(handle_step2, [model_name_input, gender_input], log_display)
        step3_btn.click(handle_step3, [model_name_input], log_display)
        step4_btn.click(handle_step4, [model_name_input], log_display)
        step5_btn.click(handle_step5, [uploaded_file, model_name_input], log_display)
        
        reset_btn.click(handle_reset, [model_name_input], log_display)
        refresh_btn.click(get_status, [model_name_input], status_display)
        
        # ä¸­é–“ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒœã‚¿ãƒ³ã®ã‚¤ãƒ™ãƒ³ãƒˆæ¥ç¶š
        analyze_data_btn.click(
            lambda: handle_analyze_intermediate_data(),
            [],
            log_display
        )
        cleanup_model_btn.click(
            lambda model_name, create_backup: handle_cleanup_intermediate_data(model_name, create_backup) if model_name else "âš ï¸ ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“",
            [model_name_input, backup_checkbox],
            log_display
        )
        cleanup_all_btn.click(
            lambda create_backup: handle_cleanup_intermediate_data(None, create_backup),
            [backup_checkbox],
            log_display
        )
    
    return demo

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨åˆ†
if __name__ == "__main__":
    try:
        print("ğŸš€ UniRig WebUI ã‚’é–‹å§‹ã—ã¦ã„ã¾ã™...")
        print("ğŸ“ ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª:", os.getcwd())
        print("ğŸ Pythonå®Ÿè¡Œç’°å¢ƒ:", sys.executable)
        print("ğŸ“¦ Pythonç‰ˆæœ¬:", sys.version.split()[0])
        
        # Gradioã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
        app = create_simple_ui()
        
        # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•
        print("ğŸŒ WebUIã‚’èµ·å‹•ä¸­...")
        
        # ãƒãƒ¼ãƒˆè¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°å¯¾å¿œï¼‰
        preferred_port = int(os.getenv("UNIRIG_PORT", "7860"))
        
        # åˆ©ç”¨å¯èƒ½ãªãƒãƒ¼ãƒˆã‚’æ¤œç´¢
        import socket
        def find_available_port(start_port=preferred_port, end_port=preferred_port+10):
            for port in range(start_port, end_port + 1):
                try:
                    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                        s.bind(('localhost', port))
                        return port
                except OSError:
                    continue
            return None
        
        # ãƒ–ãƒ©ã‚¦ã‚¶èµ·å‹•åˆ¶å¾¡ï¼ˆç’°å¢ƒå¤‰æ•°ã§åˆ¶å¾¡å¯èƒ½ï¼‰
        auto_browser = os.getenv("UNIRIG_AUTO_BROWSER", "true").lower() == "true"
        
        # åˆ©ç”¨å¯èƒ½ãªãƒãƒ¼ãƒˆã‚’æ¢ã™
        available_port = find_available_port()
        if available_port is None:
            print(f"âŒ åˆ©ç”¨å¯èƒ½ãªãƒãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ ({preferred_port}-{preferred_port+10})")
            sys.exit(1)
        
        print(f"ğŸ“¡ ä½¿ç”¨ãƒãƒ¼ãƒˆ: {available_port}")
        print(f"ğŸŒ ã‚¢ã‚¯ã‚»ã‚¹URL: http://localhost:{available_port}")
        
        if auto_browser:
            print("ğŸš€ ãƒ–ãƒ©ã‚¦ã‚¶ãŒè‡ªå‹•çš„ã«é–‹ãã¾ã™...")
        else:
            print("ğŸ“Œ ãƒ–ãƒ©ã‚¦ã‚¶è‡ªå‹•èµ·å‹•ã¯ç„¡åŠ¹ (UNIRIG_AUTO_BROWSER=false)")
            print("ğŸ”— æ‰‹å‹•ã§ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ãã ã•ã„")
        
        app.launch(
            server_name="0.0.0.0",  # å…¨ã¦ã®IPã‚¢ãƒ‰ãƒ¬ã‚¹ã§ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
            server_port=available_port,  # åˆ©ç”¨å¯èƒ½ãªãƒãƒ¼ãƒˆ
            share=False,            # å…¬é–‹ãƒªãƒ³ã‚¯ã¯ç„¡åŠ¹ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ä½¿ç”¨ï¼‰
            inbrowser=auto_browser, # ç’°å¢ƒå¤‰æ•°ã§åˆ¶å¾¡å¯èƒ½ãªãƒ–ãƒ©ã‚¦ã‚¶è‡ªå‹•èµ·å‹•
            show_error=True,        # ã‚¨ãƒ©ãƒ¼ã‚’è¡¨ç¤º
            debug=False             # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã¯ç„¡åŠ¹
        )
        
    except Exception as e:
        print(f"âŒ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
