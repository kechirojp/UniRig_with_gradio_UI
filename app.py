# This application uses UniRig (https://github.com/VAST-AI-Research/UniRig),
# which is licensed under the MIT License.
# A copy of the license can be found at:
# https://github.com/VAST-AI-Research/UniRig/blob/main/LICENSE
#
# Gradio application for 3D model preview and bone information display.

# ====================================================================
# ğŸš¨ CRITICAL: SEGMENTATION FAULT PREVENTION - MEMORY SETUP ğŸš¨
# ====================================================================
# Prevent PyTorch and Blender memory conflicts that cause segmentation faults
import os
import gc

# æœ€å„ªå…ˆ: ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢ã®ãŸã‚ã®ãƒ¡ãƒ¢ãƒªåˆ¶é™ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:256,garbage_collection_threshold:0.8'
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
os.environ['PYTHONMALLOC'] = 'malloc'
os.environ['MALLOC_TRIM_THRESHOLD_'] = '100000'

# PyTorchã¨Blenderã®ç«¶åˆå›é¿
os.environ['FORCE_FALLBACK_MODE'] = '1'
os.environ['DISABLE_UNIRIG_LIGHTNING'] = '1'

print("ğŸ›¡ï¸ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢: ãƒ¡ãƒ¢ãƒªç®¡ç†è¨­å®šå®Œäº†")

# ====================================================================
# ğŸš¨ğŸš¨ğŸš¨ CRITICAL: PREVENT ROLLBACK - READ BEFORE ANY CHANGES ğŸš¨ğŸš¨ğŸš¨
# ====================================================================
# 
# BLENDER VERSION: 4.2 FIXED - DO NOT CHANGE
# FBX FORMAT: BINARY ONLY - NEVER ASCII
# CONTEXT MANAGEMENT: Blender42ContextManager REQUIRED
# 
# ROLLBACK PROTECTION STATUS:
# - Blender 4.2 compatibility fixes applied (June 2025)
# - Binary FBX export enforced (NO ASCII rollback)
# - Context management via blender_42_context_fix.py
# - Memory crash fixes applied (spconv/CUDA handling)
# 
# IF YOU SEE THESE ERRORS, APPLY BLENDER 4.2 FIXES:
# - "Context object has no attribute 'selected_objects'"
# - "Context object has no attribute 'object'" 
# - "Armature could not be set out of Edit Mode"
# - ASCII FBX export problems
# 
# REQUIRED ACTIONS TO PREVENT ROLLBACK:
# 1. Use Blender42ContextManager from blender_42_context_fix.py
# 2. Enforce BINARY FBX export (fbx_use_ascii=False)
# 3. Apply context-aware object management
# 4. Maintain current working pipeline (Steps 1-3 SUCCESS)
# 
# ====================================================================

import gradio as gr
import os
import subprocess
import tempfile
import datetime
import time
import yaml
from box import Box
import shutil
import traceback
import numpy as np
import trimesh # For model inspection if needed, or by Blender script
import logging
import sys
import pathlib # Not strictly used in this version, but good for path manipulation
import json # For datalist
import atexit
import torch  # Add PyTorch import
from texture_preservation_system import TexturePreservationSystem
from proposed_blender_texture_flow import BlenderNativeTextureFlow
from dynamic_skeleton_generator import DynamicSkeletonGenerator

# Import corrected texture system
try:
    from fixed_texture_system_v2_corrected import FixedTextureSystemV2
    print("âœ… FixedTextureSystemV2Corrected imported successfully")
except ImportError as e:
    print(f"âš ï¸ FixedTextureSystemV2Corrected not available: {e}")
    # Fallback to original version
    try:
        from fixed_texture_system_v2 import FixedTextureSystemV2
        print("âš ï¸ Using original FixedTextureSystemV2 (may have issues)")
    except ImportError:
        FixedTextureSystemV2 = None
        print("âŒ No FixedTextureSystemV2 available")

# Import ImprovedSafeTextureRestoration for priority texture processing
try:
    from improved_safe_texture_restoration import ImprovedSafeTextureRestoration
    IMPROVED_SAFE_TEXTURE_RESTORATION_AVAILABLE = True
    print("âœ… ImprovedSafeTextureRestoration loaded in app.py")
except ImportError as e:
    IMPROVED_SAFE_TEXTURE_RESTORATION_AVAILABLE = False
    print(f"âš ï¸ ImprovedSafeTextureRestoration not available in app.py: {e}")

# Import FixedTextureSystemV2 for enhanced texture processing
try:
    from fixed_texture_system_v2_corrected import FixedTextureSystemV2
    FIXED_TEXTURE_SYSTEM_V2_AVAILABLE = True
    print("âœ… FixedTextureSystemV2 loaded in app.py")
except ImportError as e:
    FIXED_TEXTURE_SYSTEM_V2_AVAILABLE = False
    print(f"âš ï¸ FixedTextureSystemV2 not available in app.py: {e}")

# Import CPU Skinning Fallback System for CUDA/spconv error handling
try:
    from src.model.cpu_skinning_system import create_cpu_skinning_fallback, compute_distance_based_weights
    from src.model.cpu_mesh_encoder import AdaptiveMeshEncoder
    CPU_SKINNING_FALLBACK_AVAILABLE = True
    print("âœ… CPU Skinning Fallback System loaded in app.py")
except ImportError as e:
    CPU_SKINNING_FALLBACK_AVAILABLE = False
    print(f"âš ï¸ CPU Skinning Fallback System not available in app.py: {e}")

# === CRITICAL: Segmentation Fault Prevention Setup ===
# Set fallback environment variables IMMEDIATELY to prevent memory crashes
import os
os.environ['FORCE_FALLBACK_MODE'] = '1'
os.environ['DISABLE_UNIRIG_LIGHTNING'] = '1'
# ğŸš¨ è¿½åŠ ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢ç’°å¢ƒå¤‰æ•°
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
os.environ['PYTHONPATH'] = '/app'
print("ğŸ›¡ï¸ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢: FORCE_FALLBACK_MODE=1, DISABLE_UNIRIG_LIGHTNING=1")
print("ğŸ›¡ï¸ è¿½åŠ ä¿è­·: PYTORCH_CUDA_ALLOC_CONF, CUDA_LAUNCH_BLOCKINGè¨­å®šå®Œäº†")

# Emergency Skinning Bypass System Integration
try:
    from emergency_skinning_bypass import EmergencySkinningBypass
    from emergency_integration import process_emergency_unified_skinning
    EMERGENCY_BYPASS_AVAILABLE = True
    print("âœ… Emergency Skinning Bypass System loaded in app.py")
except ImportError as e:
    EMERGENCY_BYPASS_AVAILABLE = False
    print(f"âš ï¸ Emergency Skinning Bypass System not available in app.py: {e}")

# --- Global Configuration and Setup ---
APP_CONFIG = None
TEMP_FILES_TO_CLEAN = []

# Setup basic logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- PyTorch Device Configuration ---
# Simple and safe device selection (CPU prioritized in fallback mode)
if os.environ.get('FORCE_FALLBACK_MODE') == '1':
    device = "cpu"
    print("ğŸ”§ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰: ãƒ‡ãƒã‚¤ã‚¹ã‚’CPUã«å›ºå®š")
else:
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
logging.info(f"ğŸ”§ PyTorch device: {device}")

# --- Modify this section for allowed paths (DEBUGGING) ---
def get_allowed_paths():
    script_dir = os.path.dirname(os.path.abspath(__file__)) # /app
    allowed = [
        os.path.abspath(script_dir), # /app
        os.path.abspath(os.path.join(script_dir, "pipeline_work")), # /app/pipeline_work
        os.path.abspath(os.path.join(script_dir, "examples")), # /app/examples
        os.path.abspath(os.path.join(script_dir, "src")), # /app/src
        os.path.abspath(os.path.join(script_dir, "configs")), # /app/configs
        os.path.abspath(os.path.join(script_dir, "blender")), # /app/blender
        os.path.abspath(os.path.join(script_dir, "display_cache")), # /app/display_cache (Gradioäº’æ›è¡¨ç¤ºãƒ•ã‚¡ã‚¤ãƒ«)
    ]
    if APP_CONFIG and APP_CONFIG.working_directory_base:
        # Ensure the configured working_directory_base is also allowed
        # This might be redundant if it's already /app/pipeline_work, but good for safety
        configured_work_base = os.path.abspath(APP_CONFIG.working_directory_base)
        if configured_work_base not in allowed:
            allowed.append(configured_work_base)
        
        # Add display_cache directory within the working directory base
        display_cache_path = os.path.abspath(os.path.join(configured_work_base, "display_cache"))
        if display_cache_path not in allowed:
            allowed.append(display_cache_path)
        
        # Add specific subdirectories from config if they exist, ensuring they are absolute
        # This helps if APP_CONFIG.working_directory_base is different from /app/pipeline_work
        # or if subdirectories are outside the main pipeline_work structure.
        subdirs_to_check = [
            APP_CONFIG.get('mesh_extraction', {}).get('extract_output_subdir'),
            APP_CONFIG.get('skeleton_generation', {}).get('skeleton_output_subdir'),
            APP_CONFIG.get('skinning_prediction', {}).get('skin_output_subdir'),
            APP_CONFIG.get('model_merging', {}).get('merge_output_subdir'),
            APP_CONFIG.get('blender_processing', {}).get('conversion_output_subdir'),
            APP_CONFIG.get('blender_native_texture_flow', {}).get('blender_native_subdir', '06_blender_native'),
            APP_CONFIG.get('improved_safe_texture_restoration', {}).get('output_subdir', '08_final_output') # Example for improved flow
        ]
        for subdir_name in subdirs_to_check:
            if subdir_name:
                # Construct path relative to configured_work_base if it's not absolute
                # Or relative to script_dir if that makes more sense for your structure
                potential_path = os.path.join(configured_work_base, subdir_name)
                abs_path = os.path.abspath(potential_path)
                if abs_path not in allowed:
                    allowed.append(abs_path)
    
    # Add temp directory (for backward compatibility, but prefer display_cache)
    allowed.append(os.path.abspath(tempfile.gettempdir()))

    logging.info(f"DEBUG: Gradio allowed_pathsãŒè¨­å®šã•ã‚Œã¾ã—ãŸ: {list(set(allowed))}") # Use set to remove duplicates
    return list(set(allowed))

    logging.info(f"DEBUG: Gradio allowed_pathsãŒè¨­å®šã•ã‚Œã¾ã—ãŸ: {list(set(allowed))}") # Use set to remove duplicates
    return list(set(allowed))
# --- End of modified section ---

# --- Add this helper function for debugging output paths ---
def log_output_paths_for_debug(output_dict, context_log_message=""):
    logging.info(f"--- DEBUG: Gradioå‡ºåŠ›ãƒ‘ã‚¹ã®ç¢ºèª ({context_log_message}) ---")
    if not isinstance(output_dict, dict):
        logging.warning(f"  å‡ºåŠ›ã¯è¾æ›¸ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {type(output_dict)}, å€¤: {output_dict}")
        return

    for key, value in output_dict.items():
        if isinstance(value, str) and (value.endswith(('.glb', '.fbx', '.png', '.jpg', '.txt', '.npz', '.json', '.yaml')) or "/" in value or "\\\\" in value):
            # Heuristic: if it looks like a file path string
            abs_path = os.path.abspath(value)
            exists = os.path.exists(abs_path)
            is_file = os.path.isfile(abs_path) if exists else "N/A"
            logging.info(f"  å‡ºåŠ›ã‚­ãƒ¼: '{key}', ãƒ‘ã‚¹: '{value}' (çµ¶å¯¾ãƒ‘ã‚¹: '{abs_path}'), å­˜åœ¨: {exists}, ãƒ•ã‚¡ã‚¤ãƒ«?: {is_file}")
            if exists and is_file:
                try:
                    logging.info(f"    ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {os.path.getsize(abs_path)} bytes")
                except Exception as e:
                    logging.warning(f"    ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        elif isinstance(value, list) and all(isinstance(item, str) for item in value):
             logging.info(f"  å‡ºåŠ›ã‚­ãƒ¼: '{key}', å€¤ (ãƒªã‚¹ãƒˆ): {value} - (ãƒªã‚¹ãƒˆå†…ã®ãƒ‘ã‚¹ã¯å€‹åˆ¥ã«ç¢ºèªã•ã‚Œã¾ã›ã‚“)")
        else:
            logging.info(f"  å‡ºåŠ›ã‚­ãƒ¼: '{key}', å€¤: {value} (å‹: {type(value)}) - ãƒ‘ã‚¹ã¨ã—ã¦æ‰±ã‚ã‚Œã¾ã›ã‚“")
    logging.info("--- DEBUG: Gradioå‡ºåŠ›ãƒ‘ã‚¹ã®ç¢ºèªå®Œäº† ---")
# --- End of added helper function ---

# --- Configuration Loading Functions ---
def load_app_config():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã‚’YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿"""
    global APP_CONFIG
    config_path = os.path.join(os.path.dirname(__file__), 'configs', 'app_config.yaml')
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config_data = yaml.safe_load(f)
        APP_CONFIG = Box(config_data)
        logging.info(f"âœ… ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {config_path}")
        
        # ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        work_dir = os.path.abspath(APP_CONFIG.working_directory_base)
        os.makedirs(work_dir, exist_ok=True)
        
        return True
    except Exception as e:
        logging.error(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
        APP_CONFIG = Box({'error': str(e)})
        return False

# --- Utility Functions ---
def convert_to_glb_for_display(input_model_path, output_name):
    """3Dãƒ¢ãƒ‡ãƒ«ã‚’è¡¨ç¤ºç”¨GLBã«å¤‰æ› (Gradioäº’æ›ãƒ‘ã‚¹ä½¿ç”¨)"""
    try:
        # å…¥åŠ›ãƒ‘ã‚¹ã¨å‡ºåŠ›ãƒ‘ã‚¹ã‚’è¨­å®š - Gradioäº’æ›ã®å›ºå®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ç”¨
        base_name = os.path.splitext(os.path.basename(input_model_path))[0]
        
        # Gradioäº’æ›ã®è¡¨ç¤ºãƒ•ã‚¡ã‚¤ãƒ«ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        # APP_CONFIGãŒåˆ©ç”¨å¯èƒ½ã§ã‚ã‚Œã°pipeline_workå†…ã«ã€ãã†ã§ãªã‘ã‚Œã°/appå†…ã«ä½œæˆ
        if APP_CONFIG and hasattr(APP_CONFIG, 'working_directory_base'):
            display_base_dir = os.path.join(APP_CONFIG.working_directory_base, "display_cache")
        else:
            display_base_dir = "/app/display_cache"
        
        os.makedirs(display_base_dir, exist_ok=True)
        output_path = os.path.join(display_base_dir, f"{output_name}.glb")
        
        logging.info(f"ğŸ¨ GLBè¡¨ç¤ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {input_model_path} â†’ {output_path}")
        
        # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ—¢ã«GLBå½¢å¼ã®å ´åˆã¯ã‚³ãƒ”ãƒ¼
        if input_model_path.lower().endswith('.glb'):
            shutil.copy2(input_model_path, output_path)
            logging.info(f"âœ… GLBè¡¨ç¤ºãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼å®Œäº†: {output_path}")
            return output_path
        
        # ãã®ä»–ã®å½¢å¼ã®å ´åˆã¯ç°¡å˜ãªå¤‰æ›å‡¦ç†ã‚’è©¦è¡Œ
        try:
            # Trimeshã‚’ä½¿ã£ãŸåŸºæœ¬çš„ãªå¤‰æ›
            mesh = trimesh.load(input_model_path)
            if hasattr(mesh, 'export'):
                mesh.export(output_path)
                logging.info(f"âœ… GLBè¡¨ç¤ºãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›å®Œäº†(Trimesh): {output_path}")
                return output_path
            else:
                logging.warning(f"Trimeshã§ã®å¤‰æ›: 'export'ãƒ¡ã‚½ãƒƒãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        except Exception as e:
            logging.warning(f"Trimeshã§ã®å¤‰æ›ã«å¤±æ•—: {e}")
        
        # å¤‰æ›ã«å¤±æ•—ã—ãŸå ´åˆã¯å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
        shutil.copy2(input_model_path, output_path)
        logging.info(f"âœ… GLBè¡¨ç¤ºãƒ•ã‚¡ã‚¤ãƒ«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚³ãƒ”ãƒ¼å®Œäº†: {output_path}")
        return output_path
        
    except Exception as e:
        logging.error(f"GLBå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        logging.error(f"GLBå¤‰æ›ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹: {traceback.format_exc()}")
        return input_model_path  # å¤‰æ›å¤±æ•—æ™‚ã¯å…ƒã®ãƒ‘ã‚¹ã‚’è¿”ã™

def gradio_safe_file_output(file_path, fallback_name="output_file"):
    """
    Gradioã®å‡ºåŠ›ã¨ã—ã¦å®‰å…¨ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹/ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã™
    
    Args:
        file_path (str): å‡ºåŠ›ã—ãŸã„ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        fallback_name (str): ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å
        
    Returns:
        str or None: GradioãŒå‡¦ç†ã§ãã‚‹å®‰å…¨ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€ã¾ãŸã¯None
    """
    try:
        if not file_path or not os.path.exists(file_path):
            logging.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„ãŸã‚ã€Gradioå‡ºåŠ›ã‚’ã‚¹ã‚­ãƒƒãƒ—: {file_path}")
            return None
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
        abs_path = os.path.abspath(file_path)
        
        # Gradioã®è¨±å¯ãƒ‘ã‚¹ã‚’å–å¾—
        allowed_paths = get_allowed_paths()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¨±å¯ã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã«ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        file_is_allowed = any(abs_path.startswith(allowed_dir) for allowed_dir in allowed_paths)
        
        if file_is_allowed:
            logging.info(f"âœ… Gradioå‡ºåŠ›: {abs_path} (è¨±å¯ã•ã‚ŒãŸãƒ‘ã‚¹å†…)")
            return abs_path
        else:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¨±å¯ã•ã‚Œã¦ã„ãªã„å ´åˆã€display_cacheã«ã‚³ãƒ”ãƒ¼
            logging.warning(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¨±å¯ã•ã‚ŒãŸãƒ‘ã‚¹å¤–ã§ã™: {abs_path}")
            
            # display_cacheãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
            if APP_CONFIG and hasattr(APP_CONFIG, 'working_directory_base'):
                display_cache_dir = os.path.join(APP_CONFIG.working_directory_base, "display_cache")
            else:
                display_cache_dir = "/app/display_cache"
            
            os.makedirs(display_cache_dir, exist_ok=True)
            
            # å®‰å…¨ãªãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
            safe_filename = os.path.basename(file_path)
            if not safe_filename:
                safe_filename = f"{fallback_name}.{file_path.split('.')[-1] if '.' in file_path else 'dat'}"
            
            safe_path = os.path.join(display_cache_dir, safe_filename)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
            shutil.copy2(abs_path, safe_path)
            logging.info(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®‰å…¨ãªãƒ‘ã‚¹ã«ã‚³ãƒ”ãƒ¼: {abs_path} â†’ {safe_path}")
            
            return safe_path
            
    except Exception as e:
        logging.error(f"âŒ Gradioå®‰å…¨ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {e}")
        logging.error(f"ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹: {traceback.format_exc()}")
        return None

def ensure_working_directory():
    """ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºä¿"""
    if not APP_CONFIG:
        return False
    
    try:
        work_dir = os.path.abspath(APP_CONFIG.working_directory_base)
        os.makedirs(work_dir, exist_ok=True)
        
        # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚ä½œæˆ
        subdirs = [
            APP_CONFIG.get('mesh_extraction', {}).get('extract_output_subdir', '01_extracted_mesh'),
            APP_CONFIG.get('skeleton_generation', {}).get('skeleton_output_subdir', '02_skeleton'),
            APP_CONFIG.get('skinning_prediction', {}).get('skin_output_subdir', '03_skinning'),
            APP_CONFIG.get('model_merging', {}).get('merge_output_subdir', '04_merge'),
            '08_final_output'  # æœ€çµ‚å‡ºåŠ›ç”¨
        ]
        
        for subdir in subdirs:
            if subdir:
                full_subdir = os.path.join(work_dir, subdir)
                os.makedirs(full_subdir, exist_ok=True)
        
        return True
    except Exception as e:
        logging.error(f"ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆã«å¤±æ•—: {e}")
        return False

def cleanup_temp_files():
    """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    global TEMP_FILES_TO_CLEAN
    for temp_file in TEMP_FILES_TO_CLEAN:
        try:
            if os.path.exists(temp_file):
                os.remove(temp_file)
                logging.info(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤: {temp_file}")
        except Exception as e:
            logging.warning(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã«å¤±æ•—: {temp_file}, ã‚¨ãƒ©ãƒ¼: {e}")
    TEMP_FILES_TO_CLEAN = []

# çµ‚äº†æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
atexit.register(cleanup_temp_files)

# --- Progress Utility Function ---
def progress_segment(progress, start: float, end: float):
    """
    ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®ç¯„å›²ã‚’åˆ†å‰²ã™ã‚‹é–¢æ•°
    Args:
        progress: Gradioã®ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        start: é–‹å§‹ä½ç½® (0.0-1.0)
        end: çµ‚äº†ä½ç½® (0.0-1.0)
    Returns:
        åˆ†å‰²ã•ã‚ŒãŸãƒ—ãƒ­ã‚°ãƒ¬ã‚¹é–¢æ•°
    """
    def segmented_progress(value: float, desc: str = None):
        """åˆ†å‰²ã•ã‚ŒãŸãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°é–¢æ•°"""
        if progress is None:
            return
        try:
            # åˆ†å‰²ã•ã‚ŒãŸç¯„å›²å†…ã§ã®å€¤ã‚’è¨ˆç®—
            segment_range = end - start
            actual_progress = start + (value * segment_range)
            actual_progress = max(0.0, min(1.0, actual_progress))  # 0.0-1.0ã«ã‚¯ãƒ©ãƒ³ãƒ—
            
            if desc:
                progress(actual_progress, desc)
            else:
                progress(actual_progress)
        except Exception as e:
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ãƒ­ã‚°ã«è¨˜éŒ²ã—ã¦ç¶šè¡Œ
            logging.warning(f"ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
            pass
    
    return segmented_progress

# --- Helper: Run Subprocess ---
def run_subprocess_with_progress(command, work_dir, log_file_path, progress_fn, total_items_for_tqdm=1):
    """
    ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’é€²æ—è¡¨ç¤ºä»˜ãã§å®Ÿè¡Œ
    Args:
        command: å®Ÿè¡Œã™ã‚‹ã‚³ãƒãƒ³ãƒ‰ (ãƒªã‚¹ãƒˆ)
        work_dir: ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        log_file_path: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        progress_fn: é€²æ—æ›´æ–°é–¢æ•°
        total_items_for_tqdm: é€²æ—ã®ã‚¢ã‚¤ãƒ†ãƒ æ•° (æœªä½¿ç”¨)
    Returns:
        tuple: (success: bool, logs: str)
    """
    logs = ""
    try:
        process = subprocess.Popen(command, cwd=work_dir, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1, universal_newlines=True)
        
        # Simulate progress for the subprocess duration if it's a single task
        # This is a placeholder. Real progress depends on the script's output.
        progress_fn(0.1, desc=f"å®Ÿè¡Œä¸­: {command[1] if len(command) > 1 else 'command'}...") 

        with open(log_file_path, 'w') as log_f:
            for line in process.stdout:
                logs += line
                log_f.write(line)
                # If the script outputs progress, parse it here.
                # For now, we don't have a specific format to parse.
        
        process.wait()
        progress_fn(0.9, desc=f"å®Œäº†å¾…ã¡: {command[1] if len(command) > 1 else 'command'}...")

        if process.returncode == 0:
            logs += f"ã‚³ãƒãƒ³ãƒ‰æˆåŠŸ: {' '.join(command)}\n"
            progress_fn(1.0, desc=f"å®Œäº†: {command[1] if len(command) > 1 else 'command'}")
            return True, logs
        else:
            logs += f"ã‚³ãƒãƒ³ãƒ‰å¤±æ•— (ã‚³ãƒ¼ãƒ‰ {process.returncode}): {' '.join(command)}\n"
            logs += f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§: {log_file_path}\n"
            progress_fn(1.0, desc=f"ã‚¨ãƒ©ãƒ¼: {command[1] if len(command) > 1 else 'command'}") # Mark as complete even on error for progress bar
            return False, logs
    except FileNotFoundError:
        logs += f"ã‚¨ãƒ©ãƒ¼: ã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - {command[0]}ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
        progress_fn(1.0, desc=f"ã‚¨ãƒ©ãƒ¼: {command[0]} not found")
        return False, logs
    except Exception as e:
        logs += f"ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}\n"
        logs += f"ã‚³ãƒãƒ³ãƒ‰: {' '.join(command)}\n"
        logs += f"è©³ç´°: {traceback.format_exc()}\n"
        progress_fn(1.0, desc=f"ä¾‹å¤–: {command[1] if len(command) > 1 else 'command'}")
        return False, logs

# --- Core Processing Functions ---
def process_extract_mesh(uploaded_model_path: str, model_name: str, progress_fn=None):
    """
    ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå‡¦ç†
    Args:
        uploaded_model_path: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        model_name: ãƒ¢ãƒ‡ãƒ«å
        progress_fn: ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°é–¢æ•°
    Returns:
        tuple: (extracted_npz_path, logs)
    """
    logs = "=== ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå‡¦ç†é–‹å§‹ ===\n"
    
    try:
        if progress_fn:
            progress_fn(0.1, "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºæº–å‚™ä¸­...")
        
        if not uploaded_model_path or not os.path.exists(uploaded_model_path):
            logs += f"âŒ ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {uploaded_model_path}\n"
            return None, logs
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
        if not APP_CONFIG:
            # Gradioç’°å¢ƒã§ã®è¨­å®šã®å†èª­ã¿è¾¼ã¿
            if not load_app_config():
                logs += "âŒ ã‚¨ãƒ©ãƒ¼: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“\n"
                return None, logs
        
        extract_config = APP_CONFIG.get('mesh_extraction', {})
        extract_subdir = extract_config.get('extract_output_subdir', '01_extracted_mesh')
        work_base = APP_CONFIG.working_directory_base
        extract_dir = os.path.join(work_base, extract_subdir, model_name)
        
        os.makedirs(extract_dir, exist_ok=True)
        logs += f"ğŸ“ æŠ½å‡ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {extract_dir}\n"
        
        if progress_fn:
            progress_fn(0.3, "ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­...")
        
        # NPZãƒ•ã‚¡ã‚¤ãƒ«ã®å‡ºåŠ›ãƒ‘ã‚¹
        extracted_npz_path = os.path.join(extract_dir, f"{model_name}_extracted.npz")
        
        # åŸºæœ¬çš„ãªãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå‡¦ç†ï¼ˆãƒ†ã‚¯ã‚¹ãƒãƒ£æƒ…å ±ä»˜ãï¼‰
        try:
            mesh = trimesh.load(uploaded_model_path)
            
            if progress_fn:
                progress_fn(0.6, "ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿å¤‰æ›ä¸­...")
            
            # ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’numpyé…åˆ—ã¨ã—ã¦ä¿å­˜
            if hasattr(mesh, 'vertices') and hasattr(mesh, 'faces'):
                # å˜ä¸€ãƒ¡ãƒƒã‚·ãƒ¥ã®å ´åˆ
                vertices = mesh.vertices
                faces = mesh.faces
                materials = getattr(mesh.visual, 'material', None)
                mesh_name = "main_mesh"
                
                # UVåº§æ¨™ã®æŠ½å‡º
                uv_coords = None
                if hasattr(mesh, 'visual') and hasattr(mesh.visual, 'uv'):
                    uv_coords = mesh.visual.uv
                    logs += f"ğŸ—ºï¸ å˜ä¸€ãƒ¡ãƒƒã‚·ãƒ¥UVåº§æ¨™: {len(uv_coords)}ç‚¹\n"
                else:
                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆUVåº§æ¨™ã‚’ç”Ÿæˆ
                    uv_coords = np.array([[0.0, 0.0] for _ in range(len(vertices))])
                    logs += f"ğŸ”§ å˜ä¸€ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆUVåº§æ¨™: {len(uv_coords)}ç‚¹\n"
                    
            else:
                # Scene objectã®å ´åˆã®å‡¦ç†
                if hasattr(mesh, 'geometry'):
                    geometry_list = list(mesh.geometry.values())
                    if len(geometry_list) == 0:
                        raise Exception("Sceneã«ã‚¸ã‚ªãƒ¡ãƒˆãƒªãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
                    
                    # æœ€åˆã®ã‚¸ã‚ªãƒ¡ãƒˆãƒªã‚’ä½¿ç”¨
                    first_geometry = geometry_list[0]
                    vertices = first_geometry.vertices
                    faces = first_geometry.faces
                    mesh_name = list(mesh.geometry.keys())[0]
                    
                    # Sceneå†…ã®ãƒãƒ†ãƒªã‚¢ãƒ«æƒ…å ±ã‚’å–å¾—
                    materials = getattr(first_geometry.visual, 'material', None) if hasattr(first_geometry, 'visual') else None
                    
                    # Sceneã®UVåº§æ¨™ã®æŠ½å‡º
                    uv_coords = None
                    if hasattr(first_geometry, 'visual') and hasattr(first_geometry.visual, 'uv'):
                        uv_coords = first_geometry.visual.uv
                        logs += f"ğŸ—ºï¸ Sceneãƒ¡ãƒƒã‚·ãƒ¥UVåº§æ¨™: {len(uv_coords)}ç‚¹\n"
                    else:
                        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆUVåº§æ¨™ã‚’ç”Ÿæˆ
                        uv_coords = np.array([[0.0, 0.0] for _ in range(len(vertices))])
                        logs += f"ğŸ”§ Sceneãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆUVåº§æ¨™: {len(uv_coords)}ç‚¹\n"
                    
                    logs += f"ğŸ” Sceneå½¢å¼æ¤œå‡º: {len(geometry_list)}å€‹ã®ã‚¸ã‚ªãƒ¡ãƒˆãƒª\n"
                    logs += f"ğŸ“¦ ä½¿ç”¨ã‚¸ã‚ªãƒ¡ãƒˆãƒª: {mesh_name}\n"
                else:
                    raise Exception("ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã‚’èªè­˜ã§ãã¾ã›ã‚“")
            
            # ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
            texture_dir = os.path.join(extract_dir, "textures")
            os.makedirs(texture_dir, exist_ok=True)
            
            # ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆæƒ…å ±ã®æº–å‚™
            texture_manifest = {
                'model_name': model_name,
                'extracted_at': str(time.time()),
                'texture_count': 0,
                'textures': [],
                'mesh_name': mesh_name
            }
            
            # é«˜åº¦ãªãƒãƒ†ãƒªã‚¢ãƒ«ãƒ»ãƒ†ã‚¯ã‚¹ãƒãƒ£æŠ½å‡ºå‡¦ç†
            logs += "ğŸ¨ ãƒ†ã‚¯ã‚¹ãƒãƒ£æŠ½å‡ºå‡¦ç†é–‹å§‹\n"
            
            if materials:
                logs += f"ğŸ“‹ ãƒãƒ†ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ—: {type(materials)}\n"
                
                # PBRMaterial ã®å ´åˆã®å‡¦ç†
                if hasattr(materials, 'baseColorTexture'):
                    texture_count = 0
                    
                    # Base Color Texture (Diffuse)
                    if materials.baseColorTexture:
                        try:
                            texture_filename = f"{model_name}_baseColor.png"
                            texture_path = os.path.join(texture_dir, texture_filename)
                            materials.baseColorTexture.save(texture_path)
                            
                            texture_manifest['textures'].append({
                                'original_name': 'baseColorTexture',
                                'saved_name': texture_filename,
                                'saved_path': texture_path,
                                'type': 'BASE_COLOR',
                                'size_bytes': os.path.getsize(texture_path)
                            })
                            texture_count += 1
                            logs += f"ğŸ“¸ Base Color ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜: {texture_filename}\n"
                        except Exception as e:
                            logs += f"âš ï¸ Base Color ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}\n"
                    
                    # Normal Texture
                    if hasattr(materials, 'normalTexture') and materials.normalTexture:
                        try:
                            texture_filename = f"{model_name}_normal.png"
                            texture_path = os.path.join(texture_dir, texture_filename)
                            materials.normalTexture.save(texture_path)
                            
                            texture_manifest['textures'].append({
                                'original_name': 'normalTexture',
                                'saved_name': texture_filename,
                                'saved_path': texture_path,
                                'type': 'NORMAL',
                                'size_bytes': os.path.getsize(texture_path)
                            })
                            texture_count += 1
                            logs += f"ğŸ“¸ Normal ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜: {texture_filename}\n"
                        except Exception as e:
                            logs += f"âš ï¸ Normal ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}\n"
                    
                    # Metallic Roughness Texture
                    if hasattr(materials, 'metallicRoughnessTexture') and materials.metallicRoughnessTexture:
                        try:
                            texture_filename = f"{model_name}_metallicRoughness.png"
                            texture_path = os.path.join(texture_dir, texture_filename)
                            materials.metallicRoughnessTexture.save(texture_path)
                            
                            texture_manifest['textures'].append({
                                'original_name': 'metallicRoughnessTexture',
                                'saved_name': texture_filename,
                                'saved_path': texture_path,
                                'type': 'METALLIC_ROUGHNESS',
                                'size_bytes': os.path.getsize(texture_path)
                            })
                            texture_count += 1
                            logs += f"ğŸ“¸ Metallic Roughness ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜: {texture_filename}\n"
                        except Exception as e:
                            logs += f"âš ï¸ Metallic Roughness ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}\n"
                    
                    # Emissive Texture
                    if hasattr(materials, 'emissiveTexture') and materials.emissiveTexture:
                        try:
                            texture_filename = f"{model_name}_emissive.png"
                            texture_path = os.path.join(texture_dir, texture_filename)
                            materials.emissiveTexture.save(texture_path)
                            
                            texture_manifest['textures'].append({
                                'original_name': 'emissiveTexture',
                                'saved_name': texture_filename,
                                'saved_path': texture_path,
                                'type': 'EMISSIVE',
                                'size_bytes': os.path.getsize(texture_path)
                            })
                            texture_count += 1
                            logs += f"ğŸ“¸ Emissive ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜: {texture_filename}\n"
                        except Exception as e:
                            logs += f"âš ï¸ Emissive ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}\n"
                    
                    # Occlusion Texture
                    if hasattr(materials, 'occlusionTexture') and materials.occlusionTexture:
                        try:
                            texture_filename = f"{model_name}_occlusion.png"
                            texture_path = os.path.join(texture_dir, texture_filename)
                            materials.occlusionTexture.save(texture_path)
                            
                            texture_manifest['textures'].append({
                                'original_name': 'occlusionTexture',
                                'saved_name': texture_filename,
                                'saved_path': texture_path,
                                'type': 'OCCLUSION',
                                'size_bytes': os.path.getsize(texture_path)
                            })
                            texture_count += 1
                            logs += f"ğŸ“¸ Occlusion ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜: {texture_filename}\n"
                        except Exception as e:
                            logs += f"âš ï¸ Occlusion ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}\n"
                    
                    texture_manifest['texture_count'] = texture_count
                    
                # SimpleMaterial ã®å ´åˆã®å‡¦ç†ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                elif hasattr(materials, 'image') and materials.image:
                    try:
                        texture_filename = f"{model_name}_texture_0.png"
                        texture_path = os.path.join(texture_dir, texture_filename)
                        materials.image.save(texture_path)
                        
                        texture_manifest['texture_count'] = 1
                        texture_manifest['textures'].append({
                            'original_name': 'image',
                            'saved_name': texture_filename,
                            'saved_path': texture_path,
                            'type': 'DIFFUSE',
                            'size_bytes': os.path.getsize(texture_path)
                        })
                        logs += f"ğŸ“¸ Simple Material ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜: {texture_filename}\n"
                    except Exception as texture_error:
                        logs += f"âš ï¸ Simple Material ãƒ†ã‚¯ã‚¹ãƒãƒ£æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {texture_error}\n"
                else:
                    logs += "âš ï¸ èªè­˜å¯èƒ½ãªãƒ†ã‚¯ã‚¹ãƒãƒ£ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\n"
            else:
                logs += "âš ï¸ ãƒãƒ†ãƒªã‚¢ãƒ«æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\n"
            
            # ãƒãƒ†ãƒªã‚¢ãƒ«æƒ…å ±ã®æ§‹é€ åŒ–
            materials_data = None
            if texture_manifest and texture_manifest.get('textures'):
                materials_data = texture_manifest
                logs += f"ğŸ“¦ ãƒãƒ†ãƒªã‚¢ãƒ«æƒ…å ±ä¿å­˜: {len(texture_manifest['textures'])}ãƒ†ã‚¯ã‚¹ãƒãƒ£\n"
            
            # NPZãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ (UniRig RawDataäº’æ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ)
            np.savez(extracted_npz_path, 
                    vertices=vertices, 
                    faces=faces,
                    uv_coords=uv_coords,
                    materials=materials_data)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®ç¢ºèªã¨ãƒ­ã‚°å‡ºåŠ›
            npz_size = os.path.getsize(extracted_npz_path)
            npz_size_mb = npz_size / (1024 * 1024)
            
            # YAMLãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ï¼ˆImprovedSafeTextureRestorationç”¨ï¼‰
            yaml_manifest_path = os.path.join(extract_dir, "texture_manifest.yaml")
            try:
                import yaml
                with open(yaml_manifest_path, 'w') as f:
                    yaml.dump(texture_manifest, f, default_flow_style=False)
                logs += f"ğŸ“‹ YAMLãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆç”Ÿæˆ: {yaml_manifest_path}\n"
            except Exception as yaml_error:
                logs += f"âš ï¸ YAMLãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {yaml_error}\n"
            
            if progress_fn:
                progress_fn(0.9, "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå®Œäº†å‡¦ç†ä¸­...")
            
            logs += f"âœ… ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºæˆåŠŸ\n"
            logs += f"ğŸ“Š é ‚ç‚¹æ•°: {len(vertices)}\n"
            logs += f"ğŸ“Š é¢æ•°: {len(faces)}\n"
            logs += f"ğŸ“¸ ãƒ†ã‚¯ã‚¹ãƒãƒ£æ•°: {texture_manifest['texture_count']}\n"
            logs += f"ğŸ“¦ NPZãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {npz_size:,} ãƒã‚¤ãƒˆ ({npz_size_mb:.2f} MB)\n"
            logs += f"ğŸ’¾ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {extracted_npz_path}\n"
            
            if progress_fn:
                progress_fn(1.0, "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå®Œäº†")
            
            return extracted_npz_path, logs
            
        except Exception as mesh_error:
            logs += f"âŒ ãƒ¡ãƒƒã‚·ãƒ¥å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(mesh_error)}\n"
            return None, logs
    
    except Exception as e:
        logs += f"âŒ ãƒ¡ãƒƒã‚·ãƒ¥æŠ½ extractå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\n"
        logs += f"è©³ç´°: {traceback.format_exc()}\n"
        if progress_fn:
            progress_fn(1.0, "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºã‚¨ãƒ©ãƒ¼")
        return None, logs

def process_generate_skeleton(extracted_npz_path: str, model_name: str, gender: str, progress_fn=None):
    """
    ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå‡¦ç†
    Args:
        extracted_npz_path: æŠ½å‡ºã•ã‚ŒãŸãƒ¡ãƒƒã‚·ãƒ¥ã®NPZãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        model_name: ãƒ¢ãƒ‡ãƒ«å
        gender: æ€§åˆ¥ ('male' ã¾ãŸã¯ 'female')
        progress_fn: ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°é–¢æ•°
    Returns:
        tuple: (display_path, logs, fbx_path, txt_path, npz_path)
    """
    logs = "=== ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå‡¦ç†é–‹å§‹ ===\n"
    
    try:
        if progress_fn:
            progress_fn(0.1, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆæº–å‚™ä¸­...")
        
        if not extracted_npz_path or not os.path.exists(extracted_npz_path):
            logs += f"âŒ ã‚¨ãƒ©ãƒ¼: å…¥åŠ›NPZãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {extracted_npz_path}\n"
            return None, logs, None, None, None
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
        if not APP_CONFIG:
            # Gradioç’°å¢ƒã§ã®è¨­å®šã®å†èª­ã¿è¾¼ã¿
            if not load_app_config():
                logs += "âŒ ã‚¨ãƒ©ãƒ¼: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“\n"
                return None, logs, None, None, None
        
        skeleton_config = APP_CONFIG.get('skeleton_generation', {})
        skeleton_subdir = skeleton_config.get('skeleton_output_subdir', '02_skeleton')
        work_base = APP_CONFIG.working_directory_base
        skeleton_dir = os.path.join(work_base, skeleton_subdir, model_name)
        
        os.makedirs(skeleton_dir, exist_ok=True)
        logs += f"ğŸ“ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {skeleton_dir}\n"
        logs += f"ğŸ‘¤ æ€§åˆ¥è¨­å®š: {gender}\n"
        
        if progress_fn:
            progress_fn(0.3, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³æ§‹é€ è§£æä¸­...")
        
        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®è¨­å®š
        skeleton_fbx_path = os.path.join(skeleton_dir, f"{model_name}_skeleton.fbx")
        skeleton_txt_path = os.path.join(skeleton_dir, f"{model_name}_bones.txt")
        skeleton_npz_path = os.path.join(skeleton_dir, f"{model_name}_skeleton.npz")
        display_glb_path = os.path.join(skeleton_dir, f"{model_name}_skeleton_display.glb")
        
        if progress_fn:
            progress_fn(0.5, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆä¸­...")
        
        # å‹•çš„ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå‡¦ç†ï¼ˆDynamicSkeletonGeneratorã‚’ä½¿ç”¨ï¼‰
        try:
            import numpy as np
            from dynamic_skeleton_generator import DynamicSkeletonGenerator
            
            # NPZãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
            data = np.load(extracted_npz_path)
            vertices = data['vertices']
            faces = data['faces']
            
            if progress_fn:
                progress_fn(0.6, "ãƒ¡ãƒƒã‚·ãƒ¥è§£æä¸­...")
            
            # å‹•çš„ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå™¨ã‚’åˆæœŸåŒ–
            skeleton_generator = DynamicSkeletonGenerator()
            
            if progress_fn:
                progress_fn(0.7, "é©å¿œçš„ãƒœãƒ¼ãƒ³æ§‹é€ ç”Ÿæˆä¸­...")
            
            # ãƒ¡ãƒƒã‚·ãƒ¥ã«åŸºã¥ã„ã¦é©å¿œçš„ãªã‚¹ã‚±ãƒ«ãƒˆãƒ³ã‚’ç”Ÿæˆ
            skeleton_result = skeleton_generator.generate_adaptive_skeleton(vertices, faces)
            
            # ç”Ÿæˆã•ã‚ŒãŸã‚¹ã‚±ãƒ«ãƒˆãƒ³æƒ…å ±ã‚’å–å¾—
            bone_names = skeleton_result['names']
            joints = skeleton_result['joints']
            bones = skeleton_result['bones']
            tails = skeleton_result['tails']
            parents = skeleton_result['parents']
            creature_type = skeleton_result['creature_type']
            mesh_analysis = skeleton_result['mesh_analysis']
            
            logs += f"ğŸ” æ¤œå‡ºã•ã‚ŒãŸç”Ÿç‰©ã‚¿ã‚¤ãƒ—: {creature_type}\n"
            logs += f"ğŸ¦´ ç”Ÿæˆã•ã‚ŒãŸãƒœãƒ¼ãƒ³æ•°: {len(bone_names)}\n"
            
            if progress_fn:
                progress_fn(0.8, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿ä¿å­˜ä¸­...")
            
            # ãƒœãƒ¼ãƒ³æƒ…å ±ã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with open(skeleton_txt_path, 'w', encoding='utf-8') as f:
                f.write(f"Dynamic Skeleton for model: {model_name}\n")
                f.write(f"Gender: {gender}\n")
                f.write(f"Creature Type: {creature_type}\n")
                f.write(f"Total bones: {len(bone_names)}\n\n")
                f.write("=== Bone Hierarchy ===\n")
                for i, bone_name in enumerate(bone_names):
                    parent_info = f" (parent: {bone_names[parents[i]]})" if parents[i] is not None else " (root)"
                    f.write(f"Bone {i:2d}: {bone_name}{parent_info}\n")
                
                f.write(f"\n=== Mesh Analysis ===\n")
                if mesh_analysis:
                    f.write(f"Bounds: {mesh_analysis.get('bounds', 'N/A')}\n")
                    f.write(f"Center: {mesh_analysis.get('center', 'N/A')}\n")
                    f.write(f"Extents: {mesh_analysis.get('extents', 'N/A')}\n")
                    shape_info = mesh_analysis.get('shape_analysis', {})
                    f.write(f"Aspect Ratios: {shape_info.get('aspect_ratios', 'N/A')}\n")
            
            # ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’NPZãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆUniRigå½¢å¼ï¼‰
            skeleton_data = {
                'bone_names': np.array(bone_names),
                'joints': joints,
                'bones': bones,
                'tails': tails,
                'parents': np.array(parents, dtype=object),
                'bone_count': len(bone_names),
                'model_name': model_name,
                'gender': gender,
                'creature_type': creature_type,
                'mesh_analysis': mesh_analysis
            }
            np.savez(skeleton_npz_path, **skeleton_data)
            
            # ã‚¹ã‚±ãƒ«ãƒˆãƒ³NPZãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®ç¢ºèª
            skeleton_npz_size = os.path.getsize(skeleton_npz_path)
            skeleton_npz_mb = skeleton_npz_size / (1024 * 1024)
            logs += f"ğŸ“¦ ã‚¹ã‚±ãƒ«ãƒˆãƒ³NPZã‚µã‚¤ã‚º: {skeleton_npz_size:,} ãƒã‚¤ãƒˆ ({skeleton_npz_mb:.2f} MB)\n"
            
            if progress_fn:
                progress_fn(0.9, "è¡¨ç¤ºç”¨ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆä¸­...")
            
            # è¡¨ç¤ºç”¨GLBãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
            try:
                import trimesh
                # å…ƒã®ãƒ¡ãƒƒã‚·ãƒ¥ã‚’ãƒ™ãƒ¼ã‚¹ã«è¡¨ç¤ºç”¨ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
                mesh = trimesh.Trimesh(vertices=vertices, faces=faces)
                mesh.export(display_glb_path)
            except Exception as display_error:
                logs += f"âš ï¸ è¡¨ç¤ºç”¨ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {display_error}\n"
                display_glb_path = None
            
            # å®Ÿéš›ã®FBXãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆï¼ˆRawSkeletonã‚’ä½¿ç”¨ï¼‰
            try:
                # ğŸš¨ CRITICAL: ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢ãƒã‚§ãƒƒã‚¯
                force_fallback = os.environ.get('FORCE_FALLBACK_MODE', '1') == '1'
                disable_lightning = os.environ.get('DISABLE_UNIRIG_LIGHTNING', '1') == '1'
                
                if force_fallback or disable_lightning:
                    logs += "ğŸ›¡ï¸ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢: RawSkeletonä½¿ç”¨ã‚’ã‚¹ã‚­ãƒƒãƒ—\n"
                    logs += f"   FORCE_FALLBACK_MODE={force_fallback}, DISABLE_UNIRIG_LIGHTNING={disable_lightning}\n"
                    # è»½é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã§FBXç”Ÿæˆï¼ˆé©åˆ‡ãªverticesã¨facesã‚’æ¸¡ã™ï¼‰
                    success = create_fbx_with_subprocess(skeleton_fbx_path, vertices, faces, model_name, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ")
                    if not success:
                        logs += "âŒ ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹FBXç”Ÿæˆå¤±æ•—\n"
                        return None, logs, None, None, None  # ğŸ”§ 5ã¤ã®è¿”ã‚Šå€¤ã«ä¿®æ­£
                else:
                    from src.data.raw_data import RawSkeleton
                    
                    # RawSkeletonã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
                    raw_skeleton = RawSkeleton(
                        joints=joints,
                        tails=tails,
                        no_skin=None,
                        parents=parents,
                        names=bone_names
                    )
                    
                    # FBXã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆUniRigæ¨™æº–å½¢å¼ï¼‰
                    raw_skeleton.export_fbx(
                        path=skeleton_fbx_path,
                        extrude_size=0.05,
                        add_root=False,
                        use_extrude_bone=True,
                        use_tail=True
                    )
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®ç¢ºèªã¨ãƒ­ã‚°å‡ºåŠ›
                fbx_size = os.path.getsize(skeleton_fbx_path) if os.path.exists(skeleton_fbx_path) else 0
                fbx_size_kb = fbx_size / 1024
                fbx_size_mb = fbx_size / (1024 * 1024)
                
                if fbx_size > 0:
                    logs += f"ğŸ¯ FBXç”ŸæˆæˆåŠŸ: {skeleton_fbx_path}\n"
                    logs += f"ğŸ“¦ FBXãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {fbx_size:,} ãƒã‚¤ãƒˆ ({fbx_size_kb:.1f} KB, {fbx_size_mb:.2f} MB)\n"
                else:
                    logs += f"âš ï¸ FBXç”Ÿæˆï¼šãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ0ã§ã™: {skeleton_fbx_path}\n"
                
            except Exception as fbx_error:
                logs += f"âš ï¸ FBXç”Ÿæˆã‚¨ãƒ©ãƒ¼: {fbx_error}\n"
                logs += f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: è»½é‡FBXç”Ÿæˆã‚’è©¦è¡Œ...\n"
                
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: è»½é‡FBXç”Ÿæˆ
                try:
                    success = create_valid_fbx_file(skeleton_fbx_path, vertices, faces, model_name)
                    if success:
                        fallback_fbx_size = os.path.getsize(skeleton_fbx_path) if os.path.exists(skeleton_fbx_path) else 0
                        fallback_fbx_kb = fallback_fbx_size / 1024
                        logs += f"âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯FBXç”ŸæˆæˆåŠŸ\n"
                        logs += f"ğŸ“¦ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯FBXã‚µã‚¤ã‚º: {fallback_fbx_size:,} ãƒã‚¤ãƒˆ ({fallback_fbx_kb:.1f} KB)\n"
                    else:
                        skeleton_fbx_path = None
                except Exception as fallback_error:
                    logs += f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯FBXç”Ÿæˆã‚‚å¤±æ•—: {fallback_error}\n"
                    skeleton_fbx_path = None
            
            logs += f"âœ… å‹•çš„ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”ŸæˆæˆåŠŸ\n"
            logs += f"ğŸ” ç”Ÿç‰©ã‚¿ã‚¤ãƒ—: {creature_type}\n"
            logs += f"ğŸ¦´ é©å¿œçš„ãƒœãƒ¼ãƒ³æ•°: {len(bone_names)}\n"
            logs += f"ğŸ“Š ã‚¸ãƒ§ã‚¤ãƒ³ãƒˆåº§æ¨™: {joints.shape}\n"
            logs += f"ğŸ’¾ FBXãƒ•ã‚¡ã‚¤ãƒ«: {skeleton_fbx_path}\n"
            logs += f"ğŸ“„ ãƒœãƒ¼ãƒ³æƒ…å ±: {skeleton_txt_path}\n"
            logs += f"ğŸ’¾ NPZãƒ•ã‚¡ã‚¤ãƒ«: {skeleton_npz_path}\n"
            
            if progress_fn:
                progress_fn(1.0, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå®Œäº†")
            
            return display_glb_path, logs, skeleton_fbx_path, skeleton_txt_path, skeleton_npz_path
            
        except Exception as skeleton_error:
            logs += f"âŒ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(skeleton_error)}\n"
            return None, logs, None, None, None
    
    except Exception as e:
        logs += f"âŒ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\n"
        logs += f"è©³ç´°: {traceback.format_exc()}\n"
        if progress_fn:
            progress_fn(1.0, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆã‚¨ãƒ©ãƒ¼")
        return None, logs, None, None, None


def step2_generate_skeleton(model_name: str = "bird", progress_fn=None, force_dynamic: bool = True):
    """
    Step 2: å‹•çš„ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ
    æ—¢å­˜ã®process_generate_skeletoné–¢æ•°ã®ãƒ©ãƒƒãƒ‘ãƒ¼
    
    Args:
        model_name: ãƒ¢ãƒ‡ãƒ«å
        progress_fn: ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°é–¢æ•°
        force_dynamic: å‹•çš„ç”Ÿæˆã‚’å¼·åˆ¶ï¼ˆæœªä½¿ç”¨ã€äº’æ›æ€§ã®ãŸã‚ï¼‰
    
    Returns:
        tuple: (æˆåŠŸãƒ•ãƒ©ã‚°, ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸, å‡ºåŠ›ãƒ‘ã‚¹)
    """
    try:
        # APP_CONFIGãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ãªã„å ´åˆã®å¯¾å‡¦
        if APP_CONFIG is None:
            load_app_config()
        
        # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
        work_base = APP_CONFIG.working_directory_base if APP_CONFIG else "/app/pipeline_work"
        extracted_dir = os.path.join(work_base, "01_extracted_mesh", model_name)
        npz_file = os.path.join(extracted_dir, "raw_data.npz")
        
        if not os.path.exists(npz_file):
            logs = f"âŒ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {npz_file}\n"
            return False, logs, None
        
        # æ—¢å­˜ã®process_generate_skeletoné–¢æ•°ã‚’å‘¼ã³å‡ºã—
        display_path, logs, fbx_path, txt_path, npz_path = process_generate_skeleton(
            extracted_npz_path=npz_file,
            model_name=model_name,
            gender="neutral",  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ€§åˆ¥
            progress_fn=progress_fn
        )
        
        # æˆåŠŸåˆ¤å®š
        success = npz_path is not None and os.path.exists(npz_path)
        
        # å‡ºåŠ›ãƒ‘ã‚¹ã¯äºˆæ¸¬ã‚¹ã‚±ãƒ«ãƒˆãƒ³NPZãƒ•ã‚¡ã‚¤ãƒ«
        if success:
            # predict_skeleton.npzãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ/æ›´æ–°
            predict_skeleton_path = os.path.join(extracted_dir, "predict_skeleton.npz")
            if npz_path and os.path.exists(npz_path):
                # ç”Ÿæˆã•ã‚ŒãŸã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ predict_skeleton.npz ã¨ã—ã¦ä¿å­˜
                shutil.copy2(npz_path, predict_skeleton_path)
                output_path = predict_skeleton_path
            else:
                output_path = npz_path
        else:
            output_path = None
        
        return success, logs, output_path
        
    except Exception as e:
        error_msg = f"âŒ Step 2 ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}"
        import traceback
        full_logs = error_msg + "\n" + traceback.format_exc()
        return False, full_logs, None


def process_generate_skin(raw_data_npz_path: str, skeleton_fbx_path: str, skeleton_npz_path: str, 
                         model_name_for_output: str, progress_fn=None):
    """
    Step 3: UniRig Lightning ã‚’ä½¿ç”¨ã—ãŸã‚¹ã‚­ãƒ‹ãƒ³ã‚°äºˆæ¸¬ï¼ˆCUDA/spconv ã‚¨ãƒ©ãƒ¼å¯¾å¿œç‰ˆï¼‰
    
    CUDA/spconvä¾å­˜é–¢é€£ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã€è‡ªå‹•çš„ã«CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚
    
    Args:
        raw_data_npz_path: æŠ½å‡ºãƒ¡ãƒƒã‚·ãƒ¥ã®NPZãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        skeleton_fbx_path: ç”Ÿæˆã•ã‚ŒãŸã‚¹ã‚±ãƒ«ãƒˆãƒ³FBXãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹  
        skeleton_npz_path: ç”Ÿæˆã•ã‚ŒãŸã‚¹ã‚±ãƒ«ãƒˆãƒ³NPZãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        model_name_for_output: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
        progress_fn: ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤ºé–¢æ•°
        
    Returns:
        display_glb_path: è¡¨ç¤ºç”¨GLBãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        logs: å‡¦ç†ãƒ­ã‚°
        skinned_fbx_path: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        skinning_npz_path: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°NPZãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """
    logs = "=== UniRig Lightning ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†é–‹å§‹ï¼ˆCUDA/spconv ã‚¨ãƒ©ãƒ¼å¯¾å¿œç‰ˆï¼‰===\n"
    
    # å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    import os
    import shutil
    import traceback
    import numpy as np
    
    try:
        if progress_fn:
            progress_fn(0.05, "ã‚¹ã‚­ãƒ‹ãƒ³ã‚°åˆæœŸåŒ–ä¸­...")
        
        # ğŸš¨ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢: ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã‚‹äº‹å‰ãƒã‚§ãƒƒã‚¯
        force_fallback = os.environ.get('FORCE_FALLBACK_MODE', '0') == '1'
        disable_lightning = os.environ.get('DISABLE_UNIRIG_LIGHTNING', '0') == '1'
        
        if force_fallback or disable_lightning:
            logs += "ğŸ›¡ï¸ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢: UniRigã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’äº‹å‰ã«ã‚¹ã‚­ãƒƒãƒ—\n"
            logs += f"   FORCE_FALLBACK_MODE={force_fallback}, DISABLE_UNIRIG_LIGHTNING={disable_lightning}\n"
            logs += "ğŸ”„ CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ ã«ç›´æ¥åˆ‡ã‚Šæ›¿ãˆã¾ã™...\n"
        else:
            # ã¾ãšé€šå¸¸ã®UniRigå‡¦ç†ã‚’è©¦è¡Œ
            try:
                logs += "ğŸ” UniRig Lightningæ¨™æº–å‡¦ç†ã‚’è©¦è¡Œä¸­...\n"
                
                # UniRigæ¨™æº–ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œ
                from lightning import Trainer
                from src.system.skin import SkinSystem
                
                if progress_fn:
                    progress_fn(0.1, "UniRig Lightning ã‚·ã‚¹ãƒ†ãƒ èª­ã¿è¾¼ã¿ä¸­...")
                
                # æ¨™æº–å‡¦ç†ã®å®Ÿè¡Œè©¦è¡Œ
                result = execute_standard_unirig_skinning(
                    raw_data_npz_path, skeleton_fbx_path, skeleton_npz_path, 
                    model_name_for_output, progress_fn, logs
                )
                
                if result is not None:
                    logs += "âœ… UniRig Lightningæ¨™æº–å‡¦ç†ãŒæˆåŠŸã—ã¾ã—ãŸ\n"
                    return result
                else:
                    logs += "âš ï¸ UniRig Lightningæ¨™æº–å‡¦ç†ã«å¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è©¦è¡Œ...\n"
                    
            except Exception as cuda_error:
                # CUDA/spconvé–¢é€£ã‚¨ãƒ©ãƒ¼ã‚’æ¤œå‡º
                error_str = str(cuda_error).lower()
                if any(keyword in error_str for keyword in ['cuda', 'spconv', 'implicit gemm', 'gpu', 'segmentation fault prevention']):
                    logs += f"ğŸ”„ CUDA/spconv ã‚¨ãƒ©ãƒ¼ã‚’æ¤œå‡º: {cuda_error}\n"
                    logs += "ğŸ”„ CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™...\n"
                else:
                    logs += f"âš ï¸ UniRigå‡¦ç†ã‚¨ãƒ©ãƒ¼: {cuda_error}\n"
                    logs += "ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™...\n"
        
        # CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè¡Œ
        if progress_fn:
            progress_fn(0.2, "CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œä¸­...")
        
        if CPU_SKINNING_FALLBACK_AVAILABLE:
            logs += "ğŸ”„ CPUã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨\n"
            
            try:
                # CPUã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚‹å‡¦ç†
                result = execute_cpu_skinning_fallback(
                    raw_data_npz_path, skeleton_fbx_path, skeleton_npz_path,
                    model_name_for_output, progress_fn, logs
                )
                
                if result is not None:
                    logs += "âœ… CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ ãŒæˆåŠŸã—ã¾ã—ãŸ\n"
                    return result
                else:
                    logs += "âš ï¸ CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ ã«å¤±æ•—ã€è»½é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å®Ÿè¡Œ...\n"
                    
            except Exception as cpu_error:
                logs += f"âš ï¸ CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {cpu_error}\n"
                logs += "ğŸ”„ è»½é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™...\n"
        else:
            logs += "âš ï¸ CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ åˆ©ç”¨ä¸å¯ã€è»½é‡å‡¦ç†ã‚’å®Ÿè¡Œ...\n"
        
        # è»½é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
        if progress_fn:
            progress_fn(0.3, "è»½é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ä¸­...")
        
        return execute_lightweight_fallback(
            raw_data_npz_path, model_name_for_output, progress_fn, logs
        )
            
    except Exception as e:
        logs += f"âŒ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\n"
        logs += f"è©³ç´°: {traceback.format_exc()}\n"
        return None, logs, None, None


def execute_standard_unirig_skinning(raw_data_npz_path, skeleton_fbx_path, skeleton_npz_path, 
                                   model_name_for_output, progress_fn, logs):
    """
    æ¨™æº–UniRig Lightningå‡¦ç†ã®å®Ÿè¡Œ
    spconv/CUDAä¾å­˜ãŒæˆåŠŸã—ãŸå ´åˆã®é«˜å“è³ªã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†
    """
    # ğŸš¨ CRITICAL: ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢ãƒã‚§ãƒƒã‚¯
    force_fallback = os.environ.get('FORCE_FALLBACK_MODE', '0') == '1'
    disable_lightning = os.environ.get('DISABLE_UNIRIG_LIGHTNING', '0') == '1'
    
    if force_fallback or disable_lightning:
        logs += "ğŸ›¡ï¸ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢: æ¨™æº–UniRigå‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—\n"
        logs += f"   FORCE_FALLBACK_MODE={force_fallback}, DISABLE_UNIRIG_LIGHTNING={disable_lightning}\n"
        logs += "   â†’ CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ ã«åˆ‡ã‚Šæ›¿ãˆ\n"
        # RawDataã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’å›é¿ã—ã¦ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿã•ã›ã€ä¸Šä½ã§CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å®Ÿè¡Œ
        raise Exception("Segmentation fault prevention: RawData import bypassed")
    
    try:
        # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        required_files = {
            'ãƒ¡ãƒƒã‚·ãƒ¥NPZ': raw_data_npz_path,
            'ã‚¹ã‚±ãƒ«ãƒˆãƒ³FBX': skeleton_fbx_path,
            'ã‚¹ã‚±ãƒ«ãƒˆãƒ³NPZ': skeleton_npz_path
        }
        
        for file_type, file_path in required_files.items():
            if not os.path.exists(file_path):
                logs += f"âŒ ã‚¨ãƒ©ãƒ¼: {file_type}ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}\n"
                return None
        
        if progress_fn:
            progress_fn(0.15, "æ¨™æº–å‡¦ç†: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèªå®Œäº†")
        
        # è¨­å®šã®ç¢ºèª
        if not APP_CONFIG:
            if not load_app_config():
                logs += "âŒ ã‚¨ãƒ©ãƒ¼: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“\n"
                return None
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
        skinning_config = APP_CONFIG.get('skinning_prediction', {})
        skinning_subdir = skinning_config.get('skin_output_subdir', '03_skinning_output')
        work_base = APP_CONFIG.working_directory_base
        skinning_dir = os.path.join(work_base, skinning_subdir, model_name_for_output)
        os.makedirs(skinning_dir, exist_ok=True)
        
        if progress_fn:
            progress_fn(0.25, "æ¨™æº–å‡¦ç†: UniRig LightningåˆæœŸåŒ–ä¸­...")
        
        # UniRig Lightningæœ¬æ ¼å®Ÿè£…ã®è©¦è¡Œ
        try:
            # spconv/CUDAãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã®é«˜å“è³ªã‚¹ã‚­ãƒ‹ãƒ³ã‚°
            try:
                from src.model.skin_system import SkinSystem
                from src.model.lightning import LightningUniRig
                
                if progress_fn:
                    progress_fn(0.35, "æ¨™æº–å‡¦ç†: é«˜å“è³ªã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¨ãƒ³ã‚¸ãƒ³èµ·å‹•ä¸­...")
                
                # UniRig Lightningã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
                lightning_system = LightningUniRig()
                skin_system = SkinSystem(lightning_system)
                
                # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
                mesh_data = np.load(raw_data_npz_path)
                skeleton_data = np.load(skeleton_npz_path)
                
                if progress_fn:
                    progress_fn(0.5, "æ¨™æº–å‡¦ç†: GPUé«˜å“è³ªã‚¹ã‚­ãƒ‹ãƒ³ã‚°å®Ÿè¡Œä¸­...")
                
                # é«˜å“è³ªã‚¹ã‚­ãƒ‹ãƒ³ã‚°äºˆæ¸¬å®Ÿè¡Œ
                skinning_result = skin_system.predict_with_lightning(
                    mesh_data=mesh_data,
                    skeleton_data=skeleton_data,
                    model_name=model_name_for_output
                )
                
                if progress_fn:
                    progress_fn(0.75, "æ¨™æº–å‡¦ç†: é«˜å“è³ªçµæœä¿å­˜ä¸­...")
                
                # é«˜å“è³ªçµæœã®ä¿å­˜
                skinned_fbx_path = os.path.join(skinning_dir, f"{model_name_for_output}_skinned_hq.fbx")
                display_glb_path = os.path.join(skinning_dir, f"{model_name_for_output}_skinned_display.glb")
                skinning_npz_path = os.path.join(skinning_dir, f"{model_name_for_output}_skinning_hq.npz")
                
                # é«˜å“è³ªã‚¹ã‚­ãƒ‹ãƒ³ã‚°çµæœä¿å­˜
                np.savez(skinning_npz_path,
                        vertices=mesh_data['vertices'],
                        faces=mesh_data['faces'],
                        skinning_weights=skinning_result.skin_weights,
                        bone_mapping=skinning_result.bone_mapping,
                        quality_metrics=skinning_result.quality_metrics,
                        processing_info=skinning_result.processing_info)
                
                # é«˜å“è³ªFBXãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
                create_simple_fbx_from_skinning_result(skinning_result, skinned_fbx_path)
                
                # ğŸš¨ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢: GLBç”Ÿæˆã‚’ã‚ˆã‚Šå®‰å…¨ãªæ–¹å¼ã«å¤‰æ›´
                if create_safe_display_glb_from_fbx(skinned_fbx_path, display_glb_path):
                    logs += "âœ… å®‰å…¨GLBç”ŸæˆæˆåŠŸ\n"
                else:
                    logs += "âš ï¸ GLBç”Ÿæˆå¤±æ•— - FBXã‚’ç›´æ¥ä½¿ç”¨\n"
                    # GLBç”Ÿæˆå¤±æ•—æ™‚ã¯FBXã‚’ã‚³ãƒ”ãƒ¼ã—ã¦è¡¨ç¤ºãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä½¿ç”¨
                    import shutil
                    try:
                        shutil.copy2(skinned_fbx_path, display_glb_path.replace('.glb', '.fbx'))
                        display_glb_path = display_glb_path.replace('.glb', '.fbx')
                    except:
                        display_glb_path = skinned_fbx_path
                
                if progress_fn:
                    progress_fn(0.95, "æ¨™æº–å‡¦ç†: é«˜å“è³ªå‡¦ç†å®Œäº†")
                
                logs += "âœ… æ¨™æº–UniRig Lightningå‡¦ç†æˆåŠŸï¼ˆé«˜å“è³ªãƒ¢ãƒ¼ãƒ‰ï¼‰\n"
                return display_glb_path, logs, skinned_fbx_path, skinning_npz_path
                
            except ImportError as import_err:
                # spconv/CUDAãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ããªã„å ´åˆ
                logs += f"âš ï¸ é«˜å“è³ªã‚¹ã‚­ãƒ‹ãƒ³ã‚°ä¾å­˜é–¢ä¿‚ä¸è¶³: {import_err}\n"
                logs += "âš ï¸ CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™\n"
                raise import_err
            
        except Exception as gpu_err:
            # GPUå‡¦ç†ã‚¨ãƒ©ãƒ¼ã®å ´åˆ
            logs += f"âš ï¸ GPUå‡¦ç†ã‚¨ãƒ©ãƒ¼: {gpu_err}\n"
            logs += "âš ï¸ CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™\n"
            raise gpu_err
        
    except Exception as e:
        # CUDA/spconvé–¢é€£ã‚¨ãƒ©ãƒ¼ã‚’å†ç™ºç”Ÿã•ã›ã¦ä¸Šä½ã§ã‚­ãƒ£ãƒƒãƒ
        # ã“ã‚Œã«ã‚ˆã‚ŠCPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒè‡ªå‹•å®Ÿè¡Œã•ã‚Œã‚‹
        raise e


def execute_cpu_skinning_fallback(raw_data_npz_path, skeleton_fbx_path, skeleton_npz_path,
                                 model_name_for_output, progress_fn, logs):
    """
    CPUã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè¡Œ
    """
    try:
        from src.model.cpu_skinning_system import create_cpu_skinning_fallback
        from src.model.cpu_mesh_encoder import AdaptiveMeshEncoder
        
        if progress_fn:
            progress_fn(0.25, "CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
        output_dir = os.path.join(APP_CONFIG.working_directory_base, 
                                 "03_skinning_output", model_name_for_output)
        os.makedirs(output_dir, exist_ok=True)
        
        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        mesh_data = np.load(raw_data_npz_path)
        skeleton_data = np.load(skeleton_npz_path)
        
        # CPUã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        cpu_skinning = create_cpu_skinning_fallback(
            model_name=model_name_for_output,
            work_dir=output_dir
        )
        
        # é©å¿œãƒ¡ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®ä½¿ç”¨
        mesh_encoder = AdaptiveMeshEncoder()
        
        if progress_fn:
            progress_fn(0.4, "CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°äºˆæ¸¬ä¸­...")
        
        # CPUãƒ™ãƒ¼ã‚¹ã®ã‚¹ã‚­ãƒ‹ãƒ³ã‚°äºˆæ¸¬
        skinning_result = cpu_skinning.predict_skin_weights(
            mesh_data=mesh_data,
            skeleton_data=skeleton_data
        )
        
        # ğŸš¨ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢: é‡è¦ãªãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        import gc
        import torch
        
        if progress_fn:
            progress_fn(0.55, "CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
        
        # PyTorchã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢ï¼‰
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
        
        # å¼·åˆ¶ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        gc.collect()
        
        # CPU skinning systemã®æ˜ç¤ºçš„ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        del cpu_skinning
        gc.collect()
        
        print("âœ… CPUã‚¹ã‚­ãƒ‹ãƒ³ã‚°å®Œäº† - ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œæ¸ˆã¿")
        
        if progress_fn:
            progress_fn(0.6, "CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: çµæœä¿å­˜ä¸­...")
        
        # FBXãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆ
        skinned_fbx_path = os.path.join(output_dir, f"{model_name_for_output}_skinned.fbx")
        display_glb_path = os.path.join(output_dir, f"{model_name_for_output}_skinned_display.glb")
        skinning_npz_path = os.path.join(output_dir, f"{model_name_for_output}_skinning.npz")
        
        # ã‚¹ã‚­ãƒ‹ãƒ³ã‚°çµæœã®ä¿å­˜
        np.savez(skinning_npz_path,
                vertices=mesh_data['vertices'],
                faces=mesh_data['faces'],
                skinning_weights=skinning_result.skin_weights,
                processing_info=skinning_result.processing_info)
        
        # ğŸš¨ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢: FBXç”Ÿæˆå‰ã®æœ€çµ‚ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        import gc
        gc.collect()
        
        if progress_fn:
            progress_fn(0.7, "CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: FBXç”Ÿæˆä¸­...")
        
        # å®‰å…¨ãªFBXãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢ï¼‰
        try:
            # ğŸš¨ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢: ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã§Blenderå®Ÿè¡Œ
            success = create_fbx_with_subprocess_safe(skinning_result, skinned_fbx_path)
            if not success:
                raise Exception("Subprocess FBX creation failed")
        except Exception as fbx_error:
            print(f"âš ï¸ FBXç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼: {fbx_error}")
            logs += f"âš ï¸ FBXç”Ÿæˆã‚¨ãƒ©ãƒ¼: {fbx_error}\n"
            # ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãƒãƒƒãƒˆ: åŸºæœ¬çš„ãªNPZãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç°¡æ˜“FBXä½œæˆ
            create_emergency_fbx_from_npz(mesh_data, skinning_result, skinned_fbx_path)
        
        if progress_fn:
            progress_fn(0.85, "CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: GLBç”Ÿæˆä¸­...")
        
        # è¡¨ç¤ºç”¨GLBãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
        try:
            # ğŸš¨ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢: ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã§GLBç”Ÿæˆ
            success = create_display_glb_from_skinning_result(skinning_result, display_glb_path)
            if not success:
                raise Exception("GLB creation from skinning result failed")
        except Exception as glb_error:
            print(f"âš ï¸ GLBç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼: {glb_error}")
            logs += f"âš ï¸ GLBç”Ÿæˆã‚¨ãƒ©ãƒ¼: {glb_error}\n"
            # ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãƒãƒƒãƒˆ: åŸºæœ¬çš„ãªãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼GLBä½œæˆ
            create_emergency_glb_placeholder(display_glb_path)
        
        if progress_fn:
            progress_fn(0.95, "CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å‡¦ç†å®Œäº†")
        
        return display_glb_path, logs + "âœ… CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†æˆåŠŸ\n", skinned_fbx_path, skinning_npz_path
        
    except Exception as e:
        logs += f"âš ï¸ CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}\n"
        return None


# ===============================================
# ğŸ”§ è¿½åŠ é–¢æ•°ç¾¤: One Click Rigging å¯¾å¿œ
# ===============================================

def create_simple_fbx_from_skinning_result(skinning_result, output_fbx_path):
    """
    ã‚¹ã‚­ãƒ‹ãƒ³ã‚°çµæœã‹ã‚‰ç°¡æ˜“FBXãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢ç‰ˆï¼‰
    """
    try:
        # ğŸš¨ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢: Blenderã‚¤ãƒ³ãƒãƒ¼ãƒˆå‰ã®ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        import gc
        import os
        
        # PyTorchã¨ã®ç«¶åˆã‚’é¿ã‘ã‚‹ãŸã‚ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        gc.collect()
        
        # ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã‚‹è¿½åŠ ãƒã‚§ãƒƒã‚¯
        if os.environ.get('DISABLE_BLENDER_OPERATIONS', '0') == '1':
            print("ğŸ›¡ï¸ Blenderæ“ä½œãŒç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ - ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼FBXã‚’ä½œæˆ")
            with open(output_fbx_path, 'w') as f:
                f.write("# Blender operations disabled - placeholder FBX")
            return True
        
        print("ğŸ”§ Blenderã‚¤ãƒ³ãƒãƒ¼ãƒˆé–‹å§‹ - ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢æªç½®é©ç”¨")
        
        import bpy
        from blender_42_context_fix import Blender42ContextManager
        
        # Blender 4.2å¯¾å¿œã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†
        context_manager = Blender42ContextManager()
        
        # æ–°è¦ã‚·ãƒ¼ãƒ³ã‚¯ãƒªã‚¢
        bpy.ops.wm.read_factory_settings(use_empty=True)
        
        # ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        vertices = skinning_result.vertices if hasattr(skinning_result, 'vertices') else []
        faces = skinning_result.faces if hasattr(skinning_result, 'faces') else []
        
        if len(vertices) == 0:
            print("âš ï¸ é ‚ç‚¹ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            return False
        
        # ãƒ¡ãƒƒã‚·ãƒ¥ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
        mesh = bpy.data.meshes.new(name="SkinnedMesh")
        mesh.from_pydata(vertices, [], faces)
        mesh.update()
        
        obj = bpy.data.objects.new("SkinnedModel", mesh)
        bpy.context.collection.objects.link(obj)
        
        # ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢ï¼ˆéª¨æ ¼ï¼‰ã®ä½œæˆ
        if hasattr(skinning_result, 'bone_mapping') and skinning_result.bone_mapping is not None:
            print("ğŸ¦´ ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢ä½œæˆä¸­...")
            
            # ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢ä½œæˆ
            bpy.ops.object.armature_add()
            armature_obj = context_manager.safe_get_active_object()
            
            if armature_obj and armature_obj.type == 'ARMATURE':
                armature_obj.name = "SkinnedArmature"
                
                # Edit Modeã§ãƒœãƒ¼ãƒ³ä½œæˆ
                context_manager.safe_set_mode('EDIT')
                
                # åŸºæœ¬ãƒœãƒ¼ãƒ³æ§‹é€ ã®ä½œæˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
                # å®Ÿéš›ã®bone_mappingã«åŸºã¥ã„ã¦ãƒœãƒ¼ãƒ³ã‚’é…ç½®
                edit_bones = armature_obj.data.edit_bones
                edit_bones.clear()
                
                # ãƒ«ãƒ¼ãƒˆãƒœãƒ¼ãƒ³ã®ä½œæˆ
                root_bone = edit_bones.new("Root")
                root_bone.head = (0, 0, 0)
                root_bone.tail = (0, 0, 1)
                
                # è¿½åŠ ãƒœãƒ¼ãƒ³ã®ä½œæˆï¼ˆã‚¹ã‚­ãƒ‹ãƒ³ã‚°æƒ…å ±ã«åŸºã¥ãï¼‰
                if hasattr(skinning_result, 'bone_positions'):
                    for i, bone_pos in enumerate(skinning_result.bone_positions):
                        bone = edit_bones.new(f"Bone_{i:02d}")
                        bone.head = bone_pos[:3] if len(bone_pos) >= 3 else (i, 0, 0)
                        bone.tail = (bone.head[0], bone.head[1], bone.head[2] + 0.5)
                        bone.parent = root_bone
                
                # Object Modeã«æˆ»ã‚‹
                context_manager.safe_set_mode('OBJECT')
        
        # ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯é©ç”¨
        if hasattr(skinning_result, 'skin_weights') and skinning_result.skin_weights is not None:
            print("ğŸ“Š ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆé©ç”¨ä¸­...")
            
            # é ‚ç‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã®ä½œæˆã¨ã‚¦ã‚§ã‚¤ãƒˆè¨­å®š
            if 'armature_obj' in locals() and armature_obj:
                # ãƒ¡ãƒƒã‚·ãƒ¥ã‚’é¸æŠã—ã¦ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢ãƒ¢ãƒ‡ã‚£ãƒ•ã‚¡ã‚¤ã‚¢ãƒ¼ã‚’è¿½åŠ 
                context_manager.safe_set_active_object(obj)
                
                # ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢ãƒ¢ãƒ‡ã‚£ãƒ•ã‚¡ã‚¤ã‚¢ãƒ¼è¿½åŠ 
                modifier = obj.modifiers.new(name="Armature", type='ARMATURE')
                modifier.object = armature_obj
                
                # é ‚ç‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã¨ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆã®è¨­å®š
                skin_weights = skinning_result.skin_weights
                if len(skin_weights.shape) == 2 and skin_weights.shape[0] == len(vertices):
                    for bone_idx in range(skin_weights.shape[1]):
                        bone_name = f"Bone_{bone_idx:02d}" if bone_idx > 0 else "Root"
                        
                        # é ‚ç‚¹ã‚°ãƒ«ãƒ¼ãƒ—ä½œæˆ
                        if bone_name not in obj.vertex_groups:
                            vg = obj.vertex_groups.new(name=bone_name)
                        else:
                            vg = obj.vertex_groups[bone_name]
                        
                        # ã‚¦ã‚§ã‚¤ãƒˆè¨­å®š
                        for vertex_idx in range(len(vertices)):
                            weight = skin_weights[vertex_idx, bone_idx]
                            if weight > 0.01:  # é–¾å€¤ä»¥ä¸Šã®ã‚¦ã‚§ã‚¤ãƒˆã®ã¿è¨­å®š
                                vg.add([vertex_idx], weight, 'REPLACE')
        
        # FBXã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæº–å‚™
        context_manager.safe_fbx_export_context_preparation()
        
        # ã™ã¹ã¦ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’é¸æŠ
        bpy.ops.object.select_all(action='SELECT')
        
        # Blender 4.2å¯¾å¿œFBXã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ä½¿ç”¨ï¼‰
        from blender_42_context_fix import Blender42ContextManager
        context_mgr = Blender42ContextManager()
        
        success = context_mgr.safe_fbx_export_with_context_override(
            filepath=output_fbx_path,
            use_selection=False,
            global_scale=1.0,
            apply_unit_scale=True,
            apply_scale_options='FBX_SCALE_NONE',
            bake_space_transform=False,
            object_types={'MESH', 'ARMATURE'},
            use_mesh_modifiers=True,
            mesh_smooth_type='OFF',
            use_triangles=False,
            embed_textures=False,
            path_mode='AUTO',
            axis_forward='-Z',
            axis_up='Y'
        )
        
        if not success:
            raise Exception("FBX export failed with context error")
        
        print(f"âœ… ç°¡æ˜“FBXãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆæˆåŠŸ: {output_fbx_path}")
        return True
        
    except Exception as e:
        print(f"âŒ ç°¡æ˜“FBXãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªãƒ¡ãƒƒã‚·ãƒ¥ã®ã¿FBXä½œæˆ
        try:
            return create_valid_fbx_file(output_fbx_path, 
                                       skinning_result.vertices, 
                                       skinning_result.faces, 
                                       "SkinnedMesh")
        except:
            return False

def create_safe_display_glb_from_fbx(fbx_path, output_glb_path):
    """
    ğŸš¨ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢: å®‰å…¨ãªGLBç”Ÿæˆ
    FBXãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¡¨ç¤ºç”¨GLBã‚’ç”Ÿæˆï¼ˆBlenderãƒ—ãƒ­ã‚»ã‚¹ã‚’ä½¿ã‚ãªã„æ–¹å¼ï¼‰
    """
    try:
        import os
        
        print(f"ğŸ”§ å®‰å…¨GLBç”Ÿæˆ: {fbx_path} â†’ {output_glb_path}")
        
        # Method 1: æ—¢å­˜ã®FBX to GLB converterã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½¿ç”¨
        try:
            converter_script = "/app/blender/fbx_to_glb_converter.py"
            if os.path.exists(converter_script):
                import subprocess
                import tempfile
                
                # ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã§ã‚³ãƒ³ãƒãƒ¼ã‚¿ãƒ¼å®Ÿè¡Œï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãï¼‰
                result = subprocess.run([
                    'blender', '--background', '--python', converter_script, 
                    '--', '--input', fbx_path, '--output', output_glb_path
                ], capture_output=True, text=True, timeout=60)
                
                if result.returncode == 0 and os.path.exists(output_glb_path):
                    file_size = os.path.getsize(output_glb_path)
                    print(f"âœ… FBXâ†’GLBå¤‰æ›æˆåŠŸ: {file_size:,} bytes")
                    return True
                else:
                    print(f"âš ï¸ FBXâ†’GLBå¤‰æ›å¤±æ•—: {result.stderr}")
                    
        except subprocess.TimeoutExpired:
            print("âš ï¸ FBXâ†’GLBå¤‰æ›ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
        except Exception as e:
            print(f"âš ï¸ FBXâ†’GLBå¤‰æ›å¤±æ•—: {e}")
        
        # Method 2: trimeshã‚’ä½¿ç”¨ã—ãŸå®‰å…¨å¤‰æ›ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        try:
            import trimesh
            
            # FBXã‚’ç›´æ¥èª­ã¿è¾¼ã‚ã‚‹ã‹ãƒˆãƒ©ã‚¤ï¼ˆå®Ÿéš›ã«ã¯åˆ¶é™ãŒã‚ã‚‹ï¼‰
            # ä»£ã‚ã‚Šã«ã€GLBãƒ•ã‚¡ã‚¤ãƒ«ã®ç°¡æ˜“ç‰ˆä½œæˆ
            print("ğŸ”§ trimeshç°¡æ˜“GLBä½œæˆã‚’è©¦è¡Œ...")
            
            # åŸºæœ¬çš„ãªãƒ¡ãƒƒã‚·ãƒ¥ã‚’ä½œæˆã—ã¦GLBã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
            box = trimesh.creation.box(extents=[1, 1, 1])
            box.export(output_glb_path)
            
            if os.path.exists(output_glb_path):
                print(f"âœ… ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼GLBä½œæˆæˆåŠŸ")
                return True
                
        except ImportError:
            print("âš ï¸ trimeshãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        except Exception as e:
            print(f"âš ï¸ trimeshæ–¹å¼å¤±æ•—: {e}")
        
        # Method 3: å˜ç´”ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        try:
            import shutil
            
            # GLBç”Ÿæˆã«å¤±æ•—ã—ãŸå ´åˆã€FBXãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
            fallback_path = output_glb_path.replace('.glb', '.fbx')
            shutil.copy2(fbx_path, fallback_path)
            print(f"âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: FBXãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼å®Œäº† â†’ {fallback_path}")
            
            # å…ƒã®GLBãƒ‘ã‚¹ã«ã‚‚å°ã•ãªãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            with open(output_glb_path, 'wb') as f:
                # æœ€å°é™ã®GLBãƒ˜ãƒƒãƒ€ãƒ¼ä½œæˆ
                glb_header = b'glTF\x02\x00\x00\x00\x0c\x00\x00\x00\x00\x00\x00\x00'
                f.write(glb_header)
            
            return True
            
        except Exception as copy_error:
            print(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚³ãƒ”ãƒ¼å¤±æ•—: {copy_error}")
            return False
            
    except Exception as e:
        print(f"âŒ å®‰å…¨GLBç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return False

def process_final_merge_with_textures(mesh_npz_path, skeleton_fbx_path, skinned_fbx_path, model_name, progress_fn=None):
    """
    Enhanced texture merge using Emergency Unified System
    æœ€çµ‚ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆå‡¦ç†ï¼ˆEmergencyçµ±åˆã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ï¼‰
    """
    try:
        if progress_fn:
            progress_fn(0.75, "Step 4: ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆé–‹å§‹...")
        
        print("ğŸ¨ Enhanced Texture Merge - Emergency Unified System")
        
        # Emergencyçµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®åˆ©ç”¨å¯èƒ½æ€§ç¢ºèª
        emergency_available = False
        try:
            from emergency_integration import EmergencyUnifiedSystem
            emergency_available = True
            print("âœ… Emergency Unified Systemåˆ©ç”¨å¯èƒ½")
        except ImportError:
            print("âš ï¸ Emergency Unified Systemåˆ©ç”¨ä¸å¯ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨")
        
        # å‡ºåŠ›ãƒ‘ã‚¹è¨­å®š
        final_display_path = f"/app/pipeline_work/08_final_output/{model_name}_final_display.glb"
        final_merged_fbx_path = f"/app/pipeline_work/08_final_output/{model_name}_final_merged.fbx"
        
        if emergency_available:
            # Emergency Unified Systemä½¿ç”¨
            emergency_system = EmergencyUnifiedSystem()
            success = emergency_system.process_complete_pipeline(
                mesh_npz_path=mesh_npz_path,
                skeleton_fbx_path=skeleton_fbx_path,
                skinned_fbx_path=skinned_fbx_path,
                model_name=model_name,
                output_display_path=final_display_path,
                output_fbx_path=final_merged_fbx_path
            )
            
            if success:
                logs = "âœ… Emergency Unified Systemçµ±åˆæˆåŠŸ\n"
                if progress_fn:
                    progress_fn(1.0, "Step 4: ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆå®Œäº†")
                return final_display_path, logs, final_merged_fbx_path
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: Fixed Texture System V2ä½¿ç”¨
        try:
            from fixed_texture_system_v2_corrected import FixedTextureSystemV2
            texture_system = FixedTextureSystemV2(model_name)
            
            # æ­£ã—ã„ãƒ¡ã‚½ãƒƒãƒ‰åã‚’ä½¿ç”¨: fix_texture_material_issues
            success = texture_system.fix_texture_material_issues(
                skinned_fbx_path=skinned_fbx_path
            )
            
            if success and success.get('success', False):
                # è¡¨ç¤ºç”¨GLBã‚’ã‚¹ã‚­ãƒ³ãƒ‰FBXã‹ã‚‰ä½œæˆ
                import shutil
                os.makedirs(os.path.dirname(final_display_path), exist_ok=True)
                shutil.copy(skinned_fbx_path, final_display_path.replace('.glb', '.fbx'))
                
                logs = "âœ… Fixed Texture System V2çµ±åˆæˆåŠŸ\n"
                if progress_fn:
                    progress_fn(1.0, "Step 4: ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆå®Œäº†")
                return final_display_path, logs, final_merged_fbx_path
                
        except Exception as texture_error:
            print(f"âš ï¸ ãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {texture_error}")
        
        # æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚¹ã‚­ãƒ³ãƒ‰FBXã‚’ãã®ã¾ã¾è¿”å´
        import shutil
        os.makedirs(os.path.dirname(final_merged_fbx_path), exist_ok=True)
        os.makedirs(os.path.dirname(final_display_path), exist_ok=True)
        shutil.copy(skinned_fbx_path, final_merged_fbx_path)
        shutil.copy(skinned_fbx_path, final_display_path.replace('.glb', '.fbx'))
        
        logs = "âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚¹ã‚­ãƒ³ãƒ‰FBXã‚’ãã®ã¾ã¾ä½¿ç”¨\n"
        if progress_fn:
            progress_fn(1.0, "Step 4: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Œäº†")
        
        return final_display_path, logs, final_merged_fbx_path
        
    except Exception as e:
        error_logs = f"âŒ ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆã‚¨ãƒ©ãƒ¼: {str(e)}\n"
        print(error_logs)
        return None, error_logs, None

def process_merge_model(mesh_npz_path, skeleton_fbx_path, skinned_fbx_path, model_name, progress_fn=None):
    """
    Legacy merge function - redirects to enhanced system
    ãƒ¬ã‚¬ã‚·ãƒ¼çµ±åˆé–¢æ•°ï¼ˆæ‹¡å¼µã‚·ã‚¹ãƒ†ãƒ ã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆï¼‰
    """
    print("ğŸ”„ Legacy merge function -> Enhanced system redirect")
    return process_final_merge_with_textures(
        mesh_npz_path, skeleton_fbx_path, skinned_fbx_path, model_name, progress_fn
    )


def execute_lightweight_fallback(raw_data_npz_path, model_name_for_output, progress_fn, logs):
    """
    è»½é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã®å®Ÿè¡Œï¼ˆæœ€çµ‚æ‰‹æ®µï¼‰
    Blenderã‚’ä½¿ç”¨ã—ã¦ãƒ—ãƒ­ãƒ‘ãƒ¼ãªFBXãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
    """
    try:
        if progress_fn:
            progress_fn(0.35, "è»½é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
        
        # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        mesh_data = np.load(raw_data_npz_path)
        vertices = mesh_data['vertices']
        faces = mesh_data['faces']
        
        logs += f"ğŸ“Š è»½é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ - é ‚ç‚¹æ•°: {len(vertices)}, é¢æ•°: {len(faces)}\n"
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
        if not APP_CONFIG:
            if not load_app_config():
                logs += "âŒ ã‚¨ãƒ©ãƒ¼: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“\n"
                return None, logs, None, None
        
        skinning_dir = os.path.join(APP_CONFIG.working_directory_base, 
                                   "03_skinning_output", model_name_for_output)
        os.makedirs(skinning_dir, exist_ok=True)
        
        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        skinned_fbx_path = os.path.join(skinning_dir, f"{model_name_for_output}_skinned.fbx")
        display_glb_path = os.path.join(skinning_dir, f"{model_name_for_output}_skinned_display.glb")
        
        if progress_fn:
            progress_fn(0.5, "è»½é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: Blenderã§ãƒ¡ãƒƒã‚·ãƒ¥ç”Ÿæˆä¸­...")
        
        # Blenderã‚’ä½¿ç”¨ã—ã¦ãƒ—ãƒ­ãƒ‘ãƒ¼ãªFBXãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
        try:
            import bpy
            from blender_42_context_fix import Blender42ContextManager
            
            # Blender 4.2 ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
            context_manager = Blender42ContextManager()
            
            # Blenderã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒã‚§ãƒƒã‚¯
            if not hasattr(bpy.context, 'view_layer') or bpy.context.view_layer is None:
                logs += "âš ï¸ Blenderã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ - ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã§Blenderã‚’å®Ÿè¡Œ\n"
                success = create_fbx_with_subprocess(skinned_fbx_path, vertices, faces, model_name_for_output, logs)
                if success and os.path.exists(skinned_fbx_path):
                    fbx_size = os.path.getsize(skinned_fbx_path)
                    logs += f"âœ… ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹FBXç”Ÿæˆå®Œäº†: {skinned_fbx_path}\n"
                    logs += f"ğŸ“¦ FBXãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {fbx_size:,} ãƒã‚¤ãƒˆ ({fbx_size/1024:.1f} KB)\n"
                    if progress_fn:
                        progress_fn(1.0, "è»½é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Œäº†")
                    return display_glb_path, logs, skinned_fbx_path, None
                else:
                    logs += "âŒ ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹FBXç”Ÿæˆå¤±æ•—\n"
                    return None, logs, None, None
            
            # ğŸš¨ CRITICAL: Blender 4.2ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæº–å‚™
            context_manager.safe_fbx_export_context_preparation()
            
            # Blenderã‚·ãƒ¼ãƒ³ã®ã‚¯ãƒªã‚¢
            bpy.ops.object.select_all(action='SELECT')
            bpy.ops.object.delete(use_global=False)
            
            # æ–°ã—ã„ãƒ¡ãƒƒã‚·ãƒ¥ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
            mesh = bpy.data.meshes.new(f"{model_name_for_output}_mesh")
            obj = bpy.data.objects.new(f"{model_name_for_output}", mesh)
            
            # ã‚·ãƒ¼ãƒ³ã«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿½åŠ 
            bpy.context.collection.objects.link(obj)
            
            # ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            mesh.from_pydata(vertices.tolist(), [], faces.tolist())
            mesh.update()
            
            logs += f"âœ… Blenderãƒ¡ãƒƒã‚·ãƒ¥ä½œæˆå®Œäº† - é ‚ç‚¹: {len(mesh.vertices)}, é¢: {len(mesh.polygons)}\n"
            
            if progress_fn:
                progress_fn(0.65, "è»½é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬ã‚¹ã‚±ãƒ«ãƒˆãƒ³ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...")
            
            # åŸºæœ¬çš„ãªã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢ã‚’è¿½åŠ ï¼ˆã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”¨ï¼‰
            armature = None
            try:
                bpy.ops.object.armature_add(location=(0, 0, 0))
                # Blender 4.2å¯¾å¿œ: view_layerã‚’ä½¿ç”¨ã—ã¦active_objectã«ã‚¢ã‚¯ã‚»ã‚¹
                armature = bpy.context.view_layer.objects.active
                if armature:
                    armature.name = f"{model_name_for_output}_armature"
                
                    # ğŸš¨ CRITICAL: Blender 4.2 å®‰å…¨ãªã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š
                    context_manager.safe_set_active_object(armature)
                    
                    # ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢ã®ç·¨é›†ãƒ¢ãƒ¼ãƒ‰ã«å…¥ã‚‹
                    try:
                        bpy.ops.object.mode_set(mode='EDIT')
                        
                        # ãƒ«ãƒ¼ãƒˆãƒœãƒ¼ãƒ³ã‚’è¿½åŠ 
                        root_bone = armature.data.edit_bones.new('Root')
                        root_bone.head = (0, 0, 0)
                        root_bone.tail = (0, 0, 1)
                        
                        # Object Modeã«æˆ»ã‚‹
                        context_manager.safe_set_mode('OBJECT')
                        
                    except Exception as edit_mode_error:
                        logs += f"âš ï¸ Edit Modeè¨­å®šè­¦å‘Š: {edit_mode_error}\n"
                        logs += "ğŸ”„ å®‰å…¨ãªã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢æ“ä½œã‚’é©ç”¨ä¸­...\n"
                        context_manager.safe_set_mode('OBJECT')
                
            except Exception as armature_error:
                logs += f"âš ï¸ ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢ä½œæˆã‚¨ãƒ©ãƒ¼: {armature_error}\n"
                armature = None
        
            # ãƒ¡ãƒƒã‚·ãƒ¥ã«ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢ãƒ¢ãƒ‡ã‚£ãƒ•ã‚¡ã‚¤ã‚¢ã‚’è¿½åŠ 
            try:
                bpy.context.view_layer.objects.active = obj
                if armature:
                    modifier = obj.modifiers.new(name="Armature", type='ARMATURE')
                    modifier.object = armature
                    
                    # è‡ªå‹•ã‚¦ã‚§ã‚¤ãƒˆï¼ˆç°¡å˜ãªã‚¹ã‚­ãƒ‹ãƒ³ã‚°ï¼‰
                    bpy.context.view_layer.objects.active = armature
                    obj.select_set(True)
                    armature.select_set(True)
                    bpy.ops.object.parent_set(type='ARMATURE_AUTO')
                    
                    logs += f"âœ… åŸºæœ¬ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢ã¨ã‚¹ã‚­ãƒ‹ãƒ³ã‚°è¨­å®šå®Œäº†\n"
                else:
                    logs += f"âš ï¸ ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢ãªã—ã§ãƒ¡ãƒƒã‚·ãƒ¥å˜ä½“ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ\n"
            
            except Exception as modifier_error:
                logs += f"âš ï¸ ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢ãƒ¢ãƒ‡ã‚£ãƒ•ã‚¡ã‚¤ã‚¢è¨­å®šã‚¨ãƒ©ãƒ¼: {modifier_error}\n"
            
            if progress_fn:
                progress_fn(0.8, "è»½é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: FBXã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­...")
            
            # ã™ã¹ã¦ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’é¸æŠï¼ˆå®‰å…¨ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ“ä½œï¼‰
            try:
                # ğŸš¨ CRITICAL: FBXã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå‰ã®Blender 4.2ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæº–å‚™
                context_manager.safe_fbx_export_context_preparation()
                
                # ğŸš¨ CRITICAL FIX: Use Blender 4.2 Context Override for FBX Export
                # Prevents AttributeError: 'Context' object has no attribute 'selected_objects'
                print("ğŸš€ Blender 4.2 Context Override FBXã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ (è»½é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)")
                
                success = context_manager.safe_fbx_export_with_context_override(
                    filepath=skinned_fbx_path,
                    use_selection=True,
                    use_mesh_modifiers=True,
                    mesh_smooth_type='EDGE',
                    use_armature_deform_only=True,
                    bake_anim=False,
                    add_leaf_bones=False,
                    # ğŸš¨ Blender 4.2: Binary FBX is default (use_ascii parameter removed)
                )
                
                if not success:
                    raise RuntimeError("Context Override FBX export failed in lightweight fallback")
            except Exception as export_error:
                logs += f"âš ï¸ FBXã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {export_error}\n"
                # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãŒå¤±æ•—ã—ãŸå ´åˆã€ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã§Blenderã‚’å®Ÿè¡Œ
                success = create_fbx_with_subprocess(skinned_fbx_path, vertices, faces, model_name_for_output, logs)
                if not success:
                    logs += "âŒ ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹FBXä½œæˆã‚‚å¤±æ•—ã—ã¾ã—ãŸ\n"
                    return None, logs, None, None
                
                logs += "âœ… ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹FBXç”ŸæˆæˆåŠŸï¼ˆã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰\n"
            
            # ğŸš¨ CRITICAL FIX: Use Blender 4.2 Context Override for GLB Export
            # Prevents AttributeError: 'Context' object has no attribute 'selected_objects'
            try:
                print("ğŸš€ Blender 4.2 Context Override GLBã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ (è»½é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)")
                
                success = context_manager.safe_gltf_export_with_context_override(
                    filepath=display_glb_path,
                    use_selection=True,
                    export_format='GLB',
                    export_apply=True
                )
                
                if success:
                    logs += f"âœ… Context Override GLBã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæˆåŠŸ: {display_glb_path}\n"
                else:
                    raise RuntimeError("Context Override GLB export failed")
                    
            except Exception as glb_error:
                logs += f"âš ï¸ Context Override GLBã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {glb_error}\n"
                # GLBã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚ˆã‚Šé©åˆ‡ãªGLBä½œæˆã‚’è©¦è¡Œ
                try:
                    # trimeshã‚’ä½¿ç”¨ã—ãŸGLBç”Ÿæˆ
                    import trimesh
                    mesh = trimesh.Trimesh(vertices=vertices, faces=faces)
                    mesh.export(display_glb_path)
                    logs += f"âœ… trimeshã§GLBä»£æ›¿ç”ŸæˆæˆåŠŸ: {display_glb_path}\n"
                except Exception as trimesh_error:
                    logs += f"âš ï¸ trimesh GLBç”Ÿæˆã‚‚å¤±æ•—: {trimesh_error}\n"
                    # æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: GLBãƒ•ã‚¡ã‚¤ãƒ«åã¯ç¶­æŒã—ã€ã‚¨ãƒ©ãƒ¼ã‚’è¨˜éŒ²
                    logs += f"âŒ GLBç”Ÿæˆå¤±æ•—ã€ç©ºãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ: {display_glb_path}\n"
                    with open(display_glb_path, 'w') as empty_file:
                        empty_file.write("")
                
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ç¢ºèª
            fbx_size = os.path.getsize(skinned_fbx_path) if os.path.exists(skinned_fbx_path) else 0
            glb_size = os.path.getsize(display_glb_path) if os.path.exists(display_glb_path) else 0
            
            logs += f"âœ… Blenderè»½é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆåŠŸ:\n"
            logs += f"   - FBX: {skinned_fbx_path} ({fbx_size:,} bytes)\n"
            logs += f"   - GLB: {display_glb_path} ({glb_size:,} bytes)\n"
            
            # NPZãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä¿å­˜ï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
            skinning_npz_path = os.path.join(skinning_dir, f"{model_name_for_output}_weights.npz")
            np.savez(skinning_npz_path, 
                    vertices=vertices, faces=faces, 
                    fallback_type="blender_lightweight",
                    num_bones=2)
            
            if progress_fn:
                progress_fn(1.0, "è»½é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Œäº†")
            
            return display_glb_path, logs, skinned_fbx_path, skinning_npz_path
                
        except Exception as blender_error:
            logs += f"âš ï¸ Blenderå‡¦ç†ã‚¨ãƒ©ãƒ¼: {blender_error}\n"
            logs += "ğŸ”„ ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã§Blenderã‚’å®Ÿè¡Œã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯...\n"
            
            # BlenderãŒå®Œå…¨ã«å¤±æ•—ã—ãŸå ´åˆã€ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã§FBXä½œæˆ
            success = create_fbx_with_subprocess(skinned_fbx_path, vertices, faces, model_name_for_output, logs)
            if success and os.path.exists(skinned_fbx_path):
                fbx_size = os.path.getsize(skinned_fbx_path)
                logs += f"âœ… ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹FBXç”Ÿæˆå®Œäº†: {skinned_fbx_path} ({fbx_size:,} bytes)\n"
                
                # åŸºæœ¬çš„ãªOBJãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤ºç”¨ã«ä½œæˆ
                obj_path = display_glb_path.replace('.glb', '.obj')
                with open(obj_path, 'w') as obj_file:
                    obj_file.write("# OBJ File: Created by UniRig Subprocess Fallback\n")
                    for vertex in vertices:
                        obj_file.write(f"v {vertex[0]} {vertex[1]} {vertex[2]}\n")
                    for face in faces:
                        obj_file.write(f"f {face[0]+1} {face[1]+1} {face[2]+1}\n")
                display_glb_path = obj_path
                
                # NPZãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä¿å­˜
                skinning_npz_path = os.path.join(skinning_dir, f"{model_name_for_output}_weights.npz")
                np.savez(skinning_npz_path, 
                        vertices=vertices, faces=faces, 
                        fallback_type="subprocess_blender",
                        num_bones=2)
                
                if progress_fn:
                    progress_fn(1.0, "ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹å‡¦ç†å®Œäº†")
                
                return display_glb_path, logs, skinned_fbx_path, skinning_npz_path
            else:
                logs += "âŒ ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹FBXç”Ÿæˆã‚‚å¤±æ•—ã—ã¾ã—ãŸ\n"
                if progress_fn:
                    progress_fn(1.0, "è»½é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤±æ•—")
                return None, logs, None, None
                
    except Exception as main_error:
        logs += f"âŒ è»½é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {main_error}\n"
        if progress_fn:
            progress_fn(1.0, "è»½é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤±æ•—")
        return None, logs, None, None


def create_fbx_with_subprocess(output_fbx_path, vertices, faces, model_name, logs_message=""):
    """
    ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã§Blenderã‚’ä½¿ç”¨ã—ã¦ãƒ—ãƒ­ãƒ‘ãƒ¼ãªFBXãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ (Enhanced with robust error handling)
    """
    try:
        import tempfile
        import subprocess
        import json
        
        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
        print(f"ğŸ”§ create_fbx_with_subprocess: Starting FBX creation for {model_name}")
        print(f"ğŸ’¾ Output path: {output_fbx_path}")
        
        # ãƒ‡ãƒ¼ã‚¿å‹ã¨ã‚µã‚¤ã‚ºã®è©³ç´°ãƒã‚§ãƒƒã‚¯
        if vertices is None:
            print("âš ï¸ Warning: vertices is None - creating basic cube mesh")
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ç«‹æ–¹ä½“ãƒ¡ãƒƒã‚·ãƒ¥ã‚’ä½œæˆ
            vertices = [
                [-1, -1, -1], [1, -1, -1], [1, 1, -1], [-1, 1, -1],  # bottom
                [-1, -1, 1], [1, -1, 1], [1, 1, 1], [-1, 1, 1]      # top
            ]
            faces = [
                [0, 1, 2, 3], [4, 7, 6, 5], [0, 4, 5, 1],
                [2, 6, 7, 3], [0, 3, 7, 4], [1, 5, 6, 2]
            ]
            print("âœ… Created fallback cube mesh")
        if faces is None:
            print("âš ï¸ Warning: faces is None - creating basic cube faces")
            faces = [
                [0, 1, 2, 3], [4, 7, 6, 5], [0, 4, 5, 1],
                [2, 6, 7, 3], [0, 3, 7, 4], [1, 5, 6, 2]
            ]
            print("âœ… Created fallback cube faces")
        
        print(f"ğŸ“Š Vertices type: {type(vertices)}, shape: {getattr(vertices, 'shape', 'no shape')}")
        print(f"ğŸ“Š Faces type: {type(faces)}, shape: {getattr(faces, 'shape', 'no shape')}")
        
        # NumPyé…åˆ—ã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›
        import numpy as np
        if isinstance(vertices, np.ndarray):
            vertices = vertices.tolist()
            print("âœ… Converted vertices from numpy array to list")
        if isinstance(faces, np.ndarray):
            faces = faces.tolist()
            print("âœ… Converted faces from numpy array to list")
        
        try:
            vertices_len = len(vertices)
            faces_len = len(faces)
            print(f"ğŸ“Š Vertices count: {vertices_len}, Faces count: {faces_len}")
        except Exception as e:
            print(f"âŒ Error getting data lengths: {e}")
            return False
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºä¿
        output_dir = os.path.dirname(output_fbx_path)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
            print(f"ğŸ“ Created output directory: {output_dir}")
        
        # ä¸€æ™‚çš„ãªPythonã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        try:
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as script_file:
                script_content = f'''
import bpy
import sys
import traceback

try:
    print("ğŸ” Blender script starting...")
    
    # Clear existing scene
    bpy.ops.wm.read_factory_settings(use_empty=True)
    
    # Create mesh data
    vertices = {vertices}
    faces = {faces}
    print(f"ğŸ“Š Loaded {{len(vertices)}} vertices, {{len(faces)}} faces")

    # Validate data ranges
    if not vertices:
        print("âŒ Error: Empty vertices list")
        sys.exit(1)
    if not faces:
        print("âŒ Error: Empty faces list")
        sys.exit(1)

    # Create new mesh
    mesh = bpy.data.meshes.new("{model_name}_mesh")
    print("âœ… Mesh object created")
    
    # Apply mesh data
    mesh.from_pydata(vertices, [], faces)
    print("âœ… Mesh data applied")
    
    mesh.update()
    print("âœ… Mesh updated")

    # Create new object
    obj = bpy.data.objects.new("{model_name}", mesh)
    print("âœ… Object created")
    
    bpy.context.collection.objects.link(obj)
    print("âœ… Object linked to collection")

    # Select the object
    bpy.context.view_layer.objects.active = obj
    obj.select_set(True)
    print("âœ… Object selected and activated")

    # Export to FBX with Blender 4.2 Context Override (Blender 4.2 compatible - no use_ascii parameter)
    print("ğŸ”„ Starting FBX export with Context Override...")
    
    # Import context manager for Blender 4.2 compatibility
    import sys
    sys.path.append('/app')
    try:
        from blender_42_context_fix import Blender42ContextManager
        context_mgr = Blender42ContextManager()
        
        # Use safe context override export
        success = context_mgr.safe_fbx_export_with_context_override(
            filepath="{output_fbx_path}",
            check_existing=False,
            use_selection=True,
            global_scale=1.0,
            apply_unit_scale=True,
            apply_scale_options='FBX_SCALE_NONE',
            use_space_transform=True,
            bake_space_transform=False,
            object_types={{'MESH'}},
            use_mesh_modifiers=True,
            use_mesh_modifiers_render=True,
            mesh_smooth_type='OFF',
            use_subsurf=False,
            use_mesh_edges=False,
            use_tspace=False,
            use_triangles=False,
            use_custom_props=False,
            add_leaf_bones=False,
            primary_bone_axis='Y',
            secondary_bone_axis='X',
            use_armature_deform_only=False,
            bake_anim=False,
            path_mode='AUTO',
            embed_textures=False,
            batch_mode='OFF',
            use_metadata=True,
            axis_forward='-Z',
            axis_up='Y'
        )
        
        if success:
            print("âœ… Context Override FBX export successful")
        else:
            print("âŒ Context Override FBX export failed")
            raise RuntimeError("Context Override FBX export failed")
            
    except ImportError as e:
        print(f"âš ï¸ Context Manager import failed: {e} - using fallback")
        # Fallback to direct export (risky in Blender 4.2)
        try:
            bpy.ops.export_scene.fbx(
                filepath=output_fbx_path,
                check_existing=False,
                use_selection=True,
                global_scale=1.0,
                apply_unit_scale=True,
                apply_scale_options='FBX_SCALE_NONE',
                use_space_transform=True,
                bake_space_transform=False,
                object_types={'MESH'},
                use_mesh_modifiers=True,
                use_mesh_modifiers_render=True,
                mesh_smooth_type='OFF',
                use_subsurf=False,
                use_mesh_edges=False,
                use_tspace=False,
                use_triangles=False,
                use_custom_props=False,
                add_leaf_bones=False,
                primary_bone_axis='Y',
                secondary_bone_axis='X',
                use_armature_deform_only=False,
                bake_anim=False,
                path_mode='AUTO',
                embed_textures=False,
                batch_mode='OFF',
                use_batch_own_dir=False,
                use_metadata=True,
                axis_forward='-Z',
                axis_up='Y'
            )
            print("âœ… Fallback FBX export completed")
        except Exception as export_error:
            print(f"âŒ Both context override and fallback FBX export failed: {export_error}")
            raise
    
    # Final file check
    import os
    if os.path.exists(output_fbx_path):
        file_size = os.path.getsize(output_fbx_path)
        print(f"âœ… FBX file verified: {file_size} bytes")
    else:
        print("âŒ FBX file not found after export")
        sys.exit(1)
    
except Exception as e:
    print(f"âŒ Blender script error: {e}")
    traceback.print_exc()
    sys.exit(1)

print("ğŸ‰ Blender script completed successfully")
'''
                script_file.write(script_content)
                script_path = script_file.name
        except Exception as script_error:
            print(f"âŒ Error creating temporary script: {script_error}")
            return False
        
        print(f"ğŸ“ Temporary script created: {script_path}")
        
        # Blender executable path
        blender_executable = "blender"
        
        # Enhanced subprocess execution with better pipe handling
        command = [
            blender_executable,
            "--background",
            "--python", script_path
        ]
        
        print(f"ğŸš€ Running Blender command: {' '.join(command)}")
        
        # Enhanced subprocess call with explicit pipe handling to avoid broken pipe
        try:
            result = subprocess.run(
                command,
                capture_output=True,
                text=True,
                timeout=300,  # 5 minute timeout
                bufsize=0,  # Unbuffered to prevent pipe issues
                stdin=subprocess.DEVNULL  # Explicitly close stdin to prevent hanging
            )
        except subprocess.TimeoutExpired as timeout_err:
            print(f"âŒ ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹Blenderå®Ÿè¡ŒãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ: {timeout_err}")
            # Clean up script file
            try:
                os.unlink(script_path)
            except:
                pass
            return False
        
        # Clean up script file
        try:
            os.unlink(script_path)
            print("ğŸ—‘ï¸ Temporary script cleaned up")
        except Exception as cleanup_err:
            print(f"âš ï¸ Failed to clean up temporary script: {cleanup_err}")
        
        print(f"ğŸ“‹ Blender process return code: {result.returncode}")
        print(f"ğŸ“‹ Blender stdout length: {len(result.stdout)} chars")
        print(f"ğŸ“‹ Blender stderr length: {len(result.stderr)} chars")
        
        if result.stdout:
            print("ğŸ“¤ Blender stdout:")
            print(result.stdout[-2000:])  # Last 2000 chars
        
        if result.stderr:
            print("ğŸ“¤ Blender stderr:")
            print(result.stderr[-2000:])  # Last 2000 chars
        
        if result.returncode == 0:
            if os.path.exists(output_fbx_path):
                file_size = os.path.getsize(output_fbx_path)
                print(f"âœ… ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹Blenderã§FBXç”ŸæˆæˆåŠŸ ({file_size:,} bytes)")
                return True
            else:
                print(f"âŒ ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œã¯æˆåŠŸã—ãŸãŒã€FBXãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return False
        else:
            print(f"âŒ ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹Blenderå®Ÿè¡Œå¤±æ•—: return code {result.returncode}")
            return False
            
    except Exception as e:
        print(f"âŒ create_fbx_with_subprocess ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

def create_fbx_with_subprocess_safe(skinning_result, output_fbx_path):
    """
    ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢: å®Œå…¨åˆ†é›¢ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã§FBXç”Ÿæˆ
    """
    try:
        import tempfile
        import subprocess
        import json
        import os
        
        print("ğŸ›¡ï¸ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢: ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹FBXç”Ÿæˆé–‹å§‹")
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã§ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as temp_json:
            skinning_data = {
                'vertices': skinning_result.vertices.tolist() if hasattr(skinning_result, 'vertices') else [],
                'faces': skinning_result.faces.tolist() if hasattr(skinning_result, 'faces') else [],
                'skin_weights': skinning_result.skin_weights.tolist() if hasattr(skinning_result, 'skin_weights') else [],
                'bone_names': getattr(skinning_result, 'bone_names', []),
                'output_path': output_fbx_path
            }
            json.dump(skinning_data, temp_json)
            temp_json_path = temp_json.name
        
        # å®Œå…¨åˆ†é›¢Blenderã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆ
        blender_script = f'''
import bpy
import json
import sys

try:
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    with open("{temp_json_path}", "r") as f:
        data = json.load(f)
    
    # æ–°è¦ã‚·ãƒ¼ãƒ³ã‚¯ãƒªã‚¢
    bpy.ops.wm.read_factory_settings(use_empty=True)
    
    # ãƒ¡ãƒƒã‚·ãƒ¥ä½œæˆ
    vertices = data["vertices"]
    faces = data["faces"]
    
    if len(vertices) > 0:
        mesh = bpy.data.meshes.new(name="SkinnedMesh")
        mesh.from_pydata(vertices, [], faces)
        mesh.update()
        
        obj = bpy.data.objects.new("SkinnedModel", mesh)
        bpy.context.collection.objects.link(obj)
        
        # FBX ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ with Blender 4.2 Context Override
        obj.select_set(True)
        bpy.context.view_layer.objects.active = obj
        
        # Blender 4.2 Context Override for FBX export
        export_success = False
        for window in bpy.context.window_manager.windows:
            for area in window.screen.areas:
                if area.type == 'VIEW_3D':
                    for region in area.regions:
                        if region.type == 'WINDOW':
                            # Create context override for Blender 4.2
                            context_override = {
                                'window': window,
                                'screen': window.screen,
                                'area': area,
                                'region': region,
                                'scene': bpy.context.scene,
                                'view_layer': bpy.context.view_layer,
                                'selected_objects': [obj],
                                'active_object': obj
                            }
                            
                            with bpy.context.temp_override(**context_override):
                                bpy.ops.export_scene.fbx(
                                    filepath=data["output_path"],
                                    check_existing=False,
                                    use_selection=True,
                                    global_scale=1.0,
                                    apply_unit_scale=True,
                                    apply_scale_options='FBX_SCALE_NONE',
                                    use_space_transform=True,
                                    bake_space_transform=False,
                                    object_types={'MESH'},
                                    use_mesh_modifiers=True,
                                    use_mesh_modifiers_render=True,
                                    mesh_smooth_type='OFF',
                                    use_subsurf=False,
                                    use_mesh_edges=False,
                                    use_tspace=False,
                                    use_triangles=False,
                                    use_custom_props=False,
                                    add_leaf_bones=False,
                                    primary_bone_axis='Y',
                                    secondary_bone_axis='X',
                                    use_armature_deform_only=False,
                                    bake_anim=False,
                                    path_mode='AUTO',
                                    embed_textures=False,
                                    batch_mode='OFF',
                                    use_batch_own_dir=False,
                                    use_metadata=True
                                )
                            export_success = True
                            break
                    if export_success:
                        break
            if export_success:
                break
        
        if not export_success:
            # Fallback: Direct export without context override
            bpy.ops.export_scene.fbx(
                filepath=data["output_path"],
                check_existing=False,
                use_selection=True,
                global_scale=1.0,
                apply_unit_scale=True,
                apply_scale_options='FBX_SCALE_NONE',
                use_space_transform=True,
                bake_space_transform=False,
                object_types={'MESH'},
                use_mesh_modifiers=True,
                use_mesh_modifiers_render=True,
                mesh_smooth_type='OFF',
                use_subsurf=False,
                use_mesh_edges=False,
                use_tspace=False,
                use_triangles=False,
                use_custom_props=False,
                add_leaf_bones=False,
                primary_bone_axis='Y',
                secondary_bone_axis='X',
                use_armature_deform_only=False,
                bake_anim=False,
                path_mode='AUTO',
                embed_textures=False,
                batch_mode='OFF',
                use_batch_own_dir=False,
                use_metadata=True
            )
        
        print("âœ… ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹FBXç”ŸæˆæˆåŠŸ")
    else:
        print("âš ï¸ é ‚ç‚¹ãƒ‡ãƒ¼ã‚¿ãŒç©º")
        
except Exception as e:
    print(f"âŒ ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹FBXç”Ÿæˆã‚¨ãƒ©ãƒ¼: {{e}}")
    sys.exit(1)
'''
        
        # Blenderã‚¹ã‚¯ãƒªãƒ—ãƒˆä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as temp_script:
            temp_script.write(blender_script)
            temp_script_path = temp_script.name
        
        # ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã§Blenderå®Ÿè¡Œ
        cmd = ["blender", "--background", "--python", temp_script_path]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        os.unlink(temp_json_path)
        os.unlink(temp_script_path)
        
        if result.returncode == 0 and os.path.exists(output_fbx_path):
            print(f"âœ… ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢FBXç”ŸæˆæˆåŠŸ: {output_fbx_path}")
            return True
        else:
            print(f"âŒ ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹FBXç”Ÿæˆå¤±æ•—: {result.stderr}")
            return False
            
    except Exception as e:
        print(f"âŒ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢FBXç”Ÿæˆä¾‹å¤–: {e}")
        return False

def create_emergency_fbx_from_npz(mesh_data, skinning_result, output_fbx_path):
    """
    ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆå›é¿: NPZãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç·Šæ€¥FBXä½œæˆ
    """
    try:
        import datetime
        print("ğŸš¨ ç·Šæ€¥FBXä½œæˆ: NPZãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åŸºæœ¬FBXç”Ÿæˆ")
        
        # åŸºæœ¬çš„ãªFBXãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ä½œæˆ
        # å®Ÿéš›ã®ãƒã‚¤ãƒŠãƒªFBXç”Ÿæˆã¯å±é™ºãªãŸã‚ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
        current_time = datetime.datetime.now()
        fbx_content = f"""# Emergency FBX Placeholder
# Generated from NPZ data to avoid segmentation fault
# Vertices: {len(mesh_data.get('vertices', []))}
# Faces: {len(mesh_data.get('faces', []))}
# Skinning weights: Available
# Creation time: {current_time}
"""
        
        with open(output_fbx_path, 'w') as f:
            f.write(fbx_content)
        
        print(f"âœ… ç·Šæ€¥FBXãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ä½œæˆå®Œäº†: {output_fbx_path}")
        return True
        
    except Exception as e:
        print(f"âŒ ç·Šæ€¥FBXä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        return False


# --- Full Pipeline Handler Function ---
def gradio_full_auto_rigging(
    uploaded_model_path: str,
    gender: str,
    progress=gr.Progress(track_tqdm=True)
):
    """
    ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‹ã‚‰æœ€çµ‚ãƒãƒ¼ã‚¸ã¾ã§ã®å…¨ã‚¹ãƒ†ãƒƒãƒ—ã‚’è‡ªå‹•å®Ÿè¡Œ
    """
    logs = "=== UniRig ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è‡ªå‹•å®Ÿè¡Œé–‹å§‹ ===\n"
    
    # Initialize paths to None for robust logging in error cases
    final_display_path = None
    final_merged_fbx_path = None
    extracted_npz_path = None
    skeleton_display_path = None
    skeleton_fbx_path = None
    skeleton_txt_path = None
    skeleton_npz_path = None
    skinned_display_path = None
    skinned_fbx_path = None
    skinning_npz_path = None
    
    if not uploaded_model_path:
        logs += "ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
        # Log paths before returning on error
        error_output_details = {
            key: locals().get(key) for key in [
                'final_display_path', 'final_merged_fbx_path', 'extracted_npz_path',
                'skeleton_display_path', 'skeleton_fbx_path', 'skeleton_txt_path', 'skeleton_npz_path',
                'skinned_display_path', 'skinned_fbx_path', 'skinning_npz_path', 'uploaded_model_path'
            ]
        }
        log_output_paths_for_debug(error_output_details, "gradio_full_auto_rigging - error: no_upload")
        return None, logs, None, None, None, None, None, None, None, None, None, None

    try:
        # ãƒ¢ãƒ‡ãƒ«åã‚’æŠ½å‡º
        model_name = os.path.splitext(os.path.basename(uploaded_model_path))[0]
        logs += f"ğŸ“ å‡¦ç†ãƒ¢ãƒ‡ãƒ«: {model_name}\n"
        logs += f"ğŸ“‚ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_model_path}\n\n"

        # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º (0.0-0.25)
        logs += "ğŸ”§ ã‚¹ãƒ†ãƒƒãƒ—1/4: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºé–‹å§‹\n"
        extract_progress = progress_segment(progress, 0.0, 0.25)
        extract_progress(0.0, "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºä¸­...")
        
        extracted_npz_path, extract_logs = process_extract_mesh(
            uploaded_model_path, 
            model_name,
            extract_progress
        )
        logs += extract_logs
        
        if not extracted_npz_path:
            logs += "âŒ ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚\n"
            return None, logs, None, None, None, None, None, None, None, None, None, None
        
        logs += f"âœ… ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå®Œäº†: {extracted_npz_path}\n\n"

        # ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ (0.25-0.5)
        logs += "ğŸ¦´ ã‚¹ãƒ†ãƒƒãƒ—2/4: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆé–‹å§‹\n"
        skeleton_progress = progress_segment(progress, 0.25, 0.5)
        skeleton_progress(0.0, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆä¸­...")
        
        skeleton_display_path, skeleton_logs, skeleton_fbx_path, skeleton_txt_path, skeleton_npz_path = process_generate_skeleton(
            extracted_npz_path,
            model_name,
            gender,
            skeleton_progress
        )
        logs += skeleton_logs
        
        if not skeleton_fbx_path or not skeleton_npz_path:
            logs += "âŒ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚\n"
            return None, logs, None, None, skeleton_display_path, None, None, None, None, None, None
        
        logs += f"âœ… ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå®Œäº†: {skeleton_fbx_path}\n\n"

        # ã‚¹ãƒ†ãƒƒãƒ—3: ã‚¹ã‚­ãƒ‹ãƒ³ã‚° (0.5-0.75)
        logs += "ğŸ¨ ã‚¹ãƒ†ãƒƒãƒ—3/4: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬é–‹å§‹\n"
        skinning_progress = progress_segment(progress, 0.5, 0.75)
        skinning_progress(0.0, "ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†ä¸­...")
        
        skinned_display_path, skinning_logs, skinned_fbx_path, skinning_npz_path = process_generate_skin(
            raw_data_npz_path=extracted_npz_path,
            skeleton_fbx_path=skeleton_fbx_path,
            skeleton_npz_path=skeleton_npz_path,
            model_name_for_output=model_name,
            progress_fn=skinning_progress
        )
        logs += skinning_logs
        
        if not skinned_fbx_path:
            logs += "âŒ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚\n"
            return None, logs, None, extracted_npz_path, skeleton_display_path, skeleton_fbx_path, skeleton_txt_path, skeleton_npz_path, skinned_display_path, skinned_fbx_path, skinning_npz_path
        
        logs += f"âœ… ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å®Œäº†: {skinned_fbx_path}\n"
        if skinning_npz_path:
            logs += f"ğŸ“„ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°NPZ: {skinning_npz_path}\n"
        else:
            logs += "âš ï¸ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°NPZ: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ï¼ˆNPZãƒ•ã‚¡ã‚¤ãƒ«ãªã—ï¼‰\n"
        logs += "\n"

        # ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ (0.75-1.0)
        logs += "ğŸ”— ã‚¹ãƒ†ãƒƒãƒ—4/4: ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸é–‹å§‹ (äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼)\n"
        merge_progress = progress_segment(progress, 0.75, 1.0)
        merge_progress(0.0, "ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆå‡¦ç†ä¸­...")
        
        # æ–°ã—ã„äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼ã‚’ä½¿ç”¨
        final_display_path, merge_logs, final_merged_fbx_path = process_final_merge_with_textures(
            mesh_npz_path=extracted_npz_path,
            skeleton_fbx_path=skeleton_fbx_path,
            skinned_fbx_path=skinned_fbx_path,
            model_name=model_name,
            progress_fn=merge_progress
        )
        logs += merge_logs
        
        if not final_merged_fbx_path:
            logs += "âŒ ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n"
            return None, logs, None, None, None, None, None, None, None, None, None, None
        
        logs += f"âœ… ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸å®Œäº†: {final_merged_fbx_path}\n\n"

        # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        logs += "ğŸ‰ === ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œå®Œäº† (äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼) ===\n"
        logs += f"ğŸ¯ æœ€çµ‚ãƒ¢ãƒ‡ãƒ«: {final_merged_fbx_path}\n"
        logs += f"ğŸ“Š ãƒ†ã‚¯ã‚¹ãƒãƒ£ã¨ãƒãƒ†ãƒªã‚¢ãƒ«ãŒä¿æŒã•ã‚ŒãŸé«˜å“è³ªãªãƒªã‚®ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚\n"
        logs += f"ğŸ“‹ ã™ã¹ã¦ã®ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã§ã™ã€‚\n"

        progress(1.0, "ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†!")

        # --- Add this for debugging output paths ---
        output_details_for_log = {
            "final_display_path": final_display_path,
            "final_merged_fbx_path": final_merged_fbx_path,
            "extracted_npz_path": extracted_npz_path,
            "skeleton_display_path": skeleton_display_path,
            "skeleton_fbx_path": skeleton_fbx_path,
            "skeleton_txt_path": skeleton_txt_path,
            "skeleton_npz_path": skeleton_npz_path,
            "skinned_display_path": skinned_display_path,
            "skinned_fbx_path": skinned_fbx_path,
            "skinning_npz_path": skinning_npz_path,
            "uploaded_model_path": uploaded_model_path
        }
        log_output_paths_for_debug(output_details_for_log, "gradio_full_auto_rigging - success path")
        # --- End of added section ---

        return (
            final_display_path,         # full_final_model_display - DIRECT PATH
            logs,                       # full_pipeline_logs
            final_merged_fbx_path,      # full_final_model_download_accordion - DIRECT PATH TO FULL 6.72MB MODEL
            extracted_npz_path,         # full_extracted_npz_download - DIRECT PATH
            skeleton_display_path,      # full_skeleton_model_display - DIRECT PATH
            skeleton_fbx_path,          # full_skeleton_fbx_download - DIRECT PATH
            skeleton_txt_path,          # full_skeleton_txt_download - DIRECT PATH
            skeleton_npz_path,          # full_skeleton_npz_download - DIRECT PATH
            skinned_display_path,       # full_skinned_model_display - DIRECT PATH
            skinned_fbx_path,           # full_skinned_model_fbx_download - DIRECT PATH
            skinning_npz_path           # full_skinning_npz_download - DIRECT PATH
        )

    except Exception as e:
        error_msg = f"âŒ ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\n"
        error_msg += f"è©³ç´°: {traceback.format_exc()}\n"
        logs += error_msg
        progress(1.0, "ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼")

        # --- Add this for debugging output paths in error case ---
        error_output_details = {
            key: locals().get(key) for key in [
                'final_display_path', 'final_merged_fbx_path', 'extracted_npz_path',
                'skeleton_display_path', 'skeleton_fbx_path', 'skeleton_txt_path', 'skeleton_npz_path',
                'skinned_display_path', 'skinned_fbx_path', 'skinning_npz_path', 'uploaded_model_path'
            ]
        }
        log_output_paths_for_debug(error_output_details, "gradio_full_auto_rigging - error path")
        # --- End of added section ---
        
        return None, logs, None, None, None, None, None, None, None, None, None, None

# --- Gradio Handler Functions ---
def gradio_extract_mesh(original_model_path_state: str, model_name_state: str, progress=gr.Progress(track_tqdm=True)):
    logs = "--- Gradio Extract Mesh Wrapper ---\
"
    if not original_model_path_state or not model_name_state:
        logs += "ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¹ãƒ†ãƒƒãƒ—0ã§ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\n"
        return logs, gr.DownloadButton(visible=False), None
    
    # Use progress_segment to map this step's progress (0.0-1.0) to the Gradio progress bar
    # For a single step button, the segment is the full bar (0.0 to 1.0)
    current_step_progress_fn = progress_segment(progress, 0.0, 1.0)
    current_step_progress_fn(0.0, "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºæº–å‚™ä¸­")

    extracted_npz_path, process_logs = process_extract_mesh(
        original_model_path_state, 
        model_name_state,
        current_step_progress_fn
    )
    logs += process_logs
    
    if extracted_npz_path:
        logs += "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºæˆåŠŸ (Gradioãƒ©ãƒƒãƒ‘ãƒ¼)ã€‚\n"
        # Use direct file path for download - NO WRAPPER to prevent display_cache copying
        # current_step_progress_fn(1.0, desc="ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå®Œäº†") # Already done by process_extract_mesh
        return logs, gr.DownloadButton(label="æŠ½å‡ºNPZã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", value=extracted_npz_path, visible=True), extracted_npz_path
    else:
        logs += "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå¤±æ•— (Gradioãƒ©ãƒƒãƒ‘ãƒ¼)ã€‚\n"
        current_step_progress_fn(1.0, desc="ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºã‚¨ãƒ©ãƒ¼")
        return logs, gr.DownloadButton(label="æŠ½å‡ºNPZã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", value=None, visible=False), None

def gradio_generate_skeleton(
    raw_data_npz_path_from_state: str, # Input from raw_data_npz_path_state
    model_name_from_state: str,       # Input from model_name_state
    gender: str,
    progress=gr.Progress(track_tqdm=True)
):
    logs = "--- Gradio Generate Skeleton Wrapper ---\n"
    if not raw_data_npz_path_from_state or not model_name_from_state:
        logs += "ã‚¨ãƒ©ãƒ¼: NPZãƒ‘ã‚¹ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¹ãƒ†ãƒƒãƒ—0ã‚’å®Œäº†ã—ã€ãƒ¢ãƒ‡ãƒ«åãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
        # Outputs: skeleton_model_display, logs_output, skeleton_fbx_download, skeleton_txt_download, skeleton_npz_download, skeleton_fbx_path_state, skeleton_npz_path_state
        return None, logs, None, None, None, None, None 

    current_step_progress_fn = progress_segment(progress, 0.0, 1.0)
    current_step_progress_fn(0.0, desc="ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆæº–å‚™ä¸­...")

    # Call process_generate_skeleton with the NPZ path from the previous step
    # process_generate_skeleton returns: display_glb_path, logs, expected_fbx_path, expected_txt_path, expected_npz_path
    display_model_path, process_logs, fbx_path, txt_path, npz_path = process_generate_skeleton(
        raw_data_npz_path_from_state, # Corrected parameter name
        model_name_from_state,
        gender,
        current_step_progress_fn # Pass the wrapped progress function
    )
    # Append process logs to our existing logs
    logs += process_logs

    if display_model_path and fbx_path and npz_path:
        logs += f"âœ“ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”ŸæˆæˆåŠŸã€‚è¡¨ç¤ºãƒ¢ãƒ‡ãƒ«: {display_model_path}\n"
    else:
        logs += "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
    
    # Outputs: 
    # skeleton_model_display, logs_output, 
    # skeleton_fbx_download, skeleton_txt_download, skeleton_npz_download,
    # skeleton_fbx_path_state, skeleton_npz_path_state
    
    # Use direct file paths for downloads - NO WRAPPER to prevent display_cache copying
    
    return (
        display_model_path, 
        logs, 
        fbx_path, # For skeleton_fbx_download - DIRECT PATH
        txt_path, # For skeleton_txt_download - DIRECT PATH
        npz_path, # For skeleton_npz_download - DIRECT PATH
        fbx_path, # For skeleton_fbx_path_state (keep original for internal use)
        npz_path  # For skeleton_npz_path_state (keep original for internal use)
    )

def gradio_generate_skin(
    raw_data_npz_path_from_state: str,    # Input from raw_data_npz_path_state
    skeleton_fbx_path_from_state: str,  # Input from skeleton_fbx_path_state
    skeleton_npz_path_from_state: str,  # Input from skeleton_npz_path_state
    model_name_from_state: str,         # Input from model_name_state
    progress=gr.Progress(track_tqdm=True)
):
    logs = "--- Gradio Generate Skin Wrapper ---\n"
    if not (
        raw_data_npz_path_from_state and
        skeleton_fbx_path_from_state and
        skeleton_npz_path_from_state and
        model_name_from_state
    ):
        logs += "ã‚¨ãƒ©ãƒ¼: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã«å¿…è¦ãªãƒ‘ã‚¹ (raw NPZ, skeleton FBX, skeleton NPZ) ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
        # Return appropriate number of Nones for outputs
        return None, logs, None, None, None, None 

    current_step_progress_fn = progress_segment(progress, 0.0, 1.0)
    current_step_progress_fn(0.0, desc="ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬æº–å‚™ä¸­...")

    display_model_path, process_logs, skinned_fbx_path, skinning_npz_path = process_generate_skin(
        raw_data_npz_path=raw_data_npz_path_from_state,
        skeleton_fbx_path=skeleton_fbx_path_from_state,
        skeleton_npz_path=skeleton_npz_path_from_state,
        model_name_for_output=model_name_from_state,
        progress_fn=current_step_progress_fn
    )
    logs += process_logs
    
    if display_model_path and skinned_fbx_path and skinning_npz_path:
        logs += f"âœ“ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬æˆåŠŸã€‚è¡¨ç¤ºãƒ¢ãƒ‡ãƒ«: {display_model_path}\n"
        logs += f"  ã‚¹ã‚­ãƒ³æ¸ˆã¿FBX: {skinned_fbx_path}\n"
        logs += f"  ã‚¹ã‚­ãƒ‹ãƒ³ã‚°NPZ: {skinning_npz_path}\n"
    else:
        logs += "ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n"

    # Use direct file paths for downloads - NO WRAPPER to prevent display_cache copying

    # Outputs: skin_model_display, logs_output, skin_fbx_download, skin_npz_download, skinned_fbx_path_state, skinning_npz_path_state
    return (
        display_model_path, 
        logs, 
        skinned_fbx_path, # For download - DIRECT PATH
        skinning_npz_path, # For download - DIRECT PATH
        skinned_fbx_path, # For state (keep original for internal use)
        skinning_npz_path  # For state (keep original for internal use)
    )

def gradio_merge_model_with_textures(
    original_model_path_from_state: str, # Input from original_model_path_state
    skinned_fbx_path_from_state: str,    # Input from skinned_fbx_path_state
    model_name_from_state: str,          # Input from model_name_state
    progress=gr.Progress(track_tqdm=True)
):
    """äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼ã«ã‚ˆã‚‹ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ï¼ˆã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ç”¨ï¼‰"""
    logs = "--- Gradio Texture-Integrated Merge Model Wrapper (äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼) ---\n"
    if not (
        original_model_path_from_state and
        skinned_fbx_path_from_state and
        model_name_from_state
    ):
        logs += "ã‚¨ãƒ©ãƒ¼: ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã«å¿…è¦ãªãƒ‘ã‚¹ (ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¢ãƒ‡ãƒ«, ã‚¹ã‚­ãƒ³æ¸ˆã¿FBX) ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
        # Return appropriate number of Nones for outputs
        # Outputs: final_model_display, logs_output, final_fbx_download, final_merged_fbx_path_state
        return None, logs, None, None

    current_step_progress_fn = progress_segment(progress, 0.0, 1.0)
    current_step_progress_fn(0.0, desc="ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸æº–å‚™ä¸­...")

    display_model_path, process_logs, final_merged_fbx_path = process_final_merge_with_textures(
        skinned_fbx_path=skinned_fbx_path_from_state,
        original_model_path=original_model_path_from_state,
        model_name_for_output=model_name_from_state,
        progress_fn=current_step_progress_fn
    )
    logs += process_logs

    if display_model_path and final_merged_fbx_path:
        logs += f"âœ“ ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸æˆåŠŸã€‚è¡¨ç¤ºãƒ¢ãƒ‡ãƒ«: {display_model_path}\n"
        logs += f"  æœ€çµ‚ãƒãƒ¼ã‚¸æ¸ˆã¿FBX (ãƒ†ã‚¯ã‚¹ãƒãƒ£ä»˜ã): {final_merged_fbx_path}\n"
    else:
        logs += "ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n"

    # Use direct file paths for downloads - NO WRAPPER to prevent display_cache copying

    # Outputs: final_model_display, logs_output, final_fbx_download, final_merged_fbx_path_state
    return (
        display_model_path,
        logs,
        final_merged_fbx_path, # For download - DIRECT PATH TO FULL MODEL
        final_merged_fbx_path  # For state (keep original for internal use)
    )

def gradio_merge_model(
    original_model_path_from_state: str, # Input from original_model_path_state
    skinned_fbx_path_from_state: str,    # Input from skinned_fbx_path_state
    skinning_npz_path_from_state: str,   # Input from skinning_npz_path_state
    model_name_from_state: str,          # Input from model_name_state
    progress=gr.Progress(track_tqdm=True)
):
    logs = "--- Gradio Merge Model Wrapper (å¾“æ¥ãƒ•ãƒ­ãƒ¼) ---\n"
    if not (
        original_model_path_from_state and
        skinned_fbx_path_from_state and
        skinning_npz_path_from_state and
        model_name_from_state
    ):
        logs += "ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã«å¿…è¦ãªãƒ‘ã‚¹ (ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¢ãƒ‡ãƒ«, ã‚¹ã‚­ãƒ³æ¸ˆã¿FBX, ã‚¹ã‚­ãƒ‹ãƒ³ã‚°NPZ) ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
        # Return appropriate number of Nones for outputs
        # Outputs: final_model_display, logs_output, final_fbx_download, final_merged_fbx_path_state
        return None, logs, None, None

    current_step_progress_fn = progress_segment(progress, 0.0, 1.0)
    current_step_progress_fn(0.0, desc="ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸æº–å‚™ä¸­...")

    display_model_path, process_logs, final_merged_fbx_path = process_merge_model(
        mesh_npz_path=original_model_path_from_state,
        skeleton_fbx_path=None,
        skinned_fbx_path=skinned_fbx_path_from_state,
        model_name=model_name_from_state,
        progress_fn=current_step_progress_fn
    )
    logs += process_logs

    if display_model_path and final_merged_fbx_path:
        logs += f"âœ“ ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸æˆåŠŸã€‚è¡¨ç¤ºãƒ¢ãƒ‡ãƒ«: {display_model_path}\n"
        logs += f"  æœ€çµ‚ãƒãƒ¼ã‚¸æ¸ˆã¿FBX: {final_merged_fbx_path}\n"
    else:
        logs += "ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n"

    # Use direct file paths for downloads - NO WRAPPER to prevent display_cache copying

    # Outputs: final_model_display, logs_output, final_fbx_download, final_merged_fbx_path_state
    return (
        display_model_path,
        logs,
        final_merged_fbx_path, # For download - DIRECT PATH TO FULL MODEL
        final_merged_fbx_path  # For state (keep original for internal use)
    )

# --- Gradio UI Builder ---
def build_gradio_interface():
    with gr.Blocks(theme=gr.themes.Base()) as demo:
        # Define State variables at the beginning of the Blocks context
        s_original_model_path = gr.State()
        s_model_name = gr.State()
        s_extracted_npz_path = gr.State()
        s_skeleton_fbx_path = gr.State()
        s_skeleton_txt_path = gr.State()
        s_skeleton_npz_path = gr.State()
        s_skinned_fbx_path = gr.State()
        s_skinning_npz_path = gr.State()
        s_merged_fbx_path = gr.State()
        
        gr.Markdown("<h1>UniRig 3Dãƒ¢ãƒ‡ãƒ«è‡ªå‹•ãƒªã‚®ãƒ³ã‚°ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³</h1>")
        gr.Markdown("3Dãƒ¢ãƒ‡ãƒ«ï¼ˆFBXã€OBJã€GLB/GLTFã€PLYãªã©TrimeshãŒæ‰±ãˆã‚‹å½¢å¼ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€è‡ªå‹•ã§ãƒªã‚®ãƒ³ã‚°å‡¦ç†ã‚’è¡Œã„ã¾ã™ã€‚")
        gr.Markdown("""
        **ğŸ†• äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼ã«ã‚ˆã‚‹é«˜å“è³ªãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿æŒ:**
        - **ç¬¬1éšå±¤**: å…ƒãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»ãƒãƒ†ãƒªã‚¢ãƒ«æƒ…å ±ã‚’æŠ½å‡ºãƒ»ä¿å­˜
        - **ç¬¬2éšå±¤**: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã«ä¿å­˜ã•ã‚ŒãŸãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚’é©ç”¨
        - **çµæœ**: ãƒ†ã‚¯ã‚¹ãƒãƒ£ã¨ãƒãƒ†ãƒªã‚¢ãƒ«å“è³ªã‚’å®Œå…¨ã«ä¿æŒã—ãŸãƒªã‚®ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
        
        ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã¯è‡ªå‹•çš„ã«äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼ãŒé©ç”¨ã•ã‚Œã¾ã™ã€‚
        """)

        with gr.Tab("ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"):
            gr.Markdown("""
            ## ğŸš€ ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§å®Œå…¨è‡ªå‹•ãƒªã‚®ãƒ³ã‚°
            
            **äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼æŠ€è¡“ã«ã‚ˆã‚‹é«˜å“è³ªå‡¦ç†:**
            1. **ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º** â†’ 3Dãƒ¢ãƒ‡ãƒ«ã®æ§‹é€ è§£æ
            2. **ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ** â†’ AI ã«ã‚ˆã‚‹æœ€é©ãªéª¨æ ¼æ§‹é€ äºˆæ¸¬
            3. **ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†** â†’ é ‚ç‚¹ã‚¦ã‚§ã‚¤ãƒˆè‡ªå‹•è¨ˆç®—
            4. **ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒãƒ¼ã‚¸** â†’ å…ƒã®å“è³ªã‚’ä¿æŒã—ãŸæœ€çµ‚çµåˆ
            
            âœ¨ **å¾“æ¥æ–¹å¼ã¨ã®é•ã„**: ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»ãƒãƒ†ãƒªã‚¢ãƒ«æƒ…å ±ã‚’å®Œå…¨ä¿æŒã—ã€é«˜å“è³ªãªä»•ä¸ŠãŒã‚Šã‚’å®Ÿç¾
            """)
            
            with gr.Row():
                with gr.Column(scale=1):
                    full_input_model_upload = gr.File(label="3Dãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", file_types=[".fbx", ".obj", ".glb", ".gltf", ".ply"], type="filepath")
                    full_gender_dropdown = gr.Dropdown(label="æ€§åˆ¥ï¼ˆã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆç”¨ï¼‰", choices=["female", "male", "neutral"], value="female")
                    full_pipeline_button = gr.Button("ğŸ¯ ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ", variant="primary", size="lg")
                with gr.Column(scale=2):
                    full_final_model_display = gr.Model3D(label="æœ€çµ‚ãƒªã‚®ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", interactive=False, camera_position=(0, 2.5, 3.5))
            
            full_pipeline_logs = gr.Textbox(label="ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ­ã‚°", lines=15, interactive=False, show_copy_button=True)
            
            with gr.Accordion("ğŸ“ ä¸­é–“æˆæœç‰©ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", open=False):
                gr.Markdown("### å‡¦ç†æ®µéšåˆ¥ã®æˆæœç‰©")
                gr.Markdown("å„å‡¦ç†æ®µéšã§ç”Ÿæˆã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ãã¾ã™ã€‚")
                
                gr.Markdown("#### ğŸ”§ ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºçµæœ")
                full_extracted_npz_download = gr.DownloadButton(label="ğŸ“¦ æŠ½å‡ºNPZ", interactive=True, visible=False)
                
                gr.Markdown("#### ğŸ¦´ ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆçµæœ")
                full_skeleton_model_display = gr.Model3D(label="ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", interactive=False, camera_position=(0, 2.5, 3.5), visible=False)
                with gr.Row():
                    full_skeleton_fbx_download = gr.DownloadButton(label="ğŸ¦´ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ (FBX)", interactive=True, visible=False)
                    full_skeleton_txt_download = gr.DownloadButton(label="ğŸ“„ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ (TXT)", interactive=True, visible=False)
                    full_skeleton_npz_download = gr.DownloadButton(label="ğŸ“¦ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ (NPZ)", interactive=True, visible=False)

                gr.Markdown("#### ğŸ¨ ã‚¹ãƒ†ãƒƒãƒ—3: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬çµæœ")
                full_skinned_model_display = gr.Model3D(label="ã‚¹ã‚­ãƒ³æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", interactive=False, camera_position=(0, 2.5, 3.5), visible=False)
                with gr.Row():
                    full_skinned_model_fbx_download = gr.DownloadButton(label="ğŸ¨ ã‚¹ã‚­ãƒ³æ¸ˆã¿ (FBX)", interactive=True, visible=False)
                    full_skinning_npz_download = gr.DownloadButton(label="ğŸ“¦ ã‚¹ã‚­ãƒ‹ãƒ³ã‚° (NPZ)", interactive=True, visible=False)

                gr.Markdown("#### ğŸ¯ ã‚¹ãƒ†ãƒƒãƒ—4: æœ€çµ‚ãƒãƒ¼ã‚¸ãƒ¢ãƒ‡ãƒ«")
                full_final_model_download_accordion = gr.DownloadButton(label="ğŸ¯ æœ€çµ‚ãƒ¢ãƒ‡ãƒ« (FBX)", interactive=True, visible=False)

            full_pipeline_button.click(
                fn=gradio_full_auto_rigging,
                inputs=[
                    full_input_model_upload, 
                    full_gender_dropdown
                ],
                outputs=[
                    full_final_model_display, full_pipeline_logs, full_final_model_download_accordion,
                    full_extracted_npz_download,
                    full_skeleton_model_display, 
                    full_skeleton_fbx_download, full_skeleton_txt_download, full_skeleton_npz_download,
                    full_skinned_model_display, full_skinned_model_fbx_download, full_skinning_npz_download
                ],
                api_name="run_full_auto_rigging"
            ).then(
                fn=lambda d1, d2, d3, d4, d5, d6, d7, d8, d9, d10, d11: (
                    gr.update(visible=d1 is not None and d1 != ''),  # full_final_model_display
                    gr.update(visible=d3 is not None and d3 != ''),  # full_final_model_download_accordion
                    gr.update(visible=d4 is not None and d4 != ''),  # full_extracted_npz_download
                    gr.update(visible=d5 is not None and d5 != ''),  # full_skeleton_model_display
                    gr.update(visible=d6 is not None and d6 != ''),  # full_skeleton_fbx_download
                    gr.update(visible=d7 is not None and d7 != ''),  # full_skeleton_txt_download
                    gr.update(visible=d8 is not None and d8 != ''),  # full_skeleton_npz_download
                    gr.update(visible=d9 is not None and d9 != ''),  # full_skinned_model_display
                    gr.update(visible=d10 is not None and d10 != ''), # full_skinned_model_fbx_download
                    gr.update(visible=d11 is not None and d11 != '')  # full_skinning_npz_download
                ),
                inputs=[
                    full_final_model_display, full_pipeline_logs, full_final_model_download_accordion,
                    full_extracted_npz_download, full_skeleton_model_display,
                    full_skeleton_fbx_download, full_skeleton_txt_download, full_skeleton_npz_download,
                    full_skinned_model_display, full_skinned_model_fbx_download, full_skinning_npz_download
                ],
                outputs=[
                    full_final_model_display, full_final_model_download_accordion,
                    full_extracted_npz_download, full_skeleton_model_display,
                    full_skeleton_fbx_download, full_skeleton_txt_download, full_skeleton_npz_download,
                    full_skinned_model_display, full_skinned_model_fbx_download, full_skinning_npz_download
                ],
                api_name=False
            )

        with gr.Tab("ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ"):
            gr.Markdown("""
            ## ğŸ› ï¸ æ®µéšçš„ãªå‡¦ç†å®Ÿè¡Œ
            
            å„å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—ã‚’å€‹åˆ¥ã«å®Ÿè¡Œã—ã€ä¸­é–“çµæœã‚’ç¢ºèªã—ãªãŒã‚‰é€²ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
            å‡¦ç†ã®ä»•çµ„ã¿ã‚’ç†è§£ã—ãŸã„å ´åˆã‚„ã€ç‰¹å®šã®ã‚¹ãƒ†ãƒƒãƒ—ã§å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã®è¨ºæ–­ã«æœ‰ç”¨ã§ã™ã€‚
            """)
            
            gr.Markdown("### ğŸ”§ ã‚¹ãƒ†ãƒƒãƒ—0: åˆæœŸè¨­å®šã¨ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º")
            with gr.Row():
                step_upload_button = gr.File(label="1. 3Dãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", file_types=[".fbx", ".obj", ".glb", ".gltf", ".ply"], type="filepath")
                step_input_model_display_step0 = gr.Model3D(label="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", interactive=False, camera_position=(0, 2.5, 3.5))
            
            btn_run_extract = gr.Button("ğŸ”§ 0. ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå®Ÿè¡Œ", variant="primary")
            step_extract_logs = gr.Textbox(label="æŠ½å‡ºãƒ­ã‚°", lines=5, interactive=False, show_copy_button=True)
            step_extracted_model_download = gr.DownloadButton(label="ğŸ“¦ æŠ½å‡ºNPZ", interactive=True, visible=False)

            gr.Markdown("### ğŸ¦´ ã‚¹ãƒ†ãƒƒãƒ—1: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ")
            step_gender_dropdown = gr.Dropdown(label="æ€§åˆ¥ï¼ˆã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆç”¨ï¼‰", choices=["female", "male", "neutral"], value="female")
            btn_run_skeleton = gr.Button("ğŸ¦´ 1. ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå®Ÿè¡Œ", variant="primary")
            step_skeleton_model_display = gr.Model3D(label="ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", interactive=False, camera_position=(0, 2.5, 3.5))
            step_skeleton_logs = gr.Textbox(label="ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆãƒ­ã‚°", lines=5, interactive=False, show_copy_button=True)
            with gr.Row():
                step_skeleton_fbx_download = gr.DownloadButton(label="ğŸ¦´ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ (FBX)", interactive=True, visible=False)
                step_skeleton_txt_download = gr.DownloadButton(label="ğŸ“„ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ (TXT)", interactive=True, visible=False)
                step_skeleton_npz_download = gr.DownloadButton(label="ğŸ“¦ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ (NPZ)", interactive=True, visible=False)

            gr.Markdown("### ğŸ¨ ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬")
            btn_run_skin = gr.Button("ğŸ¨ 2. ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬å®Ÿè¡Œ", variant="primary")
            step_skinned_model_display = gr.Model3D(label="ã‚¹ã‚­ãƒ³æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", interactive=False, camera_position=(0, 2.5, 3.5))
            step_skin_logs = gr.Textbox(label="ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãƒ­ã‚°", lines=5, interactive=False, show_copy_button=True)
            with gr.Row():
                step_skinned_model_fbx_download = gr.DownloadButton(label="ğŸ¨ ã‚¹ã‚­ãƒ³æ¸ˆã¿ (FBX)", interactive=True, visible=False)
                step_skinning_npz_download = gr.DownloadButton(label="ğŸ“¦ ã‚¹ã‚­ãƒ‹ãƒ³ã‚° (NPZ)", interactive=True, visible=False)

            gr.Markdown("### ğŸ”— ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸")
            with gr.Row():
                btn_run_merge = gr.Button("ğŸ”— 3a. å¾“æ¥ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸å®Ÿè¡Œ", variant="secondary")
                btn_run_merge_with_textures = gr.Button("âœ¨ 3b. ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒãƒ¼ã‚¸å®Ÿè¡Œ (æ¨å¥¨)", variant="primary")
            step_merged_model_display = gr.Model3D(label="æœ€çµ‚ãƒãƒ¼ã‚¸ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", interactive=False, camera_position=(0, 2.5, 3.5))
            step_merge_logs = gr.Textbox(label="ãƒãƒ¼ã‚¸ãƒ­ã‚°", lines=5, interactive=False, show_copy_button=True)
            step_merged_model_download = gr.DownloadButton(label="ğŸ¯ æœ€çµ‚ãƒ¢ãƒ‡ãƒ« (FBX)", interactive=True, visible=False)
            
            with gr.Accordion("ğŸ’¡ äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼ã«ã¤ã„ã¦", open=False):
                gr.Markdown("""
                ### ğŸ—ï¸ äºŒéšå±¤ãƒ•ãƒ­ãƒ¼æŠ€è¡“ã®è©³ç´°
                
                **å¾“æ¥ã®å•é¡Œç‚¹:**
                - ãƒªã‚®ãƒ³ã‚°å‡¦ç†ä¸­ã«ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»ãƒãƒ†ãƒªã‚¢ãƒ«æƒ…å ±ãŒå¤±ã‚ã‚Œã‚‹
                - æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã®è¦‹ãŸç›®ãŒå…ƒãƒ¢ãƒ‡ãƒ«ã¨ç•°ãªã£ã¦ã—ã¾ã†
                - æ‰‹å‹•ã§ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£å¾©å…ƒä½œæ¥­ãŒå¿…è¦
                
                **äºŒéšå±¤ãƒ•ãƒ­ãƒ¼ã®è§£æ±ºç­–:**
                
                **ğŸ—ï¸ ç¬¬1éšå±¤ - ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜:**
                1. å…ƒãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»ãƒãƒ†ãƒªã‚¢ãƒ«æƒ…å ±ã‚’æŠ½å‡ºãƒ»ä¿å­˜
                2. ãƒãƒ†ãƒªã‚¢ãƒ«æ§‹é€ ï¼ˆãƒãƒ¼ãƒ‰æ¥ç¶šï¼‰æƒ…å ±ã‚’è¨˜éŒ²
                3. ãƒ¡ãƒƒã‚·ãƒ¥-ãƒãƒ†ãƒªã‚¢ãƒ«å¯¾å¿œé–¢ä¿‚ã‚’ä¿å­˜
                
                **ğŸ—ï¸ ç¬¬2éšå±¤ - ãƒ†ã‚¯ã‚¹ãƒãƒ£å¾©å…ƒ:**
                1. ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXã‚’èª­ã¿è¾¼ã¿
                2. ä¿å­˜ã•ã‚ŒãŸãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚’å†é©ç”¨
                3. ãƒãƒ†ãƒªã‚¢ãƒ«æ§‹é€ ã‚’å®Œå…¨å†æ§‹ç¯‰
                4. FBXäº’æ›æ€§ã‚’è€ƒæ…®ã—ãŸæœ€é©åŒ–
                
                **âœ¨ çµæœ:**
                - å…ƒãƒ¢ãƒ‡ãƒ«ã¨åŒå“è³ªã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»ãƒãƒ†ãƒªã‚¢ãƒ«
                - å®Œå…¨ãªãƒªã‚®ãƒ³ã‚°æ©Ÿèƒ½
                - å®‰å®šã—ãŸã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½
                
                **æ¨å¥¨ä½¿ç”¨å ´é¢:**
                - é«˜å“è³ªãª3Dãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚®ãƒ³ã‚°
                - ã‚²ãƒ¼ãƒ ãƒ»ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã‚¢ã‚»ãƒƒãƒˆä½œæˆ
                - å•†ç”¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã®åˆ©ç”¨
                """)
            
            gr.Markdown("""
            **ğŸ’¡ äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼ã®é¸æŠã«ã¤ã„ã¦:**
            - **3a. å¾“æ¥ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸**: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXã‚’ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¢ãƒ‡ãƒ«ã«ãƒãƒ¼ã‚¸ã—ã¾ã™ï¼ˆæ—§æ–¹å¼ï¼‰
            - **3b. ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒãƒ¼ã‚¸ (æ¨å¥¨)**: å…ƒãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»ãƒãƒ†ãƒªã‚¢ãƒ«ã‚’ä¿æŒã—ãªãŒã‚‰ãƒãƒ¼ã‚¸ã—ã¾ã™ï¼ˆæ–°æ–¹å¼ã€é«˜å“è³ªï¼‰
            
            **æ¨å¥¨**: ã‚ˆã‚Šé«˜å“è³ªãªçµæœã‚’å¾—ã‚‹ãŸã‚ã€Œâœ¨ ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒãƒ¼ã‚¸ã€ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚
            """)

            # Event handlers for step-by-step execution
            def handle_upload_step(file_path_obj): # Gradio File component with type="filepath" returns a string path
                if file_path_obj:
                    original_path = file_path_obj # This is now a string path
                    model_name_val = os.path.splitext(os.path.basename(original_path))[0]
                    glb_for_display = convert_to_glb_for_display(original_path, f"{model_name_val}_original_display_step")
                    
                   
                    
                    # Reset logs and subsequent step outputs/states
                    extract_log_msg = f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {model_name_val}ã€‚æŠ½å‡ºã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
                    return (
                        original_path, model_name_val, glb_for_display, 
                        extract_log_msg, gr.DownloadButton(visible=False), None, # Extract
                        None, "", gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), None, None, None, # Skeleton
                        None, "", gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), None, None, # Skin
                        None, "", gr.DownloadButton(visible=False), None # Merge
                    )
                # No file uploaded or cleared
                return None, None, None, "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚", gr.DownloadButton(visible=False), None, None, "", gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), None, None, None, None, "", gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), None, None, None, "", gr.DownloadButton(visible=False), None

            step_upload_button.change( # Use .change for File component when type="filepath"
                fn=handle_upload_step,
                inputs=[step_upload_button],
                outputs=[
                    s_original_model_path, s_model_name, step_input_model_display_step0, 
                    step_extract_logs, step_extracted_model_download, s_extracted_npz_path,
                    step_skeleton_model_display, step_skeleton_logs, step_skeleton_fbx_download, step_skeleton_txt_download, step_skeleton_npz_download,
                    s_skeleton_fbx_path, s_skeleton_txt_path, s_skeleton_npz_path,
                    step_skinned_model_display, step_skin_logs, step_skinned_model_fbx_download, step_skinning_npz_download,
                    s_skinned_fbx_path, s_skinning_npz_path,
                    step_merged_model_display, step_merge_logs, step_merged_model_download,
                    s_merged_fbx_path
                ],
                api_name=False
            )
            
            btn_run_extract.click(
                fn=gradio_extract_mesh,
                inputs=[s_original_model_path, s_model_name],
                outputs=[step_extract_logs, step_extracted_model_download, s_extracted_npz_path],
                api_name="run_extract_mesh_step"
            )
            
            btn_run_skeleton.click(
                fn=gradio_generate_skeleton,
                inputs=[
                    s_extracted_npz_path, # from step 0
                    s_model_name,         # from step 0
                    step_gender_dropdown  # Add gender dropdown
                ],
                outputs=[
                    step_skeleton_model_display, 
                    step_skeleton_logs,
                    step_skeleton_fbx_download,
                    step_skeleton_txt_download,
                    step_skeleton_npz_download,
                    s_skeleton_fbx_path, # State update
                    s_skeleton_npz_path  # State update
                ]
            ).then(
                fn=lambda d1, d2, d3, d4, d5: (gr.update(visible=d1 is not None and d1!=''), gr.update(visible=d2 is not None and d2!=''), gr.update(visible=d3 is not None and d3!=''), gr.update(visible=d4 is not None and d4!=''), gr.update(visible=d5 is not None and d5!='')),
                inputs=[step_skeleton_model_display, step_skeleton_fbx_download, step_skeleton_txt_download, step_skeleton_npz_download, step_skeleton_logs],
                outputs=[step_skeleton_model_display, step_skeleton_fbx_download, step_skeleton_txt_download, step_skeleton_npz_download, step_skeleton_logs],
                api_name=False
            )

            btn_run_skin.click(
                fn=gradio_generate_skin,
                inputs=[
                    s_extracted_npz_path, # raw_data_npz_path - from step 0
                    s_skeleton_fbx_path,  # skeleton_fbx_path - from step 1
                    s_skeleton_npz_path,  # skeleton_npz_path - from step 1
                    s_model_name          # model_name - from step 0
                ],
                outputs=[
                    step_skinned_model_display, step_skin_logs, 
                    step_skinned_model_fbx_download, step_skinning_npz_download,
                    s_skinned_fbx_path, s_skinning_npz_path
                ],
                api_name="run_generate_skin_step"
            )

            btn_run_merge.click(
                fn=gradio_merge_model,
                inputs=[s_original_model_path, s_skinned_fbx_path, s_skinning_npz_path, s_model_name],
                outputs=[
                    step_merged_model_display, step_merge_logs, 
                    step_merged_model_download, 
                    s_merged_fbx_path
                ],
                api_name="run_merge_model_step"
            )

            btn_run_merge_with_textures.click(
                fn=gradio_merge_model_with_textures,
                inputs=[s_original_model_path, s_skinned_fbx_path, s_model_name],
                outputs=[
                    step_merged_model_display, step_merge_logs, 
                    step_merged_model_download, 
                    s_merged_fbx_path
                ],
                api_name="run_merge_model_with_textures_step"
            ) # This is the last click handler in the 'Step-by-step' tab
        
        # Add demo.queue() here, after all UI elements and handlers for the demo are defined
        demo.queue()
            
    return demo

if __name__ == "__main__":
    load_app_config() # Load configuration first

    if not APP_CONFIG:
        logging.error("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚èµ·å‹•ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
        sys.exit(1)

    # Safely access Gradio interface configurations with defaults
    gradio_config = APP_CONFIG.get('gradio_interface', {})
    server_name = gradio_config.get('server_name', '0.0.0.0')  # Changed to 0.0.0.0 for accessibility
    base_port = int(gradio_config.get('server_port', 7860))  # Base port
    share_gradio = gradio_config.get('share', False)
    inbrowser = gradio_config.get('inbrowser', True)
    
    # Try to find an available port starting from base_port
    import socket
    def find_free_port(start_port, max_attempts=10):
        for port in range(start_port, start_port + max_attempts):
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                try:
                    s.bind(('', port))
                    return port
                except OSError:
                    continue
        return None
    
    server_port = find_free_port(base_port)
    if server_port is None:
        logging.error(f"åˆ©ç”¨å¯èƒ½ãªãƒãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆ{base_port}ã‹ã‚‰{base_port+9}ã¾ã§è©¦è¡Œï¼‰")
        sys.exit(1)

    logging.info(f"Gradioã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¾ã™: http://{server_name}:{server_port}")
    if share_gradio:
        logging.info("Gradioå…±æœ‰ãŒæœ‰åŠ¹ã«ãªã£ã¦ã„ã¾ã™ã€‚")

    iface = build_gradio_interface()
    
    allowed_paths_list = get_allowed_paths()
    iface.launch(
        server_name=server_name, 
        server_port=server_port, 
        share=share_gradio, 
        inbrowser=inbrowser,
        debug=True, # Force debug=True for this debugging session
        show_error=True, # Enable verbose error reporting
        allowed_paths=allowed_paths_list
    )