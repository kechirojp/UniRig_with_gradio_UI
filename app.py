# This application uses UniRig (https://github.com/VAST-AI-Research/UniRig),
# which is licensed under the MIT License.
# A copy of the license can be found at:
# https://github.com/VAST-AI-Research/UniRig/blob/main/LICENSE
#
# Gradio application for 3D model preview and bone information display.

import gradio as gr
import os
import subprocess
import tempfile
import datetime
import time
import yaml
from box import Box
import shutil
import traceback
import numpy as np
import trimesh # For model inspection if needed, or by Blender script
import logging
import sys
import pathlib # Not strictly used in this version, but good for path manipulation
import json # For datalist
import atexit
import torch  # Add PyTorch import
from texture_preservation_system import TexturePreservationSystem
from proposed_blender_texture_flow import BlenderNativeTextureFlow
from dynamic_skeleton_generator import DynamicSkeletonGenerator

# Import ImprovedSafeTextureRestoration for priority texture processing
try:
    from improved_safe_texture_restoration import ImprovedSafeTextureRestoration
    IMPROVED_SAFE_TEXTURE_RESTORATION_AVAILABLE = True
    print("âœ… ImprovedSafeTextureRestoration loaded in app.py")
except ImportError as e:
    IMPROVED_SAFE_TEXTURE_RESTORATION_AVAILABLE = False
    print(f"âš ï¸ ImprovedSafeTextureRestoration not available in app.py: {e}")

# --- Global Configuration and Setup ---
APP_CONFIG = None
TEMP_FILES_TO_CLEAN = []

# Setup basic logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- PyTorch/CUDA Configuration (Fix CUDA errors) ---
# Force CPU-only execution to avoid CUDA conflicts
os.environ['CUDA_VISIBLE_DEVICES'] = ''  # Completely disable CUDA
os.environ['FORCE_CUDA'] = '0'  # Force disable CUDA
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Ensure consistent device ordering
os.environ['SPCONV_DISABLE_CUDA'] = '1'  # Disable CUDA in spconv library
os.environ['USE_CUDA'] = '0'  # Generic CUDA disable flag
# Memory management settings
os.environ['MKL_NUM_THREADS'] = '1'  # Limit MKL threads
os.environ['OMP_NUM_THREADS'] = '1'  # Limit OpenMP threads
os.environ['NUMEXPR_NUM_THREADS'] = '1'  # Limit NumExpr threads
torch.set_num_threads(1)  # Disable multi-threading for stability
torch.set_grad_enabled(False)  # Disable gradient computation for inference
torch.backends.cudnn.enabled = False  # Disable cuDNN
# Force CPU device for all operations
torch.set_default_device('cpu')
logging.info("ğŸ”§ PyTorchè¨­å®š: CPUå°‚ç”¨ãƒ¢ãƒ¼ãƒ‰ã€CUDAç„¡åŠ¹åŒ–å®Œäº†")

# --- Modify this section for allowed paths (DEBUGGING) ---
def get_allowed_paths():
    script_dir = os.path.dirname(os.path.abspath(__file__)) # /app
    allowed = [
        os.path.abspath(script_dir), # /app
        os.path.abspath(os.path.join(script_dir, "pipeline_work")), # /app/pipeline_work
        os.path.abspath(os.path.join(script_dir, "examples")), # /app/examples
        os.path.abspath(os.path.join(script_dir, "src")), # /app/src
        os.path.abspath(os.path.join(script_dir, "configs")), # /app/configs
        os.path.abspath(os.path.join(script_dir, "blender")), # /app/blender
    ]
    if APP_CONFIG and APP_CONFIG.working_directory_base:
        # Ensure the configured working_directory_base is also allowed
        # This might be redundant if it's already /app/pipeline_work, but good for safety
        configured_work_base = os.path.abspath(APP_CONFIG.working_directory_base)
        if configured_work_base not in allowed:
            allowed.append(configured_work_base)
        
        # Add specific subdirectories from config if they exist, ensuring they are absolute
        # This helps if APP_CONFIG.working_directory_base is different from /app/pipeline_work
        # or if subdirectories are outside the main pipeline_work structure.
        subdirs_to_check = [
            APP_CONFIG.get('mesh_extraction', {}).get('extract_output_subdir'),
            APP_CONFIG.get('skeleton_generation', {}).get('skeleton_output_subdir'),
            APP_CONFIG.get('skinning_prediction', {}).get('skin_output_subdir'),
            APP_CONFIG.get('model_merging', {}).get('merge_output_subdir'),
            APP_CONFIG.get('blender_processing', {}).get('conversion_output_subdir'),
            APP_CONFIG.get('blender_native_texture_flow', {}).get('blender_native_subdir', '06_blender_native'),
            APP_CONFIG.get('improved_safe_texture_restoration', {}).get('output_subdir', '08_final_output') # Example for improved flow
        ]
        for subdir_name in subdirs_to_check:
            if subdir_name:
                # Construct path relative to configured_work_base if it's not absolute
                # Or relative to script_dir if that makes more sense for your structure
                potential_path = os.path.join(configured_work_base, subdir_name)
                abs_path = os.path.abspath(potential_path)
                if abs_path not in allowed:
                    allowed.append(abs_path)
    
    # Add temp directory
    allowed.append(os.path.abspath(tempfile.gettempdir()))

    logging.info(f"DEBUG: Gradio allowed_pathsãŒè¨­å®šã•ã‚Œã¾ã—ãŸ: {list(set(allowed))}") # Use set to remove duplicates
    return list(set(allowed))
# --- End of modified section ---

# --- Add this helper function for debugging output paths ---
def log_output_paths_for_debug(output_dict, context_log_message=""):
    logging.info(f"--- DEBUG: Gradioå‡ºåŠ›ãƒ‘ã‚¹ã®ç¢ºèª ({context_log_message}) ---")
    if not isinstance(output_dict, dict):
        logging.warning(f"  å‡ºåŠ›ã¯è¾æ›¸ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {type(output_dict)}, å€¤: {output_dict}")
        return

    for key, value in output_dict.items():
        if isinstance(value, str) and (value.endswith(('.glb', '.fbx', '.png', '.jpg', '.txt', '.npz', '.json', '.yaml')) or "/" in value or "\\\\" in value):
            # Heuristic: if it looks like a file path string
            abs_path = os.path.abspath(value)
            exists = os.path.exists(abs_path)
            is_file = os.path.isfile(abs_path) if exists else "N/A"
            logging.info(f"  å‡ºåŠ›ã‚­ãƒ¼: '{key}', ãƒ‘ã‚¹: '{value}' (çµ¶å¯¾ãƒ‘ã‚¹: '{abs_path}'), å­˜åœ¨: {exists}, ãƒ•ã‚¡ã‚¤ãƒ«?: {is_file}")
            if exists and is_file:
                try:
                    logging.info(f"    ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {os.path.getsize(abs_path)} bytes")
                except Exception as e:
                    logging.warning(f"    ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        elif isinstance(value, list) and all(isinstance(item, str) for item in value):
             logging.info(f"  å‡ºåŠ›ã‚­ãƒ¼: '{key}', å€¤ (ãƒªã‚¹ãƒˆ): {value} - (ãƒªã‚¹ãƒˆå†…ã®ãƒ‘ã‚¹ã¯å€‹åˆ¥ã«ç¢ºèªã•ã‚Œã¾ã›ã‚“)")
        else:
            logging.info(f"  å‡ºåŠ›ã‚­ãƒ¼: '{key}', å€¤: {value} (å‹: {type(value)}) - ãƒ‘ã‚¹ã¨ã—ã¦æ‰±ã‚ã‚Œã¾ã›ã‚“")
    logging.info("--- DEBUG: Gradioå‡ºåŠ›ãƒ‘ã‚¹ã®ç¢ºèªå®Œäº† ---")
# --- End of added helper function ---

# --- Configuration Loading Functions ---
def load_app_config():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã‚’YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿"""
    global APP_CONFIG
    config_path = os.path.join(os.path.dirname(__file__), 'configs', 'app_config.yaml')
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config_data = yaml.safe_load(f)
        APP_CONFIG = Box(config_data)
        logging.info(f"âœ… ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {config_path}")
        
        # ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        work_dir = os.path.abspath(APP_CONFIG.working_directory_base)
        os.makedirs(work_dir, exist_ok=True)
        
        return True
    except Exception as e:
        logging.error(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
        APP_CONFIG = Box({'error': str(e)})
        return False

# --- Utility Functions ---
def convert_to_glb_for_display(input_model_path, output_name):
    """3Dãƒ¢ãƒ‡ãƒ«ã‚’è¡¨ç¤ºç”¨GLBã«å¤‰æ›"""
    try:
        # å…¥åŠ›ãƒ‘ã‚¹ã¨å‡ºåŠ›ãƒ‘ã‚¹ã‚’è¨­å®š
        base_name = os.path.splitext(os.path.basename(input_model_path))[0]
        output_dir = os.path.join(tempfile.gettempdir(), "display_models")
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, f"{output_name}.glb")
        
        # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ—¢ã«GLBå½¢å¼ã®å ´åˆã¯ã‚³ãƒ”ãƒ¼
        if input_model_path.lower().endswith('.glb'):
            shutil.copy2(input_model_path, output_path)
            return output_path
        
        # ãã®ä»–ã®å½¢å¼ã®å ´åˆã¯ç°¡å˜ãªå¤‰æ›å‡¦ç†ã‚’è©¦è¡Œ
        # TODO: ã‚ˆã‚Šé«˜åº¦ãªå¤‰æ›å‡¦ç†ã‚’å®Ÿè£…
        try:
            # Trimeshã‚’ä½¿ã£ãŸåŸºæœ¬çš„ãªå¤‰æ›
            mesh = trimesh.load(input_model_path)
            if hasattr(mesh, 'export'):
                mesh.export(output_path)
                return output_path
            else:
                logging.warning(f"Trimeshã§ã®å¤‰æ›: 'export'ãƒ¡ã‚½ãƒƒãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        except Exception as e:
            logging.warning(f"Trimeshã§ã®å¤‰æ›ã«å¤±æ•—: {e}")
        
        # å¤‰æ›ã«å¤±æ•—ã—ãŸå ´åˆã¯å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
        shutil.copy2(input_model_path, output_path)
        return output_path
        
    except Exception as e:
        logging.error(f"GLBå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        return input_model_path  # å¤‰æ›å¤±æ•—æ™‚ã¯å…ƒã®ãƒ‘ã‚¹ã‚’è¿”ã™

def ensure_working_directory():
    """ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºä¿"""
    if not APP_CONFIG:
        return False
    
    try:
        work_dir = os.path.abspath(APP_CONFIG.working_directory_base)
        os.makedirs(work_dir, exist_ok=True)
        
        # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚ä½œæˆ
        subdirs = [
            APP_CONFIG.get('mesh_extraction', {}).get('extract_output_subdir', '01_extracted_mesh'),
            APP_CONFIG.get('skeleton_generation', {}).get('skeleton_output_subdir', '02_skeleton'),
            APP_CONFIG.get('skinning_prediction', {}).get('skin_output_subdir', '03_skinning'),
            APP_CONFIG.get('model_merging', {}).get('merge_output_subdir', '04_merge'),
            '08_final_output'  # æœ€çµ‚å‡ºåŠ›ç”¨
        ]
        
        for subdir in subdirs:
            if subdir:
                full_subdir = os.path.join(work_dir, subdir)
                os.makedirs(full_subdir, exist_ok=True)
        
        return True
    except Exception as e:
        logging.error(f"ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆã«å¤±æ•—: {e}")
        return False

def cleanup_temp_files():
    """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    global TEMP_FILES_TO_CLEAN
    for temp_file in TEMP_FILES_TO_CLEAN:
        try:
            if os.path.exists(temp_file):
                os.remove(temp_file)
                logging.info(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤: {temp_file}")
        except Exception as e:
            logging.warning(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã«å¤±æ•—: {temp_file}, ã‚¨ãƒ©ãƒ¼: {e}")
    TEMP_FILES_TO_CLEAN = []

# çµ‚äº†æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
atexit.register(cleanup_temp_files)

# --- Progress Utility Function ---
def progress_segment(progress, start: float, end: float):
    """
    ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®ç¯„å›²ã‚’åˆ†å‰²ã™ã‚‹é–¢æ•°
    Args:
        progress: Gradioã®ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        start: é–‹å§‹ä½ç½® (0.0-1.0)
        end: çµ‚äº†ä½ç½® (0.0-1.0)
    Returns:
        åˆ†å‰²ã•ã‚ŒãŸãƒ—ãƒ­ã‚°ãƒ¬ã‚¹é–¢æ•°
    """
    def segmented_progress(value: float, desc: str = None):
        """åˆ†å‰²ã•ã‚ŒãŸãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°é–¢æ•°"""
        if progress is None:
            return
        try:
            # åˆ†å‰²ã•ã‚ŒãŸç¯„å›²å†…ã§ã®å€¤ã‚’è¨ˆç®—
            segment_range = end - start
            actual_progress = start + (value * segment_range)
            actual_progress = max(0.0, min(1.0, actual_progress))  # 0.0-1.0ã«ã‚¯ãƒ©ãƒ³ãƒ—
            
            if desc:
                progress(actual_progress, desc)
            else:
                progress(actual_progress)
        except Exception as e:
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ãƒ­ã‚°ã«è¨˜éŒ²ã—ã¦ç¶šè¡Œ
            logging.warning(f"ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
            pass
    
    return segmented_progress

# --- Helper: Run Subprocess ---
def run_subprocess_with_progress(command, work_dir, log_file_path, progress_fn, total_items_for_tqdm=1):
    """
    ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’é€²æ—è¡¨ç¤ºä»˜ãã§å®Ÿè¡Œ
    Args:
        command: å®Ÿè¡Œã™ã‚‹ã‚³ãƒãƒ³ãƒ‰ (ãƒªã‚¹ãƒˆ)
        work_dir: ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        log_file_path: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        progress_fn: é€²æ—æ›´æ–°é–¢æ•°
        total_items_for_tqdm: é€²æ—ã®ã‚¢ã‚¤ãƒ†ãƒ æ•° (æœªä½¿ç”¨)
    Returns:
        tuple: (success: bool, logs: str)
    """
    logs = ""
    try:
        process = subprocess.Popen(command, cwd=work_dir, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1, universal_newlines=True)
        
        # Simulate progress for the subprocess duration if it's a single task
        # This is a placeholder. Real progress depends on the script's output.
        progress_fn(0.1, desc=f"å®Ÿè¡Œä¸­: {command[1] if len(command) > 1 else 'command'}...") 

        with open(log_file_path, 'w') as log_f:
            for line in process.stdout:
                logs += line
                log_f.write(line)
                # If the script outputs progress, parse it here.
                # For now, we don't have a specific format to parse.
        
        process.wait()
        progress_fn(0.9, desc=f"å®Œäº†å¾…ã¡: {command[1] if len(command) > 1 else 'command'}...")

        if process.returncode == 0:
            logs += f"ã‚³ãƒãƒ³ãƒ‰æˆåŠŸ: {' '.join(command)}\n"
            progress_fn(1.0, desc=f"å®Œäº†: {command[1] if len(command) > 1 else 'command'}")
            return True, logs
        else:
            logs += f"ã‚³ãƒãƒ³ãƒ‰å¤±æ•— (ã‚³ãƒ¼ãƒ‰ {process.returncode}): {' '.join(command)}\n"
            logs += f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§: {log_file_path}\n"
            progress_fn(1.0, desc=f"ã‚¨ãƒ©ãƒ¼: {command[1] if len(command) > 1 else 'command'}") # Mark as complete even on error for progress bar
            return False, logs
    except FileNotFoundError:
        logs += f"ã‚¨ãƒ©ãƒ¼: ã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - {command[0]}ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
        progress_fn(1.0, desc=f"ã‚¨ãƒ©ãƒ¼: {command[0]} not found")
        return False, logs
    except Exception as e:
        logs += f"ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}\n"
        logs += f"ã‚³ãƒãƒ³ãƒ‰: {' '.join(command)}\n"
        logs += f"è©³ç´°: {traceback.format_exc()}\n"
        progress_fn(1.0, desc=f"ä¾‹å¤–: {command[1] if len(command) > 1 else 'command'}")
        return False, logs

# --- Core Processing Functions ---
def process_extract_mesh(uploaded_model_path: str, model_name: str, progress_fn=None):
    """
    ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå‡¦ç†
    Args:
        uploaded_model_path: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        model_name: ãƒ¢ãƒ‡ãƒ«å
        progress_fn: ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°é–¢æ•°
    Returns:
        tuple: (extracted_npz_path, logs)
    """
    logs = "=== ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå‡¦ç†é–‹å§‹ ===\n"
    
    try:
        if progress_fn:
            progress_fn(0.1, "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºæº–å‚™ä¸­...")
        
        if not uploaded_model_path or not os.path.exists(uploaded_model_path):
            logs += f"âŒ ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {uploaded_model_path}\n"
            return None, logs
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
        if not APP_CONFIG:
            # Gradioç’°å¢ƒã§ã®è¨­å®šã®å†èª­ã¿è¾¼ã¿
            if not load_app_config():
                logs += "âŒ ã‚¨ãƒ©ãƒ¼: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“\n"
                return None, logs
        
        extract_config = APP_CONFIG.get('mesh_extraction', {})
        extract_subdir = extract_config.get('extract_output_subdir', '01_extracted_mesh')
        work_base = APP_CONFIG.working_directory_base
        extract_dir = os.path.join(work_base, extract_subdir, model_name)
        
        os.makedirs(extract_dir, exist_ok=True)
        logs += f"ğŸ“ æŠ½å‡ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {extract_dir}\n"
        
        if progress_fn:
            progress_fn(0.3, "ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­...")
        
        # NPZãƒ•ã‚¡ã‚¤ãƒ«ã®å‡ºåŠ›ãƒ‘ã‚¹
        extracted_npz_path = os.path.join(extract_dir, f"{model_name}_extracted.npz")
        
        # åŸºæœ¬çš„ãªãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå‡¦ç†ï¼ˆãƒ†ã‚¯ã‚¹ãƒãƒ£æƒ…å ±ä»˜ãï¼‰
        try:
            mesh = trimesh.load(uploaded_model_path)
            
            if progress_fn:
                progress_fn(0.6, "ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿å¤‰æ›ä¸­...")
            
            # ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’numpyé…åˆ—ã¨ã—ã¦ä¿å­˜
            if hasattr(mesh, 'vertices') and hasattr(mesh, 'faces'):
                # å˜ä¸€ãƒ¡ãƒƒã‚·ãƒ¥ã®å ´åˆ
                vertices = mesh.vertices
                faces = mesh.faces
                materials = getattr(mesh.visual, 'material', None)
                mesh_name = "main_mesh"
            else:
                # Scene objectã®å ´åˆã®å‡¦ç†
                if hasattr(mesh, 'geometry'):
                    geometry_list = list(mesh.geometry.values())
                    if len(geometry_list) == 0:
                        raise Exception("Sceneã«ã‚¸ã‚ªãƒ¡ãƒˆãƒªãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
                    
                    # æœ€åˆã®ã‚¸ã‚ªãƒ¡ãƒˆãƒªã‚’ä½¿ç”¨
                    first_geometry = geometry_list[0]
                    vertices = first_geometry.vertices
                    faces = first_geometry.faces
                    mesh_name = list(mesh.geometry.keys())[0]
                    
                    # Sceneå†…ã®ãƒãƒ†ãƒªã‚¢ãƒ«æƒ…å ±ã‚’å–å¾—
                    materials = getattr(first_geometry.visual, 'material', None) if hasattr(first_geometry, 'visual') else None
                    
                    logs += f"ğŸ” Sceneå½¢å¼æ¤œå‡º: {len(geometry_list)}å€‹ã®ã‚¸ã‚ªãƒ¡ãƒˆãƒª\n"
                    logs += f"ğŸ“¦ ä½¿ç”¨ã‚¸ã‚ªãƒ¡ãƒˆãƒª: {mesh_name}\n"
                else:
                    raise Exception("ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã‚’èªè­˜ã§ãã¾ã›ã‚“")
            
            # ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
            texture_dir = os.path.join(extract_dir, "textures")
            os.makedirs(texture_dir, exist_ok=True)
            
            # ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆæƒ…å ±ã®æº–å‚™
            texture_manifest = {
                'model_name': model_name,
                'extracted_at': str(time.time()),
                'texture_count': 0,
                'textures': [],
                'mesh_name': mesh_name
            }
            
            # é«˜åº¦ãªãƒãƒ†ãƒªã‚¢ãƒ«ãƒ»ãƒ†ã‚¯ã‚¹ãƒãƒ£æŠ½å‡ºå‡¦ç†
            logs += "ğŸ¨ ãƒ†ã‚¯ã‚¹ãƒãƒ£æŠ½å‡ºå‡¦ç†é–‹å§‹\n"
            
            if materials:
                logs += f"ğŸ“‹ ãƒãƒ†ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ—: {type(materials)}\n"
                
                # PBRMaterial ã®å ´åˆã®å‡¦ç†
                if hasattr(materials, 'baseColorTexture'):
                    texture_count = 0
                    
                    # Base Color Texture (Diffuse)
                    if materials.baseColorTexture:
                        try:
                            texture_filename = f"{model_name}_baseColor.png"
                            texture_path = os.path.join(texture_dir, texture_filename)
                            materials.baseColorTexture.save(texture_path)
                            
                            texture_manifest['textures'].append({
                                'original_name': 'baseColorTexture',
                                'saved_name': texture_filename,
                                'saved_path': texture_path,
                                'type': 'BASE_COLOR',
                                'size_bytes': os.path.getsize(texture_path)
                            })
                            texture_count += 1
                            logs += f"ğŸ“¸ Base Color ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜: {texture_filename}\n"
                        except Exception as e:
                            logs += f"âš ï¸ Base Color ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}\n"
                    
                    # Normal Texture
                    if hasattr(materials, 'normalTexture') and materials.normalTexture:
                        try:
                            texture_filename = f"{model_name}_normal.png"
                            texture_path = os.path.join(texture_dir, texture_filename)
                            materials.normalTexture.save(texture_path)
                            
                            texture_manifest['textures'].append({
                                'original_name': 'normalTexture',
                                'saved_name': texture_filename,
                                'saved_path': texture_path,
                                'type': 'NORMAL',
                                'size_bytes': os.path.getsize(texture_path)
                            })
                            texture_count += 1
                            logs += f"ğŸ“¸ Normal ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜: {texture_filename}\n"
                        except Exception as e:
                            logs += f"âš ï¸ Normal ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}\n"
                    
                    # Metallic Roughness Texture
                    if hasattr(materials, 'metallicRoughnessTexture') and materials.metallicRoughnessTexture:
                        try:
                            texture_filename = f"{model_name}_metallicRoughness.png"
                            texture_path = os.path.join(texture_dir, texture_filename)
                            materials.metallicRoughnessTexture.save(texture_path)
                            
                            texture_manifest['textures'].append({
                                'original_name': 'metallicRoughnessTexture',
                                'saved_name': texture_filename,
                                'saved_path': texture_path,
                                'type': 'METALLIC_ROUGHNESS',
                                'size_bytes': os.path.getsize(texture_path)
                            })
                            texture_count += 1
                            logs += f"ğŸ“¸ Metallic Roughness ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜: {texture_filename}\n"
                        except Exception as e:
                            logs += f"âš ï¸ Metallic Roughness ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}\n"
                    
                    # Emissive Texture
                    if hasattr(materials, 'emissiveTexture') and materials.emissiveTexture:
                        try:
                            texture_filename = f"{model_name}_emissive.png"
                            texture_path = os.path.join(texture_dir, texture_filename)
                            materials.emissiveTexture.save(texture_path)
                            
                            texture_manifest['textures'].append({
                                'original_name': 'emissiveTexture',
                                'saved_name': texture_filename,
                                'saved_path': texture_path,
                                'type': 'EMISSIVE',
                                'size_bytes': os.path.getsize(texture_path)
                            })
                            texture_count += 1
                            logs += f"ğŸ“¸ Emissive ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜: {texture_filename}\n"
                        except Exception as e:
                            logs += f"âš ï¸ Emissive ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}\n"
                    
                    # Occlusion Texture
                    if hasattr(materials, 'occlusionTexture') and materials.occlusionTexture:
                        try:
                            texture_filename = f"{model_name}_occlusion.png"
                            texture_path = os.path.join(texture_dir, texture_filename)
                            materials.occlusionTexture.save(texture_path)
                            
                            texture_manifest['textures'].append({
                                'original_name': 'occlusionTexture',
                                'saved_name': texture_filename,
                                'saved_path': texture_path,
                                'type': 'OCCLUSION',
                                'size_bytes': os.path.getsize(texture_path)
                            })
                            texture_count += 1
                            logs += f"ğŸ“¸ Occlusion ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜: {texture_filename}\n"
                        except Exception as e:
                            logs += f"âš ï¸ Occlusion ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}\n"
                    
                    texture_manifest['texture_count'] = texture_count
                    
                # SimpleMaterial ã®å ´åˆã®å‡¦ç†ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                elif hasattr(materials, 'image') and materials.image:
                    try:
                        texture_filename = f"{model_name}_texture_0.png"
                        texture_path = os.path.join(texture_dir, texture_filename)
                        materials.image.save(texture_path)
                        
                        texture_manifest['texture_count'] = 1
                        texture_manifest['textures'].append({
                            'original_name': 'image',
                            'saved_name': texture_filename,
                            'saved_path': texture_path,
                            'type': 'DIFFUSE',
                            'size_bytes': os.path.getsize(texture_path)
                        })
                        logs += f"ğŸ“¸ Simple Material ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜: {texture_filename}\n"
                    except Exception as texture_error:
                        logs += f"âš ï¸ Simple Material ãƒ†ã‚¯ã‚¹ãƒãƒ£æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {texture_error}\n"
                else:
                    logs += "âš ï¸ èªè­˜å¯èƒ½ãªãƒ†ã‚¯ã‚¹ãƒãƒ£ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\n"
            else:
                logs += "âš ï¸ ãƒãƒ†ãƒªã‚¢ãƒ«æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\n"
            
            # NPZãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            np.savez(extracted_npz_path, 
                    vertices=vertices, 
                    faces=faces)
            
            # YAMLãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ï¼ˆImprovedSafeTextureRestorationç”¨ï¼‰
            yaml_manifest_path = os.path.join(extract_dir, "texture_manifest.yaml")
            try:
                import yaml
                with open(yaml_manifest_path, 'w') as f:
                    yaml.dump(texture_manifest, f, default_flow_style=False)
                logs += f"ğŸ“‹ YAMLãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆç”Ÿæˆ: {yaml_manifest_path}\n"
            except Exception as yaml_error:
                logs += f"âš ï¸ YAMLãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {yaml_error}\n"
            
            if progress_fn:
                progress_fn(0.9, "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå®Œäº†å‡¦ç†ä¸­...")
            
            logs += f"âœ… ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºæˆåŠŸ\n"
            logs += f"ğŸ“Š é ‚ç‚¹æ•°: {len(vertices)}\n"
            logs += f"ğŸ“Š é¢æ•°: {len(faces)}\n"
            logs += f"ğŸ“¸ ãƒ†ã‚¯ã‚¹ãƒãƒ£æ•°: {texture_manifest['texture_count']}\n"
            logs += f"ğŸ’¾ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {extracted_npz_path}\n"
            
            if progress_fn:
                progress_fn(1.0, "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå®Œäº†")
            
            return extracted_npz_path, logs
            
        except Exception as mesh_error:
            logs += f"âŒ ãƒ¡ãƒƒã‚·ãƒ¥å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(mesh_error)}\n"
            return None, logs
    
    except Exception as e:
        logs += f"âŒ ãƒ¡ãƒƒã‚·ãƒ¥æŠ½ extractå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\n"
        logs += f"è©³ç´°: {traceback.format_exc()}\n"
        if progress_fn:
            progress_fn(1.0, "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºã‚¨ãƒ©ãƒ¼")
        return None, logs

def process_generate_skeleton(extracted_npz_path: str, model_name: str, gender: str, progress_fn=None):
    """
    ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå‡¦ç†
    Args:
        extracted_npz_path: æŠ½å‡ºã•ã‚ŒãŸãƒ¡ãƒƒã‚·ãƒ¥ã®NPZãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        model_name: ãƒ¢ãƒ‡ãƒ«å
        gender: æ€§åˆ¥ ('male' ã¾ãŸã¯ 'female')
        progress_fn: ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°é–¢æ•°
    Returns:
        tuple: (display_path, logs, fbx_path, txt_path, npz_path)
    """
    logs = "=== ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå‡¦ç†é–‹å§‹ ===\n"
    
    try:
        if progress_fn:
            progress_fn(0.1, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆæº–å‚™ä¸­...")
        
        if not extracted_npz_path or not os.path.exists(extracted_npz_path):
            logs += f"âŒ ã‚¨ãƒ©ãƒ¼: å…¥åŠ›NPZãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {extracted_npz_path}\n"
            return None, logs, None, None, None
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
        if not APP_CONFIG:
            # Gradioç’°å¢ƒã§ã®è¨­å®šã®å†èª­ã¿è¾¼ã¿
            if not load_app_config():
                logs += "âŒ ã‚¨ãƒ©ãƒ¼: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“\n"
                return None, logs, None, None, None
        
        skeleton_config = APP_CONFIG.get('skeleton_generation', {})
        skeleton_subdir = skeleton_config.get('skeleton_output_subdir', '02_skeleton')
        work_base = APP_CONFIG.working_directory_base
        skeleton_dir = os.path.join(work_base, skeleton_subdir, model_name)
        
        os.makedirs(skeleton_dir, exist_ok=True)
        logs += f"ğŸ“ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {skeleton_dir}\n"
        logs += f"ğŸ‘¤ æ€§åˆ¥è¨­å®š: {gender}\n"
        
        if progress_fn:
            progress_fn(0.3, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³æ§‹é€ è§£æä¸­...")
        
        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®è¨­å®š
        skeleton_fbx_path = os.path.join(skeleton_dir, f"{model_name}_skeleton.fbx")
        skeleton_txt_path = os.path.join(skeleton_dir, f"{model_name}_bones.txt")
        skeleton_npz_path = os.path.join(skeleton_dir, f"{model_name}_skeleton.npz")
        display_glb_path = os.path.join(skeleton_dir, f"{model_name}_skeleton_display.glb")
        
        if progress_fn:
            progress_fn(0.5, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆä¸­...")
        
        # å‹•çš„ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå‡¦ç†ï¼ˆDynamicSkeletonGeneratorã‚’ä½¿ç”¨ï¼‰
        try:
            import numpy as np
            from dynamic_skeleton_generator import DynamicSkeletonGenerator
            
            # NPZãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
            data = np.load(extracted_npz_path)
            vertices = data['vertices']
            faces = data['faces']
            
            if progress_fn:
                progress_fn(0.6, "ãƒ¡ãƒƒã‚·ãƒ¥è§£æä¸­...")
            
            # å‹•çš„ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå™¨ã‚’åˆæœŸåŒ–
            skeleton_generator = DynamicSkeletonGenerator()
            
            if progress_fn:
                progress_fn(0.7, "é©å¿œçš„ãƒœãƒ¼ãƒ³æ§‹é€ ç”Ÿæˆä¸­...")
            
            # ãƒ¡ãƒƒã‚·ãƒ¥ã«åŸºã¥ã„ã¦é©å¿œçš„ãªã‚¹ã‚±ãƒ«ãƒˆãƒ³ã‚’ç”Ÿæˆ
            skeleton_result = skeleton_generator.generate_adaptive_skeleton(vertices, faces)
            
            # ç”Ÿæˆã•ã‚ŒãŸã‚¹ã‚±ãƒ«ãƒˆãƒ³æƒ…å ±ã‚’å–å¾—
            bone_names = skeleton_result['names']
            joints = skeleton_result['joints']
            bones = skeleton_result['bones']
            tails = skeleton_result['tails']
            parents = skeleton_result['parents']
            creature_type = skeleton_result['creature_type']
            mesh_analysis = skeleton_result['mesh_analysis']
            
            logs += f"ğŸ” æ¤œå‡ºã•ã‚ŒãŸç”Ÿç‰©ã‚¿ã‚¤ãƒ—: {creature_type}\n"
            logs += f"ğŸ¦´ ç”Ÿæˆã•ã‚ŒãŸãƒœãƒ¼ãƒ³æ•°: {len(bone_names)}\n"
            
            if progress_fn:
                progress_fn(0.8, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿ä¿å­˜ä¸­...")
            
            # ãƒœãƒ¼ãƒ³æƒ…å ±ã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with open(skeleton_txt_path, 'w', encoding='utf-8') as f:
                f.write(f"Dynamic Skeleton for model: {model_name}\n")
                f.write(f"Gender: {gender}\n")
                f.write(f"Creature Type: {creature_type}\n")
                f.write(f"Total bones: {len(bone_names)}\n\n")
                f.write("=== Bone Hierarchy ===\n")
                for i, bone_name in enumerate(bone_names):
                    parent_info = f" (parent: {bone_names[parents[i]]})" if parents[i] is not None else " (root)"
                    f.write(f"Bone {i:2d}: {bone_name}{parent_info}\n")
                
                f.write(f"\n=== Mesh Analysis ===\n")
                if mesh_analysis:
                    f.write(f"Bounds: {mesh_analysis.get('bounds', 'N/A')}\n")
                    f.write(f"Center: {mesh_analysis.get('center', 'N/A')}\n")
                    f.write(f"Extents: {mesh_analysis.get('extents', 'N/A')}\n")
                    shape_info = mesh_analysis.get('shape_analysis', {})
                    f.write(f"Aspect Ratios: {shape_info.get('aspect_ratios', 'N/A')}\n")
            
            # ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’NPZãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆUniRigå½¢å¼ï¼‰
            skeleton_data = {
                'bone_names': np.array(bone_names),
                'joints': joints,
                'bones': bones,
                'tails': tails,
                'parents': np.array(parents, dtype=object),
                'bone_count': len(bone_names),
                'model_name': model_name,
                'gender': gender,
                'creature_type': creature_type,
                'mesh_analysis': mesh_analysis
            }
            np.savez(skeleton_npz_path, **skeleton_data)
            
            if progress_fn:
                progress_fn(0.9, "è¡¨ç¤ºç”¨ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆä¸­...")
            
            # è¡¨ç¤ºç”¨GLBãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
            try:
                import trimesh
                # å…ƒã®ãƒ¡ãƒƒã‚·ãƒ¥ã‚’ãƒ™ãƒ¼ã‚¹ã«è¡¨ç¤ºç”¨ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
                mesh = trimesh.Trimesh(vertices=vertices, faces=faces)
                mesh.export(display_glb_path)
            except Exception as display_error:
                logs += f"âš ï¸ è¡¨ç¤ºç”¨ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {display_error}\n"
                display_glb_path = None
            
            # ç°¡æ˜“FBXãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ï¼‰
            try:
                # å®Ÿéš›ã®FBXç”Ÿæˆã¯è¤‡é›‘ãªãŸã‚ã€ã“ã“ã§ã¯ç°¡æ˜“çš„ãªå‡¦ç†
                with open(skeleton_fbx_path, 'w') as f:
                    f.write(f"; FBX skeleton for {model_name}\n")
                    f.write(f"; Generated bones: {len(bone_names)}\n")
            except Exception as fbx_error:
                logs += f"âš ï¸ FBXç”Ÿæˆã‚¨ãƒ©ãƒ¼: {fbx_error}\n"
                skeleton_fbx_path = None
            
            logs += f"âœ… å‹•çš„ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”ŸæˆæˆåŠŸ\n"
            logs += f"ğŸ” ç”Ÿç‰©ã‚¿ã‚¤ãƒ—: {creature_type}\n"
            logs += f"ğŸ¦´ é©å¿œçš„ãƒœãƒ¼ãƒ³æ•°: {len(bone_names)}\n"
            logs += f"ğŸ“Š ã‚¸ãƒ§ã‚¤ãƒ³ãƒˆåº§æ¨™: {joints.shape}\n"
            logs += f"ğŸ’¾ FBXãƒ•ã‚¡ã‚¤ãƒ«: {skeleton_fbx_path}\n"
            logs += f"ğŸ“„ ãƒœãƒ¼ãƒ³æƒ…å ±: {skeleton_txt_path}\n"
            logs += f"ğŸ’¾ NPZãƒ•ã‚¡ã‚¤ãƒ«: {skeleton_npz_path}\n"
            
            if progress_fn:
                progress_fn(1.0, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå®Œäº†")
            
            return display_glb_path, logs, skeleton_fbx_path, skeleton_txt_path, skeleton_npz_path
            
        except Exception as skeleton_error:
            logs += f"âŒ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(skeleton_error)}\n"
            return None, logs, None, None, None
    
    except Exception as e:
        logs += f"âŒ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\n"
        logs += f"è©³ç´°: {traceback.format_exc()}\n"
        if progress_fn:
            progress_fn(1.0, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆã‚¨ãƒ©ãƒ¼")
        return None, logs, None, None, None


def step2_generate_skeleton(model_name: str = "bird", progress_fn=None, force_dynamic: bool = True):
    """
    Step 2: å‹•çš„ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ
    æ—¢å­˜ã®process_generate_skeletoné–¢æ•°ã®ãƒ©ãƒƒãƒ‘ãƒ¼
    
    Args:
        model_name: ãƒ¢ãƒ‡ãƒ«å
        progress_fn: ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°é–¢æ•°
        force_dynamic: å‹•çš„ç”Ÿæˆã‚’å¼·åˆ¶ï¼ˆæœªä½¿ç”¨ã€äº’æ›æ€§ã®ãŸã‚ï¼‰
    
    Returns:
        tuple: (æˆåŠŸãƒ•ãƒ©ã‚°, ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸, å‡ºåŠ›ãƒ‘ã‚¹)
    """
    try:
        # APP_CONFIGãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ãªã„å ´åˆã®å¯¾å‡¦
        if APP_CONFIG is None:
            load_app_config()
        
        # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
        work_base = APP_CONFIG.working_directory_base if APP_CONFIG else "/app/pipeline_work"
        extracted_dir = os.path.join(work_base, "01_extracted_mesh", model_name)
        npz_file = os.path.join(extracted_dir, "raw_data.npz")
        
        if not os.path.exists(npz_file):
            logs = f"âŒ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {npz_file}\n"
            return False, logs, None
        
        # æ—¢å­˜ã®process_generate_skeletoné–¢æ•°ã‚’å‘¼ã³å‡ºã—
        display_path, logs, fbx_path, txt_path, npz_path = process_generate_skeleton(
            extracted_npz_path=npz_file,
            model_name=model_name,
            gender="neutral",  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ€§åˆ¥
            progress_fn=progress_fn
        )
        
        # æˆåŠŸåˆ¤å®š
        success = npz_path is not None and os.path.exists(npz_path)
        
        # å‡ºåŠ›ãƒ‘ã‚¹ã¯äºˆæ¸¬ã‚¹ã‚±ãƒ«ãƒˆãƒ³NPZãƒ•ã‚¡ã‚¤ãƒ«
        if success:
            # predict_skeleton.npzãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ/æ›´æ–°
            predict_skeleton_path = os.path.join(extracted_dir, "predict_skeleton.npz")
            if npz_path and os.path.exists(npz_path):
                # ç”Ÿæˆã•ã‚ŒãŸã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ predict_skeleton.npz ã¨ã—ã¦ä¿å­˜
                shutil.copy2(npz_path, predict_skeleton_path)
                output_path = predict_skeleton_path
            else:
                output_path = npz_path
        else:
            output_path = None
        
        return success, logs, output_path
        
    except Exception as e:
        error_msg = f"âŒ Step 2 ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}"
        import traceback
        full_logs = error_msg + "\n" + traceback.format_exc()
        return False, full_logs, None


def process_generate_skin(raw_data_npz_path: str, skeleton_fbx_path: str, skeleton_npz_path: str, 
                         model_name_for_output: str, progress_fn=None):
    """
    UniRigã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬å‡¦ç†ï¼ˆLightning + UniRig SkinSystemä½¿ç”¨ï¼‰
    Args:
        raw_data_npz_path: å…ƒã®ãƒ¡ãƒƒã‚·ãƒ¥NPZãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        skeleton_fbx_path: ã‚¹ã‚±ãƒ«ãƒˆãƒ³FBXãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        skeleton_npz_path: ã‚¹ã‚±ãƒ«ãƒˆãƒ³NPZãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        model_name_for_output: å‡ºåŠ›ç”¨ãƒ¢ãƒ‡ãƒ«å
        progress_fn: ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°é–¢æ•°
    Returns:
        tuple: (display_path, logs, skinned_fbx_path, skinning_npz_path)
    """
    logs = "=== UniRig Lightning ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬å‡¦ç†é–‹å§‹ ===\n"
    
    # å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    import os
    import shutil
    import traceback
    
    try:
        if progress_fn:
            progress_fn(0.1, "ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æº–å‚™ä¸­...")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰æ¤œå‡ºï¼ˆæ—©æœŸå®Ÿè¡Œï¼‰
        force_fallback = os.environ.get('FORCE_FALLBACK_MODE', '0') == '1' or \
                        os.environ.get('DISABLE_UNIRIG_LIGHTNING', '0') == '1'
        
        if force_fallback:
            logs += "ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰: è»½é‡å‡¦ç†ã‚’ä½¿ç”¨\n"
            # Blenderé–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’å®Œå…¨ã«é¿ã‘ãŸè»½é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
            try:
                import numpy as np
                
                # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
                if not raw_data_npz_path or not os.path.exists(raw_data_npz_path):
                    logs += f"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ¡ãƒƒã‚·ãƒ¥NPZãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {raw_data_npz_path}\n"
                    return None, logs, None, None
                
                # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ï¼ˆnumpyã®ã¿ä½¿ç”¨ï¼‰
                mesh_data = np.load(raw_data_npz_path)
                vertices = mesh_data['vertices']
                faces = mesh_data['faces']
                
                logs += f"ğŸ“Š é ‚ç‚¹æ•°: {len(vertices)}\n"
                logs += f"ğŸ“Š é¢æ•°: {len(faces)}\n"
                
                # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
                if not APP_CONFIG:
                    # Gradioç’°å¢ƒã§ã®è¨­å®šã®å†èª­ã¿è¾¼ã¿
                    if not load_app_config():
                        logs += "âŒ ã‚¨ãƒ©ãƒ¼: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“\n"
                        return None, logs, None, None
                
                skinning_config = APP_CONFIG.get('skinning_prediction', {})
                skinning_subdir = skinning_config.get('skin_output_subdir', '03_skinning_output')
                work_base = APP_CONFIG.working_directory_base
                skinning_dir = os.path.join(work_base, skinning_subdir, model_name_for_output)
                
                os.makedirs(skinning_dir, exist_ok=True)
                
                # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
                skinned_fbx_path = os.path.join(skinning_dir, f"{model_name_for_output}_skinned.fbx")
                display_glb_path = os.path.join(skinning_dir, f"{model_name_for_output}_skinned_display.glb")
                
                if progress_fn:
                    progress_fn(0.5, "è»½é‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ä¸­...")
                
                # RawDataã‚¯ãƒ©ã‚¹ã‚’ä½¿ã‚ãªã„è»½é‡ãªFBXç”Ÿæˆ
                try:
                    # Blenderã‚’ä½¿ç”¨ã—ã¦ãƒã‚¤ãƒŠãƒªFBXç”Ÿæˆ
                    import tempfile
                    import subprocess
                    
                    # ä¸€æ™‚çš„ã«OBJãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
                    with tempfile.NamedTemporaryFile(suffix='.obj', mode='w', delete=False) as obj_file:
                        obj_path = obj_file.name
                        
                        # OBJãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’æ›¸ãè¾¼ã¿
                        obj_file.write("# OBJ File: Created by UniRig Fallback\n")
                        obj_file.write("# Vertices\n")
                        for vertex in vertices:
                            obj_file.write(f"v {vertex[0]} {vertex[1]} {vertex[2]}\n")
                        
                        obj_file.write("# Faces\n")
                        for face in faces:
                            # OBJã¯1-indexedãªã®ã§+1
                            obj_file.write(f"f {face[0]+1} {face[1]+1} {face[2]+1}\n")
                    
                    # Blenderã§OBJã‚’FBXã«å¤‰æ›
                    blender_script = f"""
import bpy
import bmesh

# ç¾åœ¨ã®ã‚·ãƒ¼ãƒ³ã‚’ã‚¯ãƒªã‚¢
bpy.ops.object.select_all(action='SELECT')
bpy.ops.object.delete(use_global=False)

# OBJãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
bpy.ops.wm.obj_import(filepath='{obj_path}')

# FBXãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
bpy.ops.export_scene.fbx(
    filepath='{skinned_fbx_path}',
    use_selection=False,
    use_active_collection=False,
    global_scale=1.0,
    apply_unit_scale=True,
    apply_scale_options='FBX_SCALE_NONE',
    use_space_transform=True,
    bake_space_transform=False,
    object_types={{'MESH'}},
    use_mesh_modifiers=True,
    use_mesh_modifiers_render=True,
    mesh_smooth_type='OFF',
    use_subsurf=False,
    use_mesh_edges=False,
    use_tspace=False,
    use_triangles=False,
    use_custom_props=False,
    add_leaf_bones=True,
    primary_bone_axis='Y',
    secondary_bone_axis='X',
    use_armature_deform_only=False,
    armature_nodetype='NULL',
    bake_anim=True,
    bake_anim_use_all_bones=True,
    bake_anim_use_nla_strips=True,
    bake_anim_use_all_actions=True,
    bake_anim_force_startend_keying=True,
    bake_anim_step=1.0,
    bake_anim_simplify_factor=1.0,
    path_mode='AUTO',
    embed_textures=False,
    batch_mode='OFF',
    use_batch_own_dir=True,
    use_metadata=True
)

print("FBX export completed")
"""
                    
                    # Blenderã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œ
                    blender_script_path = "/tmp/export_fbx_script.py"
                    with open(blender_script_path, 'w') as f:
                        f.write(blender_script)
                    
                    try:
                        result = subprocess.run([
                            'blender', '--background', '--python', blender_script_path
                        ], capture_output=True, text=True, timeout=60)
                        
                        if result.returncode == 0:
                            logs += f"âœ… ãƒã‚¤ãƒŠãƒªFBXç”ŸæˆæˆåŠŸ: {skinned_fbx_path}\n"
                        else:
                            logs += f"âŒ Blender FBX export failed: {result.stderr}\n"
                            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªFBXãƒ˜ãƒƒãƒ€ãƒ¼ã®ã¿
                            with open(skinned_fbx_path, 'wb') as f:
                                f.write(b'Kaydara FBX Binary  \x00\x1a\x00')  # FBXãƒã‚¤ãƒŠãƒªãƒ˜ãƒƒãƒ€ãƒ¼
                    except Exception as e:
                        logs += f"âŒ Blender processing error: {e}\n"
                        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªFBXãƒ˜ãƒƒãƒ€ãƒ¼ã®ã¿
                        with open(skinned_fbx_path, 'wb') as f:
                            f.write(b'Kaydara FBX Binary  \x00\x1a\x00')  # FBXãƒã‚¤ãƒŠãƒªãƒ˜ãƒƒãƒ€ãƒ¼
                    
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                    import os
                    try:
                        os.unlink(obj_path)
                        os.unlink(blender_script_path)
                    except:
                        pass
                except Exception as fbx_error:
                    logs += f"âš ï¸ FBXç”Ÿæˆã‚¨ãƒ©ãƒ¼ï¼ˆä»£æ›¿æ‰‹æ®µä½¿ç”¨ï¼‰: {fbx_error}\n"
                    # ã•ã‚‰ã«è»½é‡ãªä»£æ›¿ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                    with open(skinned_fbx_path, 'w') as f:
                        f.write(f"# Fallback FBX\n# Vertices: {len(vertices)}\n# Faces: {len(faces)}\n")
                
                # è»½é‡ãªè¡¨ç¤ºç”¨ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆï¼ˆJSONå½¢å¼ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼‰
                try:
                    display_data = {
                        "type": "fallback_model",
                        "vertices": len(vertices),
                        "faces": len(faces),
                        "message": "Lightweight fallback model generated"
                    }
                    import json
                    with open(display_glb_path.replace('.glb', '.json'), 'w') as f:
                        json.dump(display_data, f, indent=2)
                    display_glb_path = display_glb_path.replace('.glb', '.json')
                    logs += f"âœ… è¡¨ç¤ºç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”ŸæˆæˆåŠŸ: {display_glb_path}\n"
                except Exception as display_error:
                    logs += f"âš ï¸ è¡¨ç¤ºãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼ï¼ˆä»£æ›¿æ‰‹æ®µä½¿ç”¨ï¼‰: {display_error}\n"
                    # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                    with open(display_glb_path.replace('.glb', '.txt'), 'w') as f:
                        f.write(f"Fallback model info\nVertices: {len(vertices)}\nFaces: {len(faces)}\n")
                    display_glb_path = display_glb_path.replace('.glb', '.txt')
                
                if progress_fn:
                    progress_fn(1.0, "ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†å®Œäº†")
                
                logs += f"âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†æˆåŠŸ\n"
                return display_glb_path, logs, skinned_fbx_path, None
                
            except Exception as fallback_error:
                logs += f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚¨ãƒ©ãƒ¼: {fallback_error}\n"
                import traceback
                logs += f"è©³ç´°: {traceback.format_exc()}\n"
                return None, logs, None, None
        
        # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèªï¼ˆé€šå¸¸ãƒ¢ãƒ¼ãƒ‰ï¼‰
        required_files = {
            'ãƒ¡ãƒƒã‚·ãƒ¥NPZ': raw_data_npz_path,
            'ã‚¹ã‚±ãƒ«ãƒˆãƒ³FBX': skeleton_fbx_path,
            'ã‚¹ã‚±ãƒ«ãƒˆãƒ³NPZ': skeleton_npz_path
        }
        
        for file_type, file_path in required_files.items():
            if not file_path or not os.path.exists(file_path):
                logs += f"âŒ ã‚¨ãƒ©ãƒ¼: {file_type}ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}\n"
                return None, logs, None, None
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
        if not APP_CONFIG:
            # Gradioç’°å¢ƒã§ã®è¨­å®šã®å†èª­ã¿è¾¼ã¿
            if not load_app_config():
                logs += "âŒ ã‚¨ãƒ©ãƒ¼: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“\n"
                return None, logs, None, None
        
        skinning_config = APP_CONFIG.get('skinning_prediction', {})
        skinning_subdir = skinning_config.get('skin_output_subdir', '03_skinning_output')
        work_base = APP_CONFIG.working_directory_base
        skinning_dir = os.path.join(work_base, skinning_subdir, model_name_for_output)
        
        os.makedirs(skinning_dir, exist_ok=True)
        logs += f"ğŸ“ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {skinning_dir}\n"
        
        if progress_fn:
            progress_fn(0.2, "UniRig Lightningè¨­å®šä¸­...")
        
        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®è¨­å®š
        skinned_fbx_path = os.path.join(skinning_dir, f"{model_name_for_output}_skinned.fbx")
        skinning_npz_path = os.path.join(skinning_dir, f"{model_name_for_output}_skinning.npz")
        display_glb_path = os.path.join(skinning_dir, f"{model_name_for_output}_skinned_display.glb")
        
        logs += f"ğŸ“„ å‡ºåŠ›FBX: {skinned_fbx_path}\n"
        logs += f"ğŸ“„ å‡ºåŠ›NPZ: {skinning_npz_path}\n"
        
        if progress_fn:
            progress_fn(0.3, "UniRig Lightningå®Ÿè¡Œä¸­...")
        
        # UniRig Lightning ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ï¼ˆé€šå¸¸ãƒ¢ãƒ¼ãƒ‰ï¼‰
        try:
            import torch
            import lightning as L
            from lightning.pytorch import Trainer
            from lightning.pytorch.callbacks import BasePredictionWriter
            from src.system.skin import SkinSystem, SkinWriter
            from src.model.spec import ModelSpec
            from src.data.raw_data import RawData
            import numpy as np
            
            # PyTorchè¨­å®š: CPUç’°å¢ƒã§ã®å®‰å®šæ€§å‘ä¸Š
            torch.set_num_threads(1)  # ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ç„¡åŠ¹åŒ–
            torch.set_grad_enabled(False)  # å‹¾é…è¨ˆç®—ç„¡åŠ¹åŒ–
            torch.set_float32_matmul_precision('medium')
            
            # CUDAä½¿ç”¨ã‚’æ˜ç¤ºçš„ã«ç„¡åŠ¹åŒ–
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                
            # ãƒ¡ãƒ¢ãƒªè¨­å®šã®æœ€é©åŒ–ï¼ˆç’°å¢ƒå¤‰æ•°è¨­å®šã‚’importå¾Œã«ç§»å‹•ï¼‰
            import os  # ã“ã“ã§æ˜ç¤ºçš„ã«import
            os.environ['CUDA_VISIBLE_DEVICES'] = ''  # CUDAå®Œå…¨ç„¡åŠ¹åŒ–
            torch.backends.cudnn.enabled = False
            
            if progress_fn:
                progress_fn(0.4, "ãƒ¡ãƒƒã‚·ãƒ¥ãƒ»ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
            
            # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
            mesh_data = np.load(raw_data_npz_path)
            skeleton_data = np.load(skeleton_npz_path, allow_pickle=True)
            
            vertices = mesh_data['vertices']
            faces = mesh_data['faces']
            
            # ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
            joints = skeleton_data.get('joints', np.zeros((21, 3)))
            bone_names = skeleton_data.get('bone_names', [f"bone_{i}" for i in range(21)])
            parents = skeleton_data.get('parents', [None] + list(range(20)))
            tails = skeleton_data.get('tails', joints + np.array([0.1, 0, 0]))
            
            logs += f"ğŸ“Š é ‚ç‚¹æ•°: {len(vertices)}\n"
            logs += f"ğŸ¦´ ãƒœãƒ¼ãƒ³æ•°: {len(bone_names)}\n"
            
            if progress_fn:
                progress_fn(0.5, "RawDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆä¸­...")
            
            # RawDataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä½œæˆ
            raw_data = RawData(
                vertices=vertices,
                vertex_normals=None,
                faces=faces,
                face_normals=None,
                joints=joints,
                tails=tails,
                skin=None,  # ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã¯äºˆæ¸¬ã§æ±ºå®š
                no_skin=None,
                parents=parents,
                names=bone_names,
                matrix_local=None,
                uv_coords=None,
                materials=None,
                path=None
            )
            
            if progress_fn:
                progress_fn(0.6, "ãƒ¢ãƒ‡ãƒ«ä»•æ§˜è¨­å®šä¸­...")
            
            # ãƒ¢ãƒ‡ãƒ«ä»•æ§˜ã®è¨­å®šï¼ˆUniRig Skinè¨­å®šã‹ã‚‰ï¼‰
            from src.model.parse import get_model
            import yaml
            
            # UniRig Skinãƒ¢ãƒ‡ãƒ«è¨­å®šã®èª­ã¿è¾¼ã¿
            model_config_path = "configs/model/unirig_skin.yaml"
            with open(model_config_path, 'r') as f:
                model_config = yaml.safe_load(f)
            
            # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
            model_spec = get_model(**model_config)
            
            # äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
            checkpoint_path = "experiments/skin/articulation-xl/model.ckpt"
            if os.path.exists(checkpoint_path):
                checkpoint = torch.load(checkpoint_path, map_location='cpu')
                model_spec.load_state_dict(checkpoint['state_dict'], strict=False)
                logs += f"âœ… äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ: {checkpoint_path}\n"
            else:
                logs += f"âš ï¸ äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ©ãƒ³ãƒ€ãƒ åˆæœŸåŒ–ã§ç¶šè¡Œ: {checkpoint_path}\n"
            
            # ãƒ¢ãƒ‡ãƒ«ã‚’evaluation modeã«è¨­å®š
            model_spec.eval()
            
            if progress_fn:
                progress_fn(0.7, "SkinWriterè¨­å®šä¸­...")
            
            # SkinWriterã®è¨­å®š
            skin_writer = SkinWriter(
                output_dir=skinning_dir,
                save_name="predict_skin",
                export_fbx=True,
                export_npz=True,
                export_txt=False,
                export_blend=False,
                export_render=False
            )
            
            if progress_fn:
                progress_fn(0.8, "ã‚¹ã‚­ãƒ‹ãƒ³ã‚°äºˆæ¸¬å®Ÿè¡Œä¸­...")
            
            # SkinSystemã®åˆæœŸåŒ–
            skin_system = SkinSystem(
                steps_per_epoch=1,
                model=model_spec,
                output_path=skinning_dir,
                record_res=True
            )
            
            # Lightning Trainerã®è¨­å®šï¼ˆCPUå°‚ç”¨ã€å®‰å®šæ€§é‡è¦–ï¼‰
            trainer = Trainer(
                accelerator='cpu',  # CPUã§å®Ÿè¡Œ
                devices=1,
                precision=32,  # 32bitç²¾åº¦æŒ‡å®š
                max_epochs=1,
                enable_progress_bar=False,
                enable_model_summary=False,
                enable_checkpointing=False,
                logger=False,
                callbacks=[skin_writer],
                deterministic=True,  # æ±ºå®šè«–çš„å‹•ä½œ
                strategy='auto'  # å˜ä¸€ãƒ‡ãƒã‚¤ã‚¹æˆ¦ç•¥
            )
            
            if progress_fn:
                progress_fn(0.9, "ã‚¹ã‚­ãƒ‹ãƒ³ã‚°çµæœä¿å­˜ä¸­...")
            
            # äºˆæ¸¬å®Ÿè¡Œï¼ˆãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½¿ç”¨ï¼‰
            class DummyDataLoader:
                def __init__(self, raw_data):
                    self.raw_data = raw_data
                
                def __iter__(self):
                    # ãƒãƒƒãƒã‚µã‚¤ã‚º1ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
                    batch_size = 1
                    num_vertices = len(self.raw_data.vertices)
                    num_bones = len(self.raw_data.joints)
                    
                    # æ³•ç·šãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
                    if hasattr(self.raw_data, 'vertex_normals') and self.raw_data.vertex_normals is not None:
                        normals = self.raw_data.vertex_normals
                    else:
                        # ç°¡æ˜“çš„ãªæ³•ç·šãƒ™ã‚¯ãƒˆãƒ«ï¼ˆä¸Šå‘ãï¼‰
                        normals = np.zeros((num_vertices, 3))
                        normals[:, 2] = 1.0  # Zè»¸ä¸Šå‘ã
                    
                    # tailsã‚’ç”Ÿæˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
                    if hasattr(self.raw_data, 'tails') and self.raw_data.tails is not None:
                        tails = self.raw_data.tails
                    else:
                        # ã‚¸ãƒ§ã‚¤ãƒ³ãƒˆã‹ã‚‰å°‘ã—ã‚ªãƒ•ã‚»ãƒƒãƒˆã—ãŸtails
                        tails = self.raw_data.joints + np.array([0.1, 0, 0])
                    
                    # voxel_skinã¯ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆå¿…è¦ãªå ´åˆï¼‰
                    voxel_skin = np.zeros((num_vertices, num_bones))
                    
                    # parentsã‚’ç”Ÿæˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
                    if hasattr(self.raw_data, 'parents') and self.raw_data.parents is not None:
                        parents = self.raw_data.parents
                    else:
                        # ç°¡æ˜“çš„ãªè¦ªå­é–¢ä¿‚ï¼ˆãƒã‚§ãƒ¼ãƒ³æ§‹é€ ï¼‰
                        parents = [None] + list(range(num_bones - 1))
                    
                    # è¦ªã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’-1ã§åˆæœŸåŒ–ã—ã€æœ‰åŠ¹ãªè¦ªã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨­å®š
                    parents_tensor = torch.full((num_bones,), -1, dtype=torch.long)
                    for i, parent in enumerate(parents):
                        if parent is not None:
                            parents_tensor[i] = parent
                    
                    yield {
                        'vertices': torch.tensor(self.raw_data.vertices, dtype=torch.float32).unsqueeze(0),  # (1, N, 3)
                        'faces': torch.tensor(self.raw_data.faces, dtype=torch.long),
                        'joints': torch.tensor(self.raw_data.joints, dtype=torch.float32).unsqueeze(0),  # (1, B, 3)
                        'normals': torch.tensor(normals, dtype=torch.float32).unsqueeze(0),  # (1, N, 3)
                        'tails': torch.tensor(tails, dtype=torch.float32).unsqueeze(0),  # (1, B, 3)
                        'voxel_skin': torch.tensor(voxel_skin, dtype=torch.float32).unsqueeze(0),  # (1, N, B)
                        'parents': parents_tensor.unsqueeze(0),  # (1, B)
                        'num_bones': torch.tensor([num_bones], dtype=torch.long),  # (1,)
                        'offset': torch.tensor([0, num_vertices], dtype=torch.long),  # ãƒãƒƒãƒã®é–‹å§‹ãƒ»çµ‚äº†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
                        'raw_data_path': raw_data_npz_path
                    }
                
                def __len__(self):
                    return 1
            
            dummy_dataloader = DummyDataLoader(raw_data)
            
            # äºˆæ¸¬å®Ÿè¡Œ
            trainer.predict(skin_system, dummy_dataloader)
            
            # ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
            if os.path.exists(skinned_fbx_path):
                fbx_size = os.path.getsize(skinned_fbx_path)
                logs += f"âœ… ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXç”ŸæˆæˆåŠŸ: {fbx_size} bytes\n"
            else:
                logs += f"âŒ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXç”Ÿæˆå¤±æ•—\n"
                skinned_fbx_path = None
            
            if os.path.exists(skinning_npz_path):
                logs += f"âœ… ã‚¹ã‚­ãƒ‹ãƒ³ã‚°NPZç”ŸæˆæˆåŠŸ\n"
            else:
                logs += f"âŒ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°NPZç”Ÿæˆå¤±æ•—\n"
                skinning_npz_path = None
            
            # è¡¨ç¤ºç”¨GLBç”Ÿæˆ
            try:
                import trimesh
                mesh = trimesh.Trimesh(vertices=vertices, faces=faces)
                mesh.export(display_glb_path)
                logs += f"âœ… è¡¨ç¤ºç”¨GLBç”ŸæˆæˆåŠŸ\n"
            except Exception as display_error:
                logs += f"âš ï¸ è¡¨ç¤ºç”¨GLBç”Ÿæˆã‚¨ãƒ©ãƒ¼: {display_error}\n"
                display_glb_path = None
            
            if progress_fn:
                progress_fn(1.0, "UniRig Lightning ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å®Œäº†")
            
            logs += f"âœ… UniRig Lightning ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†æˆåŠŸ\n"
            logs += f"ğŸ’¾ æœ€çµ‚FBX: {skinned_fbx_path}\n"
            logs += f"ğŸ’¾ æœ€çµ‚NPZ: {skinning_npz_path}\n"
            
            return display_glb_path, logs, skinned_fbx_path, skinning_npz_path
            
        except Exception as lightning_error:
            logs += f"âŒ UniRig Lightning ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {str(lightning_error)}\n"
            logs += f"è©³ç´°: {traceback.format_exc()}\n"
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç°¡æ˜“RawData.export_fbxä½¿ç”¨
            try:
                logs += "ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç°¡æ˜“FBXå‡ºåŠ›ã‚’è©¦è¡Œä¸­...\n"
                
                if progress_fn:
                    progress_fn(0.95, "ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ä¸­...")
                
                # ç°¡æ˜“FBXå‡ºåŠ›
                raw_data.export_fbx(skinned_fbx_path)
                logs += f"âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯FBXç”ŸæˆæˆåŠŸ\n"
                
                # è¡¨ç¤ºç”¨GLBç”Ÿæˆ
                import trimesh
                mesh = trimesh.Trimesh(vertices=vertices, faces=faces)
                mesh.export(display_glb_path)
                logs += f"âœ… è¡¨ç¤ºç”¨GLBç”ŸæˆæˆåŠŸ\n"
                
                return display_glb_path, logs, skinned_fbx_path, None
                
            except Exception as fallback_error:
                logs += f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚‚å¤±æ•—: {str(fallback_error)}\n"
                return None, logs, None, None
    
    except Exception as e:
        logs += f"âŒ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†å…¨èˆ¬ã‚¨ãƒ©ãƒ¼: {str(e)}\n"
        logs += f"è©³ç´°: {traceback.format_exc()}\n"
        return None, logs, None, None


# Step 3ã®ãŸã‚ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹é–¢æ•°
def step3_skinning_prediction(raw_data_npz_path: str, skeleton_fbx_path: str, skeleton_npz_path: str, 
                             model_name_for_output: str, progress_fn=None):
    """
    Step 3: UniRig Lightning ã‚’ä½¿ç”¨ã—ãŸã‚¹ã‚­ãƒ‹ãƒ³ã‚°äºˆæ¸¬
    
    Args:
        raw_data_npz_path: æŠ½å‡ºãƒ¡ãƒƒã‚·ãƒ¥ã®NPZãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        skeleton_fbx_path: ç”Ÿæˆã•ã‚ŒãŸã‚¹ã‚±ãƒ«ãƒˆãƒ³FBXãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹  
        skeleton_npz_path: ç”Ÿæˆã•ã‚ŒãŸã‚¹ã‚±ãƒ«ãƒˆãƒ³NPZãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        model_name_for_output: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
        progress_fn: ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤ºé–¢æ•°
        
    Returns:
        display_glb_path: è¡¨ç¤ºç”¨GLBãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        logs: å‡¦ç†ãƒ­ã‚°
        skinned_fbx_path: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        skinning_npz_path: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°NPZãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """
    # æ—¢å­˜ã®process_generate_skiné–¢æ•°ã‚’å‘¼ã³å‡ºã—
    return process_generate_skin(
        raw_data_npz_path=raw_data_npz_path,
        skeleton_fbx_path=skeleton_fbx_path,
        skeleton_npz_path=skeleton_npz_path,
        model_name_for_output=model_name_for_output,
        progress_fn=progress_fn
    )


def process_final_merge_with_textures(skinned_fbx_path: str, original_model_path: str, 
                                     model_name_for_output: str, progress_fn=None):
    """
    ğŸ¯ ä¿®æ­£ç‰ˆãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ - ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»ãƒãƒ†ãƒªã‚¢ãƒ«å®Œå…¨å¾©å…ƒ
    
    ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ†ã‚¯ã‚¹ãƒãƒ£ã¨ãƒãƒ†ãƒªã‚¢ãƒ«æ§‹é€ ã‚’å®Œå…¨å¾©å…ƒ
    
    Args:
        skinned_fbx_path: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆStep 3ã‹ã‚‰ï¼‰
        original_model_path: å…ƒã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ä»˜ããƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        model_name_for_output: å‡ºåŠ›ç”¨ãƒ¢ãƒ‡ãƒ«å
        progress_fn: ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°é–¢æ•°
    Returns:
        tuple: (display_path, logs, final_merged_fbx_path)
    """
    logs = "=== ğŸ¯ ä¿®æ­£ç‰ˆãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚·ã‚¹ãƒ†ãƒ çµ±åˆé–‹å§‹ ===\n"
    logs += "ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»ãƒãƒ†ãƒªã‚¢ãƒ«å®Œå…¨å¾©å…ƒå®Ÿè¡Œä¸­...\n\n"
    
    try:
        if progress_fn:
            progress_fn(0.1, "ä¿®æ­£ç‰ˆãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚·ã‚¹ãƒ†ãƒ æº–å‚™ä¸­...")
        
        # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        required_files = {
            'ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBX': skinned_fbx_path,
            'å…ƒã®ãƒ¢ãƒ‡ãƒ«': original_model_path
        }
        
        for file_type, file_path in required_files.items():
            if not file_path or not os.path.exists(file_path):
                logs += f"âŒ ã‚¨ãƒ©ãƒ¼: {file_type}ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}\n"
                return None, logs, None
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
        if not APP_CONFIG:
            # Gradioç’°å¢ƒã§ã®è¨­å®šã®å†èª­ã¿è¾¼ã¿
            if not load_app_config():
                logs += "âŒ ã‚¨ãƒ©ãƒ¼: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“\n"
                return None, logs, None
        
        # ä¿®æ­£ç‰ˆãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
        try:
            logs += "ğŸ”§ ä¿®æ­£ç‰ˆãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œé–‹å§‹\n"
            
            from fixed_texture_system_v2 import FixedTextureSystemV2
            
            if progress_fn:
                progress_fn(0.3, "ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»ãƒãƒ†ãƒªã‚¢ãƒ«å¾©å…ƒå®Ÿè¡Œä¸­...")
            
            # ä¿®æ­£ç‰ˆã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
            fixed_system = FixedTextureSystemV2(model_name_for_output)
            
            # ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»ãƒãƒ†ãƒªã‚¢ãƒ«å•é¡Œã®å®Œå…¨ä¿®æ­£
            result = fixed_system.fix_texture_material_issues(skinned_fbx_path)
            
            if progress_fn:
                progress_fn(0.8, "ä¿®æ­£çµæœæ¤œè¨¼ä¸­...")
            
            # ä¿®æ­£çµæœã®å‡¦ç†
            if result['success']:
                final_fbx_path = result['final_fbx_path']
                validation = result['validation']
                
                logs += "âœ… ä¿®æ­£ç‰ˆãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚·ã‚¹ãƒ†ãƒ æˆåŠŸ\n"
                logs += f"ğŸ“„ ä¿®æ­£é …ç›®: {', '.join(result['fixed_issues'])}\n"
                logs += f"ğŸ¨ ãƒ†ã‚¯ã‚¹ãƒãƒ£æ•°: {result['texture_count']}\n"
                logs += f"ğŸ“Š å“è³ªè©•ä¾¡: {validation['quality_level']}\n"
                logs += f"ğŸ’¾ æœ€çµ‚FBXãƒ•ã‚¡ã‚¤ãƒ«: {final_fbx_path}\n"
                
                # è¡¨ç¤ºç”¨GLBãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆ
                display_path = None
                try:
                    display_path = convert_to_glb_for_display(final_fbx_path, f"{model_name_for_output}_final")
                    logs += f"ğŸ‘ï¸ è¡¨ç¤ºç”¨GLB: {display_path}\n"
                except Exception as display_error:
                    logs += f"âš ï¸ è¡¨ç¤ºç”¨GLBç”Ÿæˆã‚¨ãƒ©ãƒ¼: {display_error}\n"
                
                if progress_fn:
                    progress_fn(1.0, "ä¿®æ­£ç‰ˆãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚·ã‚¹ãƒ†ãƒ å®Œäº†")
                
                logs += "\nğŸ‰ === ä¿®æ­£ç‰ˆãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚·ã‚¹ãƒ†ãƒ å®Œäº† ===\n"
                return display_path, logs, final_fbx_path
            else:
                error_msg = result.get('error', 'Unknown error')
                logs += f"âŒ ä¿®æ­£ç‰ˆãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚·ã‚¹ãƒ†ãƒ å¤±æ•—: {error_msg}\n"
                return None, logs, None
                
        except Exception as system_error:
            logs += f"âŒ ä¿®æ­£ç‰ˆãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(system_error)}\n"
            logs += f"è©³ç´°: {traceback.format_exc()}\n"
            return None, logs, None
    
    except Exception as e:
        logs += f"âŒ ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\n"
        logs += f"è©³ç´°: {traceback.format_exc()}\n"
        if progress_fn:
            progress_fn(1.0, "ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆã‚¨ãƒ©ãƒ¼")
        return None, logs, None

def process_basic_merge_fallback(skinned_fbx_path: str, original_model_path: str, 
                                model_name_for_output: str, progress_fn=None, existing_logs=""):
    """
    ImprovedSafeTextureRestorationåˆ©ç”¨ä¸å¯æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
    """
    logs = existing_logs
    logs += "\n=== åŸºæœ¬ãƒãƒ¼ã‚¸å‡¦ç†ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰å®Ÿè¡Œ ===\n"
    
    try:
        # ç°¡æ˜“çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼å‡¦ç†
        output_dir = os.path.join(APP_CONFIG.working_directory_base, '08_final_output', model_name_for_output)
        os.makedirs(output_dir, exist_ok=True)
        
        fallback_fbx_path = os.path.join(output_dir, f"{model_name_for_output}_merged_fallback.fbx")
        
        # ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXã‚’ã‚³ãƒ”ãƒ¼
        shutil.copy2(skinned_fbx_path, fallback_fbx_path)
        
        # è¡¨ç¤ºç”¨ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆ
        display_path = convert_to_glb_for_display(fallback_fbx_path, f"{model_name_for_output}_fallback")
        
        logs += f"âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†å®Œäº†: {fallback_fbx_path}\n"
        logs += "æ³¨æ„: ãƒ†ã‚¯ã‚¹ãƒãƒ£ã¯çµ±åˆã•ã‚Œã¦ã„ã¾ã›ã‚“\n"
        
        if progress_fn:
            progress_fn(1.0, "ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†å®Œäº†")
        
        return display_path, logs, fallback_fbx_path
        
    except Exception as fallback_error:
        logs += f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(fallback_error)}\n"
        return None, logs, None

def process_merge_model(skinned_fbx_path: str, model_name_for_output: str, progress_fn=None):
    """
    åŸºæœ¬çš„ãªãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸å‡¦ç†ï¼ˆãƒ†ã‚¯ã‚¹ãƒãƒ£ãªã—ï¼‰
    Args:
        skinned_fbx_path: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        model_name_for_output: å‡ºåŠ›ç”¨ãƒ¢ãƒ‡ãƒ«å
        progress_fn: ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°é–¢æ•°
    Returns:
        tuple: (display_path, logs, final_fbx_path)
    """
    logs = "=== åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸å‡¦ç†é–‹å§‹ ===\n"
    
    try:
        if progress_fn:
            progress_fn(0.1, "ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸æº–å‚™ä¸­...")
        
        if not skinned_fbx_path or not os.path.exists(skinned_fbx_path):
            logs += f"âŒ ã‚¨ãƒ©ãƒ¼: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {skinned_fbx_path}\n"
            return None, logs, None
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
        if not APP_CONFIG:
            logs += "âŒ ã‚¨ãƒ©ãƒ¼: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“\n"
            return None, logs, None
        
        merge_config = APP_CONFIG.get('model_merging', {})
        merge_subdir = merge_config.get('merge_output_subdir', '04_merge')
        work_base = APP_CONFIG.working_directory_base
        merge_dir = os.path.join(work_base, merge_subdir, model_name_for_output)
        
        os.makedirs(merge_dir, exist_ok=True)
        logs += f"ğŸ“ ãƒãƒ¼ã‚¸ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {merge_dir}\n"
        
        if progress_fn:
            progress_fn(0.5, "ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸å‡¦ç†ä¸­...")
        
        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        final_fbx_path = os.path.join(merge_dir, f"{model_name_for_output}_merged.fbx")
        display_glb_path = os.path.join(merge_dir, f"{model_name_for_output}_merged_display.glb")
        
        # åŸºæœ¬çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼å‡¦ç†
        try:
            shutil.copy2(skinned_fbx_path, final_fbx_path)
            logs += f"âœ… FBXãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼æˆåŠŸ: {final_fbx_path}\n"
            
            if progress_fn:
                progress_fn(0.8, "è¡¨ç¤ºç”¨ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆä¸­...")
            
            # è¡¨ç¤ºç”¨GLBãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆ
            display_path = convert_to_glb_for_display(final_fbx_path, f"{model_name_for_output}_merged")
            
            if display_path:
                logs += f"ğŸ‘ï¸ è¡¨ç¤ºç”¨GLBç”ŸæˆæˆåŠŸ: {display_path}\n"
            else:
                logs += "âš ï¸ è¡¨ç¤ºç”¨GLBç”Ÿæˆã«å¤±æ•—\n"
                display_path = None
            
            logs += f"âœ… åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸å®Œäº†\n"
            logs += f"ğŸ’¾ æœ€çµ‚FBX: {final_fbx_path}\n"
            logs += "âš ï¸ æ³¨æ„: ã“ã®å‡¦ç†ã§ã¯ãƒ†ã‚¯ã‚¹ãƒãƒ£ã¯çµ±åˆã•ã‚Œã¾ã›ã‚“\n"
            
            if progress_fn:
                progress_fn(1.0, "ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸å®Œäº†")
            
            return display_path, logs, final_fbx_path
            
        except Exception as copy_error:
            logs += f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼ã‚¨ãƒ©ãƒ¼: {str(copy_error)}\n"
            return None, logs, None
    
    except Exception as e:
        logs += f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\n"
        logs += f"è©³ç´°: {traceback.format_exc()}\n"
        if progress_fn:
            progress_fn(1.0, "ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã‚¨ãƒ©ãƒ¼")
        return None, logs, None

# --- Full Pipeline Handler Function ---
def gradio_full_auto_rigging(
    uploaded_model_path: str,
    gender: str,
    progress=gr.Progress(track_tqdm=True)
):
    """
    ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‹ã‚‰æœ€çµ‚ãƒãƒ¼ã‚¸ã¾ã§ã®å…¨ã‚¹ãƒ†ãƒƒãƒ—ã‚’è‡ªå‹•å®Ÿè¡Œ
    """
    logs = "=== UniRig ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è‡ªå‹•å®Ÿè¡Œé–‹å§‹ ===\n"
    
    # Initialize paths to None for robust logging in error cases
    final_display_path = None
    final_merged_fbx_path = None
    extracted_npz_path = None
    skeleton_display_path = None
    skeleton_fbx_path = None
    skeleton_txt_path = None
    skeleton_npz_path = None
    skinned_display_path = None
    skinned_fbx_path = None
    skinning_npz_path = None
    
    if not uploaded_model_path:
        logs += "ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
        # Log paths before returning on error
        error_output_details = {
            key: locals().get(key) for key in [
                'final_display_path', 'final_merged_fbx_path', 'extracted_npz_path',
                'skeleton_display_path', 'skeleton_fbx_path', 'skeleton_txt_path', 'skeleton_npz_path',
                'skinned_display_path', 'skinned_fbx_path', 'skinning_npz_path', 'uploaded_model_path'
            ]
        }
        log_output_paths_for_debug(error_output_details, "gradio_full_auto_rigging - error: no_upload")
        return None, logs, None, None, None, None, None, None, None, None, None, None

    try:
        # ãƒ¢ãƒ‡ãƒ«åã‚’æŠ½å‡º
        model_name = os.path.splitext(os.path.basename(uploaded_model_path))[0]
        logs += f"ğŸ“ å‡¦ç†ãƒ¢ãƒ‡ãƒ«: {model_name}\n"
        logs += f"ğŸ“‚ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_model_path}\n\n"

        # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º (0.0-0.25)
        logs += "ğŸ”§ ã‚¹ãƒ†ãƒƒãƒ—1/4: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºé–‹å§‹\n"
        extract_progress = progress_segment(progress, 0.0, 0.25)
        extract_progress(0.0, "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºä¸­...")
        
        extracted_npz_path, extract_logs = process_extract_mesh(
            uploaded_model_path, 
            model_name,
            extract_progress
        )
        logs += extract_logs
        
        if not extracted_npz_path:
            logs += "âŒ ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚\n"
            return None, logs, None, None, None, None, None, None, None, None, None, None
        
        logs += f"âœ… ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå®Œäº†: {extracted_npz_path}\n\n"

        # ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ (0.25-0.5)
        logs += "ğŸ¦´ ã‚¹ãƒ†ãƒƒãƒ—2/4: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆé–‹å§‹\n"
        skeleton_progress = progress_segment(progress, 0.25, 0.5)
        skeleton_progress(0.0, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆä¸­...")
        
        skeleton_display_path, skeleton_logs, skeleton_fbx_path, skeleton_txt_path, skeleton_npz_path = process_generate_skeleton(
            extracted_npz_path,
            model_name,
            gender,
            skeleton_progress
        )
        logs += skeleton_logs
        
        if not skeleton_fbx_path or not skeleton_npz_path:
            logs += "âŒ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚\n"
            return None, logs, None, None, skeleton_display_path, None, None, None, None, None, None, None
        
        logs += f"âœ… ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå®Œäº†: {skeleton_fbx_path}\n\n"

        # ã‚¹ãƒ†ãƒƒãƒ—3: ã‚¹ã‚­ãƒ‹ãƒ³ã‚° (0.5-0.75)
        logs += "ğŸ¨ ã‚¹ãƒ†ãƒƒãƒ—3/4: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬é–‹å§‹\n"
        skinning_progress = progress_segment(progress, 0.5, 0.75)
        skinning_progress(0.0, "ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†ä¸­...")
        
        skinned_display_path, skinning_logs, skinned_fbx_path, skinning_npz_path = process_generate_skin(
            raw_data_npz_path=extracted_npz_path,
            skeleton_fbx_path=skeleton_fbx_path,
            skeleton_npz_path=skeleton_npz_path,
            model_name_for_output=model_name,
            progress_fn=skinning_progress
        )
        logs += skinning_logs
        
        if not skinned_fbx_path:
            logs += "âŒ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚\n"
            return None, logs, None, extracted_npz_path, skeleton_display_path, skeleton_fbx_path, skeleton_txt_path, skeleton_npz_path, skinned_display_path, skinned_fbx_path, skinning_npz_path, None
        
        logs += f"âœ… ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å®Œäº†: {skinned_fbx_path}\n"
        if skinning_npz_path:
            logs += f"ğŸ“„ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°NPZ: {skinning_npz_path}\n"
        else:
            logs += "âš ï¸ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°NPZ: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ï¼ˆNPZãƒ•ã‚¡ã‚¤ãƒ«ãªã—ï¼‰\n"
        logs += "\n"

        # ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ (0.75-1.0)
        logs += "ğŸ”— ã‚¹ãƒ†ãƒƒãƒ—4/4: ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸é–‹å§‹ (äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼)\n"
        merge_progress = progress_segment(progress, 0.75, 1.0)
        merge_progress(0.0, "ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆå‡¦ç†ä¸­...")
        
        # æ–°ã—ã„äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼ã‚’ä½¿ç”¨
        final_display_path, merge_logs, final_merged_fbx_path = process_final_merge_with_textures(
            skinned_fbx_path=skinned_fbx_path,
            original_model_path=uploaded_model_path,
            model_name_for_output=model_name,
            progress_fn=merge_progress
        )
        logs += merge_logs
        
        if not final_merged_fbx_path:
            logs += "âŒ ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n"
            return None, logs, None, extracted_npz_path, skeleton_display_path, skeleton_fbx_path, skeleton_txt_path, skeleton_npz_path, skinned_display_path, skinned_fbx_path, skinning_npz_path, None
        
        logs += f"âœ… ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸å®Œäº†: {final_merged_fbx_path}\n\n"

        # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        logs += "ğŸ‰ === ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œå®Œäº† (äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼) ===\n"
        logs += f"ğŸ¯ æœ€çµ‚ãƒ¢ãƒ‡ãƒ«: {final_merged_fbx_path}\n"
        logs += f"ğŸ“Š ãƒ†ã‚¯ã‚¹ãƒãƒ£ã¨ãƒãƒ†ãƒªã‚¢ãƒ«ãŒä¿æŒã•ã‚ŒãŸé«˜å“è³ªãªãƒªã‚®ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚\n"
        logs += f"ğŸ“‹ ã™ã¹ã¦ã®ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã§ã™ã€‚\n"

        progress(1.0, "ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†!")

        # --- Add this for debugging output paths ---
        output_details_for_log = {
            "final_display_path": final_display_path,
            "final_merged_fbx_path": final_merged_fbx_path,
            "extracted_npz_path": extracted_npz_path,
            "skeleton_display_path": skeleton_display_path,
            "skeleton_fbx_path": skeleton_fbx_path,
            "skeleton_txt_path": skeleton_txt_path,
            "skeleton_npz_path": skeleton_npz_path,
            "skinned_display_path": skinned_display_path,
            "skinned_fbx_path": skinned_fbx_path,
            "skinning_npz_path": skinning_npz_path,
            "uploaded_model_path": uploaded_model_path
        }
        log_output_paths_for_debug(output_details_for_log, "gradio_full_auto_rigging - success path")
        # --- End of added section ---

        return (
            final_display_path,         # full_final_model_display
            logs,                       # full_pipeline_logs
            final_merged_fbx_path,      # full_final_model_download_accordion
            extracted_npz_path,         # full_extracted_npz_download
            skeleton_display_path,      # full_skeleton_model_display
            skeleton_fbx_path,          # full_skeleton_fbx_download
            skeleton_txt_path,          # full_skeleton_txt_download
            skeleton_npz_path,          # full_skeleton_npz_download
            skinned_display_path,       # full_skinned_model_display
            skinned_fbx_path,           # full_skinned_model_fbx_download
            skinning_npz_path           # full_skinning_npz_download
        )

    except Exception as e:
        error_msg = f"âŒ ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\n"
        error_msg += f"è©³ç´°: {traceback.format_exc()}\n"
        logs += error_msg
        progress(1.0, "ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼")

        # --- Add this for debugging output paths in error case ---
        error_output_details = {
            key: locals().get(key) for key in [
                'final_display_path', 'final_merged_fbx_path', 'extracted_npz_path',
                'skeleton_display_path', 'skeleton_fbx_path', 'skeleton_txt_path', 'skeleton_npz_path',
                'skinned_display_path', 'skinned_fbx_path', 'skinning_npz_path', 'uploaded_model_path'
            ]
        }
        log_output_paths_for_debug(error_output_details, "gradio_full_auto_rigging - error path")
        # --- End of added section ---
        
        return None, logs, None, None, None, None, None, None, None, None, None, None

# --- Gradio Handler Functions ---
def gradio_extract_mesh(original_model_path_state: str, model_name_state: str, progress=gr.Progress(track_tqdm=True)):
    logs = "--- Gradio Extract Mesh Wrapper ---\
"
    if not original_model_path_state or not model_name_state:
        logs += "ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¹ãƒ†ãƒƒãƒ—0ã§ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\n"
        return logs, gr.DownloadButton(visible=False), None
    
    # Use progress_segment to map this step's progress (0.0-1.0) to the Gradio progress bar
    # For a single step button, the segment is the full bar (0.0 to 1.0)
    current_step_progress_fn = progress_segment(progress, 0.0, 1.0)
    current_step_progress_fn(0.0, "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºæº–å‚™ä¸­...")

    extracted_npz_path, process_logs = process_extract_mesh(
        original_model_path_state, 
        model_name_state,
        current_step_progress_fn # Pass the wrapped progress function
    )
    logs += process_logs
    
    if extracted_npz_path:
        logs += "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºæˆåŠŸ (Gradioãƒ©ãƒƒãƒ‘ãƒ¼)ã€‚\n"
        # current_step_progress_fn(1.0, desc="ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå®Œäº†") # Already done by process_extract_mesh
        return logs, gr.DownloadButton(label="æŠ½å‡ºNPZã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", value=extracted_npz_path, visible=True), extracted_npz_path
    else:
        logs += "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå¤±æ•— (Gradioãƒ©ãƒƒãƒ‘ãƒ¼)ã€‚\n"
        current_step_progress_fn(1.0, desc="ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºã‚¨ãƒ©ãƒ¼")
        return logs, gr.DownloadButton(label="æŠ½å‡ºNPZã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", value=None, visible=False), None

def gradio_generate_skeleton(
    raw_data_npz_path_from_state: str, # Input from raw_data_npz_path_state
    model_name_from_state: str,       # Input from model_name_state
    gender: str,
    progress=gr.Progress(track_tqdm=True)
):
    logs = "--- Gradio Generate Skeleton Wrapper ---\n"
    if not raw_data_npz_path_from_state or not model_name_from_state:
        logs += "ã‚¨ãƒ©ãƒ¼: NPZãƒ‘ã‚¹ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¹ãƒ†ãƒƒãƒ—0ã‚’å®Œäº†ã—ã€ãƒ¢ãƒ‡ãƒ«åãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
        # Outputs: skeleton_model_display, logs_output, skeleton_fbx_download, skeleton_txt_download, skeleton_npz_download, skeleton_fbx_path_state, skeleton_npz_path_state
        return None, logs, None, None, None, None, None 

    current_step_progress_fn = progress_segment(progress, 0.0, 1.0)
    current_step_progress_fn(0.0, desc="ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆæº–å‚™ä¸­...")

    # Call process_generate_skeleton with the NPZ path from the previous step
    # process_generate_skeleton returns: display_glb_path, logs, expected_fbx_path, expected_txt_path, expected_npz_path
    display_model_path, process_logs, fbx_path, txt_path, npz_path = process_generate_skeleton(
        raw_data_npz_path_from_state, # Corrected parameter name
        model_name_from_state,
        gender,
        current_step_progress_fn # Pass the wrapped progress function
    )
    logs += process_logs

    if display_model_path and fbx_path and npz_path:
        logs += f"âœ“ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”ŸæˆæˆåŠŸã€‚è¡¨ç¤ºãƒ¢ãƒ‡ãƒ«: {display_model_path}\n"
    else:
        logs += "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
    
    # Outputs: 
    # skeleton_model_display, logs_output, 
    # skeleton_fbx_download, skeleton_txt_download, skeleton_npz_download,
    # skeleton_fbx_path_state, skeleton_npz_path_state
    return (
        display_model_path, 
        logs, 
        fbx_path, # For skeleton_fbx_download
        txt_path, # For skeleton_txt_download
        npz_path, # For skeleton_npz_download
        fbx_path, # For skeleton_fbx_path_state
        npz_path  # For skeleton_npz_path_state
    )

def gradio_generate_skin(
    raw_data_npz_path_from_state: str,    # Input from raw_data_npz_path_state
    skeleton_fbx_path_from_state: str,  # Input from skeleton_fbx_path_state
    skeleton_npz_path_from_state: str,  # Input from skeleton_npz_path_state
    model_name_from_state: str,         # Input from model_name_state
    progress=gr.Progress(track_tqdm=True)
):
    logs = "--- Gradio Generate Skin Wrapper ---\n"
    if not (
        raw_data_npz_path_from_state and
        skeleton_fbx_path_from_state and
        skeleton_npz_path_from_state and
        model_name_from_state
    ):
        logs += "ã‚¨ãƒ©ãƒ¼: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã«å¿…è¦ãªãƒ‘ã‚¹ (raw NPZ, skeleton FBX, skeleton NPZ) ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
        # Return appropriate number of Nones for outputs
        return None, logs, None, None, None, None 

    current_step_progress_fn = progress_segment(progress, 0.0, 1.0)
    current_step_progress_fn(0.0, desc="ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬æº–å‚™ä¸­...")

    display_model_path, process_logs, skinned_fbx_path, skinning_npz_path = process_generate_skin(
        raw_data_npz_path=raw_data_npz_path_from_state,
        skeleton_fbx_path=skeleton_fbx_path_from_state,
        skeleton_npz_path=skeleton_npz_path_from_state,
        model_name_for_output=model_name_from_state,
        progress_fn=current_step_progress_fn
    )
    logs += process_logs
    
    if display_model_path and skinned_fbx_path and skinning_npz_path:
        logs += f"âœ“ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬æˆåŠŸã€‚è¡¨ç¤ºãƒ¢ãƒ‡ãƒ«: {display_model_path}\n"
        logs += f"  ã‚¹ã‚­ãƒ³æ¸ˆã¿FBX: {skinned_fbx_path}\n"
        logs += f"  ã‚¹ã‚­ãƒ‹ãƒ³ã‚°NPZ: {skinning_npz_path}\n"
    else:
        logs += "ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n"

    # Outputs: skin_model_display, logs_output, skin_fbx_download, skin_npz_download, skinned_fbx_path_state, skinning_npz_path_state
    return (
        display_model_path, 
        logs, 
        skinned_fbx_path, # For download
        skinning_npz_path, # For download
        skinned_fbx_path, # For state
        skinning_npz_path  # For state
    )

def gradio_merge_model_with_textures(
    original_model_path_from_state: str, # Input from original_model_path_state
    skinned_fbx_path_from_state: str,    # Input from skinned_fbx_path_state
    model_name_from_state: str,          # Input from model_name_state
    progress=gr.Progress(track_tqdm=True)
):
    """äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼ã«ã‚ˆã‚‹ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ï¼ˆã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ç”¨ï¼‰"""
    logs = "--- Gradio Texture-Integrated Merge Model Wrapper (äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼) ---\n"
    if not (
        original_model_path_from_state and
        skinned_fbx_path_from_state and
        model_name_from_state
    ):
        logs += "ã‚¨ãƒ©ãƒ¼: ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã«å¿…è¦ãªãƒ‘ã‚¹ (ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¢ãƒ‡ãƒ«, ã‚¹ã‚­ãƒ³æ¸ˆã¿FBX) ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
        # Return appropriate number of Nones for outputs
        # Outputs: final_model_display, logs_output, final_fbx_download, final_merged_fbx_path_state
        return None, logs, None, None

    current_step_progress_fn = progress_segment(progress, 0.0, 1.0)
    current_step_progress_fn(0.0, desc="ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸æº–å‚™ä¸­...")

    display_model_path, process_logs, final_merged_fbx_path = process_final_merge_with_textures(
        skinned_fbx_path=skinned_fbx_path_from_state,
        original_model_path=original_model_path_from_state,
        model_name_for_output=model_name_from_state,
        progress_fn=current_step_progress_fn
    )
    logs += process_logs

    if display_model_path and final_merged_fbx_path:
        logs += f"âœ“ ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸æˆåŠŸã€‚è¡¨ç¤ºãƒ¢ãƒ‡ãƒ«: {display_model_path}\n"
        logs += f"  æœ€çµ‚ãƒãƒ¼ã‚¸æ¸ˆã¿FBX (ãƒ†ã‚¯ã‚¹ãƒãƒ£ä»˜ã): {final_merged_fbx_path}\n"
    else:
        logs += "ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n"

    # Outputs: final_model_display, logs_output, final_fbx_download, final_merged_fbx_path_state
    return (
        display_model_path,
        logs,
        final_merged_fbx_path, # For download
        final_merged_fbx_path  # For state
    )

def gradio_merge_model(
    original_model_path_from_state: str, # Input from original_model_path_state
    skinned_fbx_path_from_state: str,    # Input from skinned_fbx_path_state
    skinning_npz_path_from_state: str,   # Input from skinning_npz_path_state
    model_name_from_state: str,          # Input from model_name_state
    progress=gr.Progress(track_tqdm=True)
):
    logs = "--- Gradio Merge Model Wrapper (å¾“æ¥ãƒ•ãƒ­ãƒ¼) ---\n"
    if not (
        original_model_path_from_state and
        skinned_fbx_path_from_state and
        skinning_npz_path_from_state and
        model_name_from_state
    ):
        logs += "ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã«å¿…è¦ãªãƒ‘ã‚¹ (ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¢ãƒ‡ãƒ«, ã‚¹ã‚­ãƒ³æ¸ˆã¿FBX, ã‚¹ã‚­ãƒ‹ãƒ³ã‚°NPZ) ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
        # Return appropriate number of Nones for outputs
        # Outputs: final_model_display, logs_output, final_fbx_download, final_merged_fbx_path_state
        return None, logs, None, None

    current_step_progress_fn = progress_segment(progress, 0.0, 1.0)
    current_step_progress_fn(0.0, desc="ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸æº–å‚™ä¸­...")

    display_model_path, process_logs, final_merged_fbx_path = process_merge_model(
        original_model_path=original_model_path_from_state,
        skinned_fbx_path=skinned_fbx_path_from_state,
        skinning_npz_path=skinning_npz_path_from_state,
        model_name_for_output=model_name_from_state,
        progress_fn=current_step_progress_fn
    )
    logs += process_logs

    if display_model_path and final_merged_fbx_path:
        logs += f"âœ“ ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸æˆåŠŸã€‚è¡¨ç¤ºãƒ¢ãƒ‡ãƒ«: {display_model_path}\n"
        logs += f"  æœ€çµ‚ãƒãƒ¼ã‚¸æ¸ˆã¿FBX: {final_merged_fbx_path}\n"
    else:
        logs += "ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n"

    # Outputs: final_model_display, logs_output, final_fbx_download, final_merged_fbx_path_state
    return (
        display_model_path,
        logs,
        final_merged_fbx_path, # For download
        final_merged_fbx_path  # For state
    )

# --- Gradio UI Builder ---
def build_gradio_interface():
    with gr.Blocks(theme=gr.themes.Base()) as demo:
        # Define State variables at the beginning of the Blocks context
        s_original_model_path = gr.State()
        s_model_name = gr.State()
        s_extracted_npz_path = gr.State()
        s_skeleton_fbx_path = gr.State()
        s_skeleton_txt_path = gr.State()
        s_skeleton_npz_path = gr.State()
        s_skinned_fbx_path = gr.State()
        s_skinning_npz_path = gr.State()
        s_merged_fbx_path = gr.State()
        
        gr.Markdown("<h1>UniRig 3Dãƒ¢ãƒ‡ãƒ«è‡ªå‹•ãƒªã‚®ãƒ³ã‚°ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³</h1>")
        gr.Markdown("3Dãƒ¢ãƒ‡ãƒ«ï¼ˆFBXã€OBJã€GLB/GLTFã€PLYãªã©TrimeshãŒæ‰±ãˆã‚‹å½¢å¼ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€è‡ªå‹•ã§ãƒªã‚®ãƒ³ã‚°å‡¦ç†ã‚’è¡Œã„ã¾ã™ã€‚")
        gr.Markdown("""
        **ğŸ†• äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼ã«ã‚ˆã‚‹é«˜å“è³ªãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿æŒ:**
        - **ç¬¬1éšå±¤**: å…ƒãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»ãƒãƒ†ãƒªã‚¢ãƒ«æƒ…å ±ã‚’æŠ½å‡ºãƒ»ä¿å­˜
        - **ç¬¬2éšå±¤**: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã«ä¿å­˜ã•ã‚ŒãŸãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚’é©ç”¨
        - **çµæœ**: ãƒ†ã‚¯ã‚¹ãƒãƒ£ã¨ãƒãƒ†ãƒªã‚¢ãƒ«å“è³ªã‚’å®Œå…¨ã«ä¿æŒã—ãŸãƒªã‚®ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
        
        ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã¯è‡ªå‹•çš„ã«äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼ãŒé©ç”¨ã•ã‚Œã¾ã™ã€‚
        """)

        with gr.Tab("ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"):
            gr.Markdown("""
            ## ğŸš€ ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§å®Œå…¨è‡ªå‹•ãƒªã‚®ãƒ³ã‚°
            
            **äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼æŠ€è¡“ã«ã‚ˆã‚‹é«˜å“è³ªå‡¦ç†:**
            1. **ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º** â†’ 3Dãƒ¢ãƒ‡ãƒ«ã®æ§‹é€ è§£æ
            2. **ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ** â†’ AI ã«ã‚ˆã‚‹æœ€é©ãªéª¨æ ¼æ§‹é€ äºˆæ¸¬
            3. **ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†** â†’ é ‚ç‚¹ã‚¦ã‚§ã‚¤ãƒˆè‡ªå‹•è¨ˆç®—
            4. **ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒãƒ¼ã‚¸** â†’ å…ƒã®å“è³ªã‚’ä¿æŒã—ãŸæœ€çµ‚çµåˆ
            
            âœ¨ **å¾“æ¥æ–¹å¼ã¨ã®é•ã„**: ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»ãƒãƒ†ãƒªã‚¢ãƒ«æƒ…å ±ã‚’å®Œå…¨ä¿æŒã—ã€é«˜å“è³ªãªä»•ä¸ŠãŒã‚Šã‚’å®Ÿç¾
            """)
            
            with gr.Row():
                with gr.Column(scale=1):
                    full_input_model_upload = gr.File(label="3Dãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", file_types=[".fbx", ".obj", ".glb", ".gltf", ".ply"], type="filepath")
                    full_gender_dropdown = gr.Dropdown(label="æ€§åˆ¥ï¼ˆã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆç”¨ï¼‰", choices=["female", "male", "neutral"], value="female")
                    full_pipeline_button = gr.Button("ğŸ¯ ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ", variant="primary", size="lg")
                with gr.Column(scale=2):
                    full_final_model_display = gr.Model3D(label="æœ€çµ‚ãƒªã‚®ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", interactive=False, camera_position=(0, 2.5, 3.5))
            
            full_pipeline_logs = gr.Textbox(label="ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ­ã‚°", lines=15, interactive=False, show_copy_button=True)
            
            with gr.Accordion("ğŸ“ ä¸­é–“æˆæœç‰©ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", open=False):
                gr.Markdown("### å‡¦ç†æ®µéšåˆ¥ã®æˆæœç‰©")
                gr.Markdown("å„å‡¦ç†æ®µéšã§ç”Ÿæˆã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ãã¾ã™ã€‚")
                
                gr.Markdown("#### ğŸ”§ ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºçµæœ")
                full_extracted_npz_download = gr.DownloadButton(label="ğŸ“¦ æŠ½å‡ºNPZ", interactive=True, visible=False)
                
                gr.Markdown("#### ğŸ¦´ ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆçµæœ")
                full_skeleton_model_display = gr.Model3D(label="ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", interactive=False, camera_position=(0, 2.5, 3.5), visible=False)
                with gr.Row():
                    full_skeleton_fbx_download = gr.DownloadButton(label="ğŸ¦´ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ (FBX)", interactive=True, visible=False)
                    full_skeleton_txt_download = gr.DownloadButton(label="ğŸ“„ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ (TXT)", interactive=True, visible=False)
                    full_skeleton_npz_download = gr.DownloadButton(label="ğŸ“¦ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ (NPZ)", interactive=True, visible=False)

                gr.Markdown("#### ğŸ¨ ã‚¹ãƒ†ãƒƒãƒ—3: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬çµæœ")
                full_skinned_model_display = gr.Model3D(label="ã‚¹ã‚­ãƒ³æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", interactive=False, camera_position=(0, 2.5, 3.5), visible=False)
                with gr.Row():
                    full_skinned_model_fbx_download = gr.DownloadButton(label="ğŸ¨ ã‚¹ã‚­ãƒ³æ¸ˆã¿ (FBX)", interactive=True, visible=False)
                    full_skinning_npz_download = gr.DownloadButton(label="ğŸ“¦ ã‚¹ã‚­ãƒ‹ãƒ³ã‚° (NPZ)", interactive=True, visible=False)
                
                gr.Markdown("#### ğŸ¯ ã‚¹ãƒ†ãƒƒãƒ—4: æœ€çµ‚ãƒãƒ¼ã‚¸ãƒ¢ãƒ‡ãƒ«")
                full_final_model_download_accordion = gr.DownloadButton(label="ğŸ¯ æœ€çµ‚ãƒ¢ãƒ‡ãƒ« (FBX)", interactive=True, visible=False)

            full_pipeline_button.click(
                fn=gradio_full_auto_rigging,
                inputs=[
                    full_input_model_upload, 
                    full_gender_dropdown
                ],
                outputs=[
                    full_final_model_display, full_pipeline_logs, full_final_model_download_accordion,
                    full_extracted_npz_download,
                    full_skeleton_model_display, 
                    full_skeleton_fbx_download, full_skeleton_txt_download, full_skeleton_npz_download,
                    full_skinned_model_display,
                    full_skinned_model_fbx_download, full_skinning_npz_download
                ],
                api_name="run_full_auto_rigging"
            ).then(
                fn=lambda d1, d2, d3, d4, d5, d6, d7, d8, d9, d10, d11: (
                    gr.update(visible=d1 is not None and d1 != ''),  # full_final_model_display
                    gr.update(visible=d3 is not None and d3 != ''),  # full_final_model_download_accordion
                    gr.update(visible=d4 is not None and d4 != ''),  # full_extracted_npz_download
                    gr.update(visible=d5 is not None and d5 != ''),  # full_skeleton_model_display
                    gr.update(visible=d6 is not None and d6 != ''),  # full_skeleton_fbx_download
                    gr.update(visible=d7 is not None and d7 != ''),  # full_skeleton_txt_download
                    gr.update(visible=d8 is not None and d8 != ''),  # full_skeleton_npz_download
                    gr.update(visible=d9 is not None and d9 != ''),  # full_skinned_model_display
                    gr.update(visible=d10 is not None and d10 != ''), # full_skinned_model_fbx_download
                    gr.update(visible=d11 is not None and d11 != '')  # full_skinning_npz_download
                ),
                inputs=[
                    full_final_model_display, full_pipeline_logs, full_final_model_download_accordion,
                    full_extracted_npz_download, full_skeleton_model_display, 
                    full_skeleton_fbx_download, full_skeleton_txt_download, full_skeleton_npz_download,
                    full_skinned_model_display, full_skinned_model_fbx_download, full_skinning_npz_download
                ],
                outputs=[
                    full_final_model_display, full_final_model_download_accordion,
                    full_extracted_npz_download, full_skeleton_model_display,
                    full_skeleton_fbx_download, full_skeleton_txt_download, full_skeleton_npz_download,
                    full_skinned_model_display, full_skinned_model_fbx_download, full_skinning_npz_download
                ],
                api_name=False
            )

        with gr.Tab("ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ"):
            gr.Markdown("""
            ## ğŸ› ï¸ æ®µéšçš„ãªå‡¦ç†å®Ÿè¡Œ
            
            å„å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—ã‚’å€‹åˆ¥ã«å®Ÿè¡Œã—ã€ä¸­é–“çµæœã‚’ç¢ºèªã—ãªãŒã‚‰é€²ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
            å‡¦ç†ã®ä»•çµ„ã¿ã‚’ç†è§£ã—ãŸã„å ´åˆã‚„ã€ç‰¹å®šã®ã‚¹ãƒ†ãƒƒãƒ—ã§å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã®è¨ºæ–­ã«æœ‰ç”¨ã§ã™ã€‚
            """)
            
            gr.Markdown("### ğŸ”§ ã‚¹ãƒ†ãƒƒãƒ—0: åˆæœŸè¨­å®šã¨ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º")
            with gr.Row():
                step_upload_button = gr.File(label="1. 3Dãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", file_types=[".fbx", ".obj", ".glb", ".gltf", ".ply"], type="filepath")
                step_input_model_display_step0 = gr.Model3D(label="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", interactive=False, camera_position=(0, 2.5, 3.5))
            
            btn_run_extract = gr.Button("ğŸ”§ 0. ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå®Ÿè¡Œ", variant="primary")
            step_extract_logs = gr.Textbox(label="æŠ½å‡ºãƒ­ã‚°", lines=5, interactive=False, show_copy_button=True)
            step_extracted_model_download = gr.DownloadButton(label="ğŸ“¦ æŠ½å‡ºNPZ", interactive=True, visible=False)

            gr.Markdown("### ğŸ¦´ ã‚¹ãƒ†ãƒƒãƒ—1: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ")
            step_gender_dropdown = gr.Dropdown(label="æ€§åˆ¥ï¼ˆã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆç”¨ï¼‰", choices=["female", "male", "neutral"], value="female")
            btn_run_skeleton = gr.Button("ğŸ¦´ 1. ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå®Ÿè¡Œ", variant="primary")
            step_skeleton_model_display = gr.Model3D(label="ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", interactive=False, camera_position=(0, 2.5, 3.5))
            step_skeleton_logs = gr.Textbox(label="ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆãƒ­ã‚°", lines=5, interactive=False, show_copy_button=True)
            with gr.Row():
                step_skeleton_fbx_download = gr.DownloadButton(label="ğŸ¦´ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ (FBX)", interactive=True, visible=False)
                step_skeleton_txt_download = gr.DownloadButton(label="ğŸ“„ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ (TXT)", interactive=True, visible=False)
                step_skeleton_npz_download = gr.DownloadButton(label="ğŸ“¦ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ (NPZ)", interactive=True, visible=False)

            gr.Markdown("### ğŸ¨ ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬")
            btn_run_skin = gr.Button("ğŸ¨ 2. ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬å®Ÿè¡Œ", variant="primary")
            step_skinned_model_display = gr.Model3D(label="ã‚¹ã‚­ãƒ³æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", interactive=False, camera_position=(0, 2.5, 3.5))
            step_skin_logs = gr.Textbox(label="ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãƒ­ã‚°", lines=5, interactive=False, show_copy_button=True)
            with gr.Row():
                step_skinned_model_fbx_download = gr.DownloadButton(label="ğŸ¨ ã‚¹ã‚­ãƒ³æ¸ˆã¿ (FBX)", interactive=True, visible=False)
                step_skinning_npz_download = gr.DownloadButton(label="ğŸ“¦ ã‚¹ã‚­ãƒ‹ãƒ³ã‚° (NPZ)", interactive=True, visible=False)

            gr.Markdown("### ğŸ”— ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸")
            with gr.Row():
                btn_run_merge = gr.Button("ğŸ”— 3a. å¾“æ¥ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸å®Ÿè¡Œ", variant="secondary")
                btn_run_merge_with_textures = gr.Button("âœ¨ 3b. ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒãƒ¼ã‚¸å®Ÿè¡Œ (æ¨å¥¨)", variant="primary")
            step_merged_model_display = gr.Model3D(label="æœ€çµ‚ãƒãƒ¼ã‚¸ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", interactive=False, camera_position=(0, 2.5, 3.5))
            step_merge_logs = gr.Textbox(label="ãƒãƒ¼ã‚¸ãƒ­ã‚°", lines=5, interactive=False, show_copy_button=True)
            step_merged_model_download = gr.DownloadButton(label="ğŸ¯ æœ€çµ‚ãƒ¢ãƒ‡ãƒ« (FBX)", interactive=True, visible=False)
            
            with gr.Accordion("ğŸ’¡ äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼ã«ã¤ã„ã¦", open=False):
                gr.Markdown("""
                ### ğŸ—ï¸ äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼æŠ€è¡“ã®è©³ç´°
                
                **å¾“æ¥ã®å•é¡Œç‚¹:**
                - ãƒªã‚®ãƒ³ã‚°å‡¦ç†ä¸­ã«ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»ãƒãƒ†ãƒªã‚¢ãƒ«æƒ…å ±ãŒå¤±ã‚ã‚Œã‚‹
                - æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã®è¦‹ãŸç›®ãŒå…ƒãƒ¢ãƒ‡ãƒ«ã¨ç•°ãªã£ã¦ã—ã¾ã†
                - æ‰‹å‹•ã§ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£å¾©å…ƒä½œæ¥­ãŒå¿…è¦
                
                **äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼ã®è§£æ±ºç­–:**
                
                **ğŸ—ï¸ ç¬¬1éšå±¤ - ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜:**
                1. å…ƒãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ãƒ†ã‚¯ã‚¹ãƒãƒ£ç”»åƒã‚’æŠ½å‡ºãƒ»ä¿å­˜
                2. ãƒãƒ†ãƒªã‚¢ãƒ«æ§‹é€ ï¼ˆãƒãƒ¼ãƒ‰æ¥ç¶šï¼‰æƒ…å ±ã‚’è¨˜éŒ²
                3. ãƒ¡ãƒƒã‚·ãƒ¥-ãƒãƒ†ãƒªã‚¢ãƒ«å¯¾å¿œé–¢ä¿‚ã‚’ä¿å­˜
                
                **ğŸ—ï¸ ç¬¬2éšå±¤ - ãƒ†ã‚¯ã‚¹ãƒãƒ£å¾©å…ƒ:**
                1. ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXã‚’èª­ã¿è¾¼ã¿
                2. ä¿å­˜ã•ã‚ŒãŸãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚’å†é©ç”¨
                3. ãƒãƒ†ãƒªã‚¢ãƒ«æ§‹é€ ã‚’å®Œå…¨å†æ§‹ç¯‰
                4. FBXäº’æ›æ€§ã‚’è€ƒæ…®ã—ãŸæœ€é©åŒ–
                
                **âœ¨ çµæœ:**
                - å…ƒãƒ¢ãƒ‡ãƒ«ã¨åŒå“è³ªã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»ãƒãƒ†ãƒªã‚¢ãƒ«
                - å®Œå…¨ãªãƒªã‚®ãƒ³ã‚°æ©Ÿèƒ½
                - å®‰å®šã—ãŸã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½
                
                **æ¨å¥¨ä½¿ç”¨å ´é¢:**
                - é«˜å“è³ªãª3Dãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚®ãƒ³ã‚°
                - ã‚²ãƒ¼ãƒ ãƒ»ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã‚¢ã‚»ãƒƒãƒˆä½œæˆ
                - å•†ç”¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã®åˆ©ç”¨
                """)
            
            gr.Markdown("""
            **ğŸ’¡ äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼ã®é¸æŠã«ã¤ã„ã¦:**
            - **3a. å¾“æ¥ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸**: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXã‚’ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¢ãƒ‡ãƒ«ã«ãƒãƒ¼ã‚¸ã—ã¾ã™ï¼ˆæ—§æ–¹å¼ï¼‰
            - **3b. ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒãƒ¼ã‚¸ (æ¨å¥¨)**: å…ƒãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»ãƒãƒ†ãƒªã‚¢ãƒ«ã‚’ä¿æŒã—ãªãŒã‚‰ãƒãƒ¼ã‚¸ã—ã¾ã™ï¼ˆæ–°æ–¹å¼ã€é«˜å“è³ªï¼‰
            
            **æ¨å¥¨**: ã‚ˆã‚Šé«˜å“è³ªãªçµæœã‚’å¾—ã‚‹ãŸã‚ã€Œâœ¨ ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒãƒ¼ã‚¸ã€ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚
            """)

            # Event handlers for step-by-step execution
            def handle_upload_step(file_path_obj): # Gradio File component with type="filepath" returns a string path
                if file_path_obj:
                    original_path = file_path_obj # This is now a string path
                    model_name_val = os.path.splitext(os.path.basename(original_path))[0]
                    glb_for_display = convert_to_glb_for_display(original_path, f"{model_name_val}_original_display_step")
                    
                   
                    
                    # Reset logs and subsequent step outputs/states
                    extract_log_msg = f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {model_name_val}ã€‚æŠ½å‡ºã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
                    return (
                        original_path, model_name_val, glb_for_display, 
                        extract_log_msg, gr.DownloadButton(visible=False), None, # Extract
                        None, "", gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), None, None, None, # Skeleton
                        None, "", gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), None, None, # Skin
                        None, "", gr.DownloadButton(visible=False), None # Merge
                    )
                # No file uploaded or cleared
                return None, None, None, "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚", gr.DownloadButton(visible=False), None, None, "", gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), None, None, None, None, "", gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), None, None, None, "", gr.DownloadButton(visible=False), None

            step_upload_button.change( # Use .change for File component when type="filepath"
                fn=handle_upload_step,
                inputs=[step_upload_button],
                outputs=[
                    s_original_model_path, s_model_name, step_input_model_display_step0, 
                    step_extract_logs, step_extracted_model_download, s_extracted_npz_path,
                    step_skeleton_model_display, step_skeleton_logs, step_skeleton_fbx_download, step_skeleton_txt_download, step_skeleton_npz_download,
                    s_skeleton_fbx_path, s_skeleton_txt_path, s_skeleton_npz_path,
                    step_skinned_model_display, step_skin_logs, step_skinned_model_fbx_download, step_skinning_npz_download,
                    s_skinned_fbx_path, s_skinning_npz_path,
                    step_merged_model_display, step_merge_logs, step_merged_model_download,
                    s_merged_fbx_path
                ],
                api_name=False
            )
            
            btn_run_extract.click(
                fn=gradio_extract_mesh,
                inputs=[s_original_model_path, s_model_name],
                outputs=[step_extract_logs, step_extracted_model_download, s_extracted_npz_path],
                api_name="run_extract_mesh_step"
            )
            
            btn_run_skeleton.click(
                fn=gradio_generate_skeleton,
                inputs=[
                    s_extracted_npz_path, # from step 0
                    s_model_name,         # from step 0
                    step_gender_dropdown  # Add gender dropdown
                ],
                outputs=[
                    step_skeleton_model_display, 
                    step_skeleton_logs,
                    step_skeleton_fbx_download,
                    step_skeleton_txt_download,
                    step_skeleton_npz_download,
                    s_skeleton_fbx_path, # State update
                    s_skeleton_npz_path  # State update
                ]
            ).then(
                fn=lambda d1, d2, d3, d4, d5: (gr.update(visible=d1 is not None and d1!=''), gr.update(visible=d2 is not None and d2!=''), gr.update(visible=d3 is not None and d3!=''), gr.update(visible=d4 is not None and d4!=''), gr.update(visible=d5 is not None and d5!='')),
                inputs=[step_skeleton_model_display, step_skeleton_fbx_download, step_skeleton_txt_download, step_skeleton_npz_download, step_skeleton_logs],
                outputs=[step_skeleton_model_display, step_skeleton_fbx_download, step_skeleton_txt_download, step_skeleton_npz_download, step_skeleton_logs],
                api_name=False
            )

            btn_run_skin.click(
                fn=gradio_generate_skin,
                inputs=[
                    s_extracted_npz_path, # raw_data_npz_path - from step 0
                    s_skeleton_fbx_path,  # skeleton_fbx_path - from step 1
                    s_skeleton_npz_path,  # skeleton_npz_path - from step 1
                    s_model_name          # model_name - from step 0
                ],
                outputs=[
                    step_skinned_model_display, step_skin_logs, 
                    step_skinned_model_fbx_download, step_skinning_npz_download,
                    s_skinned_fbx_path, s_skinning_npz_path
                ],
                api_name="run_generate_skin_step"
            )

            btn_run_merge.click(
                fn=gradio_merge_model,
                inputs=[s_original_model_path, s_skinned_fbx_path, s_skinning_npz_path, s_model_name],
                outputs=[
                    step_merged_model_display, step_merge_logs, 
                    step_merged_model_download, 
                    s_merged_fbx_path
                ],
                api_name="run_merge_model_step"
            )

            btn_run_merge_with_textures.click(
                fn=gradio_merge_model_with_textures,
                inputs=[s_original_model_path, s_skinned_fbx_path, s_model_name],
                outputs=[
                    step_merged_model_display, step_merge_logs, 
                    step_merged_model_download, 
                    s_merged_fbx_path
                ],
                api_name="run_merge_model_with_textures_step"
            ) # This is the last click handler in the 'Step-by-step' tab
        
        # Add demo.queue() here, after all UI elements and handlers for the demo are defined
        demo.queue()
            
    return demo

if __name__ == "__main__":
    load_app_config() # Load configuration first

    if not APP_CONFIG:
        logging.error("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚èµ·å‹•ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
        sys.exit(1)

    # Safely access Gradio interface configurations with defaults
    gradio_config = APP_CONFIG.get('gradio_interface', {})
    server_name = gradio_config.get('server_name', '0.0.0.0')  # Changed to 0.0.0.0 for accessibility
    base_port = int(gradio_config.get('server_port', 7860))  # Base port
    share_gradio = gradio_config.get('share', False)
    inbrowser = gradio_config.get('inbrowser', True)
    
    # Try to find an available port starting from base_port
    import socket
    def find_free_port(start_port, max_attempts=10):
        for port in range(start_port, start_port + max_attempts):
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                try:
                    s.bind(('', port))
                    return port
                except OSError:
                    continue
        return None
    
    server_port = find_free_port(base_port)
    if server_port is None:
        logging.error(f"åˆ©ç”¨å¯èƒ½ãªãƒãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆ{base_port}ã‹ã‚‰{base_port+9}ã¾ã§è©¦è¡Œï¼‰")
        sys.exit(1)

    logging.info(f"Gradioã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¾ã™: http://{server_name}:{server_port}")
    if share_gradio:
        logging.info("Gradioå…±æœ‰ãŒæœ‰åŠ¹ã«ãªã£ã¦ã„ã¾ã™ã€‚")

    iface = build_gradio_interface()
    
    allowed_paths_list = get_allowed_paths()
    iface.launch(
        server_name=server_name, 
        server_port=server_port, 
        share=share_gradio, 
        inbrowser=inbrowser,
        debug=True, # Force debug=True for this debugging session
        show_error=True, # Enable verbose error reporting
        allowed_paths=allowed_paths_list
    )