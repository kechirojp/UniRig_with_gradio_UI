"""
ğŸ¯ UniRig WebUIå®Œå…¨ç‰ˆ - src/pipelineçµ±åˆãƒ»æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥å®Œå…¨é©ç”¨

æ”¹ä¿®å®Œäº† (2025å¹´6æœˆ14æ—¥ - æœ€çµ‚çµ±åˆç‰ˆ):
1. src/pipelineçµ±åˆã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰é‡è¤‡è§£æ¶ˆ
2. æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥å®Œå…¨é©ç”¨ 
3. åŸæµå‡¦ç†äº’æ›æ€§100%ç¢ºä¿
4. ã‚¨ãƒ©ãƒ¼å‡¦ç†ãƒ»æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ å¼·åŒ–
5. ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å®Œå…¨å¯¾å¿œ
"""
import gradio as gr
import os
import shutil
import time
import logging
import subprocess
import socket
import sys
from pathlib import Path
from typing import Tuple, Optional, Dict, Any

# ğŸ¯ æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç®¡ç†ã‚¯ãƒ©ã‚¹ï¼ˆãƒ¡ã‚¤ãƒ³ã®æ–½ç­–ï¼‰
from fixed_directory_manager import FixedDirectoryManager

# ğŸ”§ çµ±ä¸€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼ˆå®Œå…¨ç‰ˆï¼‰
from unified_pipeline_orchestrator import UnifiedPipelineOrchestrator

# ğŸ”§ src/pipelineçµ±åˆã‚¯ãƒ©ã‚¹
from src.pipeline.unified_extract import UnifiedExtractor
from src.pipeline.unified_skinning import UnifiedSkinningOrchestrator

# ğŸ”§ step_modulesçµ±åˆã‚¯ãƒ©ã‚¹
# Step1, Step2 imports will be done dynamically within functions to avoid conflicts
from src.pipeline.unified_merge import UnifiedMergeOrchestrator
from src.pipeline.unified_blender import UnifiedBlenderOrchestrator
from src.pipeline.pipeline_error_analyzer import PipelineErrorAnalyzer

# ğŸ”§ step_modulesçµ±åˆã‚¯ãƒ©ã‚¹
from step_modules.step0_asset_preservation import Step0AssetPreservation

# å®šæ•°
PIPELINE_BASE_DIR = Path("/app/pipeline_work")
DEFAULT_MODEL_NAME = "default_model"

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ­ã‚¬ãƒ¼è¨­å®š ---
app_logger = logging.getLogger("UniRigApp")
if not app_logger.handlers:
    app_logger.setLevel(logging.DEBUG)
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    console_handler.setFormatter(console_formatter)
    app_logger.addHandler(console_handler)

# --- ã‚·ãƒ³ãƒ—ãƒ«FileManagerã‚¯ãƒ©ã‚¹ ---
# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ---
def extract_model_name_from_file(file_path: str) -> str:
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«åã‚’æŠ½å‡º"""
    if not file_path:
        return DEFAULT_MODEL_NAME
    
    filename = Path(file_path).stem  # æ‹¡å¼µå­ã‚’é™¤ã„ãŸãƒ•ã‚¡ã‚¤ãƒ«å
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ äº’æ›æ€§ã®ãŸã‚ã‚µãƒ‹ã‚¿ã‚¤ã‚º
    sanitized = filename.replace(" ", "_").replace(":", "_").replace("/", "_")
    return sanitized if sanitized else DEFAULT_MODEL_NAME

def execute_complete_pipeline(uploaded_file_info, gender: str) -> tuple[bool, str]:
    """ä¸€æ°—é€šè²«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œï¼ˆè©³ç´°ãƒ­ã‚°ç‰ˆï¼‰"""
    if not uploaded_file_info:
        return False, "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ãƒ¢ãƒ‡ãƒ«åã‚’è‡ªå‹•å–å¾—
    model_name = extract_model_name_from_file(uploaded_file_info.name)
    input_file_path = uploaded_file_info.name
    
    app_logger.info(f"ä¸€æ°—é€šè²«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹: {model_name}")
    
    # è©³ç´°ãƒ­ã‚°ã®åˆæœŸåŒ–
    detailed_logs = []
    detailed_logs.append(f"ğŸ“Š ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è©³ç´°ãƒ­ã‚°")
    detailed_logs.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    
    try:
        # äº‹å‰ã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼
        detailed_logs.append(f"ğŸ” ã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼é–‹å§‹...")
        error_analyzer = PipelineErrorAnalyzer(app_logger)
        system_check = error_analyzer.validate_system_requirements()
        if not system_check["valid"]:
            detailed_logs.append(f"âŒ ã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼å¤±æ•—: {system_check['message']}")
            return False, "\n".join(detailed_logs)
        detailed_logs.append(f"âœ… ã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼å®Œäº†")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ (æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥)
        detailed_logs.append(f"ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆä¸­...")
        fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
        fdm.create_all_directories()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        original_filename = Path(input_file_path).name
        target_path = fdm.model_dir / original_filename
        file_size = Path(input_file_path).stat().st_size / (1024 * 1024)  # MB
        shutil.copy(input_file_path, target_path)
        app_logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {target_path}")
        detailed_logs.append(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: {original_filename} ({file_size:.2f}MB)")
        detailed_logs.append(f"ğŸ“‚ ä¿å­˜å…ˆ: {target_path}")
        
        # Step 0: ã‚¢ã‚»ãƒƒãƒˆä¿å­˜
        detailed_logs.append(f"")
        detailed_logs.append(f"ğŸ”§ Step 0: ã‚¢ã‚»ãƒƒãƒˆä¿å­˜é–‹å§‹")
        detailed_logs.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        app_logger.info(f"Step 0 é–‹å§‹: {model_name}")
        success, step_logs = execute_step0(model_name, str(target_path))
        if not success:
            error_report = error_analyzer.diagnose_execution_error(
                Exception(step_logs), "step0"
            )
            detailed_logs.append(f"âŒ Step 0 å¤±æ•—: {step_logs}")
            detailed_logs.append(f"ğŸ’¡ è§£æ±ºç­–: {error_report.get('suggested_solution', 'ä¸æ˜')}")
            return False, "\n".join(detailed_logs)
        detailed_logs.append(f"âœ… Step 0 å®Œäº†")
        detailed_logs.append(f"ğŸ“‹ è©³ç´°: {step_logs}")
        
        # Step 1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º
        detailed_logs.append(f"")
        detailed_logs.append(f"ğŸ”§ Step 1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºé–‹å§‹")
        detailed_logs.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        app_logger.info(f"Step 1 é–‹å§‹: {model_name}")
        success, step_logs = execute_step1_wrapper(model_name, str(target_path))
        if not success:
            error_report = error_analyzer.diagnose_execution_error(
                Exception(step_logs), "step1"
            )
            detailed_logs.append(f"âŒ Step 1 å¤±æ•—: {step_logs}")
            detailed_logs.append(f"ğŸ’¡ è§£æ±ºç­–: {error_report.get('suggested_solution', 'ä¸æ˜')}")
            return False, "\n".join(detailed_logs)
        detailed_logs.append(f"âœ… Step 1 å®Œäº†")
        detailed_logs.append(f"ğŸ“‹ è©³ç´°: {step_logs}")
        
        # Step 2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ
        detailed_logs.append(f"")
        detailed_logs.append(f"ğŸ”§ Step 2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆé–‹å§‹")
        detailed_logs.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        app_logger.info(f"Step 2 é–‹å§‹: {model_name}")
        success, step_logs = execute_step2(model_name, gender)
        if not success:
            error_report = error_analyzer.diagnose_execution_error(
                Exception(step_logs), "step2"
            )
            detailed_logs.append(f"âŒ Step 2 å¤±æ•—: {step_logs}")
            detailed_logs.append(f"ğŸ’¡ è§£æ±ºç­–: {error_report.get('suggested_solution', 'ä¸æ˜')}")
            return False, "\n".join(detailed_logs)
        detailed_logs.append(f"âœ… Step 2 å®Œäº†")
        detailed_logs.append(f"ğŸ“‹ è©³ç´°: {step_logs}")
        
        # Step 3: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°
        detailed_logs.append(f"")
        detailed_logs.append(f"ğŸ”§ Step 3: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨é–‹å§‹")
        detailed_logs.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        app_logger.info(f"Step 3 é–‹å§‹: {model_name}")
        success, step_logs = execute_step3(model_name)
        if not success:
            error_report = error_analyzer.diagnose_execution_error(
                Exception(step_logs), "step3"
            )
            detailed_logs.append(f"âŒ Step 3 å¤±æ•—: {step_logs}")
            detailed_logs.append(f"ğŸ’¡ è§£æ±ºç­–: {error_report.get('suggested_solution', 'ä¸æ˜')}")
            return False, "\n".join(detailed_logs)
        detailed_logs.append(f"âœ… Step 3 å®Œäº†")
        detailed_logs.append(f"ğŸ“‹ è©³ç´°: {step_logs}")
        
        # Step 4: ãƒãƒ¼ã‚¸
        detailed_logs.append(f"")
        detailed_logs.append(f"ğŸ”§ Step 4: ãƒãƒ¼ã‚¸å‡¦ç†é–‹å§‹")
        detailed_logs.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        app_logger.info(f"Step 4 é–‹å§‹: {model_name}")
        success, step_logs = execute_step4(model_name)
        if not success:
            error_report = error_analyzer.diagnose_execution_error(
                Exception(step_logs), "step4"
            )
            detailed_logs.append(f"âŒ Step 4 å¤±æ•—: {step_logs}")
            detailed_logs.append(f"ğŸ’¡ è§£æ±ºç­–: {error_report.get('suggested_solution', 'ä¸æ˜')}")
            return False, "\n".join(detailed_logs)
        detailed_logs.append(f"âœ… Step 4 å®Œäº†")
        detailed_logs.append(f"ğŸ“‹ è©³ç´°: {step_logs}")
        
        # Step 5: æœ€çµ‚çµ±åˆ
        detailed_logs.append(f"")
        detailed_logs.append(f"ğŸ”§ Step 5: æœ€çµ‚çµ±åˆé–‹å§‹")
        detailed_logs.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        app_logger.info(f"Step 5 é–‹å§‹: {model_name}")
        success, step_logs = execute_step5(model_name, str(target_path))
        if not success:
            error_report = error_analyzer.diagnose_execution_error(
                Exception(step_logs), "step5"
            )
            detailed_logs.append(f"âŒ Step 5 å¤±æ•—: {step_logs}")
            detailed_logs.append(f"ğŸ’¡ è§£æ±ºç­–: {error_report.get('suggested_solution', 'ä¸æ˜')}")
            return False, "\n".join(detailed_logs)
        detailed_logs.append(f"âœ… Step 5 å®Œäº†")
        detailed_logs.append(f"ğŸ“‹ è©³ç´°: {step_logs}")
        
        # æœ€çµ‚æ¤œè¨¼
        detailed_logs.append(f"")
        detailed_logs.append(f"ğŸ” æœ€çµ‚æ¤œè¨¼é–‹å§‹")
        detailed_logs.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        final_check = fdm.get_pipeline_completion_status()
        completion_rate = sum(final_check.values()) / len(final_check) * 100
        
        detailed_logs.append(f"ğŸ“Š å®Œäº†ç‡: {completion_rate:.1f}%")
        for step, completed in final_check.items():
            status = "âœ…" if completed else "âŒ"
            detailed_logs.append(f"  {status} {step}: {'å®Œäº†' if completed else 'æœªå®Œäº†'}")
        
        final_fbx = fdm.get_step_dir('step5') / f'{model_name}_final.fbx'
        if final_fbx.exists():
            file_size = final_fbx.stat().st_size / (1024 * 1024)  # MB
            detailed_logs.append(f"ğŸ“ æœ€çµ‚å‡ºåŠ›: {final_fbx}")
            detailed_logs.append(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:.2f}MB")
        
        app_logger.info(f"ä¸€æ°—é€šè²«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†: {model_name} ({completion_rate:.1f}%)")
        return True, "\n".join(detailed_logs)
        
    except Exception as e:
        error_report = error_analyzer.diagnose_execution_error(e, "pipeline")
        app_logger.error(f"ä¸€æ°—é€šè²«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        detailed_logs.append(f"")
        detailed_logs.append(f"âŒ è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ")
        detailed_logs.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        detailed_logs.append(f"ğŸ› ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}")
        detailed_logs.append(f"ğŸ’¡ è§£æ±ºç­–: {error_report.get('suggested_solution', 'ä¸æ˜')}")
        return False, "\n".join(detailed_logs)

# --- ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œé–¢æ•°ç¾¤ï¼ˆsrc/pipelineçµ±åˆç‰ˆï¼‰ ---
def execute_step0(model_name: str, input_file_path: str) -> tuple[bool, str]:
    """Step0: ã‚¢ã‚»ãƒƒãƒˆä¿å­˜å®Ÿè¡Œï¼ˆæ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥ï¼‰"""
    try:
        fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
        
        # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
        if not Path(input_file_path).exists():
            return False, f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {input_file_path}"
        
        step0 = Step0AssetPreservation(model_name, input_file_path, fdm.get_step_dir('step0'), app_logger)
        success, logs, files = step0.preserve_assets()
        
        # æœŸå¾…å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼
        expected = fdm.get_expected_files("step0")
        created_files = []
        for key, path in expected.items():
            if path.exists():
                created_files.append(f"{key}: {path}")
        
        final_logs = logs + f"\nä½œæˆãƒ•ã‚¡ã‚¤ãƒ«: {len(created_files)}å€‹\n" + "\n".join(created_files)
        return success, final_logs
    except Exception as e:
        return False, f"Step0 ã‚¨ãƒ©ãƒ¼: {str(e)}"

def execute_step1_wrapper(model_name: str, input_file_path: str) -> tuple[bool, str]:
    """Step1ãƒ©ãƒƒãƒ‘ãƒ¼: step_modulesã®execute_step1ã‚’ä½¿ç”¨"""
    try:
        fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
        
        # äº‹å‰æ¤œè¨¼
        error_analyzer = PipelineErrorAnalyzer(app_logger)
        validation_result = error_analyzer.validate_input_requirements("step1", {
            "input_file": input_file_path,
            "model_name": model_name
        })
        
        if not validation_result["valid"]:
            return False, f"Step1 äº‹å‰æ¤œè¨¼å¤±æ•—: {validation_result['message']}"
        
        # step_modules/step1_extract.pyã‚’ä½¿ç”¨
        from step_modules.step1_extract import execute_step1
        
        output_dir = fdm.get_step_dir('step1')
        output_dir.mkdir(parents=True, exist_ok=True)
        
        success, logs, output_files = execute_step1(
            input_file_path=Path(input_file_path),
            model_name=model_name,
            step_output_dir=output_dir,
            logger_instance=app_logger
        )
        
        # æœŸå¾…å‡ºåŠ›ç¢ºèª
        expected = fdm.get_expected_files("step1")
        if expected["raw_data_npz"].exists():
            logs += f"\nâœ… æœŸå¾…å‡ºåŠ›ç¢ºèª: {expected['raw_data_npz']} (å­˜åœ¨)"
            file_size = expected["raw_data_npz"].stat().st_size
            logs += f"\nâœ… ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:,} bytes"
        else:
            logs += f"\nâŒ æœŸå¾…å‡ºåŠ›æœªä½œæˆ: {expected['raw_data_npz']}"
        
        return success, logs
    except Exception as e:
        app_logger.error(f"Step1å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return False, f"Step1 ã‚¨ãƒ©ãƒ¼: {str(e)}"

def execute_step2(model_name: str, gender: str) -> tuple[bool, str]:
    """Step2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå®Ÿè¡Œï¼ˆãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã‚’å«ã‚€ï¼‰
    
    é‡è¦: ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã®çŸ¥è¦‹ã«åŸºã¥ãã€åŸæµgenerate_skeleton.shã¨åŒã˜å‡¦ç†é †åºã‚’å®Ÿè¡Œ:
    1. ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå‰ã«å¿…ãšãƒ¡ãƒƒã‚·ãƒ¥ã‚’å†æŠ½å‡º
    2. AIæ¨è«–ç‰¹åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼ˆ--require_suffix, --faces_target_count=4000, --time=8ï¼‰
    3. å°‚ç”¨å‰å‡¦ç†ï¼ˆar_post_process.pyï¼‰ã‚’é©ç”¨
    """
    try:
        fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
        
        # ã€é‡è¦ã€‘ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢ï¼ˆãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã®ãŸã‚ï¼‰
        app_logger.info(f"Step2: ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã«ã‚ˆã‚‹ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆé–‹å§‹ - {model_name}")
        
        # ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        original_file = fdm.find_original_model_file()
        if not original_file:
            return False, "Step2: ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã«å¿…è¦ï¼‰"
        
        app_logger.info(f"Step2: ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {original_file}")
        
        # Step2å°‚ç”¨å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        output_dir = fdm.get_step_dir('step2')
        
        # step_modules/step2_skeletonã‚’ä½¿ç”¨ï¼ˆæœ€æ–°ç‰ˆï¼‰
        from step_modules.step2_skeleton import Step2Skeleton
        
        step2_module = Step2Skeleton(output_dir, app_logger)
        
        # ã€é‡è¦ã€‘ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã‚’å«ã‚€ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå®Ÿè¡Œ
        success, skeleton_logs, output_files = step2_module.generate_skeleton(
            original_file=original_file,
            model_name=model_name,
            gender=gender
        )
        
        # æœŸå¾…å‡ºåŠ›ç¢ºèª
        expected = fdm.get_expected_files("step2")
        output_check = []
        for key, path in expected.items():
            if path.exists():
                output_check.append(f"âœ“ {key}: {path}")
            else:
                output_check.append(f"âœ— {key}: {path}")
        
        # è©³ç´°ãƒ­ã‚°ã®çµ±åˆ
        combined_logs = f"""Step2å®Œäº†ãƒ­ã‚°:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆï¼‹ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºãƒ•ã‚§ãƒ¼ã‚ºã€‘
{skeleton_logs}

ã€å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã€‘
{chr(10).join(output_check)}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"""
        
        return success, combined_logs
        
    except Exception as e:
        app_logger.error(f"Step2å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return False, f"Step2 ã‚¨ãƒ©ãƒ¼: {str(e)}"


def execute_mesh_reextraction_for_skeleton(original_file: Path, model_name: str) -> tuple[bool, str]:
    """
    ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå°‚ç”¨ã®ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡º
    
    é‡è¦: åŸæµgenerate_skeleton.shã¨å®Œå…¨ã«åŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
    - --require_suffix: å³å¯†ãªå‘½åè¦å‰‡é©ç”¨
    - --faces_target_count=4000: AIæ¨è«–æœ€é©åŒ–ã•ã‚ŒãŸé¢æ•°
    - --time=8: ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ä¸
    - --post_process_script=post_process/ar_post_process.py: å°‚ç”¨å‰å‡¦ç†
    """
    app_logger.info(f"ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆç”¨ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºé–‹å§‹: {original_file}")
    
    try:
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆdataset_inference_clean/ï¼‰
        output_dir = Path("/app/dataset_inference_clean")
        
        # åŸæµgenerate_skeleton.shã¨åŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå®Ÿè¡Œ
        cmd = [
            "python", "-m", "src.data.extract",
            "--input", str(original_file),
            "--output", str(output_dir),
            "--name", model_name,
            "--require_suffix",           # å³å¯†ãªå‘½åè¦å‰‡
            "--faces_target_count", "4000",  # AIæ¨è«–æœ€é©åŒ–
            "--time", "8",                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
            "--post_process_script", "post_process/ar_post_process.py"  # å°‚ç”¨å‰å‡¦ç†
        ]
        
        app_logger.info(f"ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã‚³ãƒãƒ³ãƒ‰: {' '.join(cmd)}")
        
        # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            cwd="/app",
            timeout=300  # 5åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        )
        
        if result.returncode == 0:
            # å†æŠ½å‡ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
            reextracted_mesh = output_dir / "raw_data.npz"
            if reextracted_mesh.exists():
                file_size = reextracted_mesh.stat().st_size
                success_log = f"""âœ… ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆç”¨ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºæˆåŠŸ
ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {reextracted_mesh}
ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:,} bytes
ğŸ¯ ä½¿ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: åŸæµgenerate_skeleton.shäº’æ›
   - require_suffix: æœ‰åŠ¹
   - faces_target_count: 4000
   - time: 8
   - post_process_script: ar_post_process.py

ğŸ“ æ¨™æº–å‡ºåŠ›:
{result.stdout}"""
                app_logger.info("ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆç”¨ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºå®Œäº†")
                return True, success_log
            else:
                return False, f"å†æŠ½å‡ºãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå¤±æ•—: raw_data.npzãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        else:
            error_log = f"""âŒ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆç”¨ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºå¤±æ•—
ğŸš¨ çµ‚äº†ã‚³ãƒ¼ãƒ‰: {result.returncode}
ğŸ“ æ¨™æº–ã‚¨ãƒ©ãƒ¼:
{result.stderr}

ğŸ“ æ¨™æº–å‡ºåŠ›:
{result.stdout}"""
            return False, error_log
            
    except subprocess.TimeoutExpired:
        return False, "ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ5åˆ†åˆ¶é™ï¼‰"
    except Exception as e:
        return False, f"ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}"

def execute_step3(model_name: str) -> tuple[bool, str]:
    """Step3: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å®Ÿè¡Œï¼ˆåŸæµäº’æ›ç‰ˆï¼‰
    
    é‡è¦: åŸæµgenerate_skin.shã¨åŒã˜å‡¦ç†é †åº:
    1. ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”Ÿæˆå‰ã«å¿…ãšãƒ¡ãƒƒã‚·ãƒ¥ã‚’å†æŠ½å‡º
    2. Step2ã®å‡ºåŠ› (predict_skeleton.npz) ã¨ä½µç”¨
    3. dataset_inference_clean/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§å‡¦ç†å®Ÿè¡Œ
    """
    try:
        fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
        
        # ã€é‡è¦ã€‘ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢ï¼ˆã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”¨ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã®ãŸã‚ï¼‰
        app_logger.info(f"Step3: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”¨ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºé–‹å§‹ - {model_name}")
        
        # ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        original_file = fdm.find_original_model_file()
        if not original_file:
            return False, "Step3: ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”¨ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã«å¿…è¦ï¼‰"
        
        app_logger.info(f"Step3: ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {original_file}")
        
        # Step2ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
        step2_files = fdm.get_expected_files("step2")
        skeleton_npz = step2_files["skeleton_npz"]
        skeleton_fbx = step2_files["skeleton_fbx"]
        
        if not skeleton_npz.exists():
            return False, f"Step3: predict_skeleton.npzãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {skeleton_npz}"
        if not skeleton_fbx.exists():
            return False, f"Step3: ã‚¹ã‚±ãƒ«ãƒˆãƒ³FBXãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {skeleton_fbx}"
        
        # Step3å°‚ç”¨å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        output_dir = fdm.get_step_dir('step3')
        
        # step_modules/step3_skinning_unirigã‚’ä½¿ç”¨ï¼ˆæœ€æ–°ç‰ˆï¼‰
        from step_modules.step3_skinning_unirig import Step3Skinning
        
        step3_module = Step3Skinning(output_dir)
        
        # Step2ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«è¾æ›¸ã‚’æº–å‚™
        skeleton_files = {
            "skeleton_npz": str(skeleton_npz),
            "skeleton_fbx": str(skeleton_fbx)
        }
        
        # ã€é‡è¦ã€‘ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¨Step2å‡ºåŠ›ã‚’ä½¿ç”¨ã—ã¦ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
        # ã“ã®å†…éƒ¨ã§åŸæµã¨åŒæ§˜ã«ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºãŒå®Ÿè¡Œã•ã‚Œã‚‹
        success, logs, output_files = step3_module.apply_skinning(
            model_name=model_name,
            original_file=original_file,  # ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«
            skeleton_files=skeleton_files
        )
        
        # æœŸå¾…å‡ºåŠ›ç¢ºèª
        expected = fdm.get_expected_files("step3")
        if expected["skinned_fbx"].exists():
            logs += f"\nâœ… æœŸå¾…å‡ºåŠ›ç¢ºèª: {expected['skinned_fbx']} (å­˜åœ¨)\n"
        else:
            logs += f"\nâš ï¸ æœŸå¾…å‡ºåŠ›æœªä½œæˆ: {expected['skinned_fbx']}\n"
        
        return success, logs
    except Exception as e:
        app_logger.error(f"Step3å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return False, f"Step3 ã‚¨ãƒ©ãƒ¼: {str(e)}"

def execute_step4(model_name: str) -> tuple[bool, str]:
    """Step4: ãƒãƒ¼ã‚¸å®Ÿè¡Œï¼ˆsrc/pipelineçµ±åˆç‰ˆï¼‰"""
    try:
        fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
        
        # å…¥åŠ›æ¤œè¨¼
        valid, message, available_files = fdm.validate_step_inputs("step4")
        if not valid:
            return False, f"Step4 å…¥åŠ›æ¤œè¨¼å¤±æ•—: {message}"
        
        skeleton_fbx = available_files["skeleton_fbx"]
        skinned_fbx = available_files["skinned_fbx"]
        
        # unified_mergeã‚’ä½¿ç”¨
        merge_orchestrator = UnifiedMergeOrchestrator(app_logger)
        output_dir = fdm.get_step_dir('step4')
        output_dir.mkdir(parents=True, exist_ok=True)
        
        success, logs = merge_orchestrator.merge_skeleton_skinning_unified(
            model_name=model_name,
            skeleton_fbx=skeleton_fbx,
            skinned_fbx=skinned_fbx,
            output_dir=str(output_dir)
        )
        
        # æœŸå¾…å‡ºåŠ›ç¢ºèª
        expected = fdm.get_expected_files("step4")
        if expected["merged_fbx"].exists():
            logs += f"\næœŸå¾…å‡ºåŠ›ç¢ºèª: {expected['merged_fbx']} (å­˜åœ¨)"
        else:
            logs += f"\nâš ï¸ æœŸå¾…å‡ºåŠ›æœªä½œæˆ: {expected['merged_fbx']}"
        
        return success, logs
    except Exception as e:
        app_logger.error(f"Step4å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return False, f"Step4 ã‚¨ãƒ©ãƒ¼: {str(e)}"

def execute_step5(model_name: str, original_file_path: str) -> tuple[bool, str]:
    """Step5: æœ€çµ‚çµ±åˆå®Ÿè¡Œï¼ˆsrc/pipelineçµ±åˆç‰ˆï¼‰"""
    try:
        fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
        
        # å…¥åŠ›æ¤œè¨¼
        valid, message, available_files = fdm.validate_step_inputs("step5")
        if not valid:
            return False, f"Step5 å…¥åŠ›æ¤œè¨¼å¤±æ•—: {message}"
        
        merged_fbx = available_files["merged_fbx"]
        original_file = available_files.get("original_file", original_file_path)
        
        # unified_blenderã‚’ä½¿ç”¨
        blender_orchestrator = UnifiedBlenderOrchestrator(app_logger)
        output_dir = fdm.get_step_dir('step5')
        output_dir.mkdir(parents=True, exist_ok=True)
        
        success, logs = blender_orchestrator.integrate_with_blender_unified(
            model_name=model_name,
            original_file=original_file,
            merged_file=merged_fbx,
            output_dir=str(output_dir)
        )
        
        # æœŸå¾…å‡ºåŠ›ç¢ºèª
        expected = fdm.get_expected_files("step5")
        if expected["final_fbx"].exists():
            logs += f"\næœŸå¾…å‡ºåŠ›ç¢ºèª: {expected['final_fbx']} (å­˜åœ¨)"
        else:
            logs += f"\nâš ï¸ æœŸå¾…å‡ºåŠ›æœªä½œæˆ: {expected['final_fbx']}"
        
        return success, logs
    except Exception as e:
        app_logger.error(f"Step5å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return False, f"Step5 ã‚¨ãƒ©ãƒ¼: {str(e)}"

# --- Gradio UIï¼ˆæ”¹è‰¯ç‰ˆï¼‰ ---
def create_simple_ui():
    """æ”¹è‰¯ã•ã‚ŒãŸGradio UIä½œæˆï¼ˆsrc/pipelineçµ±åˆç‰ˆï¼‰"""
    
    with gr.Blocks(title="UniRig WebUI - å®Œå…¨ç‰ˆ") as demo:
        gr.Markdown("# ğŸ¯ UniRig WebUI - å®Œå…¨çµ±åˆç‰ˆ")
        gr.Markdown("**src/pipelineçµ±åˆãƒ»æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥å®Œå…¨é©ç”¨ãƒ»ã‚¨ãƒ©ãƒ¼äºˆé˜²ã‚·ã‚¹ãƒ†ãƒ æ­è¼‰**")
        
        with gr.Row():
            with gr.Column():
                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                uploaded_file = gr.File(
                    label="3Dãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« (.glb, .fbx, .obj, .vrm)",
                    file_types=[".glb", ".fbx", ".obj", ".vrm", ".dae", ".gltf"]
                )
                model_name_input = gr.Textbox(
                    label="ãƒ¢ãƒ‡ãƒ«å (è‡ªå‹•å–å¾—)", 
                    value="", 
                    placeholder="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã«è‡ªå‹•è¨­å®š", 
                    interactive=False
                )
                gender_input = gr.Radio(
                    ["neutral", "male", "female"], 
                    label="æ€§åˆ¥", 
                    value="neutral"
                )
                
                # ä¸€æ°—é€šè²«å‡¦ç†ãƒœã‚¿ãƒ³
                with gr.Row():
                    complete_pipeline_btn = gr.Button(
                        "ğŸš€ ä¸€æ°—é€šè²«å®Ÿè¡Œ (å…¨ã‚¹ãƒ†ãƒƒãƒ—è‡ªå‹•)", 
                        variant="primary", 
                        size="lg"
                    )
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³
                gr.Markdown("### ğŸ“¥ çµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                download_btn = gr.Button("ğŸ“¥ æœ€çµ‚FBXãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", variant="secondary")
                download_file = gr.File(label="ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«", visible=False)
                
                gr.Markdown("---")
                gr.Markdown("### ğŸ”§ å€‹åˆ¥ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰")
                
                # ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œãƒœã‚¿ãƒ³
                with gr.Row():
                    step0_btn = gr.Button("Step 0: ã‚¢ã‚»ãƒƒãƒˆä¿å­˜", size="sm")
                    step1_btn = gr.Button("Step 1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º", size="sm")
                    step2_btn = gr.Button("Step 2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ", size="sm")
                with gr.Row():
                    step3_btn = gr.Button("Step 3: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°", size="sm")
                    step4_btn = gr.Button("Step 4: ãƒãƒ¼ã‚¸", size="sm")
                    step5_btn = gr.Button("Step 5: æœ€çµ‚çµ±åˆ", size="sm")
                
                with gr.Row():
                    reset_btn = gr.Button("ğŸ”„ ãƒªã‚»ãƒƒãƒˆ", variant="secondary", size="sm")
                    refresh_btn = gr.Button("ğŸ“Š çŠ¶æ…‹æ›´æ–°", variant="secondary", size="sm")
                
            with gr.Column():
                # çŠ¶æ…‹è¡¨ç¤º
                status_display = gr.Textbox(
                    label="ğŸ“Š ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çŠ¶æ…‹", 
                    lines=15, 
                    interactive=False,
                    placeholder="ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦çŠ¶æ…‹æ›´æ–°ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„",
                    max_lines=20
                )
                log_display = gr.Textbox(
                    label="ğŸ“‹ å®Ÿè¡Œãƒ­ã‚°", 
                    lines=15, 
                    interactive=False,
                    placeholder="å®Ÿè¡Œãƒ­ã‚°ãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™",
                    max_lines=25
                )
        
        # --- ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ ---
        def handle_upload(uploaded_file_info):
            if not uploaded_file_info:
                return "", "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ãƒ¢ãƒ‡ãƒ«åã‚’è‡ªå‹•å–å¾—
                model_name = extract_model_name_from_file(uploaded_file_info.name)
                fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
                fdm.create_all_directories()
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
                original_filename = Path(uploaded_file_info.name).name
                target_path = fdm.model_dir / original_filename
                shutil.copy(uploaded_file_info.name, target_path)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—
                file_size = target_path.stat().st_size / (1024 * 1024)  # MB
                
                return model_name, f"âœ… ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†\\nğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«: {original_filename}\\nğŸ“ ã‚µã‚¤ã‚º: {file_size:.2f} MB\\nğŸ·ï¸ ãƒ¢ãƒ‡ãƒ«å: {model_name}\\nğŸ“‚ ä¿å­˜å…ˆ: {target_path}"
            except Exception as e:
                return "", f"âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}"
        
        def get_status(model_name):
            """è©³ç´°ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çŠ¶æ…‹è¡¨ç¤º"""
            if not model_name:
                return "âš ï¸ ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            try:
                fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
                
                # çŠ¶æ…‹è©³ç´°ã®æ§‹ç¯‰
                status_lines = []
                status_lines.append(f"ğŸ“Š UniRig ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çŠ¶æ…‹ãƒ¬ãƒãƒ¼ãƒˆ")
                status_lines.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
                status_lines.append(f"ğŸ·ï¸ ãƒ¢ãƒ‡ãƒ«å: {model_name}")
                status_lines.append(f"ğŸ“ ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {fdm.model_dir}")
                status_lines.append(f"â° æ›´æ–°æ™‚åˆ»: {time.strftime('%Y-%m-%d %H:%M:%S')}")
                status_lines.append(f"")
                
                # å®Œäº†ç‡è¨ˆç®—
                completion_status = fdm.get_pipeline_completion_status()
                completed_steps = sum(completion_status.values())
                total_steps = len(completion_status)
                completion_rate = completed_steps / total_steps * 100
                
                status_lines.append(f"ğŸ å…¨ä½“é€²æ—: {completed_steps}/{total_steps} ã‚¹ãƒ†ãƒƒãƒ—å®Œäº† ({completion_rate:.1f}%)")
                status_lines.append(f"")
                
                # å„ã‚¹ãƒ†ãƒƒãƒ—ã®è©³ç´°çŠ¶æ…‹
                step_details = {
                    'step0': 'ğŸ”§ Step 0: ã‚¢ã‚»ãƒƒãƒˆä¿å­˜',
                    'step1': 'ğŸ”§ Step 1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º', 
                    'step2': 'ğŸ”§ Step 2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ',
                    'step3': 'ğŸ”§ Step 3: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨',
                    'step4': 'ğŸ”§ Step 4: ãƒãƒ¼ã‚¸å‡¦ç†',
                    'step5': 'ğŸ”§ Step 5: æœ€çµ‚çµ±åˆ'
                }
                
                status_lines.append(f"ï¿½ ã‚¹ãƒ†ãƒƒãƒ—åˆ¥è©³ç´°çŠ¶æ…‹:")
                status_lines.append(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
                
                for step_id, step_name in step_details.items():
                    is_completed = completion_status.get(step_id, False)
                    status_icon = "âœ…" if is_completed else "â³"
                    status_text = "å®Œäº†" if is_completed else "æœªå®Ÿè¡Œ"
                    
                    status_lines.append(f"{status_icon} {step_name}: {status_text}")
                    
                    # æœŸå¾…ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
                    try:
                        expected_files = fdm.get_expected_files(step_id)
                        for file_key, file_path in expected_files.items():
                            if file_path.exists():
                                file_size = file_path.stat().st_size / (1024 * 1024)  # MB
                                status_lines.append(f"    ğŸ“ {file_key}: {file_path.name} ({file_size:.2f}MB)")
                            else:
                                status_lines.append(f"    âŒ {file_key}: æœªä½œæˆ")
                    except Exception as e:
                        status_lines.append(f"    âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«çŠ¶æ…‹ç¢ºèªã‚¨ãƒ©ãƒ¼: {str(e)}")
                    
                    status_lines.append(f"")
                
                # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡
                if fdm.model_dir.exists():
                    total_size = sum(f.stat().st_size for f in fdm.model_dir.rglob('*') if f.is_file())
                    total_size_mb = total_size / (1024 * 1024)
                    status_lines.append(f"ğŸ’¾ ç·ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡: {total_size_mb:.2f}MB")
                
                # æœ€çµ‚å‡ºåŠ›ã®çŠ¶æ…‹
                final_fbx = fdm.get_expected_files("step5").get("final_fbx")
                if final_fbx and final_fbx.exists():
                    final_size = final_fbx.stat().st_size / (1024 * 1024)
                    status_lines.append(f"ğŸ¯ æœ€çµ‚å‡ºåŠ›: {final_fbx.name} ({final_size:.2f}MB)")
                else:
                    status_lines.append(f"ğŸ¯ æœ€çµ‚å‡ºåŠ›: æœªç”Ÿæˆ")
                
                return "\n".join(status_lines)
                
            except Exception as e:
                return f"âŒ çŠ¶æ…‹å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}\nè©³ç´°: {type(e).__name__}"
        
        def handle_download(model_name):
            if not model_name:
                return None, "âš ï¸ ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            try:
                fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
                final_fbx = fdm.get_expected_files("step5")["final_fbx"]
                
                if final_fbx.exists():
                    return final_fbx, f"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æº–å‚™å®Œäº†: {final_fbx.name}"
                else:
                    return None, f"âŒ æœ€çµ‚FBXãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {final_fbx}"
            except Exception as e:
                return None, f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}"
        
        def handle_complete_pipeline(uploaded_file_info, gender):
            """ä¸€æ°—é€šè²«å‡¦ç†ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆè©³ç´°ãƒ­ã‚°è¡¨ç¤ºç‰ˆï¼‰"""
            if not uploaded_file_info:
                return "âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            # é–‹å§‹ãƒ­ã‚°
            model_name = extract_model_name_from_file(uploaded_file_info.name)
            start_log = f"""ğŸš€ ä¸€æ°—é€šè²«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹
ğŸ“ ãƒ¢ãƒ‡ãƒ«å: {model_name}
ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_file_info.name}
ğŸ‘¤ æ€§åˆ¥è¨­å®š: {gender}
â° é–‹å§‹æ™‚åˆ»: {time.strftime('%Y-%m-%d %H:%M:%S')}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
            
            success, logs = execute_complete_pipeline(uploaded_file_info, gender)
            status_icon = "âœ…" if success else "âŒ"
            
            # çµ‚äº†ãƒ­ã‚°
            end_log = f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â° çµ‚äº†æ™‚åˆ»: {time.strftime('%Y-%m-%d %H:%M:%S')}
ğŸ æœ€çµ‚çµæœ: {status_icon} {'æˆåŠŸ' if success else 'å¤±æ•—'}
"""
            
            return f"{start_log}{logs}{end_log}"
        
        def handle_step0(uploaded_file_info, model_name):
            if not uploaded_file_info or not model_name:
                return "âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            start_log = f"""ğŸ”§ Step 0: ã‚¢ã‚»ãƒƒãƒˆä¿å­˜é–‹å§‹
ğŸ“ ãƒ¢ãƒ‡ãƒ«å: {model_name}
ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_file_info.name}
â° é–‹å§‹æ™‚åˆ»: {time.strftime('%Y-%m-%d %H:%M:%S')}

"""
            success, logs = execute_step0(model_name, uploaded_file_info.name)
            status_icon = "âœ…" if success else "âŒ"
            
            return f"{start_log}{logs}\n\nğŸ Step 0 çµæœ: {status_icon} {'æˆåŠŸ' if success else 'å¤±æ•—'}"
        
        def handle_step1(uploaded_file_info, model_name):
            if not uploaded_file_info or not model_name:
                return "âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            start_log = f"""ğŸ”§ Step 1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºé–‹å§‹
ğŸ“ ãƒ¢ãƒ‡ãƒ«å: {model_name}
ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_file_info.name}
â° é–‹å§‹æ™‚åˆ»: {time.strftime('%Y-%m-%d %H:%M:%S')}

"""
            success, logs = execute_step1_wrapper(model_name, uploaded_file_info.name)
            status_icon = "âœ…" if success else "âŒ"
            
            return f"{start_log}{logs}\n\nğŸ Step 1 çµæœ: {status_icon} {'æˆåŠŸ' if success else 'å¤±æ•—'}"
        
        def handle_step2(model_name, gender):
            if not model_name:
                return "âŒ ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            start_log = f"""ğŸ”§ Step 2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆé–‹å§‹
ğŸ“ ãƒ¢ãƒ‡ãƒ«å: {model_name}
ğŸ‘¤ æ€§åˆ¥è¨­å®š: {gender}
â° é–‹å§‹æ™‚åˆ»: {time.strftime('%Y-%m-%d %H:%M:%S')}

"""
            success, logs = execute_step2(model_name, gender)
            status_icon = "âœ…" if success else "âŒ"
            
            return f"{start_log}{logs}\n\nğŸ Step 2 çµæœ: {status_icon} {'æˆåŠŸ' if success else 'å¤±æ•—'}"
        
        def handle_step3(model_name):
            if not model_name:
                return "âŒ ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            start_log = f"""ğŸ”§ Step 3: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨é–‹å§‹
ğŸ“ ãƒ¢ãƒ‡ãƒ«å: {model_name}
â° é–‹å§‹æ™‚åˆ»: {time.strftime('%Y-%m-%d %H:%M:%S')}

"""
            success, logs = execute_step3(model_name)
            status_icon = "âœ…" if success else "âŒ"
            
            return f"{start_log}{logs}\n\nğŸ Step 3 çµæœ: {status_icon} {'æˆåŠŸ' if success else 'å¤±æ•—'}"
        
        def handle_step4(model_name):
            if not model_name:
                return "âŒ ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            start_log = f"""ğŸ”§ Step 4: ãƒãƒ¼ã‚¸å‡¦ç†é–‹å§‹
ğŸ“ ãƒ¢ãƒ‡ãƒ«å: {model_name}
â° é–‹å§‹æ™‚åˆ»: {time.strftime('%Y-%m-%d %H:%M:%S')}

"""
            success, logs = execute_step4(model_name)
            status_icon = "âœ…" if success else "âŒ"
            
            return f"{start_log}{logs}\n\nğŸ Step 4 çµæœ: {status_icon} {'æˆåŠŸ' if success else 'å¤±æ•—'}"
        
        def handle_step5(uploaded_file_info, model_name):
            if not uploaded_file_info or not model_name:
                return "âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
            start_log = f"""ğŸ”§ Step 5: æœ€çµ‚çµ±åˆé–‹å§‹
ğŸ“ ãƒ¢ãƒ‡ãƒ«å: {model_name}
ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_file_info.name}
â° é–‹å§‹æ™‚åˆ»: {time.strftime('%Y-%m-%d %H:%M:%S')}

"""
            success, logs = execute_step5(model_name, uploaded_file_info.name)
            status_icon = "âœ…" if success else "âŒ"
            
            return f"{start_log}{logs}\n\nğŸ Step 5 çµæœ: {status_icon} {'æˆåŠŸ' if success else 'å¤±æ•—'}"
        
        def handle_reset(model_name):
            if not model_name:
                return "âŒ ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            try:
                fdm = FixedDirectoryManager(PIPELINE_BASE_DIR, model_name, app_logger)
                if fdm.model_dir.exists():
                    shutil.rmtree(fdm.model_dir)
                    fdm.create_all_directories()
                return f"ğŸ”„ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ: {model_name}"
            except Exception as e:
                return f"âŒ ãƒªã‚»ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}"
        
        # ã‚¤ãƒ™ãƒ³ãƒˆæ¥ç¶š
        uploaded_file.change(handle_upload, [uploaded_file], [model_name_input, log_display])
        complete_pipeline_btn.click(handle_complete_pipeline, [uploaded_file, gender_input], log_display)
        download_btn.click(handle_download, [model_name_input], [download_file, log_display])
        
        step0_btn.click(handle_step0, [uploaded_file, model_name_input], log_display)
        step1_btn.click(handle_step1, [uploaded_file, model_name_input], log_display)
        step2_btn.click(handle_step2, [model_name_input, gender_input], log_display)
        step3_btn.click(handle_step3, [model_name_input], log_display)
        step4_btn.click(handle_step4, [model_name_input], log_display)
        step5_btn.click(handle_step5, [uploaded_file, model_name_input], log_display)
        
        reset_btn.click(handle_reset, [model_name_input], log_display)
        refresh_btn.click(get_status, [model_name_input], status_display)
    
    return demo

# --- ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ ---
def find_available_port(start_port=7860, max_attempts=10):
    """åˆ©ç”¨å¯èƒ½ãƒãƒ¼ãƒˆæ¤œç´¢"""
    for i in range(max_attempts):
        port = start_port + i
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
                sock.bind(('0.0.0.0', port))
                app_logger.info(f"åˆ©ç”¨å¯èƒ½ãƒãƒ¼ãƒˆ: {port}")
                return port
        except OSError:
            continue
    raise RuntimeError(f"åˆ©ç”¨å¯èƒ½ãƒãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ (ç¯„å›²: {start_port}-{start_port + max_attempts - 1})")

if __name__ == "__main__":
    app_logger.info("ğŸ¯ UniRig WebUIå®Œå…¨ç‰ˆ - èµ·å‹•é–‹å§‹")
    app_logger.info("src/pipelineçµ±åˆãƒ»æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥å®Œå…¨é©ç”¨ç‰ˆ")
    
    try:
        port = find_available_port()
        demo = create_simple_ui()
        app_logger.info("âœ… Gradioã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹æ§‹ç¯‰å®Œäº†")
        
        # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª
        PIPELINE_BASE_DIR.mkdir(parents=True, exist_ok=True)
        app_logger.info(f"ğŸ“ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {PIPELINE_BASE_DIR}")
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã®è¡¨ç¤º
        app_logger.info(f"ğŸ–¥ï¸ ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ : {sys.platform}")
        app_logger.info(f"ğŸ Python: {sys.version.split()[0]}")
        app_logger.info(f"ğŸŒ èµ·å‹•URL: http://0.0.0.0:{port}")
        
        demo.launch(
            server_name="0.0.0.0",
            server_port=port,
            share=False,
            debug=False,
            show_error=True,
            inbrowser=True  # ãƒ–ãƒ©ã‚¦ã‚¶è‡ªå‹•èµ·å‹•
        )
    except Exception as e:
        app_logger.error(f"âŒ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        sys.exit(1)
