#!/usr/bin/env python3
"""
CPUç’°å¢ƒå¯¾å¿œãƒ¡ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼

PTv3Objectï¼ˆspconvä¾å­˜ï¼‰ã®ä»£æ›¿ã¨ã—ã¦ã€CPUç’°å¢ƒã§å‹•ä½œã™ã‚‹
ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¡ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’æä¾›
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Dict, List, Optional, Tuple


class SimpleCPUMeshEncoder(nn.Module):
    """
    CPUç’°å¢ƒã§å‹•ä½œã™ã‚‹ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¡ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼
    Point Transformer V3ã®ä»£æ›¿ã¨ã—ã¦è»½é‡ãªå‡¦ç†ã‚’å®Ÿè¡Œ
    """
    
    def __init__(self, 
                 in_channels: int = 6,  # xyz + normals
                 enc_channels: List[int] = [32, 64, 128, 256],
                 num_layers: int = 4,
                 num_heads: int = 8,
                 dropout: float = 0.1):
        super().__init__()
        
        self.in_channels = in_channels
        self.enc_channels = enc_channels
        self.num_layers = num_layers
        self.num_heads = num_heads
        
        # å…¥åŠ›ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³
        self.input_proj = nn.Linear(in_channels, enc_channels[0])
        
        # éšå±¤çš„ç‰¹å¾´æŠ½å‡º
        self.encoders = nn.ModuleList()
        for i in range(len(enc_channels) - 1):
            self.encoders.append(
                nn.Sequential(
                    nn.Linear(enc_channels[i], enc_channels[i + 1]),
                    nn.LayerNorm(enc_channels[i + 1]),
                    nn.ReLU(),
                    nn.Dropout(dropout)
                )
            )
        
        # ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³å±¤
        self.attention_layers = nn.ModuleList()
        for _ in range(num_layers):
            self.attention_layers.append(
                nn.MultiheadAttention(
                    embed_dim=enc_channels[-1],
                    num_heads=num_heads,
                    dropout=dropout,
                    batch_first=True
                )
            )
            
        # LayerNorm layers
        self.layer_norms = nn.ModuleList([
            nn.LayerNorm(enc_channels[-1]) for _ in range(num_layers)
        ])
        
        # å‡ºåŠ›ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³
        self.output_proj = nn.Linear(enc_channels[-1], enc_channels[-1])
        
    def forward(self, coords: torch.Tensor, 
                features: Optional[torch.Tensor] = None,
                batch: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:
        """
        å‰å‘ãå‡¦ç†
        
        Args:
            coords: åº§æ¨™ (N, 3)
            features: ç‰¹å¾´é‡ (N, C) ã¾ãŸã¯ None
            batch: ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (N,) ã¾ãŸã¯ None
            
        Returns:
            ç‰¹å¾´é‡è¾æ›¸
        """
        device = coords.device
        N = coords.shape[0]
        
        # å…¥åŠ›ç‰¹å¾´é‡ã®æº–å‚™
        if features is None:
            # åº§æ¨™ã®ã¿ã‚’ä½¿ç”¨
            input_features = coords  # (N, 3)
        else:
            # åº§æ¨™ã¨ç‰¹å¾´é‡ã‚’çµåˆ
            input_features = torch.cat([coords, features], dim=-1)  # (N, 3+C)
            
        # ãƒãƒƒãƒå‡¦ç†ã®æº–å‚™
        if batch is None:
            batch = torch.zeros(N, dtype=torch.long, device=device)
            
        # ãƒãƒƒãƒã”ã¨ã®å‡¦ç†
        batch_size = batch.max().item() + 1
        outputs = []
        
        for b in range(batch_size):
            mask = (batch == b)
            if not mask.any():
                continue
                
            batch_features = input_features[mask]  # (N_b, C)
            
            # å…¥åŠ›ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³
            x = self.input_proj(batch_features)
            
            # éšå±¤çš„ç‰¹å¾´æŠ½å‡º
            for encoder in self.encoders:
                x = encoder(x)
                
            # Self-attentionå‡¦ç†
            for attn, norm in zip(self.attention_layers, self.layer_norms):
                residual = x
                x, _ = attn(x, x, x)
                x = norm(x + residual)
                
            # å‡ºåŠ›ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³
            x = self.output_proj(x)
            
            outputs.append(x)
            
        # ãƒãƒƒãƒã‚’å†çµåˆ
        if len(outputs) == 1:
            final_features = outputs[0]
        else:
            final_features = torch.cat(outputs, dim=0)
            
        return {
            'features': final_features,
            'coordinates': coords
        }


class CPUMeshEncoderWrapper:
    """
    PTv3Objectã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹äº’æ›ã®ãƒ©ãƒƒãƒ‘ãƒ¼
    """
    
    def __init__(self, enc_channels: List[int] = [32, 64, 128, 256], **kwargs):
        self.enc_channels = enc_channels
        self.encoder = SimpleCPUMeshEncoder(enc_channels=enc_channels, **kwargs)
        
    def __call__(self, *args, **kwargs):
        return self.encoder(*args, **kwargs)
        
    def cuda(self):
        """CUDAç§»è¡Œï¼ˆCPUç‰ˆã§ã¯ä½•ã‚‚ã—ãªã„ï¼‰"""
        return self
        
    def cpu(self):
        """CPUç§»è¡Œ"""
        self.encoder = self.encoder.cpu()
        return self
        
    def to(self, device):
        """ãƒ‡ãƒã‚¤ã‚¹ç§»è¡Œ"""
        self.encoder = self.encoder.to(device)
        return self
        
    def train(self, mode=True):
        """è¨“ç·´ãƒ¢ãƒ¼ãƒ‰è¨­å®š"""
        self.encoder.train(mode)
        return self
        
    def eval(self):
        """è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰è¨­å®š"""
        self.encoder.eval()
        return self
        
    def parameters(self):
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—"""
        return self.encoder.parameters()
        
    def state_dict(self):
        """çŠ¶æ…‹è¾æ›¸å–å¾—"""
        return self.encoder.state_dict()
        
    def load_state_dict(self, state_dict):
        """çŠ¶æ…‹è¾æ›¸èª­ã¿è¾¼ã¿"""
        return self.encoder.load_state_dict(state_dict)


def get_cpu_encoder(**kwargs) -> CPUMeshEncoderWrapper:
    """
    CPUå¯¾å¿œã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°
    PTv3Objectã®get_encoderé–¢æ•°ã¨äº’æ›
    """
    return CPUMeshEncoderWrapper(**kwargs)


class AdaptiveMeshEncoder(nn.Module):
    """
    GPU/CPUç’°å¢ƒã‚’è‡ªå‹•åˆ¤å®šã—ã¦é©åˆ‡ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’é¸æŠ
    """
    
    def __init__(self, fallback_to_cpu: bool = True, **kwargs):
        super().__init__()
        self.fallback_to_cpu = fallback_to_cpu
        
        # CUDAåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
        self.use_cuda = torch.cuda.is_available() and not fallback_to_cpu
        
        if self.use_cuda:
            try:
                # PTv3Objectã‚’è©¦è¡Œ
                from .pointcept.models.PTv3Object import get_encoder as get_ptv3_encoder
                self.encoder = get_ptv3_encoder(**kwargs)
                self.encoder_type = "ptv3"
                print("ğŸš€ PTv3Object ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’ä½¿ç”¨ï¼ˆCUDAï¼‰")
            except Exception as e:
                print(f"âš ï¸ PTv3ObjectåˆæœŸåŒ–å¤±æ•—: {e}")
                print("ğŸ”„ CPUã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
                self.encoder = get_cpu_encoder(**kwargs)
                self.encoder_type = "cpu"
        else:
            self.encoder = get_cpu_encoder(**kwargs)
            self.encoder_type = "cpu"
            print("ğŸ”§ CPUã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’ä½¿ç”¨")
            
    def forward(self, *args, **kwargs):
        return self.encoder(*args, **kwargs)
        
    def get_encoder_info(self) -> Dict[str, str]:
        """ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼æƒ…å ±ã‚’å–å¾—"""
        return {
            "type": self.encoder_type,
            "device": "cuda" if self.use_cuda else "cpu",
            "fallback_enabled": self.fallback_to_cpu
        }


def get_adaptive_encoder(**kwargs) -> AdaptiveMeshEncoder:
    """
    ç’°å¢ƒã«å¿œã˜ãŸé©å¿œçš„ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’å–å¾—
    """
    return AdaptiveMeshEncoder(**kwargs)
