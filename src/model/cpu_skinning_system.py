#!/usr/bin/env python3
"""
CPUç’°å¢ƒå¯¾å¿œã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 

UniRig ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬ã®CPUç’°å¢ƒãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè£…
CUDA/spconvä¾å­˜ã‚’å›é¿ã—ã€CPUç’°å¢ƒã§å‹•ä½œã™ã‚‹è»½é‡ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import os
import json
import logging
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass

from .cpu_mesh_encoder import get_adaptive_encoder


@dataclass
class SkinningResult:
    """ã‚¹ã‚­ãƒ‹ãƒ³ã‚°çµæœãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    skin_weights: np.ndarray  # (N, J) 
    vertex_groups: Dict[str, Any]
    processing_info: Dict[str, Any]


class CPUSkinningPredictor(nn.Module):
    """
    CPUç’°å¢ƒã§ã®ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬
    """
    
    def __init__(self, 
                 feat_dim: int = 256,
                 num_heads: int = 8,
                 max_bones: int = 256,
                 dropout: float = 0.1):
        super().__init__()
        
        self.feat_dim = feat_dim
        self.num_heads = num_heads
        self.max_bones = max_bones
        
        # ãƒ¡ãƒƒã‚·ãƒ¥ç‰¹å¾´æŠ½å‡º
        self.mesh_encoder = get_adaptive_encoder(
            enc_channels=[32, 64, 128, feat_dim],
            num_heads=num_heads,
            dropout=dropout
        )
        
        # ãƒœãƒ¼ãƒ³ç‰¹å¾´ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼
        self.bone_encoder = nn.Sequential(
            nn.Linear(3, 64),  # joint coordinates
            nn.ReLU(),
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Linear(128, feat_dim)
        )
        
        # ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³æ©Ÿæ§‹
        self.mesh_bone_attention = nn.MultiheadAttention(
            embed_dim=feat_dim,
            num_heads=num_heads,
            dropout=dropout,
            batch_first=True
        )
        
        # ã‚¹ã‚­ãƒ³ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬ãƒ˜ãƒƒãƒ‰
        self.skin_predictor = nn.Sequential(
            nn.Linear(feat_dim, feat_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(feat_dim // 2, max_bones),
            nn.Softmax(dim=-1)
        )
        
        # ãƒ¬ã‚¤ãƒ¤ãƒ¼æ­£è¦åŒ–
        self.mesh_norm = nn.LayerNorm(feat_dim)
        self.bone_norm = nn.LayerNorm(feat_dim)
        
    def forward(self, 
                vertices: torch.Tensor,  # (N, 3)
                normals: torch.Tensor,   # (N, 3)
                joints: torch.Tensor,    # (J, 3)
                num_bones: int) -> torch.Tensor:
        """
        ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬
        
        Args:
            vertices: é ‚ç‚¹åº§æ¨™
            normals: é ‚ç‚¹æ³•ç·š
            joints: ãƒœãƒ¼ãƒ³åº§æ¨™
            num_bones: å®Ÿéš›ã®ãƒœãƒ¼ãƒ³æ•°
            
        Returns:
            skin_weights: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆ (N, num_bones)
        """
        device = vertices.device
        N = vertices.shape[0]
        
        # ãƒ¡ãƒƒã‚·ãƒ¥ç‰¹å¾´æŠ½å‡º
        mesh_input = torch.cat([vertices, normals], dim=-1)  # (N, 6)
        mesh_features = self.mesh_encoder(
            coords=vertices,
            features=normals
        )['features']  # (N, feat_dim)
        
        mesh_features = self.mesh_norm(mesh_features)
        
        # ãƒœãƒ¼ãƒ³ç‰¹å¾´æŠ½å‡º
        bone_features = self.bone_encoder(joints[:num_bones])  # (num_bones, feat_dim)
        bone_features = self.bone_norm(bone_features)
        
        # ãƒ¡ãƒƒã‚·ãƒ¥-ãƒœãƒ¼ãƒ³ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³
        # mesh_features: (N, feat_dim) -> (N, 1, feat_dim)
        # bone_features: (num_bones, feat_dim) -> (1, num_bones, feat_dim)
        mesh_query = mesh_features.unsqueeze(1)  # (N, 1, feat_dim)
        bone_key_value = bone_features.unsqueeze(0).expand(N, -1, -1)  # (N, num_bones, feat_dim)
        
        # ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³è¨ˆç®—
        attended_features, attention_weights = self.mesh_bone_attention(
            query=mesh_query,
            key=bone_key_value,
            value=bone_key_value
        )  # attended_features: (N, 1, feat_dim)
        
        attended_features = attended_features.squeeze(1)  # (N, feat_dim)
        
        # ã‚¹ã‚­ãƒ³ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬
        skin_weights_full = self.skin_predictor(attended_features)  # (N, max_bones)
        
        # å®Ÿéš›ã®ãƒœãƒ¼ãƒ³æ•°ã«åˆ‡ã‚Šè©°ã‚
        skin_weights = skin_weights_full[:, :num_bones]  # (N, num_bones)
        
        # æ­£è¦åŒ–
        skin_weights = skin_weights / (skin_weights.sum(dim=-1, keepdim=True) + 1e-8)
        
        return skin_weights


class CPUSkinningSystem:
    """
    CPUç’°å¢ƒã§ã®ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ çµ±åˆã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self, model_name: str, work_dir: str):
        self.model_name = model_name
        self.work_dir = work_dir
        self.device = torch.device("cpu")
        
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        self.predictor = CPUSkinningPredictor(
            feat_dim=256,
            num_heads=8,
            max_bones=256
        ).to(self.device)
        
        self.predictor.eval()
        
        # ãƒ­ã‚®ãƒ³ã‚°
        self.logger = logging.getLogger(__name__)
        
    def predict_skin_weights(self, 
                           mesh_data: Dict[str, np.ndarray],
                           skeleton_data: Dict[str, np.ndarray]) -> SkinningResult:
        """
        ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬ï¼ˆãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼‰
        
        Args:
            mesh_data: ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ï¼ˆvertices, faces, normalsç­‰ï¼‰
            skeleton_data: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿ï¼ˆjoints, parentsç­‰ï¼‰
            
        Returns:
            SkinningResult: äºˆæ¸¬çµæœ
        """
        try:
            self.logger.info("ğŸ”„ CPUç’°å¢ƒã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬é–‹å§‹")
            
            # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            vertices = torch.from_numpy(mesh_data['vertices']).float().to(self.device)
            normals = self._compute_normals(vertices, mesh_data['faces']) if 'normals' not in mesh_data else torch.from_numpy(mesh_data['normals']).float().to(self.device)
            
            # ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
            joints = torch.from_numpy(skeleton_data['joints']).float().to(self.device)
            num_bones = len(joints)
            
            self.logger.info(f"ğŸ“Š é ‚ç‚¹æ•°: {len(vertices)}, ãƒœãƒ¼ãƒ³æ•°: {num_bones}")
            
            # æ¨è«–å®Ÿè¡Œ
            with torch.no_grad():
                skin_weights = self.predictor(
                    vertices=vertices,
                    normals=normals,
                    joints=joints,
                    num_bones=num_bones
                )
            
            # CPUå´ã«ç§»å‹•
            skin_weights_np = skin_weights.cpu().numpy()
            
            # é ‚ç‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã®ç”Ÿæˆ
            vertex_groups = self._create_vertex_groups(
                skin_weights_np, 
                skeleton_data.get('bone_names', [f"Bone_{i:02d}" for i in range(num_bones)])
            )
            
            # å‡¦ç†æƒ…å ±
            processing_info = {
                'method': 'cpu_fallback',
                'num_vertices': len(vertices),
                'num_bones': num_bones,
                'device': str(self.device),
                'model_type': self.predictor.mesh_encoder.get_encoder_info()['type']
            }
            
            result = SkinningResult(
                skin_weights=skin_weights_np,
                vertex_groups=vertex_groups,
                processing_info=processing_info
            )
            
            self.logger.info("âœ… CPUç’°å¢ƒã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬å®Œäº†")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            raise
            
    def _compute_normals(self, vertices: torch.Tensor, faces: np.ndarray) -> torch.Tensor:
        """é ‚ç‚¹æ³•ç·šã®è¨ˆç®—"""
        faces_tensor = torch.from_numpy(faces).long().to(vertices.device)
        
        # é¢æ³•ç·šã®è¨ˆç®—
        v0 = vertices[faces_tensor[:, 0]]
        v1 = vertices[faces_tensor[:, 1]]
        v2 = vertices[faces_tensor[:, 2]]
        
        face_normals = torch.cross(v1 - v0, v2 - v0, dim=1)
        face_normals = F.normalize(face_normals, dim=1)
        
        # é ‚ç‚¹æ³•ç·šã®åˆæœŸåŒ–
        vertex_normals = torch.zeros_like(vertices)
        
        # é¢æ³•ç·šã‚’é ‚ç‚¹ã«ç´¯ç©
        for i in range(3):
            vertex_normals.index_add_(0, faces_tensor[:, i], face_normals)
            
        # æ­£è¦åŒ–
        vertex_normals = F.normalize(vertex_normals, dim=1)
        
        return vertex_normals
        
    def _create_vertex_groups(self, skin_weights: np.ndarray, bone_names: List[str]) -> Dict[str, Any]:
        """é ‚ç‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã®ä½œæˆ"""
        vertex_groups = {}
        
        for bone_idx, bone_name in enumerate(bone_names):
            weights = skin_weights[:, bone_idx]
            # é–¾å€¤ä»¥ä¸Šã®ã‚¦ã‚§ã‚¤ãƒˆã®ã¿ä¿æŒ
            significant_weights = weights[weights > 0.01]
            significant_indices = np.where(weights > 0.01)[0]
            
            if len(significant_weights) > 0:
                vertex_groups[bone_name] = {
                    'indices': significant_indices.astype(np.int32),
                    'weights': significant_weights.astype(np.float32)
                }
                
        # voxel_skinå½¢å¼ã§ã®ä¿å­˜ï¼ˆUniRigäº’æ›ï¼‰
        vertex_groups['voxel_skin'] = skin_weights.astype(np.float32)
        
        return vertex_groups
        
    def save_skinning_data(self, result: SkinningResult, output_path: str):
        """ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜"""
        np.savez_compressed(output_path,
            skin_weights=result.skin_weights,
            vertex_groups=result.vertex_groups,
            processing_info=result.processing_info
        )
        self.logger.info(f"ğŸ’¾ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {output_path}")


def create_cpu_skinning_fallback(model_name: str, work_dir: str) -> CPUSkinningSystem:
    """
    CPUç’°å¢ƒã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°
    """
    return CPUSkinningSystem(model_name, work_dir)


# è·é›¢ãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆè¨ˆç®—ï¼ˆã•ã‚‰ãªã‚‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
def compute_distance_based_weights(vertices: np.ndarray, 
                                 joints: np.ndarray,
                                 max_influences: int = 4) -> np.ndarray:
    """
    è·é›¢ãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆè¨ˆç®—
    AIãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    """
    num_vertices = len(vertices)
    num_joints = len(joints)
    
    # å„é ‚ç‚¹ã‹ã‚‰å„ã‚¸ãƒ§ã‚¤ãƒ³ãƒˆã¸ã®è·é›¢ã‚’è¨ˆç®—
    distances = np.zeros((num_vertices, num_joints))
    
    for i, vertex in enumerate(vertices):
        for j, joint in enumerate(joints):
            distances[i, j] = np.linalg.norm(vertex - joint)
    
    # è·é›¢ã®é€†æ•°ã‚’ã‚¦ã‚§ã‚¤ãƒˆã¨ã—ã¦ä½¿ç”¨
    weights = 1.0 / (distances + 1e-6)  # 0é™¤ç®—å›é¿
    
    # ä¸Šä½max_influenceså€‹ã®ã‚¦ã‚§ã‚¤ãƒˆã®ã¿ä¿æŒ
    for i in range(num_vertices):
        vertex_weights = weights[i]
        top_indices = np.argpartition(vertex_weights, -max_influences)[-max_influences:]
        
        # ä¸Šä½ä»¥å¤–ã‚’0ã«è¨­å®š
        mask = np.zeros(num_joints, dtype=bool)
        mask[top_indices] = True
        weights[i, ~mask] = 0.0
        
        # æ­£è¦åŒ–
        weights[i] = weights[i] / (weights[i].sum() + 1e-8)
    
    return weights.astype(np.float32)
