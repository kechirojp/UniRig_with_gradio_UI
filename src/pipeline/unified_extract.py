"""
ğŸ¯ UniRigçµ±ä¸€ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå™¨ - Shell Scriptå®Œå…¨ç½®ãæ›ãˆç‰ˆ
ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å®Œå…¨å¯¾å¿œã€çµ±ä¸€å‘½åè¦å‰‡æº–æ‹ 

å…ƒã®extract.shã®å…¨æ©Ÿèƒ½ã‚’Pythonã§å†å®Ÿè£…
- Windows/Mac/Linuxå®Œå…¨å¯¾å¿œ
- çµ±ä¸€å‘½åè¦å‰‡æº–æ‹ 
- ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ è‡ªå‹•æ¤œå‡º
- Shell Scriptä¾å­˜å®Œå…¨æ’é™¤
"""

import os
import sys
import subprocess
import time
import logging
from pathlib import Path
from typing import Tuple, Optional, Dict, Any
import platform

class UnifiedExtractor:
    """ğŸ¯ çµ±ä¸€ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå™¨ (Shell Scriptç½®ãæ›ãˆ)"""
    
    def __init__(self, logger: Optional[logging.Logger] = None):
        self.logger = logger or logging.getLogger(__name__)
        self.platform = platform.system().lower()
        self.python_exec = self._detect_python_executable()
        
    def _detect_python_executable(self) -> str:
        """ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥Pythonå®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•æ¤œå‡º"""
        if self.platform == "windows":
            # Windowsæ¨™æº–Python
            candidates = ["python", "python.exe", "python3", "python3.exe"]
        else:
            # Unixç³» (Mac/Linux)
            candidates = ["python3", "python", "/usr/bin/python3", "/usr/local/bin/python3"]
        
        # UniRigç’°å¢ƒã®å„ªå…ˆãƒ‘ã‚¹
        conda_python = "/opt/conda/envs/UniRig/bin/python3"
        if Path(conda_python).exists():
            return conda_python
            
        # ã‚·ã‚¹ãƒ†ãƒ æ¨™æº–Pythonã‚’æ¤œç´¢
        for candidate in candidates:
            try:
                result = subprocess.run([candidate, "--version"], 
                                      capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    self.logger.info(f"Pythonå®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º: {candidate}")
                    return candidate
            except (subprocess.TimeoutExpired, FileNotFoundError):
                continue
                
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return "python3" if self.platform != "windows" else "python"
    
    def _validate_npz_structure(self, npz_path: Path, expected_keys: list = None) -> bool:
        """NPZå†…éƒ¨æ§‹é€ ã®åŸæµå‡¦ç†äº’æ›æ€§ç¢ºèª"""
        try:
            import numpy as np
            data = np.load(npz_path, allow_pickle=True)
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæœŸå¾…ã‚­ãƒ¼ (raw_data.npzç”¨)
            if expected_keys is None:
                expected_keys = ["vertices", "faces"]  # æœ€å°è¦ä»¶
            
            missing_keys = [key for key in expected_keys if key not in data.keys()]
            
            if missing_keys:
                self.logger.error(f"ERROR: Missing required keys in NPZ: {missing_keys}")
                self.logger.error(f"Available keys: {list(data.keys())}")
                return False
            
            # ãƒ‡ãƒ¼ã‚¿å‹æ¤œè¨¼
            if "vertices" in data and not isinstance(data["vertices"], np.ndarray):
                self.logger.error("ERROR: 'vertices' must be numpy array")
                return False
                
            if "faces" in data and not isinstance(data["faces"], np.ndarray):
                self.logger.error("ERROR: 'faces' must be numpy array")
                return False
            
            self.logger.info(f"NPZ structure validated: {npz_path} (keys: {list(data.keys())})")
            return True
            
        except Exception as e:
            self.logger.error(f"ERROR: Failed to validate NPZ structure: {e}")
            return False

    def extract_mesh_unified(self,
                            input_file: str,
                            model_name: str,
                            output_dir: str,
                            **kwargs) -> Dict[str, Any]:
        """
        çµ±ä¸€å‘½åè¦å‰‡å¯¾å¿œãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º
        
        Args:
            input_file: å…¥åŠ›3Dãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            model_name: ãƒ¢ãƒ‡ãƒ«å (çµ±ä¸€å‘½åè¦å‰‡ç”¨)  
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            **kwargs: ãã®ä»–ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        
        Returns:
            Dict: çµ±ä¸€å½¢å¼ã®çµæœè¾æ›¸
        """
        # 1. åŸæµå‡¦ç†å®Ÿè¡Œ
        success, logs = self._execute_original_extract(input_file, output_dir, **kwargs)
        
        if success:
            # 2. çµ±ä¸€å‘½åè¦å‰‡é©ç”¨
            from fixed_directory_manager import FixedDirectoryManager
            
            dir_manager = FixedDirectoryManager(
                base_dir=Path(output_dir).parent, 
                model_name=model_name,
                logger=self.logger
            )
            
            # åŸæµå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
            original_output = Path(output_dir) / "raw_data.npz"
            
            if original_output.exists():
                # çµ±ä¸€å‘½åè¦å‰‡ã§ã‚³ãƒ”ãƒ¼
                unified_output = dir_manager.ensure_unified_output(
                    'step1', 'mesh_npz', original_output
                )
                
                return {
                    'success': True,
                    'unified_files': {'mesh_npz': str(unified_output)},
                    'original_files': {'raw_data_npz': str(original_output)},
                    'logs': logs
                }
            else:
                return {
                    'success': False,
                    'error': 'NPZå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“',
                    'logs': logs
                }
        
        return {'success': False, 'logs': logs}

    def extract_mesh(self,
                    input_file: str,
                    output_dir: str,
                    model_name: str,
                    cfg_data: str = "configs/data/quick_inference.yaml",
                    cfg_task: str = "configs/task/quick_inference_unirig_skin.yaml",
                    faces_target_count: int = 50000,
                    force_override: bool = False,
                    num_runs: int = 1
                    ) -> Tuple[bool, str, Dict[str, Any]]:
        """ãƒ¬ã‚¬ã‚·ãƒ¼äº’æ›æ€§ãƒ¡ã‚½ãƒƒãƒ‰"""
        result = self.extract_mesh_unified(
            input_file=input_file,
            model_name=model_name,
            output_dir=output_dir,
            cfg_data=cfg_data,
            cfg_task=cfg_task,
            faces_target_count=faces_target_count,
            force_override=force_override,
            num_runs=num_runs
        )
        
        return result['success'], result.get('logs', ''), result
    
    def _execute_original_extract(self, input_file: str, output_dir: str, **kwargs) -> Tuple[bool, str]:
        """Execute original extract flow (src.data.extract)"""
        
        # Default values
        cfg_data = kwargs.get('cfg_data', "configs/data/quick_inference.yaml")
        cfg_task = kwargs.get('cfg_task', "configs/task/quick_inference_unirig_skin.yaml")
        faces_target_count = kwargs.get('faces_target_count', 50000)
        force_override = kwargs.get('force_override', False)
        num_runs = kwargs.get('num_runs', 1)
        model_name = kwargs.get('model_name', 'unknown')
        
        start_time = time.time()
        logs = f"Original mesh extraction started: {model_name}\n"
        
        try:
            # Input file validation
            input_path = Path(input_file)
            if not input_path.exists():
                error_msg = f"Input file not found: {input_file}"
                self.logger.error(error_msg)
                return False, logs + error_msg
            
            # Create output directory
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            # çµ±åˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
            temp_dir = output_path / ".temp"
            unified_config_path = self._create_unified_config(cfg_data, cfg_task, temp_dir)
            
            # ç¾åœ¨æ™‚åˆ»ã‚’ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨ã—ã¦ç”Ÿæˆ
            import datetime
            timestamp = datetime.datetime.now().strftime("%Y_%m_%d_%H_%M_%S")
            
            # Build mesh extraction command (ä¿®æ­£ç‰ˆ - å˜ä¸€--configä½¿ç”¨)
            cmd_args = [
                self.python_exec,
                "-m", "src.data.extract",
                f"--config={unified_config_path}",
                f"--require_suffix=obj,fbx,FBX,dae,glb,gltf,vrm",
                f"--input={input_file}",
                f"--output_dir={output_dir}",
                f"--faces_target_count={faces_target_count}",
                f"--force_override={str(force_override).lower()}",
                f"--num_runs={num_runs}",
                f"--id=0",
                f"--time={timestamp}"
            ]
            
            self.logger.info(f"Mesh extraction command: {' '.join(cmd_args)}")
            logs += f"Command: {' '.join(cmd_args)}\n"
            
            # ãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œ (ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä¿è­·)
            result = subprocess.run(
                cmd_args,
                capture_output=True,
                text=True,
                timeout=600,  # 10åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                cwd="/app"  # ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå›ºå®š
            )
            
            execution_time = time.time() - start_time
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹å®šç¾©
            expected_output_npz = Path(output_dir) / "raw_data.npz"  # åŸæµå‡¦ç†å›ºå®šå
            unified_output_npz = Path(output_dir) / "raw_data.npz"   # çµ±ä¸€å‘½åï¼ˆåŒã˜ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
            
            if result.returncode == 0:
                logs += f"âœ… ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºæˆåŠŸ ({execution_time:.2f}ç§’)\n"
                logs += f"æ¨™æº–å‡ºåŠ›: {result.stdout}\n"
                
                # NPZæ§‹é€ æ¤œè¨¼
                if expected_output_npz.exists():
                    if not self._validate_npz_structure(expected_output_npz):
                        error_msg = "âŒ NPZæ§‹é€ æ¤œè¨¼å¤±æ•—"
                        logs += error_msg + "\n"
                        self.logger.error(error_msg)
                        return False, logs, {}
                    
                    logs += f"ğŸ“ çµ±ä¸€NPZç¢ºèª: {unified_output_npz}\n"
                
                # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
                output_files = {
                    "mesh_npz": str(expected_output_npz),  # åŸæµå‡¦ç†äº’æ›
                    "unified_mesh_npz": str(unified_output_npz),  # çµ±ä¸€å‘½åè¦å‰‡
                    "file_size": expected_output_npz.stat().st_size if expected_output_npz.exists() else 0,
                    "execution_time_seconds": round(execution_time, 2)
                }
                
                self.logger.info(f"âœ… ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå®Œäº†: {expected_output_npz}")
                return True, logs, output_files
                
            else:
                error_msg = f"âŒ ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå¤±æ•— (ã‚³ãƒ¼ãƒ‰: {result.returncode})\n"
                error_msg += f"æ¨™æº–ã‚¨ãƒ©ãƒ¼: {result.stderr}\n"
                logs += error_msg
                self.logger.error(error_msg)
                return False, logs, {}
                
        except subprocess.TimeoutExpired:
            error_msg = "âŒ ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ (600ç§’)"
            logs += error_msg + "\n"
            self.logger.error(error_msg)
            return False, logs, {}
            
        except Exception as e:
            error_msg = f"âŒ ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {type(e).__name__} - {e}"
            logs += error_msg + "\n"
            self.logger.error(error_msg, exc_info=True)
            return False, logs, {}
    
    def extract_mesh_unified(self, input_file: str, model_name: str, output_dir: str) -> Tuple[bool, str]:
        """çµ±åˆãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºãƒ¡ã‚½ãƒƒãƒ‰ (app.pyçµ±åˆç”¨)"""
        try:
            self.logger.info(f"çµ±åˆãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºé–‹å§‹: {model_name}")
            
            # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
            input_path = Path(input_file)
            if not input_path.exists():
                return False, f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {input_file}"
            
            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            # åŸæµå‡¦ç†ç›´æ¥å®Ÿè¡Œãƒ‘ã‚¿ãƒ¼ãƒ³
            success, logs = self._execute_original_extract_flow(
                input_file=input_file,
                output_dir=output_dir,
                model_name=model_name
            )
            
            if success:
                # æœŸå¾…å‡ºåŠ›ç¢ºèª
                expected_output = output_path / "raw_data.npz"
                if expected_output.exists():
                    file_size = expected_output.stat().st_size / (1024 * 1024)
                    logs += f"\nâœ… æœŸå¾…å‡ºåŠ›ç¢ºèª: {expected_output} ({file_size:.2f} MB)"
                else:
                    return False, f"æœŸå¾…å‡ºåŠ›ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ: {expected_output}"
            
            return success, logs
            
        except Exception as e:
            self.logger.error(f"çµ±åˆãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return False, f"çµ±åˆãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    def _execute_original_extract_flow(self, input_file: str, output_dir: str, model_name: str) -> Tuple[bool, str]:
        """åŸæµå‡¦ç†extract.shç›´æ¥å®Ÿè¡Œ (ä¿®æ­£ç‰ˆ: åå‰ä»˜ããƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä½¿ç”¨)"""
        try:
            # extract.shã®ç›´æ¥å®Ÿè¡Œ
            extract_script = "/app/launch/inference/extract.sh"
            if not Path(extract_script).exists():
                # Fallback: Pythonå®Ÿè£…
                return self._execute_python_extract(input_file, output_dir, model_name)
            
            # åå‰ä»˜ããƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§extract.shå®Ÿè¡Œ
            cmd = [
                "bash", extract_script,
                "--input", input_file,
                "--output_dir", output_dir,
                "--faces_target_count", "50000",
                "--force_override", "true"
            ]
            
            self.logger.info(f"extract.shå®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: {' '.join(cmd)}")
            
            result = subprocess.run(
                cmd, capture_output=True, text=True, timeout=300, cwd="/app"
            )
            
            if result.returncode == 0:
                return True, f"åŸæµextract.shå®Ÿè¡ŒæˆåŠŸ:\n{result.stdout}"
            else:
                return False, f"åŸæµextract.shå®Ÿè¡Œå¤±æ•—:\n{result.stderr}"
                
        except subprocess.TimeoutExpired:
            return False, "extract.shå®Ÿè¡Œã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (300ç§’)"
        except Exception as e:
            return False, f"åŸæµextract.shå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    def _execute_python_extract(self, input_file: str, output_dir: str, model_name: str) -> Tuple[bool, str]:
        """Pythonå®Ÿè£…ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        try:
            # src.data.extractç›´æ¥å®Ÿè¡Œ
            cmd = [
                self.python_exec, "-m", "src.data.extract",
                "--cfg_data=configs/data/quick_inference.yaml",
                "--cfg_task=configs/task/quick_inference_extract.yaml",
                f"--input={input_file}",
                f"--output_dir={output_dir}"
            ]
            
            result = subprocess.run(
                cmd, capture_output=True, text=True, timeout=300, cwd="/app"
            )
            
            if result.returncode == 0:
                return True, f"Python extractå®Ÿè¡ŒæˆåŠŸ:\n{result.stdout}"
            else:
                return False, f"Python extractå®Ÿè¡Œå¤±æ•—:\n{result.stderr}"
                
        except Exception as e:
            return False, f"Python extractå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    def _create_unified_config(self,
                              cfg_data: str,
                              cfg_task: str,
                              temp_dir: Path) -> str:
        """
        ğŸ”§ è¤‡æ•°ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµ±åˆã—ãŸä¸€æ™‚è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        
        åŸæµå‡¦ç†ã®cfg_data + cfg_taskãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œ
        """
        import yaml
        from box import Box
        
        try:
            # ãƒ‡ãƒ¼ã‚¿è¨­å®šã¨ã‚¿ã‚¹ã‚¯è¨­å®šã‚’èª­ã¿è¾¼ã¿
            with open(cfg_data, 'r') as f:
                data_config = yaml.safe_load(f)
            
            with open(cfg_task, 'r') as f:
                task_config = yaml.safe_load(f)
            
            # çµ±åˆè¨­å®šã‚’ä½œæˆ (task_configãŒdata_configã‚’ä¸Šæ›¸ã)
            unified_config = {**data_config, **task_config}
            
            # ä¸€æ™‚è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            temp_config_path = temp_dir / "unified_extract_config.yaml"
            temp_dir.mkdir(parents=True, exist_ok=True)
            
            with open(temp_config_path, 'w') as f:
                yaml.dump(unified_config, f, default_flow_style=False)
            
            self.logger.info(f"çµ±åˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {temp_config_path}")
            return str(temp_config_path)
            
        except Exception as e:
            self.logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«çµ±åˆå¤±æ•—: {e}")
            raise

# ğŸ¯ ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å¯¾å¿œãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼
def create_unified_extractor(logger: Optional[logging.Logger] = None) -> UnifiedExtractor:
    """çµ±ä¸€ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå™¨ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼ (ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ è‡ªå‹•å¯¾å¿œ)"""
    return UnifiedExtractor(logger=logger)

# ğŸ¯ CLIå®Ÿè¡Œå¯¾å¿œ (extract.shç½®ãæ›ãˆ)
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="UniRigçµ±ä¸€ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º (extract.shç½®ãæ›ãˆ)")
    parser.add_argument("--input", required=True, help="å…¥åŠ›3Dãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("--output_dir", required=True, help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--model_name", required=True, help="ãƒ¢ãƒ‡ãƒ«å (çµ±ä¸€å‘½åè¦å‰‡)")
    parser.add_argument("--cfg_data", default="configs/data/quick_inference.yaml", help="ãƒ‡ãƒ¼ã‚¿è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("--cfg_task", default="configs/task/quick_inference_unirig_skin.yaml", help="ã‚¿ã‚¹ã‚¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("--faces_target_count", type=int, default=50000, help="ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé¢æ•°")
    parser.add_argument("--force_override", action="store_true", help="å¼·åˆ¶ä¸Šæ›¸ã")
    parser.add_argument("--num_runs", type=int, default=1, help="å®Ÿè¡Œå›æ•°")
    
    args = parser.parse_args()
    
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    # çµ±ä¸€ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå®Ÿè¡Œ
    extractor = create_unified_extractor()
    success, logs, output_files = extractor.extract_mesh(
        input_file=args.input,
        output_dir=args.output_dir,
        model_name=args.model_name,
        cfg_data=args.cfg_data,
        cfg_task=args.cfg_task,
        faces_target_count=args.faces_target_count,
        force_override=args.force_override,
        num_runs=args.num_runs
    )
    
    print(logs)
    print(f"å®Ÿè¡Œçµæœ: {'æˆåŠŸ' if success else 'å¤±æ•—'}")
    if output_files:
        print(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_files}")
    
    sys.exit(0 if success else 1)
