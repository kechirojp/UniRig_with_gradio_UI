"""
ğŸ¯ UniRigçµ±ä¸€ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”Ÿæˆå™¨ - Shell Scriptå®Œå…¨ç½®ãæ›ãˆç‰ˆ
ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å®Œå…¨å¯¾å¿œã€çµ±ä¸€å‘½åè¦å‰‡æº–æ‹ 

å…ƒã®generate_skin.shã®å…¨æ©Ÿèƒ½ã‚’Pythonã§å†å®Ÿè£…
- Windows/Mac/Linuxå®Œå…¨å¯¾å¿œ
- çµ±ä¸€å‘½åè¦å‰‡æº–æ‹ 
- dataset_inference_cleanä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç®¡ç†
- Shell Scriptä¾å­˜å®Œå…¨æ’é™¤
"""

import os
import sys
import subprocess
import time
import logging
import shutil
from pathlib import Path
from typing import Tuple, Optional, Dict, Any
import platform

class UnifiedSkinningGenerator:
    """ğŸ¯ çµ±ä¸€ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”Ÿæˆå™¨ (Shell Scriptç½®ãæ›ãˆ)"""
    
    def __init__(self, logger: Optional[logging.Logger] = None):
        self.logger = logger or logging.getLogger(__name__)
        self.platform = platform.system().lower()
        self.python_exec = self._detect_python_executable()
        
    def _detect_python_executable(self) -> str:
        """ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥Pythonå®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•æ¤œå‡º"""
        if self.platform == "windows":
            candidates = ["python", "python.exe", "python3", "python3.exe"]
        else:
            candidates = ["python3", "python", "/usr/bin/python3", "/usr/local/bin/python3"]
        
        # UniRigç’°å¢ƒã®å„ªå…ˆãƒ‘ã‚¹
        conda_python = "/opt/conda/envs/UniRig/bin/python3"
        if Path(conda_python).exists():
            return conda_python
            
        # ã‚·ã‚¹ãƒ†ãƒ æ¨™æº–Pythonã‚’æ¤œç´¢
        for candidate in candidates:
            try:
                result = subprocess.run([candidate, "--version"], 
                                      capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    return candidate
            except (subprocess.TimeoutExpired, FileNotFoundError):
                continue
                
        return "python3" if self.platform != "windows" else "python"
    
    def generate_skinning(self,
                         mesh_npz: str,
                         skeleton_npz: str,
                         skeleton_fbx: str,
                         output_dir: str,
                         model_name: str,
                         cfg_data: str = "configs/data/quick_inference.yaml",
                         cfg_task: str = "configs/task/quick_inference_unirig_skin.yaml",
                         force_override: bool = False,
                         faces_target_count: int = 50000
                         ) -> Tuple[bool, str, Dict[str, Any]]:
        """
        ğŸ¯ çµ±ä¸€ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”Ÿæˆå®Ÿè¡Œ (generate_skin.shå®Œå…¨ç½®ãæ›ãˆ)
        
        Args:
            mesh_npz: å…¥åŠ›ãƒ¡ãƒƒã‚·ãƒ¥NPZãƒ•ã‚¡ã‚¤ãƒ«
            skeleton_npz: å…¥åŠ›ã‚¹ã‚±ãƒ«ãƒˆãƒ³NPZãƒ•ã‚¡ã‚¤ãƒ«
            skeleton_fbx: å…¥åŠ›ã‚¹ã‚±ãƒ«ãƒˆãƒ³FBXãƒ•ã‚¡ã‚¤ãƒ«
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            model_name: ãƒ¢ãƒ‡ãƒ«å (çµ±ä¸€å‘½åè¦å‰‡ç”¨)
            cfg_data: ãƒ‡ãƒ¼ã‚¿è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
            cfg_task: ã‚¿ã‚¹ã‚¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
            force_override: å¼·åˆ¶ä¸Šæ›¸ã
            faces_target_count: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé¢æ•°
            
        Returns:
            (success, logs, output_files) - çµ±ä¸€å‘½åè¦å‰‡æº–æ‹ 
        """
        
        start_time = time.time()
        logs = f"ğŸ¯ çµ±ä¸€ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”Ÿæˆé–‹å§‹: {model_name}\n"
        
        try:
            # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
            for file_path, name in [(mesh_npz, "ãƒ¡ãƒƒã‚·ãƒ¥NPZ"), (skeleton_npz, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³NPZ"), (skeleton_fbx, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³FBX")]:
                if not Path(file_path).exists():
                    error_msg = f"âŒ {name}ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}"
                    self.logger.error(error_msg)
                    return False, logs + error_msg, {}
            
            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            # ğŸ¯ Phase 1: åŸæµå‡¦ç†äº’æ›ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™
            logs += "ğŸ“‹ Phase 1: ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™...\n"
            dataset_work_dir = self._prepare_dataset_work_directory(
                mesh_npz, skeleton_npz, skeleton_fbx, model_name
            )
            logs += f"ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {dataset_work_dir}\n"
            
            # ğŸ¯ Phase 2: å‰å‡¦ç† (extractç›¸å½“)
            logs += "ğŸ“‹ Phase 2: å‰å‡¦ç†å®Ÿè¡Œ...\n"
            extract_success, extract_logs = self._run_extract_phase(
                cfg_data, dataset_work_dir, force_override, faces_target_count
            )
            logs += extract_logs
            
            if not extract_success:
                return False, logs + "âŒ å‰å‡¦ç†æ®µéšã§å¤±æ•—", {}
            
            # ğŸ¯ Phase 3: AIæ¨è«– (run.pyç›¸å½“)
            logs += "ğŸ§  Phase 3: AIæ¨è«–å®Ÿè¡Œ...\n"
            inference_success, inference_logs = self._run_inference_phase(
                cfg_task, dataset_work_dir, model_name
            )
            logs += inference_logs
            
            if not inference_success:
                return False, logs + "âŒ AIæ¨è«–æ®µéšã§å¤±æ•—", {}
            
            # ğŸ¯ Phase 4: çµæœå›åã¨çµ±ä¸€å‘½åè¦å‰‡é©ç”¨
            logs += "ğŸ“ Phase 4: çµæœå›åã¨çµ±ä¸€å‘½å...\n"
            execution_time = time.time() - start_time
            output_files = self._collect_and_apply_unified_naming(
                dataset_work_dir, output_dir, model_name, execution_time
            )
            
            logs += f"âœ… çµ±ä¸€ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”Ÿæˆå®Œäº† ({execution_time:.2f}ç§’)\n"
            self.logger.info(f"âœ… ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”Ÿæˆå®Œäº†: {model_name}")
            
            return True, logs, output_files
            
        except Exception as e:
            error_msg = f"âŒ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”Ÿæˆä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {type(e).__name__} - {e}"
            logs += error_msg + "\n"
            self.logger.error(error_msg, exc_info=True)
            return False, logs, {}
    
    def _prepare_dataset_work_directory(self, mesh_npz: str, skeleton_npz: str, 
                                      skeleton_fbx: str, model_name: str) -> Path:
        """åŸæµå‡¦ç†äº’æ›ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™"""
        dataset_work_dir = Path("/app/dataset_inference_clean") / model_name
        dataset_work_dir.mkdir(parents=True, exist_ok=True)
        
        # å›ºå®šåã§ãƒ•ã‚¡ã‚¤ãƒ«é…ç½® (åŸæµå‡¦ç†äº’æ›)
        target_files = {
            "raw_data.npz": mesh_npz,
            "predict_skeleton.npz": skeleton_npz,
            f"{model_name}.fbx": skeleton_fbx
        }
        
        for target_name, source_path in target_files.items():
            target_path = dataset_work_dir / target_name
            shutil.copy2(source_path, target_path)
            self.logger.info(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«é…ç½®: {source_path} â†’ {target_path}")
        
        # inference_datalist.txtç”Ÿæˆ (åŸæµå‡¦ç†å¿…é ˆ)
        datalist_file = dataset_work_dir / "inference_datalist.txt"
        with open(datalist_file, 'w') as f:
            f.write(f"{model_name}\n")
        
        return dataset_work_dir
    
    def _run_extract_phase(self, cfg_data: str, dataset_work_dir: Path, 
                          force_override: bool, faces_target_count: int) -> Tuple[bool, str]:
        """Phase 2: å‰å‡¦ç†å®Ÿè¡Œ"""
        # ğŸ¯ çµ±ä¸€Extractä½¿ç”¨ (Shell Scriptä¸è¦)
        from .unified_extract import create_unified_extractor
        
        extractor = create_unified_extractor(self.logger)
        
        # dataset_work_dirå†…ã®raw_data.npzã‚’å‡¦ç†å¯¾è±¡ã¨ã™ã‚‹
        input_npz = dataset_work_dir / "raw_data.npz"
        
        success, logs, _ = extractor.extract_mesh(
            input_file=str(input_npz),
            output_dir=str(dataset_work_dir),
            model_name=dataset_work_dir.name,  # model_name
            cfg_data=cfg_data,
            force_override=force_override,
            faces_target_count=faces_target_count
        )
        
        return success, logs
    
    def _run_inference_phase(self, cfg_task: str, dataset_work_dir: Path, 
                           model_name: str) -> Tuple[bool, str]:
        """Phase 3: AIæ¨è«–å®Ÿè¡Œ"""
        cmd_args = [
            self.python_exec,
            "run.py",
            f"--task={cfg_task}",
            "--seed=12345",
            f"--output_dir={dataset_work_dir}",
            f"--npz_dir={dataset_work_dir}",  # åŸæµå‡¦ç†äº’æ›
            f"--model_name={model_name}"  # çµ±ä¸€å‘½åè¦å‰‡å¯¾å¿œ
        ]
        
        try:
            result = subprocess.run(cmd_args, capture_output=True, text=True, 
                                  timeout=900, cwd="/app")  # 15åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            
            if result.returncode == 0:
                return True, f"âœ… AIæ¨è«–æˆåŠŸ\n{result.stdout}\n"
            else:
                return False, f"âŒ AIæ¨è«–å¤±æ•—: {result.stderr}\n"
                
        except subprocess.TimeoutExpired:
            return False, "âŒ AIæ¨è«–ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (900ç§’)\n"
        except Exception as e:
            return False, f"âŒ AIæ¨è«–ã‚¨ãƒ©ãƒ¼: {e}\n"
    
    def _collect_and_apply_unified_naming(self, dataset_work_dir: Path, output_dir: str, 
                                        model_name: str, execution_time: float) -> Dict[str, Any]:
        """Phase 4: çµæœå›åã¨çµ±ä¸€å‘½åè¦å‰‡é©ç”¨"""
        output_path = Path(output_dir)
        
        # ğŸ¯ çµ±ä¸€ãƒ•ã‚¡ã‚¤ãƒ«åå®šç¾©
        unified_skinned_fbx = output_path / f"{model_name}_skinned.fbx"
        unified_skinning_npz = output_path / f"{model_name}_skinning.npz"
        
        # åŸæµå‡¦ç†å‡ºåŠ›ã‹ã‚‰çµ±ä¸€åã¸ã®åé›†
        original_files = {
            "predict_skin.npz": unified_skinning_npz,
            "skinned_model.fbx": unified_skinned_fbx,
            "result_fbx.fbx": unified_skinned_fbx,
            f"{model_name}_skinned_unirig.fbx": unified_skinned_fbx,
            f"{model_name}_skinning.npz": unified_skinning_npz
        }
        
        for original_name, unified_path in original_files.items():
            original_path = dataset_work_dir / original_name
            if original_path.exists() and not unified_path.exists():
                shutil.copy2(original_path, unified_path)
                self.logger.info(f"ğŸ“ çµ±ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å›å: {original_name} â†’ {unified_path.name}")
        
        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±æ§‹ç¯‰
        output_files = {
            "skinned_fbx": str(unified_skinned_fbx) if unified_skinned_fbx.exists() else None,
            "skinning_npz": str(unified_skinning_npz) if unified_skinning_npz.exists() else None,
            "file_size_fbx": unified_skinned_fbx.stat().st_size if unified_skinned_fbx.exists() else 0,
            "file_size_npz": unified_skinning_npz.stat().st_size if unified_skinning_npz.exists() else 0,
            "execution_time_seconds": round(execution_time, 2),
            "work_directory": str(dataset_work_dir)
        }
        
        return output_files

    def apply_skinning_unified(self, model_name: str, mesh_file: str, skeleton_file: str, output_dir: str) -> Tuple[bool, str]:
        """çµ±ä¸€ã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆapp.pyçµ±åˆç”¨ï¼‰"""
        try:
            self.logger.info(f"çµ±åˆã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨é–‹å§‹: {model_name}")
            
            # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
            mesh_path = Path(mesh_file)
            skeleton_path = Path(skeleton_file)
            
            if not mesh_path.exists():
                return False, f"ãƒ¡ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {mesh_file}"
            if not skeleton_path.exists():
                return False, f"ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {skeleton_file}"
            
            # ã‚¹ã‚±ãƒ«ãƒˆãƒ³NPZãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ (æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥æº–æ‹ )
            skeleton_dir = skeleton_path.parent
            skeleton_npz = skeleton_dir / "predict_skeleton.npz"
            
            if not skeleton_npz.exists():
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢
                skeleton_npz = skeleton_dir / f"{model_name}_skeleton.npz"
                if not skeleton_npz.exists():
                    return False, f"ã‚¹ã‚±ãƒ«ãƒˆãƒ³NPZãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {skeleton_dir}"
            
            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§åŸæµå‡¦ç†ç›¸å½“å®Ÿè¡Œ
            success, logs, output_files = self.generate_skinning(
                mesh_npz=mesh_file,
                skeleton_npz=str(skeleton_npz),
                skeleton_fbx=skeleton_file,
                output_dir=output_dir,
                model_name=model_name,
                cfg_data="configs/data/quick_inference.yaml",
                cfg_task="configs/task/quick_inference_unirig_skin.yaml",
                force_override=True,
                faces_target_count=50000
            )
            
            if success:
                # æœŸå¾…å‡ºåŠ›ç¢ºèª (æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥æº–æ‹ )
                expected_fbx = output_path / f"{model_name}_skinned_unirig.fbx"
                expected_npz = output_path / f"{model_name}_skinning.npz"
                
                output_check = []
                if expected_fbx.exists():
                    file_size = expected_fbx.stat().st_size / (1024 * 1024)
                    output_check.append(f"âœ… ã‚¹ã‚­ãƒ‹ãƒ³ã‚°FBX: {expected_fbx} ({file_size:.2f} MB)")
                else:
                    output_check.append(f"âš ï¸ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°FBXæœªä½œæˆ: {expected_fbx}")
                
                if expected_npz.exists():
                    file_size = expected_npz.stat().st_size / (1024 * 1024)
                    output_check.append(f"âœ… ã‚¹ã‚­ãƒ‹ãƒ³ã‚°NPZ: {expected_npz} ({file_size:.2f} MB)")
                else:
                    output_check.append(f"âš ï¸ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°NPZæœªä½œæˆ: {expected_npz}")
                
                logs += "\næœŸå¾…å‡ºåŠ›ç¢ºèª:\n" + "\n".join(output_check)
            
            return success, logs
            
        except Exception as e:
            self.logger.error(f"çµ±åˆã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return False, f"çµ±åˆã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨ã‚¨ãƒ©ãƒ¼: {str(e)}"

# ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼çµ±åˆã‚¨ã‚¤ãƒªã‚¢ã‚¹
class UnifiedSkinningOrchestrator(UnifiedSkinningGenerator):
    """app.pyçµ±åˆç”¨ã‚¨ã‚¤ãƒªã‚¢ã‚¹"""
    pass

# ğŸ¯ ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å¯¾å¿œãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼
def create_unified_skinning_generator(logger: Optional[logging.Logger] = None) -> UnifiedSkinningGenerator:
    """çµ±ä¸€ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”Ÿæˆå™¨ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼ (ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ è‡ªå‹•å¯¾å¿œ)"""
    return UnifiedSkinningGenerator(logger=logger)

# ğŸ¯ CLIå®Ÿè¡Œå¯¾å¿œ (generate_skin.shç½®ãæ›ãˆ)
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="UniRigçµ±ä¸€ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”Ÿæˆ (generate_skin.shç½®ãæ›ãˆ)")
    parser.add_argument("--mesh_npz", required=True, help="å…¥åŠ›ãƒ¡ãƒƒã‚·ãƒ¥NPZãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("--skeleton_npz", required=True, help="å…¥åŠ›ã‚¹ã‚±ãƒ«ãƒˆãƒ³NPZãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("--skeleton_fbx", required=True, help="å…¥åŠ›ã‚¹ã‚±ãƒ«ãƒˆãƒ³FBXãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("--output_dir", required=True, help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--model_name", required=True, help="ãƒ¢ãƒ‡ãƒ«å (çµ±ä¸€å‘½åè¦å‰‡)")
    parser.add_argument("--cfg_data", default="configs/data/quick_inference.yaml", help="ãƒ‡ãƒ¼ã‚¿è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("--cfg_task", default="configs/task/quick_inference_unirig_skin.yaml", help="ã‚¿ã‚¹ã‚¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("--force_override", action="store_true", help="å¼·åˆ¶ä¸Šæ›¸ã")
    parser.add_argument("--faces_target_count", type=int, default=50000, help="ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé¢æ•°")
    
    args = parser.parse_args()
    
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    # çµ±ä¸€ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”Ÿæˆå®Ÿè¡Œ
    generator = create_unified_skinning_generator()
    success, logs, output_files = generator.generate_skinning(
        mesh_npz=args.mesh_npz,
        skeleton_npz=args.skeleton_npz,
        skeleton_fbx=args.skeleton_fbx,
        output_dir=args.output_dir,
        model_name=args.model_name,
        cfg_data=args.cfg_data,
        cfg_task=args.cfg_task,
        force_override=args.force_override,
        faces_target_count=args.faces_target_count
    )
    
    print(logs)
    print(f"å®Ÿè¡Œçµæœ: {'æˆåŠŸ' if success else 'å¤±æ•—'}")
    if output_files:
        print(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_files}")
    
    sys.exit(0 if success else 1)
