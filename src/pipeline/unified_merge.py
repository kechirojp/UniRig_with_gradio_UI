#!/usr/bin/env python3
"""
UniRigçµ±åˆãƒãƒ¼ã‚¸ã‚·ã‚¹ãƒ†ãƒ  - merge.shå®Œå…¨Pythonç½®ãæ›ãˆ

æœ¬ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ä»¥ä¸‹ã‚’å®Ÿç¾ã—ã¾ã™ï¼š
1. ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å¯¾å¿œï¼ˆWindows/Linux/MacOSï¼‰
2. çµ±ä¸€å‘½åè¦å‰‡ã®å³æ ¼ãªé©ç”¨
3. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å‘ä¸Š
4. CLIãƒ»ãƒ—ãƒ­ã‚°ãƒ©ãƒ ä¸¡å¯¾å¿œ
5. å®Ÿè¡Œæ™‚é–“ã®æœ€é©åŒ–

çµ±ä¸€å‘½åè¦å‰‡:
- å…¥åŠ›: {model_name}.fbx (skeleton), {model_name}_skinned.fbx (skinning)
- å‡ºåŠ›: {model_name}_merged.fbx (çµ±åˆæ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«)
"""

import os
import sys
import argparse
import subprocess
import logging
from pathlib import Path
from typing import Tuple, Optional, Dict, Any

# UniRigãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

class UnifiedMergeOrchestrator:
    """çµ±ä¸€ãƒãƒ¼ã‚¸ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼"""
    
    def __init__(self, enable_debug: bool = False):
        """
        Args:
            enable_debug: ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°æœ‰åŠ¹åŒ–
        """
        self.logger = self._setup_logger(enable_debug)
        self.supported_formats = ['.obj', '.fbx', '.FBX', '.dae', '.glb', '.gltf', '.vrm']
        
    def _setup_logger(self, enable_debug: bool) -> logging.Logger:
        """ãƒ­ã‚¬ãƒ¼è¨­å®š"""
        logger = logging.getLogger('UnifiedMergeOrchestrator')
        logger.setLevel(logging.DEBUG if enable_debug else logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler(sys.stdout)
            formatter = logging.Formatter(
                '[%(asctime)s] %(levelname)s - %(message)s',
                datefmt='%Y-%m-%d %H:%M:%S'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def _validate_fbx_binary_format(self, file_path: str) -> bool:
        """FBXãƒ•ã‚¡ã‚¤ãƒ«ãŒãƒã‚¤ãƒŠãƒªå½¢å¼ã‹ãƒã‚§ãƒƒã‚¯ (src.inference.mergeäº’æ›æ€§ç¢ºä¿)"""
        try:
            with open(file_path, 'rb') as f:
                header = f.read(27)
                is_binary = header.startswith(b'Kaydara FBX Binary')
                
                if not is_binary:
                    self.logger.error(f"ERROR: ASCII FBX detected - src.inference.merge requires binary FBX: {file_path}")
                    self.logger.error("SOLUTION: Ensure FBX export uses binary format (Blender default)")
                    return False
                
                self.logger.info(f"FBX binary format verified: {file_path}")
                return True
                
        except Exception as e:
            self.logger.error(f"ERROR: Failed to validate FBX format: {e}")
            return False

    def _validate_inputs(self, source: str, target: str, output: str) -> bool:
        """å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼"""
        # å¿…é ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
        if not all([source, target, output]):
            self.logger.error("ERROR: All parameters (source, target, output) are required")
            return False
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        if not Path(source).exists():
            self.logger.error(f"ERROR: Source file not found: {source}")
            return False
            
        if not Path(target).exists():
            self.logger.error(f"ERROR: Target file not found: {target}")
            return False
        
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œè¨¼
        source_suffix = Path(source).suffix.lower()
        target_suffix = Path(target).suffix.lower()
        
        if source_suffix not in [s.lower() for s in self.supported_formats]:
            self.logger.error(f"ERROR: Unsupported source format: {source_suffix}")
            return False
            
        if target_suffix not in [s.lower() for s in self.supported_formats]:
            self.logger.error(f"ERROR: Unsupported target format: {target_suffix}")
            return False
        
        # ğŸ¯ FBXãƒã‚¤ãƒŠãƒªå½¢å¼æ¤œè¨¼è¿½åŠ  (åŸæµäº’æ›æ€§ç¢ºä¿)
        if source_suffix == '.fbx' and not self._validate_fbx_binary_format(source):
            return False
            
        if target_suffix == '.fbx' and not self._validate_fbx_binary_format(target):
            return False
        
        return True
    
    def _execute_merge_command(self, source: str, target: str, output: str) -> Tuple[bool, str]:
        """ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ã‚¸ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ"""
        try:
            # çµ±ä¸€ãƒãƒ¼ã‚¸ã‚³ãƒãƒ³ãƒ‰æ§‹ç¯‰
            cmd = [
                sys.executable, '-m', 'src.inference.merge',
                '--require_suffix=obj,fbx,FBX,dae,glb,gltf,vrm',
                '--num_runs=1',
                '--id=0',
                f'--source={source}',
                f'--target={target}',
                f'--output={output}'
            ]
            
            self.logger.info(f"Executing merge command: {' '.join(cmd)}")
            
            # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
            result = subprocess.run(
                cmd,
                cwd=project_root,
                capture_output=True,
                text=True,
                timeout=1800  # 30åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            )
            
            if result.returncode == 0:
                self.logger.info("Merge command executed successfully")
                return True, result.stdout
            else:
                self.logger.error(f"Merge command failed with code {result.returncode}")
                self.logger.error(f"STDERR: {result.stderr}")
                return False, result.stderr
                
        except subprocess.TimeoutExpired:
            self.logger.error("ERROR: Merge command timeout (30 minutes)")
            return False, "Command timeout"
        except Exception as e:
            self.logger.error(f"ERROR: Merge command execution failed: {e}")
            return False, str(e)
    
    def _apply_unified_naming_convention(self, output: str, model_name: str) -> Tuple[bool, str]:
        """çµ±ä¸€å‘½åè¦å‰‡é©ç”¨"""
        output_path = Path(output)
        expected_name = f"{model_name}_merged.fbx"
        
        # çµ±ä¸€å‘½åè¦å‰‡ãƒã‚§ãƒƒã‚¯
        if output_path.name != expected_name:
            self.logger.warning(f"Output filename does not follow unified naming convention")
            self.logger.warning(f"Expected: {expected_name}")
            self.logger.warning(f"Actual: {output_path.name}")
            
            # çµ±ä¸€å‘½åè¦å‰‡æº–æ‹ ã¸ã®ä¿®æ­£
            unified_output = output_path.parent / expected_name
            
            if output_path.exists() and output_path != unified_output:
                try:
                    output_path.rename(unified_output)
                    self.logger.info(f"Renamed to unified convention: {unified_output}")
                    return True, str(unified_output)
                except Exception as e:
                    self.logger.error(f"Failed to rename to unified convention: {e}")
                    return False, str(output_path)
            else:
                return True, str(unified_output)
        
        return True, output
    
    def _verify_output(self, output: str) -> bool:
        """å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼"""
        output_path = Path(output)
        
        if not output_path.exists():
            self.logger.error(f"ERROR: Merge failed - output file not found: {output}")
            return False
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆæœ€å°ã‚µã‚¤ã‚ºæ¤œè¨¼ï¼‰
        file_size = output_path.stat().st_size
        if file_size < 1024:  # 1KBæœªæº€ã¯ç•°å¸¸
            self.logger.error(f"ERROR: Output file suspiciously small: {file_size} bytes")
            return False
        
        self.logger.info(f"Merge completed successfully - Output file: {output} ({file_size} bytes)")
        return True
    
    def execute_merge(self, source: str, target: str, output: str) -> Tuple[bool, str, Dict[str, Any]]:
        """
        çµ±åˆãƒãƒ¼ã‚¸å®Ÿè¡Œ
        
        Args:
            source: ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
            target: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
            output: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        
        Returns:
            (success, logs, output_files): å®Ÿè¡Œçµæœ
        """
        # ãƒ¢ãƒ‡ãƒ«åã‚’å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰æ¨æ¸¬
        output_path = Path(output)
        model_name = output_path.stem.replace("_merged", "")
        
        self.logger.info(f"Starting unified merge for model: {model_name}")
        self.logger.info(f"Source (skeleton): {source}")
        self.logger.info(f"Target (skinned): {target}")
        self.logger.info(f"Output path: {output}")
        
        # å…¥åŠ›æ¤œè¨¼
        if not self._validate_inputs(source, target, output):
            return False, "Input validation failed", {}
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        output_dir = Path(output).parent
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ã‚¸ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
        success, logs = self._execute_merge_command(source, target, output)
        if not success:
            return False, f"Merge command failed: {logs}", {}
        
        # çµ±ä¸€å‘½åè¦å‰‡é©ç”¨
        success, final_output = self._apply_unified_naming_convention(output, model_name)
        if not success:
            return False, f"Failed to apply unified naming convention", {}
        
        # å‡ºåŠ›æ¤œè¨¼
        if not self._verify_output(final_output):
            return False, "Output verification failed", {}
        
        # æˆåŠŸ
        result_files = {
            "merged_fbx": final_output
        }
        
        success_log = (
            f"Merge process completed successfully with unified naming convention\n"
            f"Generated unified merged file: {final_output}\n"
            f"Original logs: {logs}"
        )
        
        return True, success_log, result_files

    def merge_skeleton_skinning_unified(self, model_name: str, skeleton_fbx: str, skinned_fbx: str, output_dir: str) -> Tuple[bool, str]:
        """çµ±ä¸€ãƒãƒ¼ã‚¸ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆapp.pyçµ±åˆç”¨ï¼‰"""
        try:
            self.logger.info(f"çµ±åˆãƒãƒ¼ã‚¸å‡¦ç†é–‹å§‹: {model_name}")
            
            # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
            skeleton_path = Path(skeleton_fbx)
            skinned_path = Path(skinned_fbx)
            
            if not skeleton_path.exists():
                return False, f"ã‚¹ã‚±ãƒ«ãƒˆãƒ³FBXãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {skeleton_fbx}"
            if not skinned_path.exists():
                return False, f"ã‚¹ã‚­ãƒ‹ãƒ³ã‚°FBXãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {skinned_fbx}"
            
            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æ±ºå®š (æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥æº–æ‹ )
            output_file = output_path / f"{model_name}_merged.fbx"
            
            # çµ±ä¸€ãƒãƒ¼ã‚¸å‡¦ç†å®Ÿè¡Œ
            success, logs, output_files = self.execute_merge(
                source=skeleton_fbx,
                target=skinned_fbx,
                output=str(output_file)
            )
            
            if success:
                # æœŸå¾…å‡ºåŠ›ç¢ºèª
                if output_file.exists():
                    file_size = output_file.stat().st_size / (1024 * 1024)
                    logs += f"\nâœ… ãƒãƒ¼ã‚¸å‡ºåŠ›ç¢ºèª: {output_file} ({file_size:.2f} MB)"
                else:
                    return False, f"ãƒãƒ¼ã‚¸å‡ºåŠ›ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ: {output_file}"
            
            return success, logs
            
        except Exception as e:
            self.logger.error(f"çµ±åˆãƒãƒ¼ã‚¸å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return False, f"çµ±åˆãƒãƒ¼ã‚¸å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}"
        
def main():
    """CLIã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    parser = argparse.ArgumentParser(
        description="UniRigçµ±åˆãƒãƒ¼ã‚¸ã‚·ã‚¹ãƒ†ãƒ  - merge.shå®Œå…¨Pythonç½®ãæ›ãˆ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  python -m src.pipeline.unified_merge --source skeleton.fbx --target skinned.fbx --output merged.fbx --model_name bird

çµ±ä¸€å‘½åè¦å‰‡:
  å…¥åŠ›: {model_name}.fbx (skeleton), {model_name}_skinned.fbx (skinning)
  å‡ºåŠ›: {model_name}_merged.fbx (çµ±åˆæ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«)
        """
    )
    
    parser.add_argument('--source', required=True, help='ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰')
    parser.add_argument('--target', required=True, help='ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰')
    parser.add_argument('--output', required=True, help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    parser.add_argument('--model_name', required=True, help='ãƒ¢ãƒ‡ãƒ«åï¼ˆçµ±ä¸€å‘½åè¦å‰‡ç”¨ï¼‰')
    parser.add_argument('--debug', action='store_true', help='ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°æœ‰åŠ¹åŒ–')
    
    args = parser.parse_args()
    
    # ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼å®Ÿè¡Œ
    orchestrator = UnifiedMergeOrchestrator(enable_debug=args.debug)
    success, logs, output_files = orchestrator.execute_merge(
        source=args.source,
        target=args.target,
        output=args.output,
        model_name=args.model_name
    )
    
    # çµæœå‡ºåŠ›
    print("\n" + "="*60)
    print("UniRigçµ±åˆãƒãƒ¼ã‚¸ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œçµæœ:")
    print("="*60)
    print(f"å®Ÿè¡ŒçŠ¶æ…‹: {'æˆåŠŸ' if success else 'å¤±æ•—'}")
    print(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_files}")
    print("\nå®Ÿè¡Œãƒ­ã‚°:")
    print(logs)
    print("="*60)
    
    sys.exit(0 if success else 1)

if __name__ == '__main__':
    main()
