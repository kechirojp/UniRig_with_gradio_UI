#!/usr/bin/env python3
"""
ğŸ” UniRig ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ãƒ†ã‚¹ãƒˆ
å‘½åè¦å‰‡ã®æŸ”è»Ÿæ€§ã¨ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã®æ¤œè¨¼æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ

2025å¹´6æœˆ14æ—¥ä½œæˆ
"""

import os
import sys
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Any

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
sys.path.insert(0, '/app')

# å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from fixed_directory_manager import FixedDirectoryManager

def setup_test_logger() -> logging.Logger:
    """ãƒ†ã‚¹ãƒˆç”¨ãƒ­ã‚¬ãƒ¼è¨­å®š"""
    logger = logging.getLogger("pipeline_file_validation_test")
    logger.setLevel(logging.DEBUG)
    
    if not logger.handlers:
        handler = logging.StreamHandler()
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
    
    return logger

def test_file_generation_patterns():
    """ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
    logger = setup_test_logger()
    logger.info("ğŸ” ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    test_model = "test_bird"
    pipeline_base = Path("/app/pipeline_work")
    
    # ãƒ†ã‚¹ãƒˆç”¨FixedDirectoryManager
    fdm = FixedDirectoryManager(pipeline_base, test_model, logger)
    
    results = {}
    
    # å„ã‚¹ãƒ†ãƒƒãƒ—ã®æœŸå¾…ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
    for step in ["step0", "step1", "step2", "step3", "step4", "step5"]:
        try:
            expected_files = fdm.get_expected_files(step)
            step_dir = fdm.get_step_dir(step)
            
            logger.info(f"[FILE] {step} æœŸå¾…ãƒ•ã‚¡ã‚¤ãƒ«:")
            for key, path in expected_files.items():
                exists = path.exists() if hasattr(path, 'exists') else False
                logger.info(f"  {key}: {path} (å­˜åœ¨: {exists})")
            
            results[step] = {
                "expected_files": expected_files,
                "step_dir": step_dir,
                "dir_exists": step_dir.exists()
            }
            
        except Exception as e:
            logger.error(f"[FAIL] {step} ã‚¨ãƒ©ãƒ¼: {e}")
            results[step] = {"error": str(e)}
    
    return results

def test_file_pattern_flexibility():
    """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æŸ”è»Ÿæ€§ãƒ†ã‚¹ãƒˆ"""
    logger = setup_test_logger()
    logger.info("ğŸ”„ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³æŸ”è»Ÿæ€§ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³
    test_patterns = {
        "step1": [
            "raw_data.npz",           # æ¨™æº–
            "extracted_mesh.npz",     # å¤‰å‰‡1
            "mesh_output.npz"         # å¤‰å‰‡2
        ],
        "step2": [
            "test_bird.fbx",          # æ¨™æº– {model_name}.fbx
            "skeleton.fbx",           # åŸæµå‡¦ç†å‡ºåŠ›
            "test_bird_skeleton.fbx"  # å¤‰å‰‡
        ],
        "step3": [
            "test_bird_skinned_unirig.fbx",  # æ¨™æº–
            "result_fbx.fbx",                # åŸæµå‡¦ç†å‡ºåŠ›
            "test_bird_skinned.fbx"          # å¤‰å‰‡
        ]
    }
    
    logger.info("ğŸ“‹ æƒ³å®šã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³:")
    for step, patterns in test_patterns.items():
        logger.info(f"  {step}:")
        for pattern in patterns:
            logger.info(f"    - {pattern}")
    
    return test_patterns

def test_step_input_validation():
    """ã‚¹ãƒ†ãƒƒãƒ—å…¥åŠ›æ¤œè¨¼æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    logger = setup_test_logger()
    logger.info("[OK] ã‚¹ãƒ†ãƒƒãƒ—å…¥åŠ›æ¤œè¨¼ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    test_model = "test_bird"
    pipeline_base = Path("/app/pipeline_work")
    fdm = FixedDirectoryManager(pipeline_base, test_model, logger)
    
    validation_results = {}
    
    # å„ã‚¹ãƒ†ãƒƒãƒ—ã®å…¥åŠ›æ¤œè¨¼
    for step in ["step2", "step3", "step4", "step5"]:
        try:
            # fdm.validate_step_inputsãƒ¡ã‚½ãƒƒãƒ‰ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if hasattr(fdm, 'validate_step_inputs'):
                valid, message, available_files = fdm.validate_step_inputs(step)
                validation_results[step] = {
                    "valid": valid,
                    "message": message,
                    "available_files": available_files if valid else {}
                }
                logger.info(f"ğŸ“Š {step} å…¥åŠ›æ¤œè¨¼: {'æˆåŠŸ' if valid else 'å¤±æ•—'}")
                if not valid:
                    logger.warning(f"  ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {message}")
                else:
                    logger.info(f"  åˆ©ç”¨å¯èƒ½ãƒ•ã‚¡ã‚¤ãƒ«: {len(available_files)}å€‹")
            else:
                validation_results[step] = {"error": "validate_step_inputsãƒ¡ã‚½ãƒƒãƒ‰ãŒå­˜åœ¨ã—ã¾ã›ã‚“"}
                logger.error(f"[FAIL] {step}: validate_step_inputsãƒ¡ã‚½ãƒƒãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
        except Exception as e:
            validation_results[step] = {"error": str(e)}
            logger.error(f"[FAIL] {step} æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
    
    return validation_results

def test_file_count_verification():
    """ãƒ•ã‚¡ã‚¤ãƒ«æ•°æ¤œè¨¼æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    logger = setup_test_logger()
    logger.info("ğŸ”¢ ãƒ•ã‚¡ã‚¤ãƒ«æ•°æ¤œè¨¼ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # å„ã‚¹ãƒ†ãƒƒãƒ—ã§æœŸå¾…ã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ•°
    expected_counts = {
        "step0": 3,  # preserved_file, metadata_json, textures_dir
        "step1": 1,  # raw_data_npz
        "step2": 2,  # skeleton_fbx, skeleton_npz
        "step3": 2,  # skinned_fbx, skinning_npz
        "step4": 1,  # merged_fbx
        "step5": 2   # final_fbx, final_fbm_dir
    }
    
    test_model = "test_bird"
    pipeline_base = Path("/app/pipeline_work")
    fdm = FixedDirectoryManager(pipeline_base, test_model, logger)
    
    count_results = {}
    
    for step, expected_count in expected_counts.items():
        try:
            expected_files = fdm.get_expected_files(step)
            actual_count = len(expected_files)
            
            count_results[step] = {
                "expected_count": expected_count,
                "actual_count": actual_count,
                "match": expected_count == actual_count,
                "files": list(expected_files.keys())
            }
            
            status = "[OK]" if expected_count == actual_count else "âš ï¸"
            logger.info(f"{status} {step}: æœŸå¾…{expected_count}å€‹ vs å®Ÿéš›{actual_count}å€‹")
            
        except Exception as e:
            count_results[step] = {"error": str(e)}
            logger.error(f"[FAIL] {step} ã‚«ã‚¦ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    return count_results

def test_flexible_file_search():
    """æŸ”è»Ÿãªãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    logger = setup_test_logger()
    logger.info("ğŸ” æŸ”è»Ÿãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    test_model = "test_bird"
    pipeline_base = Path("/app/pipeline_work")
    test_dir = pipeline_base / test_model / "01_extracted_mesh"
    test_dir.mkdir(parents=True, exist_ok=True)
    
    # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    test_files = [
        "raw_data.npz",
        "extracted_mesh.npz", 
        "mesh_output.npz",
        "other_file.txt"
    ]
    
    for file_name in test_files:
        test_file = test_dir / file_name
        test_file.write_text("test data")
    
    # NPZãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ãƒ†ã‚¹ãƒˆ
    npz_files = list(test_dir.glob("*.npz"))
    logger.info(f"[FILE] {test_dir} å†…ã®NPZãƒ•ã‚¡ã‚¤ãƒ«:")
    for npz_file in npz_files:
        logger.info(f"  - {npz_file.name}")
    
    # æŸ”è»Ÿãªæ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆ
    search_patterns = [
        "*raw_data*.npz",
        "*mesh*.npz", 
        "*.npz"
    ]
    
    search_results = {}
    for pattern in search_patterns:
        matches = list(test_dir.glob(pattern))
        search_results[pattern] = [m.name for m in matches]
        logger.info(f"ğŸ” ãƒ‘ã‚¿ãƒ¼ãƒ³ '{pattern}': {len(matches)}å€‹ã®ãƒãƒƒãƒ")
        for match in matches:
            logger.info(f"  - {match.name}")
    
    # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
    for file_name in test_files:
        test_file = test_dir / file_name
        if test_file.exists():
            test_file.unlink()
    
    return search_results

def analyze_app_py_file_handling():
    """app.pyã®ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ–¹å¼ã‚’åˆ†æ"""
    logger = setup_test_logger()
    logger.info("ğŸ“‹ app.pyãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†åˆ†æé–‹å§‹")
    
    app_py_path = Path("/app/app.py")
    
    if not app_py_path.exists():
        logger.error("[FAIL] app.pyãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return {"error": "app.py not found"}
    
    # app.pyã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–¢é€£ã®ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º
    with open(app_py_path, 'r', encoding='utf-8') as f:
        app_content = f.read()
    
    # é‡è¦ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
    important_patterns = [
        "get_expected_files",
        "validate_step_inputs",
        "exists()",
        ".glob(",
        "raw_data.npz",
        "predict_skeleton.npz",
        "_skinned_unirig.fbx",
        "_merged.fbx",
        "_final.fbx"
    ]
    
    pattern_analysis = {}
    for pattern in important_patterns:
        count = app_content.count(pattern)
        pattern_analysis[pattern] = count
        logger.info(f"ğŸ” '{pattern}': {count}å›ä½¿ç”¨")
    
    # ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œé–¢æ•°ã®åˆ†æ
    step_functions = [
        "execute_step0",
        "execute_step1", 
        "execute_step2",
        "execute_step3",
        "execute_step4",
        "execute_step5"
    ]
    
    function_analysis = {}
    for func in step_functions:
        if func in app_content:
            # é–¢æ•°å®šç¾©ã®å ´æ‰€ã‚’è¦‹ã¤ã‘ã‚‹
            lines = app_content.split('\n')
            for i, line in enumerate(lines):
                if f"def {func}" in line:
                    function_analysis[func] = {
                        "found": True,
                        "line": i + 1,
                        "definition": line.strip()
                    }
                    logger.info(f"[OK] {func}: è¡Œ{i+1}ã§å®šç¾©")
                    break
        else:
            function_analysis[func] = {"found": False}
            logger.warning(f"âš ï¸ {func}: å®šç¾©ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    return {
        "pattern_analysis": pattern_analysis,
        "function_analysis": function_analysis
    }

def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    logger = setup_test_logger()
    logger.info("ğŸš€ UniRig ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    print("="*80)
    print("ğŸ” UniRig ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ãƒ†ã‚¹ãƒˆ")
    print("="*80)
    
    # 1. ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆ
    print("\n1ï¸âƒ£ ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆ")
    file_patterns = test_file_generation_patterns()
    
    # 2. ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³æŸ”è»Ÿæ€§ãƒ†ã‚¹ãƒˆ
    print("\n2ï¸âƒ£ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³æŸ”è»Ÿæ€§ãƒ†ã‚¹ãƒˆ")
    pattern_flexibility = test_file_pattern_flexibility()
    
    # 3. ã‚¹ãƒ†ãƒƒãƒ—å…¥åŠ›æ¤œè¨¼ãƒ†ã‚¹ãƒˆ
    print("\n3ï¸âƒ£ ã‚¹ãƒ†ãƒƒãƒ—å…¥åŠ›æ¤œè¨¼ãƒ†ã‚¹ãƒˆ")
    input_validation = test_step_input_validation()
    
    # 4. ãƒ•ã‚¡ã‚¤ãƒ«æ•°æ¤œè¨¼ãƒ†ã‚¹ãƒˆ
    print("\n4ï¸âƒ£ ãƒ•ã‚¡ã‚¤ãƒ«æ•°æ¤œè¨¼ãƒ†ã‚¹ãƒˆ")
    count_verification = test_file_count_verification()
    
    # 5. æŸ”è»Ÿãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ãƒ†ã‚¹ãƒˆ
    print("\n5ï¸âƒ£ æŸ”è»Ÿãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ãƒ†ã‚¹ãƒˆ")
    flexible_search = test_flexible_file_search()
    
    # 6. app.pyãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†åˆ†æ
    print("\n6ï¸âƒ£ app.pyãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†åˆ†æ")
    app_analysis = analyze_app_py_file_handling()
    
    # ç·æ‹¬ãƒ¬ãƒãƒ¼ãƒˆ
    print("\n" + "="*80)
    print("ğŸ“Š ç·æ‹¬ãƒ¬ãƒãƒ¼ãƒˆ")
    print("="*80)
    
    logger.info("[OK] å…¨ãƒ†ã‚¹ãƒˆå®Œäº†")
    
    # é‡è¦ãªç™ºè¦‹äº‹é …ã‚’ã¾ã¨ã‚ã‚‹
    print("\nğŸ” é‡è¦ãªç™ºè¦‹äº‹é …:")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
    print("\nğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«æ•°æ•´åˆæ€§:")
    for step, result in count_verification.items():
        if "error" not in result:
            status = "[OK]" if result["match"] else "âš ï¸"
            print(f"  {status} {step}: {result['actual_count']}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«")
    
    # app.pyã§ã®é‡è¦ãƒ‘ã‚¿ãƒ¼ãƒ³ä½¿ç”¨çŠ¶æ³
    print("\nğŸ“‹ app.pyé‡è¦ãƒ‘ã‚¿ãƒ¼ãƒ³ä½¿ç”¨çŠ¶æ³:")
    if "pattern_analysis" in app_analysis:
        for pattern, count in app_analysis["pattern_analysis"].items():
            if count > 0:
                print(f"  [OK] {pattern}: {count}å›ä½¿ç”¨")
    
    # æ¨å¥¨äº‹é …
    print("\nğŸ’¡ æ¨å¥¨äº‹é …:")
    print("  1. ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèªã«glob()ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã‚’æ´»ç”¨")
    print("  2. å‘½åè¦å‰‡ã®å¤‰åŒ–ã«å¯¾å¿œã™ã‚‹æŸ”è»Ÿãªæ¤œç´¢æ©Ÿèƒ½")
    print("  3. ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã®æœŸå¾…å€¤æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ")
    print("  4. ã‚¨ãƒ©ãƒ¼æ™‚ã®è©³ç´°ãªè¨ºæ–­æƒ…å ±æä¾›")
    
    return {
        "file_patterns": file_patterns,
        "pattern_flexibility": pattern_flexibility,
        "input_validation": input_validation,
        "count_verification": count_verification,
        "flexible_search": flexible_search,
        "app_analysis": app_analysis
    }

if __name__ == "__main__":
    main()
