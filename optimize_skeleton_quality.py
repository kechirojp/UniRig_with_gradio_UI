#!/usr/bin/env python3
"""
ã‚¹ã‚±ãƒ«ãƒˆãƒ³å“è³ªå‘ä¸Šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼èª¿æ•´ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
2025å¹´6æœˆ17æ—¥ - ãƒ¡ãƒƒã‚·ãƒ¥ã«æ²¿ã£ãŸæ­£ç¢ºãªã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆã®ãŸã‚ã®è¨­å®šæœ€é©åŒ–
"""

import shutil
import yaml
from pathlib import Path

def backup_config_files():
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ"""
    config_files = [
        "/app/configs/system/ar_inference_articulationxl.yaml",
        "/app/configs/model/unirig_ar_350m_1024_81920_float32.yaml",
    ]
    
    for config_file in config_files:
        backup_path = config_file + ".backup"
        shutil.copy2(config_file, backup_path)
        print(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_path}")

def optimize_skeleton_quality():
    """ã‚¹ã‚±ãƒ«ãƒˆãƒ³å“è³ªå‘ä¸Šã®ãŸã‚ã®è¨­å®šæœ€é©åŒ–"""
    
    print("ğŸ”§ ã‚¹ã‚±ãƒ«ãƒˆãƒ³å“è³ªå‘ä¸Šè¨­å®šã‚’é©ç”¨ä¸­...")
    
    # 1. ã‚·ã‚¹ãƒ†ãƒ è¨­å®šæœ€é©åŒ– - ã‚ˆã‚Šç²¾å¯†ãªæ¨è«–
    system_config_path = "/app/configs/system/ar_inference_articulationxl.yaml"
    with open(system_config_path, 'r') as f:
        system_config = yaml.safe_load(f)
    
    # é«˜å“è³ªåŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼
    system_config['generate_kwargs'].update({
        'max_new_tokens': 6144,      # ğŸ”¥ ã‚ˆã‚Šè¤‡é›‘ãªã‚¹ã‚±ãƒ«ãƒˆãƒ³å¯¾å¿œ
        'num_beams': 30,             # ğŸ”¥ æ¢ç´¢ç²¾åº¦å‘ä¸Š
        'temperature': 1.2,          # ğŸ”¥ å®‰å®šæ€§é‡è¦–ï¼ˆå‰µé€ æ€§ã‚’å°‘ã—ä¸‹ã’ã‚‹ï¼‰
        'top_k': 8,                  # ğŸ”¥ å€™è£œã‚’çµã£ã¦ã‚ˆã‚Šç²¾å¯†ã«
        'top_p': 0.9,               # ğŸ”¥ ç¢ºç‡çš„ã‚«ãƒƒãƒˆã‚ªãƒ•ã‚’å³ã—ã
        'repetition_penalty': 2.5,   # ğŸ”¥ é‡è¤‡ã‚’é˜²æ­¢ã—ã¤ã¤è‡ªç„¶æ€§ä¿æŒ
        'do_sample': True,
        'use_dir_cls': False,
        'no_cls': False,
        'assign_cls': 'articulationxl'
    })
    
    with open(system_config_path, 'w') as f:
        yaml.safe_dump(system_config, f, default_flow_style=False)
    
    print(f"âœ… ã‚·ã‚¹ãƒ†ãƒ è¨­å®šæœ€é©åŒ–å®Œäº†: {system_config_path}")
    
    # 2. ãƒ¢ãƒ‡ãƒ«è¨­å®šæœ€é©åŒ– - ãƒ¡ãƒƒã‚·ãƒ¥ç†è§£å‘ä¸Š
    model_config_path = "/app/configs/model/unirig_ar_350m_1024_81920_float32.yaml"
    with open(model_config_path, 'r') as f:
        model_config = yaml.safe_load(f)
    
    # ãƒ¡ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼é«˜ç²¾åº¦åŒ–
    model_config['mesh_encoder'].update({
        'num_latents': 1536,         # ğŸ”¥ ãƒ¡ãƒƒã‚·ãƒ¥ç†è§£è©³ç´°åº¦å‘ä¸Š
        'embed_dim': 192,            # ğŸ”¥ ç‰¹å¾´è¡¨ç¾ã®è¤‡é›‘æ€§å‘ä¸Š
        'num_encoder_layers': 20,    # ğŸ”¥ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼æ·±åº¦å‘ä¸Š
        'heads': 12,                 # ğŸ”¥ ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³å¤šæ§˜æ€§å‘ä¸Š
        'width': 768,                # ğŸ”¥ å†…éƒ¨è¡¨ç¾å¹…æ‹¡å¤§
        'use_checkpoint': True,      # ğŸ”¥ ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
        'flash': True,               # ğŸ”¥ é«˜é€ŸåŒ–ç¶­æŒ
    })
    
    with open(model_config_path, 'w') as f:
        yaml.safe_dump(model_config, f, default_flow_style=False)
    
    print(f"âœ… ãƒ¢ãƒ‡ãƒ«è¨­å®šæœ€é©åŒ–å®Œäº†: {model_config_path}")

def create_high_quality_config():
    """é«˜å“è³ªå°‚ç”¨è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"""
    
    # é«˜å“è³ªå°‚ç”¨ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
    hq_system_config = {
        '__target__': 'ar',
        'val_interval': 1,
        'generate_kwargs': {
            'max_new_tokens': 8192,     # æœ€å¤§è¤‡é›‘æ€§
            'num_return_sequences': 1,
            'num_beams': 50,            # æœ€é«˜æ¢ç´¢ç²¾åº¦
            'do_sample': True,
            'top_k': 5,                 # æœ€ã‚‚å³é¸ã•ã‚ŒãŸå€™è£œ
            'top_p': 0.85,             # å³ã—ã„ç¢ºç‡ã‚«ãƒƒãƒˆã‚ªãƒ•
            'repetition_penalty': 2.0,
            'temperature': 1.0,         # æœ€ã‚‚å®‰å®šçš„
            'no_cls': False,
            'assign_cls': 'articulationxl',
            'use_dir_cls': False
        }
    }
    
    hq_system_path = "/app/configs/system/ar_inference_articulationxl_high_quality.yaml"
    with open(hq_system_path, 'w') as f:
        yaml.safe_dump(hq_system_config, f, default_flow_style=False)
    
    print(f"âœ… é«˜å“è³ªå°‚ç”¨è¨­å®šä½œæˆ: {hq_system_path}")
    
    # é«˜å“è³ªå°‚ç”¨ã‚¿ã‚¹ã‚¯è¨­å®š
    hq_task_config_path = "/app/configs/task/quick_inference_skeleton_articulationxl_ar_256_high_quality.yaml"
    with open("/app/configs/task/quick_inference_skeleton_articulationxl_ar_256.yaml", 'r') as f:
        base_task_config = yaml.safe_load(f)
    
    # é«˜å“è³ªç”¨ã«ã‚·ã‚¹ãƒ†ãƒ è¨­å®šã‚’å¤‰æ›´
    base_task_config['components']['system'] = 'ar_inference_articulationxl_high_quality'
    base_task_config['experiment_name'] = 'quick_inference_skeleton_articulationxl_ar_256_high_quality'
    
    with open(hq_task_config_path, 'w') as f:
        yaml.safe_dump(base_task_config, f, default_flow_style=False)
    
    print(f"âœ… é«˜å“è³ªå°‚ç”¨ã‚¿ã‚¹ã‚¯è¨­å®šä½œæˆ: {hq_task_config_path}")
    
    return hq_task_config_path

def main():
    print("ğŸš€ ã‚¹ã‚±ãƒ«ãƒˆãƒ³å“è³ªå‘ä¸Šè¨­å®šé©ç”¨é–‹å§‹")
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
    backup_config_files()
    
    # è¨­å®šæœ€é©åŒ–
    optimize_skeleton_quality()
    
    # é«˜å“è³ªå°‚ç”¨è¨­å®šä½œæˆ
    hq_config_path = create_high_quality_config()
    
    print("\nğŸ“‹ é©ç”¨ã•ã‚ŒãŸæœ€é©åŒ–:")
    print("ğŸ”¥ æ¨è«–ç²¾åº¦å‘ä¸Š:")
    print("  - num_beams: 20 â†’ 30 (æ¢ç´¢ç²¾åº¦å‘ä¸Š)")
    print("  - temperature: 1.5 â†’ 1.2 (å®‰å®šæ€§é‡è¦–)")
    print("  - top_k: 10 â†’ 8 (å€™è£œç²¾é¸)")
    print("  - max_new_tokens: 4096 â†’ 6144 (è¤‡é›‘æ€§å¯¾å¿œ)")
    
    print("\nğŸ”¥ ãƒ¡ãƒƒã‚·ãƒ¥ç†è§£å‘ä¸Š:")
    print("  - num_latents: 1024 â†’ 1536 (è©³ç´°åº¦+50%)")
    print("  - embed_dim: 128 â†’ 192 (ç‰¹å¾´è¡¨ç¾+50%)")
    print("  - num_encoder_layers: 16 â†’ 20 (æ·±åº¦å‘ä¸Š)")
    print("  - heads: 8 â†’ 12 (ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³å¤šæ§˜æ€§+50%)")
    
    print(f"\nğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print(f"1. æ¨™æº–å“è³ª: æ—¢å­˜è¨­å®šã§å†å®Ÿè¡Œ")
    print(f"2. é«˜å“è³ªãƒ¢ãƒ¼ãƒ‰: {hq_config_path} ã‚’ä½¿ç”¨")
    print(f"3. å…ƒã«æˆ»ã™å ´åˆ: .backup ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å¾©å…ƒ")
    
    print("\nâœ… ã‚¹ã‚±ãƒ«ãƒˆãƒ³å“è³ªå‘ä¸Šè¨­å®šé©ç”¨å®Œäº†")

if __name__ == "__main__":
    main()
