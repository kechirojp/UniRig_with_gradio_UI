# This application uses UniRig (https://github.com/VAST-AI-Research/UniRig),
# which is licensed under the MIT License.
# A copy of the license can be found at:
# https://github.com/VAST-AI-Research/UniRig/blob/main/LICENSE
#
# Gradio application for 3D model preview and bone information display.

import gradio as gr
import os
import subprocess
import tempfile
import datetime
import yaml
from box import Box
import shutil
import traceback
import numpy as np
import trimesh # For model inspection if needed, or by Blender script
import logging
import sys
import pathlib # Not strictly used in this version, but good for path manipulation
import json # For datalist
import atexit
from texture_preservation_system import TexturePreservationSystem
from proposed_blender_texture_flow import BlenderNativeTextureFlow

# Import ImprovedSafeTextureRestoration for priority texture processing
try:
    from improved_safe_texture_restoration import ImprovedSafeTextureRestoration
    IMPROVED_SAFE_TEXTURE_RESTORATION_AVAILABLE = True
    print("âœ… ImprovedSafeTextureRestoration loaded in app.py")
except ImportError as e:
    IMPROVED_SAFE_TEXTURE_RESTORATION_AVAILABLE = False
    print(f"âš ï¸ ImprovedSafeTextureRestoration not available in app.py: {e}")

# --- Global Configuration and Setup ---
APP_CONFIG = None
TEMP_FILES_TO_CLEAN = []

# Setup basic logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- Helper: Load Application Configuration ---
def load_app_config(config_path='configs/app_config.yaml'):
    global APP_CONFIG
    try:
        with open(config_path, 'r') as f:
            APP_CONFIG = Box(yaml.safe_load(f))
        logging.info(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: {config_path}")
        
        # Setup working directory base and ensure it exists
        base_dir = APP_CONFIG.get('working_directory_base', 'pipeline_work')
        if not os.path.isabs(base_dir):
            base_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), base_dir)
        APP_CONFIG.working_directory_base = os.path.abspath(base_dir)
        os.makedirs(APP_CONFIG.working_directory_base, exist_ok=True)
        logging.info(f"ãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ™ãƒ¼ã‚¹: {APP_CONFIG.working_directory_base}")

    except FileNotFoundError:
        logging.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")
        APP_CONFIG = Box({'error': 'Config file not found'}) # Ensure APP_CONFIG is not None
    except yaml.YAMLError as e:
        logging.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æã‚¨ãƒ©ãƒ¼: {e}")
        APP_CONFIG = Box({'error': 'Config YAML error'})
    except Exception as e:
        logging.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
        APP_CONFIG = Box({'error': f'Unexpected error loading config: {e}'})

# --- Helper: Create Unique Working Directory ---
def create_working_directory(model_name, step_name):
    if not APP_CONFIG or 'working_directory_base' not in APP_CONFIG:
        logging.error("APP_CONFIGãŒæ­£ã—ããƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ã‹ã€working_directory_baseãŒæœªå®šç¾©ã§ã™ã€‚")
        # Fallback to a temporary directory if config is not loaded
        fallback_dir = os.path.join(tempfile.gettempdir(), "unirig_fallback_work", model_name, step_name)
        os.makedirs(fallback_dir, exist_ok=True)
        logging.warning(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ç”¨ã—ã¾ã™: {fallback_dir}")
        return fallback_dir

    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    # Sanitize model_name and step_name to be filesystem-friendly
    safe_model_name = "".join(c if c.isalnum() or c in ('_', '-') else '_' for c in model_name)
    safe_step_name = "".join(c if c.isalnum() or c in ('_', '-') else '_' for c in step_name)
    
    # Use a simpler, more predictable path structure based on model name and step
    # Example: pipeline_work/bird/01_extracted_mesh/
    # No timestamp for easier debugging and re-running, unless specifically needed for uniqueness
    # For now, let's keep it simple. If multiple runs for the same model/step need to be distinct,
    # then a timestamp or run ID might be necessary.
    # work_dir = os.path.join(APP_CONFIG.working_directory_base, safe_model_name, f"{safe_step_name}_{timestamp}")
    work_dir = os.path.join(APP_CONFIG.working_directory_base, safe_model_name, safe_step_name)
    
    os.makedirs(work_dir, exist_ok=True)
    logging.info(f"ãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã—ãŸ: {work_dir}")
    return work_dir

# --- Helper: Progress Bar Segmentation ---
def progress_segment(progress_bar, start_fraction, end_fraction):
    def update_progress(current_step_progress, desc=""):
        # current_step_progress is from 0.0 to 1.0 for the current step
        overall_progress = start_fraction + (current_step_progress * (end_fraction - start_fraction))
        progress_bar(overall_progress, desc=desc)
    return update_progress

# --- Helper: Run Subprocess ---
def run_subprocess_with_progress(command, work_dir, log_file_path, progress_fn, total_items_for_tqdm=1):
    logs = ""
    try:
        process = subprocess.Popen(command, cwd=work_dir, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1, universal_newlines=True)
        
        # For simple progress if not using tqdm directly in the script
        # This assumes the script itself doesn't output tqdm-parsable lines for this specific progress bar.
        # If the script has its own tqdm, this might conflict or be redundant.
        # For now, let's simulate progress based on time or completion.
        # A more robust way would be if the script outputted progress updates.
        
        # Simulate progress for the subprocess duration if it's a single task
        # This is a placeholder. Real progress depends on the script's output.
        progress_fn(0.1, desc=f"å®Ÿè¡Œä¸­: {command[1]}...") 

        with open(log_file_path, 'w') as log_f:
            for line in process.stdout:
                logs += line
                log_f.write(line)
                # If the script outputs progress, parse it here.
                # For now, we don't have a specific format to parse.
        
        process.wait()
        progress_fn(0.9, desc=f"å®Œäº†å¾…ã¡: {command[1]}...")

        if process.returncode == 0:
            logs += f"ã‚³ãƒãƒ³ãƒ‰æˆåŠŸ: {' '.join(command)}\n"
            progress_fn(1.0, desc=f"å®Œäº†: {command[1]}")
            return True, logs
        else:
            logs += f"ã‚³ãƒãƒ³ãƒ‰å¤±æ•— (ã‚³ãƒ¼ãƒ‰ {process.returncode}): {' '.join(command)}\n"
            logs += f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§: {log_file_path}\n"
            progress_fn(1.0, desc=f"ã‚¨ãƒ©ãƒ¼: {command[1]}") # Mark as complete even on error for progress bar
            return False, logs
    except FileNotFoundError:
        logs += f"ã‚¨ãƒ©ãƒ¼: ã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - {command[0]}ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
        progress_fn(1.0, desc=f"ã‚¨ãƒ©ãƒ¼: {command[0]} not found")
        return False, logs
    except Exception as e:
        logs += f"ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}\n"
        logs += f"ã‚³ãƒãƒ³ãƒ‰: {' '.join(command)}\n"
        logs += f"è©³ç´°: {traceback.format_exc()}\n"
        progress_fn(1.0, desc=f"ä¾‹å¤–: {command[1]}")
        return False, logs

# --- Helper: Convert to GLB for Display ---
def convert_to_glb_for_display(model_path, output_name_stem, work_dir_override=None):
    if not model_path or not os.path.exists(model_path):
        logging.warning(f"GLBå¤‰æ›ã®ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ãŒç„¡åŠ¹ã¾ãŸã¯å­˜åœ¨ã—ã¾ã›ã‚“: {model_path}")
        return None

    original_model_name = os.path.splitext(os.path.basename(model_path))[0]
    
    if work_dir_override:
        # Use a specific directory if provided (e.g., a common display_cache)
        display_work_dir = work_dir_override
        os.makedirs(display_work_dir, exist_ok=True)
    else:
        # Default to a subdirectory within the model's pipeline_work for organization
        # This assumes APP_CONFIG and working_directory_base are set.
        if APP_CONFIG and APP_CONFIG.working_directory_base:
            display_work_dir = tempfile.mkdtemp(prefix=f"{original_model_name}_display_")
            TEMP_FILES_TO_CLEAN.append(display_work_dir) # Schedule for cleanup
        else: # Fallback if APP_CONFIG is not properly set
            display_work_dir = tempfile.mkdtemp(prefix="unirig_display_")
            TEMP_FILES_TO_CLEAN.append(display_work_dir)
            logging.warning(f"APP_CONFIGæœªè¨­å®šã®ãŸã‚ã€GLBè¡¨ç¤ºã«ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ç”¨: {display_work_dir}")

    # Sanitize output_name_stem for the filename
    safe_output_name_stem = "".join(c if c.isalnum() or c in ('_', '-') else '_' for c in output_name_stem)
    output_glb_path = os.path.join(display_work_dir, f"{safe_output_name_stem}_display.glb")
    
    # Ensure Blender path is correctly configured
    blender_executable = APP_CONFIG.blender_settings.blender_executable
    conversion_script = os.path.abspath(APP_CONFIG.blender_processing.conversion_script) # Ensure absolute path

    if not os.path.exists(blender_executable):
        logging.error(f"Blenderå®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {blender_executable}")
        return None
    if not os.path.exists(conversion_script):
        logging.error(f"Blenderå¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {conversion_script}")
        return None

    command = [
        blender_executable,
        "--background",
        "--python", conversion_script,
        "--",
        "--input", os.path.abspath(model_path), # Ensure absolute path for Blender
        "--output", os.path.abspath(output_glb_path) # Ensure absolute path for Blender
    ]
    
    logging.info(f"GLBå¤‰æ›ã‚³ãƒãƒ³ãƒ‰: {' '.join(command)}")
    log_file = os.path.join(display_work_dir, f"{safe_output_name_stem}_conversion.log")

    try:
        result = subprocess.run(command, cwd=os.path.dirname(conversion_script), capture_output=True, text=True, check=False)
        
        with open(log_file, 'w') as f_log:
            f_log.write("--- STDOUT ---\n")
            f_log.write(result.stdout if result.stdout else "")
            f_log.write("\n--- STDERR ---\n")
            f_log.write(result.stderr if result.stderr else "")

        if result.returncode == 0 and os.path.exists(output_glb_path):
            logging.info(f"GLBã¸ã®å¤‰æ›æˆåŠŸ: {output_glb_path}")
            return output_glb_path
        else:
            logging.error(f"GLBã¸ã®å¤‰æ›å¤±æ•—ã€‚ãƒªã‚¿ãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰: {result.returncode}")
            logging.error(f"STDOUT: {result.stdout}")
            logging.error(f"STDERR: {result.stderr}")
            logging.error(f"å¤‰æ›ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {log_file}")
            return None
    except Exception as e:
        logging.error(f"GLBå¤‰æ›ã®ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        logging.error(f"è©³ç´°: {traceback.format_exc()}")
        return None

# --- Cleanup Temporary Files ---
def cleanup_temp_files():
    for item_path in TEMP_FILES_TO_CLEAN:
        try:
            if os.path.isfile(item_path):
                os.remove(item_path)
                logging.info(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {item_path}")
            elif os.path.isdir(item_path):
                shutil.rmtree(item_path)
                logging.info(f"ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {item_path}")
        except Exception as e:
            logging.warning(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å‰Šé™¤ã‚¨ãƒ©ãƒ¼ ({item_path}): {e}")
atexit.register(cleanup_temp_files)


# --- Modify this section for allowed paths (DEBUGGING) ---
def get_allowed_paths():
    script_dir = os.path.dirname(os.path.abspath(__file__)) # /app
    allowed = [
        os.path.abspath(script_dir), # /app
        os.path.abspath(os.path.join(script_dir, "pipeline_work")), # /app/pipeline_work
        os.path.abspath(os.path.join(script_dir, "examples")), # /app/examples
        os.path.abspath(os.path.join(script_dir, "src")), # /app/src
        os.path.abspath(os.path.join(script_dir, "configs")), # /app/configs
        os.path.abspath(os.path.join(script_dir, "blender")), # /app/blender
    ]
    if APP_CONFIG and APP_CONFIG.working_directory_base:
        # Ensure the configured working_directory_base is also allowed
        # This might be redundant if it's already /app/pipeline_work, but good for safety
        configured_work_base = os.path.abspath(APP_CONFIG.working_directory_base)
        if configured_work_base not in allowed:
            allowed.append(configured_work_base)
        
        # Add specific subdirectories from config if they exist, ensuring they are absolute
        subdirs_to_check = [
            APP_CONFIG.get('mesh_extraction', {}).get('extract_output_subdir'),
            APP_CONFIG.get('skeleton_generation', {}).get('skeleton_output_subdir'),
            APP_CONFIG.get('skinning_prediction', {}).get('skin_output_subdir'),
            APP_CONFIG.get('model_merging', {}).get('merge_output_subdir'),
            APP_CONFIG.get('blender_processing', {}).get('conversion_output_subdir'),
            APP_CONFIG.get('blender_native_texture_flow', {}).get('blender_native_subdir', '06_blender_native'),
            APP_CONFIG.get('improved_safe_texture_restoration', {}).get('output_subdir', '08_final_output')
        ]
        for subdir_name in subdirs_to_check:
            if subdir_name:
                potential_path = os.path.join(configured_work_base, subdir_name)
                abs_path = os.path.abspath(potential_path)
                if abs_path not in allowed:
                    allowed.append(abs_path)
    
    allowed.append(os.path.abspath(tempfile.gettempdir()))
    unique_allowed_paths = list(set(allowed)) # Remove duplicates
    logging.info(f"DEBUG: Gradio allowed_pathsãŒè¨­å®šã•ã‚Œã¾ã—ãŸ: {unique_allowed_paths}")
    return unique_allowed_paths
# --- End of modified section --


# --- Add this helper function for debugging output paths ---
def log_output_paths_for_debug(output_dict, context_log_message=""):
    logging.info(f"--- DEBUG: Gradioå‡ºåŠ›ãƒ‘ã‚¹ã®ç¢ºèª ({context_log_message}) ---")
    if not isinstance(output_dict, dict):
        logging.warning(f"  å‡ºåŠ›ã¯è¾æ›¸ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {type(output_dict)}, å€¤: {output_dict}")
        return

    for key, value in output_dict.items():
        if isinstance(value, str) and (value.endswith(('.glb', '.fbx', '.png', '.jpg', '.txt', '.npz', '.json', '.yaml')) or "/" in value or "\\" in value):
            # Heuristic: if it looks like a file path string
            abs_path = os.path.abspath(value) if value else "N/A (None or empty string)"
            exists = os.path.exists(abs_path) if value else False
            is_file = os.path.isfile(abs_path) if exists else "N/A"
            logging.info(f"  å‡ºåŠ›ã‚­ãƒ¼: '{key}', ãƒ‘ã‚¹: '{value}' (çµ¶å¯¾ãƒ‘ã‚¹: '{abs_path}'), å­˜åœ¨: {exists}, ãƒ•ã‚¡ã‚¤ãƒ«?: {is_file}")
            if exists and is_file:
                try:
                    logging.info(f"    ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {os.path.getsize(abs_path)} bytes")
                except Exception as e:
                    logging.warning(f"    ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        elif isinstance(value, list) and all(isinstance(item, str) for item in value):
             logging.info(f"  å‡ºåŠ›ã‚­ãƒ¼: '{key}', å€¤ (ãƒªã‚¹ãƒˆ): {value} - (ãƒªã‚¹ãƒˆå†…ã®ãƒ‘ã‚¹ã¯å€‹åˆ¥ã«ç¢ºèªã•ã‚Œã¾ã›ã‚“)")
        else:
            logging.info(f"  å‡ºåŠ›ã‚­ãƒ¼: '{key}', å€¤: {value} (å‹: {type(value)}) - ãƒ‘ã‚¹ã¨ã—ã¦æ‰±ã‚ã‚Œã¾ã›ã‚“")
    logging.info("--- DEBUG: Gradioå‡ºåŠ›ãƒ‘ã‚¹ã®ç¢ºèªå®Œäº† ---")
# --- End of added helper function ---

# --- Pipeline Step 1: Mesh Extraction ---
def process_extract_mesh(original_model_path, model_name, progress_fn):
    logs = ""
    if not original_model_path or not os.path.exists(original_model_path):
        logs += f"ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {original_model_path}\n"
        progress_fn(1.0, "ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
        return None, logs

    # Create working directory for this step
    extract_config = APP_CONFIG.mesh_extraction
    work_dir = create_working_directory(model_name, extract_config.extract_output_subdir)
    log_file_path = os.path.join(work_dir, f"{model_name}_extract_log.txt")
    
    # Expected output NPZ path
    expected_npz_filename = f"{model_name}_{extract_config.output_npz_suffix}.npz"
    expected_npz_path = os.path.join(work_dir, expected_npz_filename)

    # Texture Preservation System: Analyze and Backup
    # This should happen BEFORE any UniRig processing that might lose texture info
    texture_system = TexturePreservationSystem(
        original_model_path=original_model_path,
        model_name=model_name,
        base_processing_dir=APP_CONFIG.working_directory_base, # e.g., pipeline_work/
        config=APP_CONFIG.texture_preservation_system
    )
    progress_fn(0.1, "ãƒ†ã‚¯ã‚¹ãƒãƒ£æƒ…å ±è§£æä¸­...")
    try:
        texture_backup_success, texture_info_log = texture_system.analyze_and_backup_textures()
        logs += texture_info_log
        if not texture_backup_success:
            logs += "è­¦å‘Š: ãƒ†ã‚¯ã‚¹ãƒãƒ£ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¾ãŸã¯è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã¯ç¶šè¡Œã•ã‚Œã¾ã™ãŒã€ãƒ†ã‚¯ã‚¹ãƒãƒ£ãŒå¤±ã‚ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n"
            # Decide if this is a critical failure or a warning. For now, warning.
        else:
            logs += "ãƒ†ã‚¯ã‚¹ãƒãƒ£æƒ…å ±ã®è§£æã¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n"
    except Exception as tex_e:
        logs += f"ãƒ†ã‚¯ã‚¹ãƒãƒ£å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {tex_e}\n{traceback.format_exc()}\n"
        # Continue with extraction, but log the error.

    progress_fn(0.3, "UniRigãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œä¸­...")
    # Command for UniRig's extract_mesh.py
    # Example: python src/UniRig/extract_mesh.py --mesh_path <input_model> --save_path <output_dir> --output_name <model_name_raw.npz>
    unirig_extract_script = os.path.join(APP_CONFIG.unirig_paths.base_path, extract_config.script_name)
    
    command = [
        APP_CONFIG.python_executable,
        unirig_extract_script,
        "--mesh_path", original_model_path,
        "--save_path", work_dir, # UniRig script expects directory for save_path
        "--output_name", expected_npz_filename # UniRig script will append .npz if not present, but good to be explicit
    ]
    
    success, process_logs = run_subprocess_with_progress(command, work_dir, log_file_path, progress_fn)
    logs += process_logs

    if success and os.path.exists(expected_npz_path):
        logs += f"ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºæˆåŠŸ: {expected_npz_path}\n"
        progress_fn(1.0, "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå®Œäº†")
        return expected_npz_path, logs
    else:
        logs += "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå¤±æ•—ã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
        if not os.path.exists(expected_npz_path):
            logs += f"æœŸå¾…ã•ã‚ŒãŸå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {expected_npz_path}\n"
        progress_fn(1.0, "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºã‚¨ãƒ©ãƒ¼")
        return None, logs

# --- Pipeline Step 2: Skeleton Generation ---
def process_generate_skeleton(raw_data_npz_path, model_name, gender, progress_fn):
    logs = ""
    if not raw_data_npz_path or not os.path.exists(raw_data_npz_path):
        logs += f"ã‚¨ãƒ©ãƒ¼: æŠ½å‡ºã•ã‚ŒãŸNPZãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {raw_data_npz_path}\n"
        progress_fn(1.0, "ã‚¨ãƒ©ãƒ¼: NPZãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
        return None, logs, None, None, None

    skeleton_config = APP_CONFIG.skeleton_generation
    work_dir = create_working_directory(model_name, skeleton_config.skeleton_output_subdir)
    log_file_path = os.path.join(work_dir, f"{model_name}_skeleton_log.txt")

    # Expected output paths
    # UniRig's generate_skeleton.py saves multiple files:
    # - <output_name>_skeleton_bones.txt
    # - <output_name>_skeleton.fbx
    # - <output_name>_skeleton.npz
    # - <output_name>_skeleton_mesh.glb (for visualization)
    output_name_stem = f"{model_name}_{skeleton_config.output_name_suffix}" # e.g., bird_skeleton
    
    expected_fbx_path = os.path.join(work_dir, f"{output_name_stem}.fbx")
    expected_txt_path = os.path.join(work_dir, f"{output_name_stem}_bones.txt")
    expected_npz_path = os.path.join(work_dir, f"{output_name_stem}.npz")
    expected_glb_path = os.path.join(work_dir, f"{output_name_stem}_mesh.glb") # For display

    unirig_skeleton_script = os.path.join(APP_CONFIG.unirig_paths.base_path, skeleton_config.script_name)
    command = [
        APP_CONFIG.python_executable,
        unirig_skeleton_script,
        "--raw_data_path", raw_data_npz_path,
        "--gender", gender,
        "--save_path", work_dir,
        "--output_name", output_name_stem, # UniRig script uses this as a stem
        "--rest_pose_path", APP_CONFIG.unirig_paths.rest_pose_path # Add rest pose path from config
    ]

    success, process_logs = run_subprocess_with_progress(command, work_dir, log_file_path, progress_fn)
    logs += process_logs

    if success and os.path.exists(expected_fbx_path) and os.path.exists(expected_npz_path):
        logs += f"ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”ŸæˆæˆåŠŸã€‚FBX: {expected_fbx_path}, NPZ: {expected_npz_path}\n"
        display_glb_path = expected_glb_path if os.path.exists(expected_glb_path) else None
        if not display_glb_path:
            logs += f"è­¦å‘Š: è¡¨ç¤ºç”¨GLBãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {expected_glb_path}\n"
        progress_fn(1.0, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå®Œäº†")
        return display_glb_path, logs, expected_fbx_path, expected_txt_path, expected_npz_path
    else:
        logs += "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå¤±æ•—ã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
        if not os.path.exists(expected_fbx_path): logs += f"æœŸå¾…ã•ã‚ŒãŸFBXãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {expected_fbx_path}\n"
        if not os.path.exists(expected_npz_path): logs += f"æœŸå¾…ã•ã‚ŒãŸNPZãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {expected_npz_path}\n"
        progress_fn(1.0, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆã‚¨ãƒ©ãƒ¼")
        return None, logs, None, None, None

# --- Pipeline Step 3: Skinning Prediction ---
def process_generate_skin(raw_data_npz_path, skeleton_fbx_path, skeleton_npz_path, model_name_for_output, progress_fn):
    logs = ""
    required_files = {
        "Raw NPZ": raw_data_npz_path,
        "Skeleton FBX": skeleton_fbx_path,
        "Skeleton NPZ": skeleton_npz_path
    }
    for name, path in required_files.items():
        if not path or not os.path.exists(path):
            logs += f"ã‚¨ãƒ©ãƒ¼: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã«å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - {name}: {path}\n"
            progress_fn(1.0, f"ã‚¨ãƒ©ãƒ¼: {name}ãªã—")
            return None, logs, None, None
            
    skin_config = APP_CONFIG.skinning_prediction
    work_dir = create_working_directory(model_name_for_output, skin_config.skin_output_subdir)
    log_file_path = os.path.join(work_dir, f"{model_name_for_output}_skin_log.txt")

    # Expected output paths for UniRig's generate_skin.py
    # - <output_name>_skinned_mesh.glb (visualization)
    # - <output_name>_skinning_weights.npz
    # - <output_name>_skinned.fbx (skinned model without original textures)
    output_name_stem = f"{model_name_for_output}_{skin_config.output_name_suffix}" # e.g., bird_skinned

    expected_glb_path = os.path.join(work_dir, f"{output_name_stem}_mesh.glb") # For display
    expected_skin_npz_path = os.path.join(work_dir, f"{output_name_stem}_weights.npz")
    expected_skinned_fbx_path = os.path.join(work_dir, f"{output_name_stem}.fbx")


    unirig_skin_script = os.path.join(APP_CONFIG.unirig_paths.base_path, skin_config.script_name)
    command = [
        APP_CONFIG.python_executable,
        unirig_skin_script,
        "--raw_data_path", raw_data_npz_path,
        "--skeleton_path", skeleton_npz_path, # UniRig uses the skeleton NPZ
        "--skeleton_fbx_path", skeleton_fbx_path, # And the skeleton FBX
        "--save_path", work_dir,
        "--output_name", output_name_stem, # UniRig uses this as a stem
        "--model_name", model_name_for_output # Pass model name for internal use if script supports
    ]

    success, process_logs = run_subprocess_with_progress(command, work_dir, log_file_path, progress_fn)
    logs += process_logs

    if success and os.path.exists(expected_skinned_fbx_path) and os.path.exists(expected_skin_npz_path):
        logs += f"ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬æˆåŠŸã€‚FBX: {expected_skinned_fbx_path}, NPZ: {expected_skin_npz_path}\n"
        display_glb_path = expected_glb_path if os.path.exists(expected_glb_path) else None
        if not display_glb_path:
            # Fallback: try to convert the output FBX to GLB for display if the script didn't make one
            logs += f"è­¦å‘Š: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°è¡¨ç¤ºç”¨GLBãƒ•ã‚¡ã‚¤ãƒ« ({expected_glb_path}) ãŒUniRigã‚¹ã‚¯ãƒªãƒ—ãƒˆã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚FBXã‹ã‚‰å¤‰æ›ã‚’è©¦ã¿ã¾ã™...\n"
            display_glb_path = convert_to_glb_for_display(expected_skinned_fbx_path, f"{output_name_stem}_fbx_conv")
            if display_glb_path:
                logs += f"FBXã‹ã‚‰ã®GLBå¤‰æ›æˆåŠŸ (è¡¨ç¤ºç”¨): {display_glb_path}\n"
            else:
                logs += f"è­¦å‘Š: ã‚¹ã‚­ãƒ³æ¸ˆã¿FBXã‹ã‚‰ã®GLBå¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\n"

        progress_fn(1.0, "ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å®Œäº†")
        return display_glb_path, logs, expected_skinned_fbx_path, expected_skin_npz_path
    else:
        logs += "ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬å¤±æ•—ã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
        if not os.path.exists(expected_skinned_fbx_path): logs += f"æœŸå¾…ã•ã‚ŒãŸã‚¹ã‚­ãƒ³æ¸ˆã¿FBXãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {expected_skinned_fbx_path}\n"
        if not os.path.exists(expected_skin_npz_path): logs += f"æœŸå¾…ã•ã‚ŒãŸã‚¹ã‚­ãƒ‹ãƒ³ã‚°NPZãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {expected_skin_npz_path}\n"
        progress_fn(1.0, "ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼")
        return None, logs, None, None

# --- Pipeline Step 4: Model Merging (Old UniRig method, if needed as fallback) ---
def process_merge_model(original_model_path, skinned_fbx_path, skinning_npz_path, model_name_for_output, progress_fn):
    logs = "--- æ—§UniRigãƒãƒ¼ã‚¸å‡¦ç† (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¾ãŸã¯æ¯”è¼ƒç”¨) ---\n"
    required_files = {
        "Original Model": original_model_path,
        "Skinned FBX": skinned_fbx_path,
        "Skinning NPZ": skinning_npz_path
    }
    for name, path in required_files.items():
        if not path or not os.path.exists(path):
            logs += f"ã‚¨ãƒ©ãƒ¼: ãƒãƒ¼ã‚¸ã«å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - {name}: {path}\n"
            progress_fn(1.0, f"ã‚¨ãƒ©ãƒ¼: {name}ãªã—")
            return None, logs, None

    merge_config = APP_CONFIG.model_merging # Assuming a general merge config section
    work_dir = create_working_directory(model_name_for_output, merge_config.get('merge_output_subdir_old', '04_merge_old'))
    log_file_path = os.path.join(work_dir, f"{model_name_for_output}_merge_old_log.txt")
    
    output_name_stem = f"{model_name_for_output}_{merge_config.get('output_name_suffix_old', 'final_rigged_old')}"
    expected_merged_fbx_path = os.path.join(work_dir, f"{output_name_stem}.fbx")
    
    # This refers to UniRig's original merge script, which might not handle textures well.
    unirig_merge_script = os.path.join(APP_CONFIG.unirig_paths.base_path, merge_config.script_name) # e.g., merge.py from UniRig
    
    command = [
        APP_CONFIG.python_executable,
        unirig_merge_script,
        "--fbx_path", original_model_path, # Original model with textures
        "--skeleton_path", skinned_fbx_path, # This is likely the FBX with UniRig skeleton
        "--skin_path", skinning_npz_path,   # Skinning weights
        "--save_path", work_dir,
        "--output_name", output_name_stem,
        "--uv_path", APP_CONFIG.unirig_paths.uv_template_path # UV template from config
    ]

    success, process_logs = run_subprocess_with_progress(command, work_dir, log_file_path, progress_fn)
    logs += process_logs

    if success and os.path.exists(expected_merged_fbx_path):
        logs += f"æ—§UniRigãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸æˆåŠŸ: {expected_merged_fbx_path}\n"
        display_glb_path = convert_to_glb_for_display(expected_merged_fbx_path, f"{output_name_stem}_display")
        progress_fn(1.0, "æ—§ãƒãƒ¼ã‚¸å®Œäº†")
        return display_glb_path, logs, expected_merged_fbx_path
    else:
        logs += "æ—§UniRigãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸å¤±æ•—ã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
        if not os.path.exists(expected_merged_fbx_path):
            logs += f"æœŸå¾…ã•ã‚ŒãŸãƒãƒ¼ã‚¸æ¸ˆã¿FBXãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {expected_merged_fbx_path}\n"
        progress_fn(1.0, "æ—§ãƒãƒ¼ã‚¸ã‚¨ãƒ©ãƒ¼")
        return None, logs, None

# --- Pipeline Step 4 (New): Final Merge with Texture Preservation ---
def process_final_merge_with_textures(skinned_fbx_path, original_model_path, model_name_for_output, progress_fn):
    logs = "--- ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿æŒå‹æœ€çµ‚ãƒãƒ¼ã‚¸å‡¦ç†é–‹å§‹ ---\n"
    
    required_paths = {
        "Skinned FBX (from UniRig skinning step)": skinned_fbx_path,
        "Original Model Path (with original textures)": original_model_path,
    }
    for name, path in required_paths.items():
        if not path or not os.path.exists(path):
            logs += f"ã‚¨ãƒ©ãƒ¼: æœ€çµ‚ãƒãƒ¼ã‚¸ã«å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - {name}: {path}\n"
            progress_fn(1.0, f"ã‚¨ãƒ©ãƒ¼: {name}ãªã—")
            return None, logs, None

    # Determine which texture flow to use based on availability and configuration
    use_improved_safe_flow = IMPROVED_SAFE_TEXTURE_RESTORATION_AVAILABLE and APP_CONFIG.texture_processing_priority == "improved_safe_texture_restoration"
    use_blender_native_flow = APP_CONFIG.texture_processing_priority == "blender_native_texture_flow"

    final_fbx_path = None
    display_path = None
    
    progress_fn(0.05, "ãƒ†ã‚¯ã‚¹ãƒãƒ£å‡¦ç†ãƒ•ãƒ­ãƒ¼æº–å‚™ä¸­...")

    if use_improved_safe_flow:
        logs += "ğŸš€ ImprovedSafeTextureRestoration ãƒ•ãƒ­ãƒ¼ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n"
        safe_texture_config = APP_CONFIG.improved_safe_texture_restoration
        output_subdir = safe_texture_config.get('output_subdir', '08_final_output')
        final_work_dir = create_working_directory(model_name_for_output, output_subdir)
        
        # Path to the material metadata JSON saved by TexturePreservationSystem during mesh extraction
        # This path needs to be correctly constructed based on where TexturePreservationSystem saves it.
        # TexturePreservationSystem saves it in: <base_processing_dir>/<model_name>/<metadata_subdir>/<filename>
        # Example: pipeline_work/bird/07_material_metadata/bird_material_structure.json
        tps_config = APP_CONFIG.texture_preservation_system
        metadata_dir = os.path.join(APP_CONFIG.working_directory_base, model_name_for_output, tps_config.metadata_subdir)
        material_metadata_path = os.path.join(metadata_dir, f"{model_name_for_output}_{tps_config.metadata_filename}")
        
        # Path to the backed-up textures, also from TexturePreservationSystem
        # Example: pipeline_work/bird/05_texture_preservation/
        texture_backup_dir = os.path.join(APP_CONFIG.working_directory_base, model_name_for_output, tps_config.backup_subdir)

        if not os.path.exists(material_metadata_path):
            logs += f"âŒ ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚¨ãƒ©ãƒ¼: ãƒãƒ†ãƒªã‚¢ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {material_metadata_path}ã€‚ImprovedSafeTextureRestorationã¯å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚\n"
            progress_fn(1.0, "ã‚¨ãƒ©ãƒ¼: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãªã—")
            return None, logs, None
        if not os.path.exists(texture_backup_dir) or not os.listdir(texture_backup_dir): # Check if dir exists and is not empty
            logs += f"âš ï¸ è­¦å‘Š: ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ç©ºã§ã™: {texture_backup_dir}ã€‚ãƒ†ã‚¯ã‚¹ãƒãƒ£ãŒå¾©å…ƒã•ã‚Œãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n"
            # Allow to proceed but with a warning.

        try:
            progress_fn(0.1, "ImprovedSafeTextureRestoration åˆæœŸåŒ–ä¸­...")
            safe_restorer = ImprovedSafeTextureRestoration(
                skinned_fbx_path=skinned_fbx_path,
                material_metadata_json_path=material_metadata_path,
                texture_directory_path=texture_backup_dir,
                output_directory=final_work_dir,
                model_name=model_name_for_output,
                blender_executable=APP_CONFIG.blender_settings.blender_executable,
                processing_config=safe_texture_config # Pass the specific config section
            )
            
            logs += "âš™ï¸ ImprovedSafeTextureRestoration ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œä¸­...\n"
            # This method should internally handle progress reporting via a passed callback if designed for it.
            # For now, we'll wrap its main call with broader progress updates.
            
            # If safe_restorer.run_full_pipeline takes a progress_callback:
            # sub_progress_fn = progress_segment(progress_fn, 0.1, 0.9) # Allocate 80% of this step's bar
            # final_fbx_path, stage_logs = safe_restorer.run_full_pipeline(progress_callback=sub_progress_fn)
            
            # If not, simulate progress around the call
            progress_fn(0.2, "SafeFlow: FBXã‚¤ãƒ³ãƒãƒ¼ãƒˆ...")
            final_fbx_path, stage_logs = safe_restorer.run_full_pipeline() # Assuming it returns (output_fbx_path, logs_string)
            logs += stage_logs
            
            if final_fbx_path and os.path.exists(final_fbx_path):
                logs += f"âœ… ImprovedSafeTextureRestoration æˆåŠŸã€‚æœ€çµ‚FBX: {final_fbx_path}\n"
                progress_fn(0.95, "SafeFlow: GLBãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆä¸­...")
                display_path = convert_to_glb_for_display(final_fbx_path, f"{model_name_for_output}_final_safe_textured")
            else:
                logs += f"âŒ ImprovedSafeTextureRestoration å¤±æ•—ã€‚è©³ç´°ã¯ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
                final_fbx_path = None # Ensure it's None on failure
        except Exception as e:
            logs += f"âŒ ImprovedSafeTextureRestoration å®Ÿè¡Œä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}\n{traceback.format_exc()}\n"
            final_fbx_path = None
            
    elif use_blender_native_flow:
        logs += "ğŸ”¶ BlenderNativeTextureFlow ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n"
        bntf_config = APP_CONFIG.blender_native_texture_flow
        output_subdir = bntf_config.get('blender_native_subdir', '06_blender_native') # Default from instructions
        final_work_dir = create_working_directory(model_name_for_output, output_subdir)

        # Similar to above, get metadata and texture paths
        tps_config = APP_CONFIG.texture_preservation_system
        metadata_dir = os.path.join(APP_CONFIG.working_directory_base, model_name_for_output, tps_config.metadata_subdir)
        material_metadata_path = os.path.join(metadata_dir, f"{model_name_for_output}_{tps_config.metadata_filename}")
        texture_backup_dir = os.path.join(APP_CONFIG.working_directory_base, model_name_for_output, tps_config.backup_subdir)

        if not os.path.exists(material_metadata_path):
            logs += f"âŒ ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚¨ãƒ©ãƒ¼: ãƒãƒ†ãƒªã‚¢ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {material_metadata_path}ã€‚BlenderNativeTextureFlowã¯å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚\n"
            progress_fn(1.0, "ã‚¨ãƒ©ãƒ¼: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãªã—")
            return None, logs, None
        
        try:
            progress_fn(0.1, "BlenderNativeTextureFlow åˆæœŸåŒ–ä¸­...")
            native_flow = BlenderNativeTextureFlow(
                original_model_path=original_model_path, # BNTF might need the original model directly
                skinned_fbx_path=skinned_fbx_path,       # And the skinned FBX from UniRig
                model_name=model_name_for_output,
                output_dir_base=final_work_dir, # Base for its own subdirectories if it creates them
                blender_executable=APP_CONFIG.blender_settings.blender_executable,
                material_metadata_path=material_metadata_path, # Pass metadata
                texture_backup_path=texture_backup_dir,       # Pass texture backup dir
                config=bntf_config # Pass its specific config
            )
            
            logs += "âš™ï¸ BlenderNativeTextureFlow ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œä¸­...\n"
            # progress_fn for BNTF:
            # sub_bntf_progress = progress_segment(progress_fn, 0.1, 0.9)
            # final_fbx_path, bntf_logs = native_flow.process_model_with_native_textures(progress_callback=sub_bntf_progress)
            
            progress_fn(0.2, "BNTF: Blenderå‡¦ç†ä¸­...")
            final_fbx_path, bntf_logs = native_flow.process_model_with_native_textures()
            logs += bntf_logs

            if final_fbx_path and os.path.exists(final_fbx_path):
                logs += f"âœ… BlenderNativeTextureFlow æˆåŠŸã€‚æœ€çµ‚FBX: {final_fbx_path}\n"
                progress_fn(0.95, "BNTF: GLBãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆä¸­...")
                display_path = convert_to_glb_for_display(final_fbx_path, f"{model_name_for_output}_final_native_textured")
            else:
                logs += f"âŒ BlenderNativeTextureFlow å¤±æ•—ã€‚è©³ç´°ã¯ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
                final_fbx_path = None
        except Exception as e:
            logs += f"âŒ BlenderNativeTextureFlow å®Ÿè¡Œä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}\n{traceback.format_exc()}\n"
            final_fbx_path = None
    else:
        # Fallback to old UniRig merge if no advanced texture flow is configured or available
        logs += "âš ï¸ é«˜åº¦ãªãƒ†ã‚¯ã‚¹ãƒãƒ£å‡¦ç†ãƒ•ãƒ­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚æ—§UniRigãƒãƒ¼ã‚¸å‡¦ç†ã‚’è©¦ã¿ã¾ã™ï¼ˆãƒ†ã‚¯ã‚¹ãƒãƒ£å“è³ªãŒä½ä¸‹ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰ã€‚\n"
        # This requires skinning_npz_path, which is not directly available here.
        # This indicates a potential design issue if this fallback is truly desired.
        # For now, let's assume this fallback is not the primary path and might be removed or rethought.
        # If we must call it, we need to fetch skinning_npz_path from a previous step's output.
        # This makes the function signature more complex or reliant on a shared state.
        
        # For now, let's just log that we can't do the old merge without skin_npz
        logs += "âŒ æ—§UniRigãƒãƒ¼ã‚¸å‡¦ç†ã¯ã€ã“ã®é–¢æ•°ã‚·ã‚°ãƒãƒãƒ£ã§ã¯ç›´æ¥å‘¼ã³å‡ºã›ã¾ã›ã‚“ (skinning_npz_path ãŒå¿…è¦)ã€‚\n"
        logs += "å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚ãƒ†ã‚¯ã‚¹ãƒãƒ£å‡¦ç†ãƒ•ãƒ­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚\n"
        final_fbx_path = None # Explicitly set to None
        # To actually call old merge:
        # skin_npz_path_for_fallback = ... # This needs to be found or passed
        # display_path, merge_logs_old, final_fbx_path = process_merge_model(
        #     original_model_path, skinned_fbx_path, skin_npz_path_for_fallback, model_name_for_output, progress_fn
        # )
        # logs += merge_logs_old
        
    if final_fbx_path:
        logs += f"âœ… æœ€çµ‚ãƒãƒ¼ã‚¸å‡¦ç†å®Œäº†ã€‚æœ€çµ‚ãƒ¢ãƒ‡ãƒ«: {final_fbx_path}\n"
        if not display_path: # If display_path wasn't set by the specific flow (e.g. GLB conversion failed)
            logs += "è­¦å‘Š: æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼GLBã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n"
        progress_fn(1.0, "æœ€çµ‚ãƒãƒ¼ã‚¸å®Œäº†")
    else:
        logs += "âŒ æœ€çµ‚ãƒãƒ¼ã‚¸å‡¦ç†å¤±æ•—ã€‚é©åˆ‡ãªãƒ†ã‚¯ã‚¹ãƒãƒ£å‡¦ç†ãƒ•ãƒ­ãƒ¼ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n"
        progress_fn(1.0, "æœ€çµ‚ãƒãƒ¼ã‚¸ã‚¨ãƒ©ãƒ¼")

    return display_path, logs, final_fbx_path

# --- Full Pipeline Handler Function ---
def gradio_full_auto_rigging(
    uploaded_model_path: str,
    gender: str,
    progress=gr.Progress(track_tqdm=True)
):
    """
    ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‹ã‚‰æœ€çµ‚ãƒãƒ¼ã‚¸ã¾ã§ã®å…¨ã‚¹ãƒ†ãƒƒãƒ—ã‚’è‡ªå‹•å®Ÿè¡Œ
    """
    logs = "=== UniRig ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è‡ªå‹•å®Ÿè¡Œé–‹å§‹ ===\n"
    
    # Initialize paths to None for robust logging in error cases
    final_display_path = None
    final_merged_fbx_path = None
    extracted_npz_path = None
    skeleton_display_path = None
    skeleton_fbx_path = None
    skeleton_txt_path = None
    skeleton_npz_path = None
    skinned_display_path = None
    skinned_fbx_path = None
    skinning_npz_path = None # Corrected: was skinnning_npz_path
    
    if not uploaded_model_path:
        logs += "ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
        error_output_details = {
            key: locals().get(key) for key in [
                'final_display_path', 'final_merged_fbx_path', 'extracted_npz_path',
                'skeleton_display_path', 'skeleton_fbx_path', 'skeleton_txt_path', 'skeleton_npz_path',
                'skinned_display_path', 'skinned_fbx_path', 'skinning_npz_path', 'uploaded_model_path'
            ]
        }
        log_output_paths_for_debug(error_output_details, "gradio_full_auto_rigging - error: no_upload")
        return None, logs, None, None, None, None, None, None, None, None, None, None

    try:
        # ãƒ¢ãƒ‡ãƒ«åã‚’æŠ½å‡º
        model_name = os.path.splitext(os.path.basename(uploaded_model_path))[0]
        logs += f"ğŸ“ å‡¦ç†ãƒ¢ãƒ‡ãƒ«: {model_name}\n"
        logs += f"ğŸ“‚ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_model_path}\n\n"

        # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º (0.0-0.25)
        logs += "ğŸ”§ ã‚¹ãƒ†ãƒƒãƒ—1/4: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºé–‹å§‹\n"
        extract_progress = progress_segment(progress, 0.0, 0.25)
        extract_progress(0.0, "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºä¸­...")
        
        extracted_npz_path, extract_logs = process_extract_mesh(
            uploaded_model_path, 
            model_name,
            extract_progress
        )
        logs += extract_logs
        
        if not extracted_npz_path:
            logs += "âŒ ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚\n"
            error_output_details = { key: locals().get(key) for key in [ 'final_display_path', 'final_merged_fbx_path', 'extracted_npz_path', 'skeleton_display_path', 'skeleton_fbx_path', 'skeleton_txt_path', 'skeleton_npz_path', 'skinned_display_path', 'skinned_fbx_path', 'skinning_npz_path', 'uploaded_model_path'] }
            log_output_paths_for_debug(error_output_details, "gradio_full_auto_rigging - error: mesh_extraction_failed")
            return None, logs, None, None, None, None, None, None, None, None, None, None
        
        logs += f"âœ… ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå®Œäº†: {extracted_npz_path}\n\n"

        # ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ (0.25-0.5)
        logs += "ğŸ¦´ ã‚¹ãƒ†ãƒƒãƒ—2/4: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆé–‹å§‹\n"
        skeleton_progress = progress_segment(progress, 0.25, 0.5)
        skeleton_progress(0.0, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆä¸­...")
        
        skeleton_display_path, skeleton_logs, skeleton_fbx_path, skeleton_txt_path, skeleton_npz_path = process_generate_skeleton(
            extracted_npz_path,
            model_name,
            gender,
            skeleton_progress
        )
        logs += skeleton_logs
        
        if not skeleton_fbx_path or not skeleton_npz_path:
            logs += "âŒ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚\n"
            error_output_details = { key: locals().get(key) for key in [ 'final_display_path', 'final_merged_fbx_path', 'extracted_npz_path', 'skeleton_display_path', 'skeleton_fbx_path', 'skeleton_txt_path', 'skeleton_npz_path', 'skinned_display_path', 'skinned_fbx_path', 'skinning_npz_path', 'uploaded_model_path'] }
            log_output_paths_for_debug(error_output_details, "gradio_full_auto_rigging - error: skeleton_generation_failed")
            return None, logs, None, extracted_npz_path, skeleton_display_path, None, None, None, None, None, None, None # Pass on what we have
        
        logs += f"âœ… ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå®Œäº†: {skeleton_fbx_path}\n\n"

        # ã‚¹ãƒ†ãƒƒãƒ—3: ã‚¹ã‚­ãƒ‹ãƒ³ã‚° (0.5-0.75)
        logs += "ğŸ¨ ã‚¹ãƒ†ãƒƒãƒ—3/4: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬é–‹å§‹\n"
        skinning_progress = progress_segment(progress, 0.5, 0.75)
        skinning_progress(0.0, "ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†ä¸­...")
        
        skinned_display_path, skinning_logs, skinned_fbx_path, skinning_npz_path = process_generate_skin(
            raw_data_npz_path=extracted_npz_path,
            skeleton_fbx_path=skeleton_fbx_path,
            skeleton_npz_path=skeleton_npz_path,
            model_name_for_output=model_name,
            progress_fn=skinning_progress
        )
        logs += skinning_logs
        
        if not skinned_fbx_path or not skinning_npz_path:
            logs += "âŒ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚\n"
            error_output_details = { key: locals().get(key) for key in [ 'final_display_path', 'final_merged_fbx_path', 'extracted_npz_path', 'skeleton_display_path', 'skeleton_fbx_path', 'skeleton_txt_path', 'skeleton_npz_path', 'skinned_display_path', 'skinned_fbx_path', 'skinning_npz_path', 'uploaded_model_path'] }
            log_output_paths_for_debug(error_output_details, "gradio_full_auto_rigging - error: skinning_failed")
            return None, logs, None, extracted_npz_path, skeleton_display_path, skeleton_fbx_path, skeleton_txt_path, skeleton_npz_path, skinned_display_path, None, None, None # Pass on what we have
        
        logs += f"âœ… ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å®Œäº†: {skinned_fbx_path}\n\n"

        # ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ (0.75-1.0)
        logs += "ğŸ”— ã‚¹ãƒ†ãƒƒãƒ—4/4: ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸é–‹å§‹ (äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼)\n"
        merge_progress = progress_segment(progress, 0.75, 1.0)
        merge_progress(0.0, "ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆå‡¦ç†ä¸­...")
        
        final_display_path, merge_logs, final_merged_fbx_path = process_final_merge_with_textures(
            skinned_fbx_path=skinned_fbx_path,
            original_model_path=uploaded_model_path,
            model_name_for_output=model_name,
            progress_fn=merge_progress
        )
        logs += merge_logs
        
        if not final_merged_fbx_path:
            logs += "âŒ ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n"
            error_output_details = { key: locals().get(key) for key in [ 'final_display_path', 'final_merged_fbx_path', 'extracted_npz_path', 'skeleton_display_path', 'skeleton_fbx_path', 'skeleton_txt_path', 'skeleton_npz_path', 'skinned_display_path', 'skinned_fbx_path', 'skinning_npz_path', 'uploaded_model_path'] }
            log_output_paths_for_debug(error_output_details, "gradio_full_auto_rigging - error: merge_failed")
            return None, logs, None, extracted_npz_path, skeleton_display_path, skeleton_fbx_path, skeleton_txt_path, skeleton_npz_path, skinned_display_path, skinned_fbx_path, skinning_npz_path, None # Pass on what we have
        
        logs += f"âœ… ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸å®Œäº†: {final_merged_fbx_path}\n\n"

        # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        logs += "ğŸ‰ === ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œå®Œäº† (äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼) ===\n"
        logs += f"ğŸ¯ æœ€çµ‚ãƒ¢ãƒ‡ãƒ«: {final_merged_fbx_path}\n"
        logs += f"ğŸ“Š ãƒ†ã‚¯ã‚¹ãƒãƒ£ã¨ãƒãƒ†ãƒªã‚¢ãƒ«ãŒä¿æŒã•ã‚ŒãŸé«˜å“è³ªãªãƒªã‚®ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚\n"
        logs += f"ğŸ“‹ ã™ã¹ã¦ã®ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã§ã™ã€‚\n"

        progress(1.0, "ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†!")

        output_details_for_log = {
            "final_display_path": final_display_path,
            "final_merged_fbx_path": final_merged_fbx_path,
            "extracted_npz_path": extracted_npz_path,
            "skeleton_display_path": skeleton_display_path,
            "skeleton_fbx_path": skeleton_fbx_path,
            "skeleton_txt_path": skeleton_txt_path,
            "skeleton_npz_path": skeleton_npz_path,
            "skinned_display_path": skinned_display_path,
            "skinned_fbx_path": skinned_fbx_path,
            "skinning_npz_path": skinning_npz_path,
            "uploaded_model_path": uploaded_model_path
        }
        log_output_paths_for_debug(output_details_for_log, "gradio_full_auto_rigging - success path")

        return (
            final_display_path,
            logs,
            final_merged_fbx_path,
            extracted_npz_path,
            skeleton_display_path,
            skeleton_fbx_path,
            skeleton_txt_path,
            skeleton_npz_path,
            skinned_display_path,
            skinned_fbx_path,
            skinning_npz_path
        )

    except Exception as e:
        error_msg = f"âŒ ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\n"
        error_msg += f"è©³ç´°: {traceback.format_exc()}\n"
        logs += error_msg
        progress(1.0, "ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼")
        error_output_details = {
            key: locals().get(key) for key in [
                'final_display_path', 'final_merged_fbx_path', 'extracted_npz_path',
                'skeleton_display_path', 'skeleton_fbx_path', 'skeleton_txt_path', 'skeleton_npz_path',
                'skinned_display_path', 'skinned_fbx_path', 'skinning_npz_path', 'uploaded_model_path'
            ]
        }
        log_output_paths_for_debug(error_output_details, "gradio_full_auto_rigging - exception path")
        return None, logs, None, None, None, None, None, None, None, None, None, None

# --- Gradio Handler Functions ---
def gradio_extract_mesh(original_model_path_state: str, model_name_state: str, progress=gr.Progress(track_tqdm=True)):
    logs = "--- Gradio Extract Mesh Wrapper ---\n"
    if not original_model_path_state or not model_name_state:
        logs += "ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¹ãƒ†ãƒƒãƒ—0ã§ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\n"
        return logs, gr.DownloadButton(visible=False), None
    
    current_step_progress_fn = progress_segment(progress, 0.0, 1.0)
    current_step_progress_fn(0.0, "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºæº–å‚™ä¸­...")

    extracted_npz_path, process_logs = process_extract_mesh(
        original_model_path_state, 
        model_name_state,
        current_step_progress_fn
    )
    logs += process_logs
    
    if extracted_npz_path:
        logs += "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºæˆåŠŸ (Gradioãƒ©ãƒƒãƒ‘ãƒ¼)ã€‚\n"
        return logs, gr.DownloadButton(label="æŠ½å‡ºNPZã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", value=extracted_npz_path, visible=True), extracted_npz_path
    else:
        logs += "ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå¤±æ•— (Gradioãƒ©ãƒƒãƒ‘ãƒ¼)ã€‚\n"
        return logs, gr.DownloadButton(label="æŠ½å‡ºNPZã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", value=None, visible=False), None

def gradio_generate_skeleton(
    raw_data_npz_path_from_state: str, 
    model_name_from_state: str,      
    gender: str,
    progress=gr.Progress(track_tqdm=True)
):
    logs = "--- Gradio Generate Skeleton Wrapper ---\n"
    if not raw_data_npz_path_from_state or not model_name_from_state:
        logs += "ã‚¨ãƒ©ãƒ¼: NPZãƒ‘ã‚¹ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¹ãƒ†ãƒƒãƒ—0ã‚’å®Œäº†ã—ã€ãƒ¢ãƒ‡ãƒ«åãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
        return None, logs, None, None, None, None, None 
    
    current_step_progress_fn = progress_segment(progress, 0.0, 1.0)
    current_step_progress_fn(0.0, desc="ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆæº–å‚™ä¸­...")

    display_model_path, process_logs, fbx_path, txt_path, npz_path = process_generate_skeleton(
        raw_data_npz_path_from_state, 
        model_name_from_state,
        gender,
        current_step_progress_fn
    )
    logs += process_logs

    if display_model_path and fbx_path and npz_path:
        logs += f"âœ“ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”ŸæˆæˆåŠŸã€‚è¡¨ç¤ºãƒ¢ãƒ‡ãƒ«: {display_model_path}\n"
    else:
        logs += "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
    
    return (
        display_model_path, 
        logs, 
        fbx_path, 
        txt_path, 
        npz_path, 
        fbx_path, 
        npz_path  
    )

def gradio_generate_skin(
    raw_data_npz_path_from_state: str,   
    skeleton_fbx_path_from_state: str, 
    skeleton_npz_path_from_state: str,  
    model_name_from_state: str,         
    progress=gr.Progress(track_tqdm=True)
):
    logs = "--- Gradio Generate Skin Wrapper ---\n"
    if not (
        raw_data_npz_path_from_state and
        skeleton_fbx_path_from_state and
        skeleton_npz_path_from_state and
        model_name_from_state
    ):
        logs += "ã‚¨ãƒ©ãƒ¼: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã«å¿…è¦ãªãƒ‘ã‚¹ (raw NPZ, skeleton FBX, skeleton NPZ) ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
        return None, logs, None, None, None, None 
    
    current_step_progress_fn = progress_segment(progress, 0.0, 1.0)
    current_step_progress_fn(0.0, desc="ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬æº–å‚™ä¸­...")

    display_model_path, process_logs, skinned_fbx_path, skinning_npz_path = process_generate_skin(
        raw_data_npz_path=raw_data_npz_path_from_state,
        skeleton_fbx_path=skeleton_fbx_path_from_state,
        skeleton_npz_path=skeleton_npz_path_from_state,
        model_name_for_output=model_name_from_state,
        progress_fn=current_step_progress_fn
    )
    logs += process_logs
    
    if display_model_path and skinned_fbx_path and skinning_npz_path:
        logs += f"âœ“ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬æˆåŠŸã€‚è¡¨ç¤ºãƒ¢ãƒ‡ãƒ«: {display_model_path}\n"
        logs += f"  ã‚¹ã‚­ãƒ³æ¸ˆã¿FBX: {skinned_fbx_path}\n"
        logs += f"  ã‚¹ã‚­ãƒ‹ãƒ³ã‚°NPZ: {skinning_npz_path}\n"
    else:
        logs += "ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n"

    return (
        display_model_path, 
        logs, 
        skinned_fbx_path, 
        skinning_npz_path, 
        skinned_fbx_path, 
        skinning_npz_path  
    )

def gradio_merge_model_with_textures(
    original_model_path_from_state: str, 
    skinned_fbx_path_from_state: str,   
    model_name_from_state: str,         
    progress=gr.Progress(track_tqdm=True)
):
    """äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼ã«ã‚ˆã‚‹ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ï¼ˆã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ç”¨ï¼‰"""
    logs = "--- Gradio Texture-Integrated Merge Model Wrapper (äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼) ---\n"
    if not (
        original_model_path_from_state and
        skinned_fbx_path_from_state and
        model_name_from_state
    ):
        logs += "ã‚¨ãƒ©ãƒ¼: ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã«å¿…è¦ãªãƒ‘ã‚¹ (ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¢ãƒ‡ãƒ«, ã‚¹ã‚­ãƒ³æ¸ˆã¿FBX) ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
        return None, logs, None, None
    
    current_step_progress_fn = progress_segment(progress, 0.0, 1.0)
    current_step_progress_fn(0.0, desc="ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸æº–å‚™ä¸­...")

    display_model_path, process_logs, final_merged_fbx_path = process_final_merge_with_textures(
        skinned_fbx_path=skinned_fbx_path_from_state,
        original_model_path=original_model_path_from_state,
        model_name_for_output=model_name_from_state,
        progress_fn=current_step_progress_fn
    )
    logs += process_logs

    if display_model_path and final_merged_fbx_path:
        logs += f"âœ“ ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸æˆåŠŸã€‚è¡¨ç¤ºãƒ¢ãƒ‡ãƒ«: {display_model_path}\n"
        logs += f"  æœ€çµ‚ãƒãƒ¼ã‚¸æ¸ˆã¿FBX (ãƒ†ã‚¯ã‚¹ãƒãƒ£ä»˜ã): {final_merged_fbx_path}\n"
    else:
        logs += "ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n"

    return (
        display_model_path,
        logs,
        final_merged_fbx_path, 
        final_merged_fbx_path  
    )

def gradio_merge_model(
    original_model_path_from_state: str, 
    skinned_fbx_path_from_state: str,   
    skinning_npz_path_from_state: str,  
    model_name_from_state: str,         
    progress=gr.Progress(track_tqdm=True)
):
    logs = "--- Gradio Merge Model Wrapper (å¾“æ¥ãƒ•ãƒ­ãƒ¼) ---\n"
    if not (
        original_model_path_from_state and
        skinned_fbx_path_from_state and
        skinning_npz_path_from_state and
        model_name_from_state
    ):
        logs += "ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã«å¿…è¦ãªãƒ‘ã‚¹ (ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¢ãƒ‡ãƒ«, ã‚¹ã‚­ãƒ³æ¸ˆã¿FBX, ã‚¹ã‚­ãƒ‹ãƒ³ã‚°NPZ) ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«åãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
        return None, logs, None, None
    
    current_step_progress_fn = progress_segment(progress, 0.0, 1.0)
    current_step_progress_fn(0.0, desc="ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸æº–å‚™ä¸­...")

    display_model_path, process_logs, final_merged_fbx_path = process_merge_model(
        original_model_path=original_model_path_from_state,
        skinned_fbx_path=skinned_fbx_path_from_state,
        skinning_npz_path=skinning_npz_path_from_state,
        model_name_for_output=model_name_from_state,
        progress_fn=current_step_progress_fn
    )
    logs += process_logs

    if display_model_path and final_merged_fbx_path:
        logs += f"âœ“ ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸æˆåŠŸã€‚è¡¨ç¤ºãƒ¢ãƒ‡ãƒ«: {display_model_path}\n"
        logs += f"  æœ€çµ‚ãƒãƒ¼ã‚¸æ¸ˆã¿FBX: {final_merged_fbx_path}\n"
    else:
        logs += "ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n"

    return (
        display_model_path,
        logs,
        final_merged_fbx_path, 
        final_merged_fbx_path 
    )

# --- Gradio UI Builder ---
def build_gradio_interface():
    with gr.Blocks(theme=gr.themes.Base()) as demo:
        s_original_model_path = gr.State()
        s_model_name = gr.State()
        s_extracted_npz_path = gr.State()
        s_skeleton_fbx_path = gr.State()
        s_skeleton_txt_path = gr.State() # Added state for this
        s_skeleton_npz_path = gr.State()
        s_skinned_fbx_path = gr.State()
        s_skinning_npz_path = gr.State()
        s_merged_fbx_path = gr.State()
        
        gr.Markdown("<h1>UniRig 3Dãƒ¢ãƒ‡ãƒ«è‡ªå‹•ãƒªã‚®ãƒ³ã‚°ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³</h1>")
        gr.Markdown("3Dãƒ¢ãƒ‡ãƒ«ï¼ˆFBXã€OBJã€GLB/GLTFã€PLYãªã©TrimeshãŒæ‰±ãˆã‚‹å½¢å¼ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€è‡ªå‹•ã§ãƒªã‚®ãƒ³ã‚°å‡¦ç†ã‚’è¡Œã„ã¾ã™ã€‚")
        gr.Markdown("""
        **ğŸ†• äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼ã«ã‚ˆã‚‹é«˜å“è³ªãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿æŒ:**
        - **ç¬¬1éšå±¤**: å…ƒãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»ãƒãƒ†ãƒªã‚¢ãƒ«æƒ…å ±ã‚’æŠ½å‡ºãƒ»ä¿å­˜
        - **ç¬¬2éšå±¤**: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã«ä¿å­˜ã•ã‚ŒãŸãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚’é©ç”¨
        - **çµæœ**: ãƒ†ã‚¯ã‚¹ãƒãƒ£ã¨ãƒãƒ†ãƒªã‚¢ãƒ«å“è³ªã‚’å®Œå…¨ã«ä¿æŒã—ãŸãƒªã‚®ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
        
        ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã¯è‡ªå‹•çš„ã«äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼ãŒé©ç”¨ã•ã‚Œã¾ã™ã€‚
        """)

        with gr.Tab("ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"):
            gr.Markdown("""
            ## ğŸš€ ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§å®Œå…¨è‡ªå‹•ãƒªã‚®ãƒ³ã‚°
            
            **äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼æŠ€è¡“ã«ã‚ˆã‚‹é«˜å“è³ªå‡¦ç†:**
            1. **ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º** â†’ 3Dãƒ¢ãƒ‡ãƒ«ã®æ§‹é€ è§£æ
            2. **ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ** â†’ AI ã«ã‚ˆã‚‹æœ€é©ãªéª¨æ ¼æ§‹é€ äºˆæ¸¬
            3. **ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†** â†’ é ‚ç‚¹ã‚¦ã‚§ã‚¤ãƒˆè‡ªå‹•è¨ˆç®—
            4. **ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒãƒ¼ã‚¸** â†’ å…ƒã®å“è³ªã‚’ä¿æŒã—ãŸæœ€çµ‚çµåˆ
            
            âœ¨ **å¾“æ¥æ–¹å¼ã¨ã®é•ã„**: ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»ãƒãƒ†ãƒªã‚¢ãƒ«æƒ…å ±ã‚’å®Œå…¨ä¿æŒã—ã€é«˜å“è³ªãªä»•ä¸ŠãŒã‚Šã‚’å®Ÿç¾
            """)
            
            with gr.Row():
                with gr.Column(scale=1):
                    full_input_model_upload = gr.File(label="3Dãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", file_types=[".fbx", ".obj", ".glb", ".gltf", ".ply"], type="filepath")
                    full_gender_dropdown = gr.Dropdown(label="æ€§åˆ¥ï¼ˆã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆç”¨ï¼‰", choices=["female", "male", "neutral"], value="female")
                    full_pipeline_button = gr.Button("ğŸ¯ ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ", variant="primary", size="lg")
                with gr.Column(scale=2):
                    full_final_model_display = gr.Model3D(label="æœ€çµ‚ãƒªã‚®ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", interactive=False, camera_position=(0, 2.5, 3.5))
            
            full_pipeline_logs = gr.Textbox(label="ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ­ã‚°", lines=15, interactive=False, show_copy_button=True)
            
            with gr.Accordion("ğŸ“ ä¸­é–“æˆæœç‰©ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", open=False):
                gr.Markdown("### å‡¦ç†æ®µéšåˆ¥ã®æˆæœç‰©")
                gr.Markdown("å„å‡¦ç†æ®µéšã§ç”Ÿæˆã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ãã¾ã™ã€‚")
                
                gr.Markdown("#### ğŸ”§ ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºçµæœ")
                full_extracted_npz_download = gr.DownloadButton(label="ğŸ“¦ æŠ½å‡ºNPZ", interactive=True, visible=False)
                
                gr.Markdown("#### ğŸ¦´ ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆçµæœ")
                full_skeleton_model_display = gr.Model3D(label="ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", interactive=False, camera_position=(0, 2.5, 3.5), visible=False)
                with gr.Row():
                    full_skeleton_fbx_download = gr.DownloadButton(label="ğŸ¦´ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ (FBX)", interactive=True, visible=False)
                    full_skeleton_txt_download = gr.DownloadButton(label="ğŸ“„ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ (TXT)", interactive=True, visible=False)
                    full_skeleton_npz_download = gr.DownloadButton(label="ğŸ“¦ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ (NPZ)", interactive=True, visible=False)

                gr.Markdown("#### ğŸ¨ ã‚¹ãƒ†ãƒƒãƒ—3: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬çµæœ")
                full_skinned_model_display = gr.Model3D(label="ã‚¹ã‚­ãƒ³æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", interactive=False, camera_position=(0, 2.5, 3.5), visible=False)
                with gr.Row():
                    full_skinned_model_fbx_download = gr.DownloadButton(label="ğŸ¨ ã‚¹ã‚­ãƒ³æ¸ˆã¿ (FBX)", interactive=True, visible=False)
                    full_skinning_npz_download = gr.DownloadButton(label="ğŸ“¦ ã‚¹ã‚­ãƒ‹ãƒ³ã‚° (NPZ)", interactive=True, visible=False)
                
                gr.Markdown("#### ğŸ¯ ã‚¹ãƒ†ãƒƒãƒ—4: æœ€çµ‚ãƒãƒ¼ã‚¸ãƒ¢ãƒ‡ãƒ«")
                full_final_model_download_accordion = gr.DownloadButton(label="ğŸ¯ æœ€çµ‚ãƒ¢ãƒ‡ãƒ« (FBX)", interactive=True, visible=False)

            full_pipeline_button.click(
                fn=gradio_full_auto_rigging,
                inputs=[
                    full_input_model_upload, 
                    full_gender_dropdown
                ],
                outputs=[
                    full_final_model_display, full_pipeline_logs, full_final_model_download_accordion,
                    full_extracted_npz_download,
                    full_skeleton_model_display, 
                    full_skeleton_fbx_download, full_skeleton_txt_download, full_skeleton_npz_download,
                    full_skinned_model_display,
                    full_skinned_model_fbx_download, full_skinning_npz_download
                ],
                api_name="run_full_auto_rigging"
            ).then(
                fn=lambda d1, d2, d3, d4, d5, d6, d7, d8, d9, d10, d11: (
                    gr.update(visible=d1 is not None and d1 != ''), 
                    gr.update(visible=d3 is not None and d3 != ''), 
                    gr.update(visible=d4 is not None and d4 != ''), 
                    gr.update(visible=d5 is not None and d5 != ''), 
                    gr.update(visible=d6 is not None and d6 != ''), 
                    gr.update(visible=d7 is not None and d7 != ''), 
                    gr.update(visible=d8 is not None and d8 != ''), 
                    gr.update(visible=d9 is not None and d9 != ''), 
                    gr.update(visible=d10 is not None and d10 != ''),
                    gr.update(visible=d11 is not None and d11 != '') 
                ),
                inputs=[
                    full_final_model_display, full_pipeline_logs, full_final_model_download_accordion,
                    full_extracted_npz_download, full_skeleton_model_display, 
                    full_skeleton_fbx_download, full_skeleton_txt_download, full_skeleton_npz_download,
                    full_skinned_model_display, full_skinned_model_fbx_download, full_skinning_npz_download
                ],
                outputs=[
                    full_final_model_display, full_final_model_download_accordion,
                    full_extracted_npz_download, full_skeleton_model_display,
                    full_skeleton_fbx_download, full_skeleton_txt_download, full_skeleton_npz_download,
                    full_skinned_model_display, full_skinned_model_fbx_download, full_skinning_npz_download
                ],
                api_name=False # No need for a separate API endpoint for this UI update
            )

        with gr.Tab("ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ"):
            gr.Markdown("""
            ## ğŸ› ï¸ æ®µéšçš„ãªå‡¦ç†å®Ÿè¡Œ
            
            å„å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—ã‚’å€‹åˆ¥ã«å®Ÿè¡Œã—ã€ä¸­é–“çµæœã‚’ç¢ºèªã—ãªãŒã‚‰é€²ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
            å‡¦ç†ã®ä»•çµ„ã¿ã‚’ç†è§£ã—ãŸã„å ´åˆã‚„ã€ç‰¹å®šã®ã‚¹ãƒ†ãƒƒãƒ—ã§å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã®è¨ºæ–­ã«æœ‰ç”¨ã§ã™ã€‚
            """)
            
            gr.Markdown("### ğŸ”§ ã‚¹ãƒ†ãƒƒãƒ—0: åˆæœŸè¨­å®šã¨ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º")
            with gr.Row():
                step_upload_button = gr.File(label="1. 3Dãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", file_types=[".fbx", ".obj", ".glb", ".gltf", ".ply"], type="filepath")
                step_input_model_display_step0 = gr.Model3D(label="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", interactive=False, camera_position=(0, 2.5, 3.5))
            
            btn_run_extract = gr.Button("ğŸ”§ 0. ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå®Ÿè¡Œ", variant="primary")
            step_extract_logs = gr.Textbox(label="æŠ½å‡ºãƒ­ã‚°", lines=5, interactive=False, show_copy_button=True)
            step_extracted_model_download = gr.DownloadButton(label="ğŸ“¦ æŠ½å‡ºNPZ", interactive=True, visible=False)

            gr.Markdown("### ğŸ¦´ ã‚¹ãƒ†ãƒƒãƒ—1: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ")
            step_gender_dropdown = gr.Dropdown(label="æ€§åˆ¥ï¼ˆã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆç”¨ï¼‰", choices=["female", "male", "neutral"], value="female")
            btn_run_skeleton = gr.Button("ğŸ¦´ 1. ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå®Ÿè¡Œ", variant="primary")
            step_skeleton_model_display = gr.Model3D(label="ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", interactive=False, camera_position=(0, 2.5, 3.5))
            step_skeleton_logs = gr.Textbox(label="ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆãƒ­ã‚°", lines=5, interactive=False, show_copy_button=True)
            with gr.Row():
                step_skeleton_fbx_download = gr.DownloadButton(label="ğŸ¦´ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ (FBX)", interactive=True, visible=False)
                step_skeleton_txt_download = gr.DownloadButton(label="ğŸ“„ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ (TXT)", interactive=True, visible=False)
                step_skeleton_npz_download = gr.DownloadButton(label="ğŸ“¦ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ (NPZ)", interactive=True, visible=False)

            gr.Markdown("### ğŸ¨ ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬")
            btn_run_skin = gr.Button("ğŸ¨ 2. ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ã‚¦ã‚§ã‚¤ãƒˆäºˆæ¸¬å®Ÿè¡Œ", variant="primary")
            step_skinned_model_display = gr.Model3D(label="ã‚¹ã‚­ãƒ³æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", interactive=False, camera_position=(0, 2.5, 3.5))
            step_skin_logs = gr.Textbox(label="ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãƒ­ã‚°", lines=5, interactive=False, show_copy_button=True)
            with gr.Row():
                step_skinned_model_fbx_download = gr.DownloadButton(label="ğŸ¨ ã‚¹ã‚­ãƒ³æ¸ˆã¿ (FBX)", interactive=True, visible=False)
                step_skinning_npz_download = gr.DownloadButton(label="ğŸ“¦ ã‚¹ã‚­ãƒ‹ãƒ³ã‚° (NPZ)", interactive=True, visible=False)

            gr.Markdown("### ğŸ”— ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸")
            with gr.Row():
                btn_run_merge = gr.Button("ğŸ”— 3a. å¾“æ¥ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸å®Ÿè¡Œ", variant="secondary")
                btn_run_merge_with_textures = gr.Button("âœ¨ 3b. ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒãƒ¼ã‚¸å®Ÿè¡Œ (æ¨å¥¨)", variant="primary")
            step_merged_model_display = gr.Model3D(label="æœ€çµ‚ãƒãƒ¼ã‚¸ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", interactive=False, camera_position=(0, 2.5, 3.5))
            step_merge_logs = gr.Textbox(label="ãƒãƒ¼ã‚¸ãƒ­ã‚°", lines=5, interactive=False, show_copy_button=True)
            step_merged_model_download = gr.DownloadButton(label="ğŸ¯ æœ€çµ‚ãƒ¢ãƒ‡ãƒ« (FBX)", interactive=True, visible=False)
            
            with gr.Accordion("ğŸ’¡ äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼ã«ã¤ã„ã¦", open=False):
                gr.Markdown("""
                ### ğŸ—ï¸ äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼æŠ€è¡“ã®è©³ç´°
                
                **å¾“æ¥ã®å•é¡Œç‚¹:**
                - ãƒªã‚®ãƒ³ã‚°å‡¦ç†ä¸­ã«ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»ãƒãƒ†ãƒªã‚¢ãƒ«æƒ…å ±ãŒå¤±ã‚ã‚Œã‚‹
                - æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã®è¦‹ãŸç›®ãŒå…ƒãƒ¢ãƒ‡ãƒ«ã¨ç•°ãªã£ã¦ã—ã¾ã†
                - æ‰‹å‹•ã§ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£å¾©å…ƒä½œæ¥­ãŒå¿…è¦
                
                **äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼ã®è§£æ±ºç­–:**
                
                **ğŸ—ï¸ ç¬¬1éšå±¤ - ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜:**
                1. å…ƒãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ãƒ†ã‚¯ã‚¹ãƒãƒ£ç”»åƒã‚’æŠ½å‡ºãƒ»ä¿å­˜
                2. ãƒãƒ†ãƒªã‚¢ãƒ«æ§‹é€ ï¼ˆãƒãƒ¼ãƒ‰æ¥ç¶šï¼‰æƒ…å ±ã‚’è¨˜éŒ²
                3. ãƒ¡ãƒƒã‚·ãƒ¥-ãƒãƒ†ãƒªã‚¢ãƒ«å¯¾å¿œé–¢ä¿‚ã‚’ä¿å­˜
                
                **ğŸ—ï¸ ç¬¬2éšå±¤ - ãƒ†ã‚¯ã‚¹ãƒãƒ£å¾©å…ƒ:**
                1. ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXã‚’èª­ã¿è¾¼ã¿
                2. ä¿å­˜ã•ã‚ŒãŸãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚’å†é©ç”¨
                3. ãƒãƒ†ãƒªã‚¢ãƒ«æ§‹é€ ã‚’å®Œå…¨å†æ§‹ç¯‰
                4. FBXäº’æ›æ€§ã‚’è€ƒæ…®ã—ãŸæœ€é©åŒ–
                
                **âœ¨ çµæœ:**
                - å…ƒãƒ¢ãƒ‡ãƒ«ã¨åŒå“è³ªã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»ãƒãƒ†ãƒªã‚¢ãƒ«
                - å®Œå…¨ãªãƒªã‚®ãƒ³ã‚°æ©Ÿèƒ½
                - å®‰å®šã—ãŸã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½
                
                **æ¨å¥¨ä½¿ç”¨å ´é¢:**
                - é«˜å“è³ªãª3Dãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚®ãƒ³ã‚°
                - ã‚²ãƒ¼ãƒ ãƒ»ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã‚¢ã‚»ãƒƒãƒˆä½œæˆ
                - å•†ç”¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã®åˆ©ç”¨
                """)
            
            gr.Markdown("""
            **ğŸ’¡ äºŒéšå»ºã¦ãƒ•ãƒ­ãƒ¼ã®é¸æŠã«ã¤ã„ã¦:**
            - **3a. å¾“æ¥ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸**: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXã‚’ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ¢ãƒ‡ãƒ«ã«ãƒãƒ¼ã‚¸ã—ã¾ã™ï¼ˆæ—§æ–¹å¼ï¼‰
            - **3b. ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒãƒ¼ã‚¸ (æ¨å¥¨)**: å…ƒãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ»ãƒãƒ†ãƒªã‚¢ãƒ«ã‚’ä¿æŒã—ãªãŒã‚‰ãƒãƒ¼ã‚¸ã—ã¾ã™ï¼ˆæ–°æ–¹å¼ã€é«˜å“è³ªï¼‰
            
            **æ¨å¥¨**: ã‚ˆã‚Šé«˜å“è³ªãªçµæœã‚’å¾—ã‚‹ãŸã‚ã€Œâœ¨ ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆãƒãƒ¼ã‚¸ã€ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚
            """)

            # Event handlers for step-by-step execution
            def handle_upload_step(file_path_obj): # Gradio File component with type="filepath" returns a string path
                if file_path_obj:
                    original_path = file_path_obj # This is now a string path
                    model_name_val = os.path.splitext(os.path.basename(original_path))[0]
                    glb_for_display = convert_to_glb_for_display(original_path, f"{model_name_val}_original_display_step")
                    
                   
                    
                    # Reset logs and subsequent step outputs/states
                    extract_log_msg = f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {model_name_val}ã€‚æŠ½å‡ºã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
                    return (
                        original_path, model_name_val, glb_for_display, 
                        extract_log_msg, gr.DownloadButton(visible=False), None, # Extract
                        None, "", gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), None, None, None, # Skeleton
                        None, "", gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), None, None, # Skin
                        None, "", gr.DownloadButton(visible=False), None # Merge
                    )
                # No file uploaded or cleared
                return None, None, None, "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚", gr.DownloadButton(visible=False), None, None, "", gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), None, None, None, None, "", gr.DownloadButton(visible=False), gr.DownloadButton(visible=False), None, None, None, "", gr.DownloadButton(visible=False), None

            step_upload_button.change( # Use .change for File component when type="filepath"
                fn=handle_upload_step,
                inputs=[step_upload_button],
                outputs=[
                    s_original_model_path, s_model_name, step_input_model_display_step0, 
                    step_extract_logs, step_extracted_model_download, s_extracted_npz_path,
                    step_skeleton_model_display, step_skeleton_logs, step_skeleton_fbx_download, step_skeleton_txt_download, step_skeleton_npz_download,
                    s_skeleton_fbx_path, s_skeleton_txt_path, s_skeleton_npz_path,
                    step_skinned_model_display, step_skin_logs, step_skinned_model_fbx_download, step_skinning_npz_download,
                    s_skinned_fbx_path, s_skinning_npz_path,
                    step_merged_model_display, step_merge_logs, step_merged_model_download,
                    s_merged_fbx_path
                ],
                api_name=False
            )
            
            btn_run_extract.click(
                fn=gradio_extract_mesh,
                inputs=[s_original_model_path, s_model_name],
                outputs=[step_extract_logs, step_extracted_model_download, s_extracted_npz_path],
                api_name="run_extract_mesh_step"
            )
            
            btn_run_skeleton.click(
                fn=gradio_generate_skeleton,
                inputs=[
                    s_extracted_npz_path, # from step 0
                    s_model_name,         # from step 0
                    step_gender_dropdown  # Add gender dropdown
                ],
                outputs=[
                    step_skeleton_model_display, 
                    step_skeleton_logs,
                    step_skeleton_fbx_download,
                    step_skeleton_txt_download,
                    step_skeleton_npz_download,
                    s_skeleton_fbx_path, # State update
                    s_skeleton_npz_path  # State update
                ]
            ).then(
                fn=lambda d1, d2, d3, d4, d5: (gr.update(visible=d1 is not None and d1!=''), gr.update(visible=d2 is not None and d2!=''), gr.update(visible=d3 is not None and d3!=''), gr.update(visible=d4 is not None and d4!=''), gr.update(visible=d5 is not None and d5!='')),
                inputs=[step_skeleton_model_display, step_skeleton_fbx_download, step_skeleton_txt_download, step_skeleton_npz_download, step_skeleton_logs],
                outputs=[step_skeleton_model_display, step_skeleton_fbx_download, step_skeleton_txt_download, step_skeleton_npz_download, step_skeleton_logs],
                api_name=False
            )

            btn_run_skin.click(
                fn=gradio_generate_skin,
                inputs=[
                    s_extracted_npz_path, # raw_data_npz_path - from step 0
                    s_skeleton_fbx_path,  # skeleton_fbx_path - from step 1
                    s_skeleton_npz_path,  # skeleton_npz_path - from step 1
                    s_model_name          # model_name - from step 0
                ],
                outputs=[
                    step_skinned_model_display, step_skin_logs, 
                    step_skinned_model_fbx_download, step_skinning_npz_download,
                    s_skinned_fbx_path, s_skinning_npz_path
                ],
                api_name="run_generate_skin_step"
            )

            btn_run_merge.click(
                fn=gradio_merge_model,
                inputs=[s_original_model_path, s_skinned_fbx_path, s_skinning_npz_path, s_model_name],
                outputs=[
                    step_merged_model_display, step_merge_logs, 
                    step_merged_model_download, 
                    s_merged_fbx_path
                ],
                api_name="run_merge_model_step"
            )

            btn_run_merge_with_textures.click(
                fn=gradio_merge_model_with_textures,
                inputs=[s_original_model_path, s_skinned_fbx_path, s_model_name],
                outputs=[
                    step_merged_model_display, step_merge_logs, 
                    step_merged_model_download, 
                    s_merged_fbx_path
                ],
                api_name="run_merge_model_with_textures_step"
            )
        
        demo.queue() # Ensure queue is enabled for the demo
            
    return demo

if __name__ == "__main__":
    load_app_config() 

    if not APP_CONFIG or APP_CONFIG.get('error'): # Check for error during load
        logging.error(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¨ãƒ©ãƒ¼: {APP_CONFIG.get('error', 'Unknown error')}ã€‚èµ·å‹•ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
        sys.exit(1)

    gradio_config = APP_CONFIG.get('gradio_interface', {})
    server_name = gradio_config.get('server_name', '0.0.0.0')
    base_port = int(gradio_config.get('server_port', 7860))
    share_gradio = gradio_config.get('share', False)
    inbrowser = gradio_config.get('inbrowser', True)
    
    import socket
    def find_free_port(start_port, max_attempts=10):
        for port in range(start_port, start_port + max_attempts):
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                try:
                    s.bind(('', port))
                    return port
                except OSError:
                    logging.warning(f"ãƒãƒ¼ãƒˆ {port} ã¯ä½¿ç”¨ä¸­ã§ã™ã€‚æ¬¡ã®ãƒãƒ¼ãƒˆã‚’è©¦ã—ã¾ã™...")
                    continue
        return None
    
    server_port = find_free_port(base_port)
    if server_port is None:
        logging.error(f"åˆ©ç”¨å¯èƒ½ãªãƒãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆ{base_port}ã‹ã‚‰{base_port+9}ã¾ã§è©¦è¡Œï¼‰")
        sys.exit(1)

    logging.info(f"Gradioã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¾ã™: http://{server_name}:{server_port}")
    if share_gradio:
        logging.info("Gradioå…±æœ‰ãŒæœ‰åŠ¹ã«ãªã£ã¦ã„ã¾ã™ã€‚")

    iface = build_gradio_interface()
    
    allowed_paths_list = get_allowed_paths()
    
    # Ensure debug mode is True for this session, overriding config if necessary for debugging
    # server_debug_mode = APP_CONFIG.server.get('debug_mode', False) # Get from config
    # logging.info(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: {server_debug_mode}")
    
    iface.launch(
        server_name=server_name, 
        server_port=server_port, 
        share=share_gradio, 
        inbrowser=inbrowser,
        debug=True, # Force debug=True for this debugging session
        allowed_paths=allowed_paths_list
    )