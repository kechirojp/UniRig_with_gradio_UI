#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ã‚¹ã‚­ãƒ‹ãƒ³ã‚°FBXã®ã‚¦ã‚§ã‚¤ãƒˆåˆè¨ˆåˆ†æ

ã‚¼ãƒ­é™¤ç®—ã‚¨ãƒ©ãƒ¼ã®æ ¹æœ¬åŸå› ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã€
å„é ‚ç‚¹ã®ã‚¦ã‚§ã‚¤ãƒˆåˆè¨ˆã‚’è©³ç´°ã«åˆ†æã—ã¾ã™ã€‚

å®Ÿè¡Œæ–¹æ³•:
    cd /app
    python analyze_weight_sums.py
"""

import sys
import os
import tempfile
import subprocess
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
sys.path.insert(0, '/app')

def analyze_weight_sums(fbx_path: Path):
    """å„é ‚ç‚¹ã®ã‚¦ã‚§ã‚¤ãƒˆåˆè¨ˆã‚’åˆ†æã—ã¦ã‚¼ãƒ­é™¤ç®—åŸå› ã‚’ç‰¹å®š"""
    
    blender_script = f'''
import bpy
import bmesh
import json

# æ—¢å­˜ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ã™ã¹ã¦å‰Šé™¤
bpy.ops.object.select_all(action='SELECT')
bpy.ops.object.delete(use_global=False)

try:
    # FBXãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    bpy.ops.import_scene.fbx(filepath="{fbx_path}")
    
    weight_analysis = {{
        "total_vertices": 0,
        "zero_weight_sum_vertices": [],
        "very_low_weight_vertices": [],
        "weight_sum_statistics": {{}}
    }}
    
    for obj in bpy.data.objects:
        if obj.type == 'MESH':
            mesh = obj.data
            weight_analysis["total_vertices"] = len(mesh.vertices)
            
            weight_sums = []
            zero_sum_vertices = []
            very_low_vertices = []
            
            # å„é ‚ç‚¹ã®ã‚¦ã‚§ã‚¤ãƒˆåˆè¨ˆã‚’è¨ˆç®—
            for v_idx, vertex in enumerate(mesh.vertices):
                total_weight = 0.0
                vertex_weights = []
                
                # ã“ã®é ‚ç‚¹ã®å…¨ãƒãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã®ã‚¦ã‚§ã‚¤ãƒˆã‚’åˆè¨ˆ
                for group in vertex.groups:
                    try:
                        weight = obj.vertex_groups[group.group].weight(v_idx)
                        vertex_weights.append(weight)
                        total_weight += weight
                    except:
                        pass
                
                weight_sums.append(total_weight)
                
                # ã‚¼ãƒ­åˆè¨ˆé ‚ç‚¹ã‚’è¨˜éŒ²
                if total_weight == 0.0:
                    zero_sum_vertices.append({{
                        "vertex_index": v_idx,
                        "group_count": len(vertex.groups)
                    }})
                
                # éå¸¸ã«å°ã•ã„ã‚¦ã‚§ã‚¤ãƒˆåˆè¨ˆã‚’è¨˜éŒ²
                elif total_weight < 0.001:
                    very_low_vertices.append({{
                        "vertex_index": v_idx,
                        "weight_sum": total_weight,
                        "group_count": len(vertex.groups)
                    }})
            
            # çµ±è¨ˆè¨ˆç®—
            if weight_sums:
                weight_analysis["weight_sum_statistics"] = {{
                    "min": min(weight_sums),
                    "max": max(weight_sums),
                    "average": sum(weight_sums) / len(weight_sums),
                    "zero_count": weight_sums.count(0.0),
                    "below_0001": len([w for w in weight_sums if w < 0.001 and w > 0]),
                    "below_001": len([w for w in weight_sums if w < 0.01 and w >= 0.001]),
                    "normal_range": len([w for w in weight_sums if w >= 0.01])
                }}
            
            weight_analysis["zero_weight_sum_vertices"] = zero_sum_vertices[:10]  # æœ€åˆã®10å€‹
            weight_analysis["very_low_weight_vertices"] = very_low_vertices[:10]  # æœ€åˆã®10å€‹
            
            break  # æœ€åˆã®ãƒ¡ãƒƒã‚·ãƒ¥ã®ã¿åˆ†æ
    
    print("=== WEIGHT_ANALYSIS_START ===")
    print(json.dumps(weight_analysis, indent=2))
    print("=== WEIGHT_ANALYSIS_END ===")
    
except Exception as e:
    print(f"ã‚¨ãƒ©ãƒ¼: {{e}}")
    import traceback
    traceback.print_exc()
'''
    
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã§Blenderã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆ
    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False, encoding='utf-8') as f:
        f.write(blender_script)
        script_path = f.name
    
    try:
        cmd = ["blender", "--background", "--python", script_path]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
        
        if result.returncode == 0:
            # çµæœã‚’è§£æ
            output_lines = result.stdout.split('\n')
            capturing = False
            json_lines = []
            
            for line in output_lines:
                if line.strip() == "=== WEIGHT_ANALYSIS_START ===":
                    capturing = True
                    continue
                elif line.strip() == "=== WEIGHT_ANALYSIS_END ===":
                    capturing = False
                    break
                elif capturing:
                    json_lines.append(line)
            
            if json_lines:
                try:
                    import json
                    analysis = json.loads('\n'.join(json_lines))
                    return analysis
                except json.JSONDecodeError as e:
                    print(f"âŒ JSONè§£æã‚¨ãƒ©ãƒ¼: {e}")
        else:
            print(f"âŒ Blenderå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {result.stderr}")
            
    except Exception as e:
        print(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
    finally:
        try:
            os.unlink(script_path)
        except:
            pass
    
    return None

def main():
    print("ğŸ” ã‚¹ã‚­ãƒ‹ãƒ³ã‚°FBXã®ã‚¦ã‚§ã‚¤ãƒˆåˆè¨ˆåˆ†æé–‹å§‹")
    
    fbx_path = Path("/app/pipeline_work/bird/03_skinning/bird_skinned.fbx")
    
    if not fbx_path.exists():
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {fbx_path}")
        return
    
    print(f"ğŸ“Š åˆ†æå¯¾è±¡: {fbx_path}")
    print(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {fbx_path.stat().st_size:,} bytes")
    
    analysis = analyze_weight_sums(fbx_path)
    
    if analysis:
        stats = analysis["weight_sum_statistics"]
        
        print(f"\nğŸ¯ ã‚¦ã‚§ã‚¤ãƒˆåˆè¨ˆçµ±è¨ˆ:")
        print(f"  ç·é ‚ç‚¹æ•°: {analysis['total_vertices']:,}")
        print(f"  æœ€å°ã‚¦ã‚§ã‚¤ãƒˆåˆè¨ˆ: {stats['min']:.6f}")
        print(f"  æœ€å¤§ã‚¦ã‚§ã‚¤ãƒˆåˆè¨ˆ: {stats['max']:.6f}")
        print(f"  å¹³å‡ã‚¦ã‚§ã‚¤ãƒˆåˆè¨ˆ: {stats['average']:.6f}")
        
        print(f"\nğŸš¨ å•é¡Œã®å¯èƒ½æ€§:")
        print(f"  ã‚¼ãƒ­åˆè¨ˆé ‚ç‚¹: {stats['zero_count']:,}å€‹")
        print(f"  è¶…ä½å€¤ï¼ˆ<0.001ï¼‰: {stats['below_0001']:,}å€‹")
        print(f"  ä½å€¤ï¼ˆ0.001-0.01ï¼‰: {stats['below_001']:,}å€‹")
        print(f"  æ­£å¸¸ç¯„å›²ï¼ˆâ‰¥0.01ï¼‰: {stats['normal_range']:,}å€‹")
        
        if stats['zero_count'] > 0:
            print(f"\nâŒ ã‚¼ãƒ­é™¤ç®—ã‚¨ãƒ©ãƒ¼ã®åŸå› ç™ºè¦‹ï¼")
            print(f"   {stats['zero_count']}å€‹ã®é ‚ç‚¹ã§ã‚¦ã‚§ã‚¤ãƒˆåˆè¨ˆãŒ0.0")
            print(f"   ã“ã‚Œã‚‰ã®é ‚ç‚¹ã§vertex_group_reweight[..., :group_per_vertex].sum(axis=1)ãŒ0ã«ãªã‚‹")
            
            print(f"\nğŸ“‹ ã‚¼ãƒ­åˆè¨ˆé ‚ç‚¹ã®ä¾‹:")
            for vertex in analysis["zero_weight_sum_vertices"]:
                print(f"     é ‚ç‚¹{vertex['vertex_index']}: ã‚°ãƒ«ãƒ¼ãƒ—æ•°{vertex['group_count']}")
        
        if stats['below_0001'] > 0:
            print(f"\nâš ï¸ è¶…ä½å€¤ã‚¦ã‚§ã‚¤ãƒˆé ‚ç‚¹:")
            for vertex in analysis["very_low_weight_vertices"]:
                print(f"     é ‚ç‚¹{vertex['vertex_index']}: åˆè¨ˆ{vertex['weight_sum']:.6f}")
        
        if stats['zero_count'] == 0 and stats['below_0001'] == 0:
            print(f"\nâœ… ã‚¦ã‚§ã‚¤ãƒˆåˆè¨ˆã¯æ­£å¸¸ç¯„å›²å†…")
            print(f"   ã‚¼ãƒ­é™¤ç®—ã‚¨ãƒ©ãƒ¼ã®åŸå› ã¯åˆ¥ã®ç®‡æ‰€ã«ã‚ã‚‹å¯èƒ½æ€§")
    
    else:
        print("âŒ åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()
