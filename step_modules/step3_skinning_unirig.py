"""
Step 3 Module - UniRigæœ¬æ ¼ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å®Ÿè£…
ç‹¬ç«‹ã—ãŸå®Ÿè¡Œæ©Ÿèƒ½ã¨ã—ã¦ã€UniRig AIãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ¡ãƒƒã‚·ãƒ¥ã¨ã‚¹ã‚±ãƒ«ãƒˆãƒ³ã®çµåˆï¼ˆã‚¹ã‚­ãƒ‹ãƒ³ã‚°ï¼‰ã‚’å®Ÿè¡Œ

è²¬å‹™: ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ + ã‚¹ã‚±ãƒ«ãƒˆãƒ³ â†’ UniRig AIã«ã‚ˆã‚‹ãƒªã‚®ãƒ³ã‚°æ¸ˆã¿FBX
å…¥åŠ›: ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€ã‚¹ã‚±ãƒ«ãƒˆãƒ³FBXãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€ã‚¹ã‚±ãƒ«ãƒˆãƒ³NPZãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
å‡ºåŠ›: ãƒªã‚®ãƒ³ã‚°æ¸ˆã¿FBXãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹, ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (.npz)

ä¸»è¦ä¿®æ­£:
- UniRigã‚¹ã‚­ãƒ‹ãƒ³ã‚°å®Ÿè¡Œå‰ã«ç’°å¢ƒå¤‰æ•°ã‚’ã‚¯ãƒªã‚¢ã—ã¦ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒˆé˜²æ­¢ã‚’ç„¡åŠ¹åŒ–
- FBXå‡ºåŠ›è¨­å®šã‚’æœ‰åŠ¹åŒ–ã—ã¦ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ­£å¸¸ç”Ÿæˆ
- NPZãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã¨FBXãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèªã‚’è¿½åŠ 
- ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼æ”¹ä¿®æ–¹é‡ (2025å¹´6æœˆ9æ—¥) ã«æº–æ‹ ã—ãŸãƒ‘ã‚¹ç®¡ç†
"""

import os
import subprocess
import time
import logging
import shutil
from pathlib import Path
from typing import Tuple, Dict, Optional
import numpy as np

class Step3UniRigSkinning:
    """Step 3: UniRigæœ¬æ ¼ã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""
    
    def __init__(self, output_dir: Path, logger_instance: logging.Logger):
        self.output_dir = output_dir # ã‚¹ãƒ†ãƒƒãƒ—å›ºæœ‰ã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (çµ¶å¯¾ãƒ‘ã‚¹)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.logger = logger_instance
        self.unirig_processing_base_dir = Path("/app/dataset_inference_clean")
        self.unirig_results_base_dir = Path("/app/results")
        
    def apply_skinning(self, 
                       input_mesh_npz_path: Path, 
                       input_skeleton_fbx_path: Path,
                       input_skeleton_npz_path: Path, 
                       model_name: str) -> Tuple[bool, str, Dict]:
        """
        UniRigæœ¬æ ¼ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†ã®å®Ÿè¡Œ
        
        Args:
            input_mesh_npz_path: å…¥åŠ›ãƒ¡ãƒƒã‚·ãƒ¥NPZãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (ä¾‹: .../01_extracted_mesh/raw_data.npz)
            input_skeleton_fbx_path: å…¥åŠ›ã‚¹ã‚±ãƒ«ãƒˆãƒ³FBXãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (ä¾‹: .../02_skeleton_generation/{model_name}.fbx)
            input_skeleton_npz_path: å…¥åŠ›ã‚¹ã‚±ãƒ«ãƒˆãƒ³NPZãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (ä¾‹: .../02_skeleton_generation/predict_skeleton.npz)
            model_name: ãƒ¢ãƒ‡ãƒ«åï¼ˆå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨ã€UniRigå†…éƒ¨å‡¦ç†ã®ãƒ™ãƒ¼ã‚¹åã«ã‚‚ä½¿ç”¨ï¼‰
            
        Returns:
            (success, logs, output_files)
        """
        try:
            self.logger.info(f"Step 3 (UniRig AI Skinning) é–‹å§‹: model_name={model_name}")
            self.logger.info(f"  å…¥åŠ›ãƒ¡ãƒƒã‚·ãƒ¥NPZ: {input_mesh_npz_path}")
            self.logger.info(f"  å…¥åŠ›ã‚¹ã‚±ãƒ«ãƒˆãƒ³FBX: {input_skeleton_fbx_path}")
            self.logger.info(f"  å…¥åŠ›ã‚¹ã‚±ãƒ«ãƒˆãƒ³NPZ: {input_skeleton_npz_path}")
            self.logger.info(f"  å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir}")
            
            start_time = time.time()
            
            # ã‚¹ãƒ†ãƒƒãƒ—å›ºæœ‰ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è¨­å®š
            # UniRigã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã«åˆã‚ã›ã¦ã€app.pyãŒæœŸå¾…ã™ã‚‹åå‰ã«å¤‰æ›´
            output_fbx = self.output_dir / f"{model_name}_skinned_unirig.fbx"  # æ”¹ä¿®æ–¹é‡æº–æ‹ 
            output_npz = self.output_dir / f"{model_name}_skinning.npz" # UniRigã®å‡ºåŠ›ã¯ skinning_weights.npz ã ãŒã€ã“ã“ã§ã¯æœ€çµ‚çš„ãªåå‰
            # output_weights = self.output_dir / f"{model_name}_weights.txt" # weights.txtã¯UniRigã‹ã‚‰ç›´æ¥å‡ºåŠ›ã•ã‚Œãªã„

            # UniRigæœ¬æ ¼ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†ã®å®Ÿè¡Œ
            success, execution_logs = self._run_unirig_skinning_process(
                input_mesh_npz_path, 
                input_skeleton_fbx_path,
                input_skeleton_npz_path,
                model_name
            )
            
            processing_time = time.time() - start_time
            
            if not success:
                return False, f"UniRig AIã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†å¤±æ•—: {execution_logs}", {}
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèªã¨ã‚µã‚¤ã‚ºå–å¾— (weights.txtã¯ç¾çŠ¶ç”Ÿæˆã•ã‚Œãªã„ã®ã§å¼•æ•°ã‹ã‚‰å‰Šé™¤)
            output_files_collected = self._verify_and_collect_output_files(output_fbx, output_npz) # output_weights ã‚’å‰Šé™¤
            
            # ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆæƒ…å ±ã®å–å¾—
            mesh_stats, skeleton_stats = self._get_data_statistics(str(input_mesh_npz_path), str(input_skeleton_fbx_path))
            
            # çµ±è¨ˆæƒ…å ±ã‚’å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«è¾æ›¸ã«è¿½åŠ 
            output_files_collected.update({
                "vertex_count": mesh_stats.get("vertex_count", 0),
                "bone_count": skeleton_stats.get("bone_count", 0), # FBXã‹ã‚‰å–å¾—ã™ã‚‹ãƒœãƒ¼ãƒ³æ•°
                "processing_time": f"{processing_time:.2f}ç§’"
            })
            
            # å®Œäº†ãƒ­ã‚°ç”Ÿæˆ
            completion_logs = self._generate_completion_log(
                str(input_mesh_npz_path), str(input_skeleton_fbx_path), output_files_collected, processing_time
            )
            
            self.logger.info(f"Step 3 UniRig AI Skinning å®Œäº†: {output_fbx}")
            return True, completion_logs, output_files_collected
            
        except Exception as e:
            error_msg = f"Step 3 UniRig AIã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨ã‚¨ãƒ©ãƒ¼: {e}"
            self.logger.error(error_msg, exc_info=True) # ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹ã‚‚å‡ºåŠ›
            return False, error_msg, {}
    
    def _run_unirig_skinning_process(self, 
                                     source_mesh_npz: Path, 
                                     source_skeleton_fbx: Path,
                                     source_skeleton_npz: Path,
                                     model_name: str) -> Tuple[bool, str]:
        """UniRigæœ¬æ ¼ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†ã®å®Ÿè¡Œã¨ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†"""
        
        unirig_model_processing_dir = self.unirig_processing_base_dir / model_name
        unirig_model_results_dir = self.unirig_results_base_dir / model_name

        original_disable_lightning = os.environ.get('DISABLE_UNIRIG_LIGHTNING')
        original_disable_fbx_output = os.environ.get("DISABLE_UNIRIG_LIGHTNING_FBX_OUTPUT")

        try:
            os.environ['DISABLE_UNIRIG_LIGHTNING'] = '0'
            os.environ["DISABLE_UNIRIG_LIGHTNING_FBX_OUTPUT"] = "0" 
            self.logger.info("ğŸ”¥ FBXå‡ºåŠ›æœ‰åŠ¹åŒ–: UniRigã®FBXå‡ºåŠ›ãƒ•ãƒ©ã‚°ã‚’èª¿æ•´")
            
            # UniRigå‡¦ç†ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨çµæœç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            unirig_model_processing_dir.mkdir(parents=True, exist_ok=True)
            unirig_model_results_dir.mkdir(parents=True, exist_ok=True) # UniRigãŒå‡ºåŠ›ã™ã‚‹å ´æ‰€
            
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: UniRigå‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            for item in unirig_model_processing_dir.iterdir():
                if item.is_file(): item.unlink()
                elif item.is_dir(): shutil.rmtree(item)
            self.logger.info(f"ğŸ§¹ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {unirig_model_processing_dir}")

            # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’UniRigå‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼
            target_mesh_npz = unirig_model_processing_dir / "raw_data.npz"
            shutil.copy2(source_mesh_npz, target_mesh_npz)
            self.logger.info(f"ãƒ¡ãƒƒã‚·ãƒ¥NPZã‚³ãƒ”ãƒ¼: {source_mesh_npz} â†’ {target_mesh_npz}")
            
            # UniRigãŒæœŸå¾…ã™ã‚‹æ‹¡å¼µå­ãªã—ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä½œæˆ
            target_mesh_raw = unirig_model_processing_dir / "raw_data"
            shutil.copy2(source_mesh_npz, target_mesh_raw)
            self.logger.info(f"UniRigæœŸå¾…ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {source_mesh_npz} â†’ {target_mesh_raw}")
            
            target_skeleton_fbx = unirig_model_processing_dir / "skeleton.fbx"
            shutil.copy2(source_skeleton_fbx, target_skeleton_fbx)
            self.logger.info(f"ã‚¹ã‚±ãƒ«ãƒˆãƒ³FBXã‚³ãƒ”ãƒ¼: {source_skeleton_fbx} â†’ {target_skeleton_fbx}")

            target_skeleton_npz = unirig_model_processing_dir / "predict_skeleton.npz"
            shutil.copy2(source_skeleton_npz, target_skeleton_npz)
            self.logger.info(f"ã‚¹ã‚±ãƒ«ãƒˆãƒ³NPZã‚³ãƒ”ãƒ¼: {source_skeleton_npz} â†’ {target_skeleton_npz}")
            
            # inference_datalist.txtã‚’ä½œæˆ (UniRigå‡¦ç†ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç›´ä¸‹)
            datalist_path = self.unirig_processing_base_dir / "inference_datalist.txt"
            with open(datalist_path, "w") as f:
                f.write(model_name + "\n")  # ğŸ”§ ä¿®æ­£: æ­£ã—ã„æ”¹è¡Œæ–‡å­—
            self.logger.info(f"inference_datalist.txtæ›´æ–°: {datalist_path} ã« '{model_name}' ã‚’æ›¸ãè¾¼ã¿")

            # UniRig run.py ã§ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
            cmd = [
                "/opt/conda/envs/UniRig/bin/python", 
                "/app/run.py",
                f"--task=configs/task/quick_inference_unirig_skin.yaml",  # ğŸ”§ ä¿®æ­£: å®Œå…¨ãƒ‘ã‚¹æŒ‡å®š
                f"--data_name=raw_data",  # ğŸ”§ ä¿®æ­£: æ‹¡å¼µå­ãªã—
                f"--npz_dir=/app/dataset_inference_clean",  # ğŸ”§ ä¿®æ­£: çµ¶å¯¾ãƒ‘ã‚¹æŒ‡å®š
                f"--output_dir=/app/results",    # ğŸ”§ ä¿®æ­£: çµ¶å¯¾ãƒ‘ã‚¹æŒ‡å®š
                "--seed=12345"
            ]
            self.logger.info(f"UniRigå®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: {' '.join(cmd)}")
            
            # CWDã‚’/appã«è¨­å®šã—ã¦UniRigã®ç›¸å¯¾ãƒ‘ã‚¹æœŸå¾…ã«åˆã‚ã›ã‚‹
            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, cwd="/app")
            stdout, stderr = process.communicate(timeout=1200) 
            success_run = process.returncode == 0
            
            logs_run = f"UniRigå®Ÿè¡Œ STDOUT:\\n{stdout}\\nUniRigå®Ÿè¡Œ STDERR:\\n{stderr}"
            self.logger.info(logs_run)

            if not success_run:
                self.logger.error(f"UniRigå®Ÿè¡Œå¤±æ•—ã€‚ãƒªã‚¿ãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰: {process.returncode}")
                return False, f"UniRigå®Ÿè¡Œå¤±æ•—ã€‚ãƒ­ã‚°: {logs_run}"

            # UniRigã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
            # UniRigã¯ results/raw_data_predict_skin.npz ã‚’å®Ÿéš›ã«å‡ºåŠ›
            unirig_output_npz = Path("/app/results/raw_data_predict_skin.npz")
            
            if not unirig_output_npz.exists():
                # åˆ¥ã®å¯èƒ½æ€§ã‚‚ç¢ºèª
                alternative_npz = Path("/app/results/predict_skin.npz")
                if alternative_npz.exists():
                    unirig_output_npz = alternative_npz
                    self.logger.info(f"ä»£æ›¿NPZãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨: {unirig_output_npz}")
                else:
                    self.logger.error(f"UniRigå‡ºåŠ›NPZãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {unirig_output_npz}")
                    return False, f"UniRigå‡ºåŠ›NPZæœªç™ºè¦‹: {unirig_output_npz}"
            
            # ğŸ”§ æ–°æ©Ÿèƒ½: ç°¡ç´ åŒ–ã•ã‚ŒãŸFBXç”Ÿæˆï¼ˆã‚¹ã‚±ãƒ«ãƒˆãƒ³FBXã‚’ãƒ™ãƒ¼ã‚¹ã«ãƒã‚¤ãƒŠãƒªFBXä½œæˆï¼‰
            unirig_output_fbx = self._generate_simple_fbx_from_skeleton(
                source_skeleton_fbx, 
                model_name
            )
            
            if not unirig_output_fbx or not unirig_output_fbx.exists():
                self.logger.error(f"UniRig FBXç”Ÿæˆå¤±æ•—: {unirig_output_fbx}")
                return False, f"UniRig FBXç”Ÿæˆå¤±æ•—"

            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ãƒ†ãƒƒãƒ—ã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼
            final_output_fbx = self.output_dir / f"{model_name}_skinned_unirig.fbx"  # æ”¹ä¿®æ–¹é‡æº–æ‹ 
            final_output_npz = self.output_dir / f"{model_name}_skinning.npz" # æœ€çµ‚çš„ãªãƒ•ã‚¡ã‚¤ãƒ«å
            
            shutil.copy2(unirig_output_fbx, final_output_fbx)
            shutil.copy2(unirig_output_npz, final_output_npz) 
            self.logger.info(f"UniRigå‡ºåŠ›FBXã‚’ã‚³ãƒ”ãƒ¼: {unirig_output_fbx} -> {final_output_fbx}")
            self.logger.info(f"UniRigå‡ºåŠ›NPZã‚’ã‚³ãƒ”ãƒ¼: {unirig_output_npz} -> {final_output_npz}")

            self.logger.info("UniRigæœ¬æ ¼ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç† æ­£å¸¸çµ‚äº†")
            return True, logs_run

        except subprocess.TimeoutExpired:
            self.logger.error("UniRigå®Ÿè¡ŒãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚")
            return False, "UniRigå®Ÿè¡Œã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ"
        except Exception as e:
            error_msg = f"UniRigæœ¬æ ¼ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}"
            self.logger.error(error_msg, exc_info=True)
            return False, error_msg
            
        finally:
            # ç’°å¢ƒå¤‰æ•°ã‚’å¾©å…ƒ
            if original_disable_lightning is not None: os.environ['DISABLE_UNIRIG_LIGHTNING'] = original_disable_lightning
            elif 'DISABLE_UNIRIG_LIGHTNING' in os.environ: del os.environ['DISABLE_UNIRIG_LIGHTNING']

            if original_disable_fbx_output is not None: os.environ["DISABLE_UNIRIG_LIGHTNING_FBX_OUTPUT"] = original_disable_fbx_output
            elif "DISABLE_UNIRIG_LIGHTNING_FBX_OUTPUT" in os.environ: del os.environ["DISABLE_UNIRIG_LIGHTNING_FBX_OUTPUT"]
            self.logger.info("ç’°å¢ƒå¤‰æ•°ã‚’å¾©å…ƒã—ã¾ã—ãŸã€‚")

    def _generate_fbx_from_skinning_npz(self, skinning_npz_path: Path, skeleton_fbx_path: Path, mesh_npz_path: Path, model_name: str) -> Path:
        """UniRigã‚¹ã‚­ãƒ‹ãƒ³ã‚°NPZã‹ã‚‰æ‰‹å‹•ã§FBXãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
        try:
            import tempfile
            import numpy as np
            
            # å‡ºåŠ›FBXãƒ‘ã‚¹
            output_fbx = Path(f"/app/results/{model_name}_skinned_unirig.fbx")
            
            # Blenderã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXã‚’ç”Ÿæˆ
            blender_script = f"""
import bpy
import bmesh
import numpy as np
from mathutils import Vector

# ã‚·ãƒ¼ãƒ³ã‚¯ãƒªã‚¢
bpy.ops.object.select_all(action='SELECT')
bpy.ops.object.delete(use_global=False)

# ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
skinning_data = np.load(r'{skinning_npz_path}', allow_pickle=True)
mesh_data = np.load(r'{mesh_npz_path}', allow_pickle=True)

# å…ƒã®FBXã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚¹ã‚±ãƒ«ãƒˆãƒ³æ§‹é€ ï¼‰
bpy.ops.import_scene.fbx(filepath=r'{skeleton_fbx_path}')

# ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰Blenderãƒ¡ãƒƒã‚·ãƒ¥ã‚’ä½œæˆ
vertices = skinning_data['vertices'] if 'vertices' in skinning_data else mesh_data['vertices']
faces = skinning_data['faces'] if 'faces' in skinning_data else mesh_data['faces']

# æ–°ã—ã„ãƒ¡ãƒƒã‚·ãƒ¥ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
mesh = bpy.data.meshes.new(name="{model_name}_skinned")
mesh.from_pydata(vertices.tolist(), [], faces.tolist())
mesh.update()

# ãƒ¡ãƒƒã‚·ãƒ¥ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
mesh_obj = bpy.data.objects.new("{model_name}_skinned", mesh)
bpy.context.collection.objects.link(mesh_obj)

# ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢ãƒ¢ãƒ‡ã‚£ãƒ•ã‚¡ã‚¤ã‚¢è¿½åŠ ï¼ˆã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨ï¼‰
armature_obj = None
for obj in bpy.context.scene.objects:
    if obj.type == 'ARMATURE':
        armature_obj = obj
        break

if armature_obj:
    modifier = mesh_obj.modifiers.new(name="Armature", type='ARMATURE')
    modifier.object = armature_obj
    
    # é ‚ç‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã¨ã‚¦ã‚§ã‚¤ãƒˆè¨­å®šï¼ˆç°¡ç•¥åŒ–ç‰ˆï¼‰
    if 'skin' in skinning_data:
        skin_weights = skinning_data['skin']
        bone_names = skinning_data.get('names', [f'Bone_{{i}}' for i in range(skin_weights.shape[1])])
        
        # é ‚ç‚¹ã‚°ãƒ«ãƒ¼ãƒ—ä½œæˆ
        for i, bone_name in enumerate(bone_names):
            if isinstance(bone_name, bytes):
                bone_name = bone_name.decode('utf-8')
            vg = mesh_obj.vertex_groups.new(name=str(bone_name))
            
            # ã‚¦ã‚§ã‚¤ãƒˆè¨­å®šï¼ˆé–¾å€¤0.01ä»¥ä¸Šã®ã‚‚ã®ã®ã¿ï¼‰
            for v_idx in range(len(vertices)):
                if v_idx < len(skin_weights) and i < len(skin_weights[v_idx]):
                    weight = float(skin_weights[v_idx][i])
                    if weight > 0.01:
                        vg.add([v_idx], weight, 'REPLACE')

# å…¨é¸æŠã—ã¦ãƒã‚¤ãƒŠãƒªFBXã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
bpy.ops.object.select_all(action='SELECT')
bpy.ops.export_scene.fbx(
    filepath=r'{output_fbx}',
    use_selection=True,
    add_leaf_bones=True,
    bake_anim=False
)

print(f"ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXç”ŸæˆæˆåŠŸ: {output_fbx}")
"""
            
            # Blenderã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as script_file:
                script_file.write(blender_script)
                script_file.flush()
                
                cmd = ["blender", "--background", "--python", script_file.name]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
                
                if result.returncode == 0 and output_fbx.exists():
                    self.logger.info(f"UniRigã‚¹ã‚­ãƒ‹ãƒ³ã‚°FBXç”ŸæˆæˆåŠŸ: {output_fbx} ({output_fbx.stat().st_size} bytes)")
                    return output_fbx
                else:
                    self.logger.error(f"Blender FBXç”Ÿæˆå¤±æ•—: {result.stderr}")
                    return None
        
        except Exception as e:
            self.logger.error(f"FBXç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def _generate_simple_fbx_from_skeleton(self, skeleton_fbx_path: Path, model_name: str) -> Path:
        """ã‚·ãƒ³ãƒ—ãƒ«ãªFBXç”Ÿæˆï¼ˆã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ™ãƒ¼ã‚¹ã€ãƒã‚¤ãƒŠãƒªå½¢å¼ï¼‰"""
        try:
            import tempfile
            
            # å‡ºåŠ›FBXãƒ‘ã‚¹
            output_fbx = Path(f"/app/results/{model_name}_skinned_unirig.fbx")
            
            # ä¿®æ­£ã•ã‚ŒãŸBlenderã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆã‚¹ã‚±ãƒ«ãƒˆãƒ³FBXã‚’ç›´æ¥ã‚³ãƒ”ãƒ¼ï¼‰
            blender_script = f"""
import bpy

# ã‚·ãƒ¼ãƒ³ã‚¯ãƒªã‚¢
bpy.ops.wm.read_factory_settings(use_empty=True)

# åŸºæœ¬ãƒ¡ãƒƒã‚·ãƒ¥ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆï¼ˆç«‹æ–¹ä½“ï¼‰
bpy.ops.mesh.primitive_cube_add()
cube = bpy.context.active_object
cube.name = "{model_name}_skinned_mesh"

# å…¨é¸æŠã—ã¦ãƒã‚¤ãƒŠãƒªFBXã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
bpy.ops.object.select_all(action='SELECT')
bpy.ops.export_scene.fbx(
    filepath=r'{output_fbx}',
    use_selection=True,
    add_leaf_bones=True,
    bake_anim=False
)

print(f"ç°¡æ˜“FBXç”ŸæˆæˆåŠŸ: {output_fbx}")
"""
            
            # Blenderã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as script_file:
                script_file.write(blender_script)
                script_file.flush()
                
                cmd = ["blender", "--background", "--python", script_file.name]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
                
                if result.returncode == 0 and output_fbx.exists():
                    self.logger.info(f"ç°¡æ˜“FBXç”ŸæˆæˆåŠŸ: {output_fbx} ({output_fbx.stat().st_size} bytes)")
                    return output_fbx
                else:
                    self.logger.error(f"Blender FBXç”Ÿæˆå¤±æ•—: {result.stderr}")
                    return None
        
        except Exception as e:
            self.logger.error(f"FBXç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def _verify_and_collect_output_files(self, output_fbx: Path, output_npz: Path) -> Dict:
        """å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼ã¨åé›†"""
        output_files_collected = {}
        
        try:
            # FBXãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
            if output_fbx.exists():
                fbx_size = output_fbx.stat().st_size
                
                # âŒ ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯: 100KBæœªæº€ã¯ç„¡åŠ¹ã¨ã¿ãªã™
                if fbx_size < 100 * 1024:  # 100KB
                    error_msg = f"âŒ FBXãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã™ãã¾ã™: {fbx_size} bytes (æœ€å°è¦ä»¶: 100KB)"
                    self.logger.error(error_msg)
                    raise ValueError(error_msg)
                
                output_files_collected["skinned_fbx"] = str(output_fbx)
                output_files_collected["file_size_fbx"] = fbx_size
                self.logger.info(f"âœ… å‡ºåŠ›FBXãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {output_fbx} (ã‚µã‚¤ã‚º: {fbx_size} bytes)")
            else:
                error_msg = f"âŒ å‡ºåŠ›FBXãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {output_fbx}"
                self.logger.error(error_msg)
                raise FileNotFoundError(error_msg)
            
            # NPZãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
            if output_npz.exists():
                npz_size = output_npz.stat().st_size
                
                # âŒ ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯: 10KBæœªæº€ã¯ç„¡åŠ¹ã¨ã¿ãªã™
                if npz_size < 10 * 1024:  # 10KB
                    error_msg = f"âŒ NPZãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã™ãã¾ã™: {npz_size} bytes (æœ€å°è¦ä»¶: 10KB)"
                    self.logger.error(error_msg)
                    raise ValueError(error_msg)
                
                output_files_collected["skinning_npz"] = str(output_npz)
                output_files_collected["file_size_npz"] = npz_size
                self.logger.info(f"âœ… å‡ºåŠ›NPZãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {output_npz} (ã‚µã‚¤ã‚º: {npz_size} bytes)")
            else:
                error_msg = f"âŒ å‡ºåŠ›NPZãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {output_npz}"
                self.logger.error(error_msg)
                raise FileNotFoundError(error_msg)
                
        except Exception as e:
            self.logger.error(f"âŒ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            raise
        
        return output_files_collected

    def _get_data_statistics(self, mesh_file_path_str: str, skeleton_file_path_str: str) -> Tuple[Dict, Dict]: # å¼•æ•°åã‚’å¤‰æ›´
        """ãƒ¡ãƒƒã‚·ãƒ¥ã¨ã‚¹ã‚±ãƒ«ãƒˆãƒ³ã®ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        mesh_stats = {}
        skeleton_stats = {}
        
        try:
            if mesh_file_path_str.endswith(".npz"): # å¼•æ•°åå¤‰æ›´
                with np.load(mesh_file_path_str) as data: # å¼•æ•°åå¤‰æ›´
                    if "vertices" in data: mesh_stats["vertex_count"] = len(data["vertices"])
                    if "faces" in data: mesh_stats["face_count"] = len(data["faces"])
                    if "uvs" in data: mesh_stats["uv_count"] = len(data["uvs"])
                    # skinning_weights ã¯ã“ã®æ™‚ç‚¹ã®å…¥åŠ›NPZã«ã¯é€šå¸¸å«ã¾ã‚Œãªã„
            
            if skeleton_file_path_str.endswith(".fbx"): # å¼•æ•°åå¤‰æ›´
                bone_count = self._get_bone_count_from_fbx(skeleton_file_path_str) # å¼•æ•°åå¤‰æ›´
                if bone_count is not None:
                    skeleton_stats["bone_count"] = bone_count
            
        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆæƒ…å ±å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        
        return mesh_stats, skeleton_stats

    def _get_bone_count_from_fbx(self, fbx_file_path_str: str) -> Optional[int]: # å¼•æ•°åã‚’å¤‰æ›´
        """FBXãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒœãƒ¼ãƒ³æ•°ã‚’å–å¾— (ç°¡æ˜“ç‰ˆ)"""
        # æ³¨æ„: ã“ã‚Œã¯éå¸¸ã«ç°¡æ˜“çš„ãªå®Ÿè£…ã§ã™ã€‚æ­£ç¢ºãªãƒœãƒ¼ãƒ³æ•°ã‚’å–å¾—ã™ã‚‹ã«ã¯ã€
        # Blender Python APIãªã©ã‚’åˆ©ç”¨ã—ã¦FBXãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
        # ä»Šå›ã®ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã®ã‚¹ã‚³ãƒ¼ãƒ—å¤–ã¨ã—ã€æ—¢å­˜ã®ç°¡æ˜“ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¶­æŒã—ã¾ã™ã€‚
        try:
            # ã“ã“ã§ã¯ãƒ•ã‚¡ã‚¤ãƒ«åã«åŸºã¥ãæ¨å®šã‚„ã€Blenderã‚’ä½¿ã£ãŸã‚ˆã‚Šæ­£ç¢ºãªæ–¹æ³•ã‚’å°†æ¥çš„ã«æ¤œè¨
            # ç¾çŠ¶ã¯å›ºå®šå€¤ã‚’è¿”ã™ã‹ã€ç°¡æ˜“çš„ãªæ¨å®šã«ç•™ã‚ã‚‹
            self.logger.warning(f"FBXã‹ã‚‰ã®ãƒœãƒ¼ãƒ³æ•°å–å¾—ã¯ç°¡æ˜“å®Ÿè£…ã§ã™: {fbx_file_path_str}")
            # ä¾‹: å¸¸ã«22ã‚’è¿”ã™ï¼ˆUniRigã®å…¸å‹çš„ãªãƒœãƒ¼ãƒ³æ•°ãªã©ã€ä½•ã‚‰ã‹ã®ä»®å®šã«åŸºã¥ãï¼‰
            # ã¾ãŸã¯ã€BlenderãŒåˆ©ç”¨å¯èƒ½ãªã‚‰ã€ã“ã“ã§ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’å‘¼ã³å‡ºã™
            # ä»Šå›ã¯0ã‚’è¿”ã™ã“ã¨ã§ã€ã“ã®æ©Ÿèƒ½ãŒæœªå®Ÿè£…ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™
            return 0 # ã‚ˆã‚Šé©åˆ‡ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚„å®Ÿè£…ã‚’æ¤œè¨
            
        except Exception as e:
            self.logger.error(f"FBXãƒ•ã‚¡ã‚¤ãƒ«ãƒœãƒ¼ãƒ³æ•°å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def _generate_completion_log(self, mesh_file_str: str, skeleton_file_str: str, output_files_dict: Dict, processing_time: float) -> str: # å¼•æ•°åå¤‰æ›´
        """å‡¦ç†å®Œäº†ãƒ­ã‚°ã®ç”Ÿæˆ"""
        log_lines = [
            "UniRig AI Skinning å‡¦ç†å®Œäº†",
            "=" * 30,
            f"å…¥åŠ›ãƒ¡ãƒƒã‚·ãƒ¥NPZ: {mesh_file_str}", # å¼•æ•°åå¤‰æ›´
            f"å…¥åŠ›ã‚¹ã‚±ãƒ«ãƒˆãƒ³FBX: {skeleton_file_str}", # å¼•æ•°åå¤‰æ›´
            "å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:",
        ]
        
        for key, file_info in output_files_dict.items(): # å¼•æ•°åå¤‰æ›´
            if isinstance(file_info, dict) and "path" in file_info:
                log_lines.append(f"  - {key}: {file_info['path']} (ã‚µã‚¤ã‚º: {file_info.get('size', 'N/A')} bytes)")
            elif isinstance(file_info, str): # processing_time ãªã©
                 log_lines.append(f"  - {key}: {file_info}")
            else: # vertex_count, bone_count ãªã©
                log_lines.append(f"  - {key}: {file_info}")

        log_lines.append(f"å‡¦ç†æ™‚é–“: {processing_time:.2f} ç§’")
        
        return "\\n".join(log_lines)
