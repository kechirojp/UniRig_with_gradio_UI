"""
Step3 Module - ã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨ (æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥)
ğŸ”¥ é‡è¦: Step3ã¯å¿…ãšã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç‹¬è‡ªã®ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã‚’å®Ÿè¡Œ
åŸæµå‡¦ç†generate_skin.shå®Œå…¨äº’æ›å®Ÿè£…

ğŸ“‹ 2025å¹´6æœˆ16æ—¥ä¿®æ­£: run.py + YAMLè¨­å®š + Lightningä½¿ç”¨
- åŸæµå‡¦ç†ã¨ã®å®Œå…¨ä¸€è‡´ã‚’å®Ÿç¾
- src.system.skinã®ç›´æ¥å‘¼ã³å‡ºã—ã‹ã‚‰å¤‰æ›´
- Lightningæœ€é©åŒ–ã¨YAMLè¨­å®šã®æ©æµã‚’å—ã‘ã‚‹

è²¬å‹™: ã‚ªãƒªã‚¸ãƒŠãƒ«3Dãƒ¢ãƒ‡ãƒ« + ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿ â†’ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBX
å‡ºåŠ›: {model_name}_skinned.fbx, {model_name}_skinning.npz
"""

import os
import sys
import subprocess
import shutil
import time
import logging
import tempfile
from pathlib import Path
from typing import Tuple, Dict, Any, Optional
import numpy as np

sys.path.insert(0, '/app')
sys.path.insert(0, '/app/src')

class Step3Skinning:
    """Step3: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥)"""
    
    def __init__(self, step_output_dir: Path, logger_instance: Optional[logging.Logger] = None):
        """
        Args:
            step_output_dir: Step3å°‚ç”¨å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ä¾‹: /app/pipeline_work/{model_name}/03_skinning/)
            logger_instance: ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        self.step_output_dir = step_output_dir
        self.step_output_dir.mkdir(parents=True, exist_ok=True)
        self.logger = logger_instance if logger_instance else logging.getLogger(__name__)
        
        # UniRigå‡¦ç†ç”¨ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (run.pyãŒæœŸå¾…ã™ã‚‹æ§‹é€ )
        self.unirig_processing_base_dir = Path("/app/dataset_inference_clean")
        self.unirig_processing_base_dir.mkdir(parents=True, exist_ok=True)
    
    def apply_skinning(self, 
                      original_file: Path, 
                      model_name: str, 
                      skeleton_files: Dict[str, str]
                     ) -> Tuple[bool, str, Dict[str, Any]]:
        """
        ğŸ”¥ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨ - ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç‹¬è‡ªãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºå®Ÿè¡Œ
        
        é‡è¦: Step1ã®çµæœã¯ä½¿ç”¨ã›ãšã€ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç‹¬è‡ªã«ãƒ¡ãƒƒã‚·ãƒ¥ã‚’å†æŠ½å‡º
        åŸæµå‡¦ç†generate_skin.shå®Œå…¨äº’æ›
        
        Args:
            original_file: ã‚ªãƒªã‚¸ãƒŠãƒ«3Dãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« (.glb, .fbx, .vrmç­‰)
            model_name: ãƒ¢ãƒ‡ãƒ«åï¼ˆçµ±ä¸€å‘½åè¦å‰‡ãƒ™ãƒ¼ã‚¹ï¼‰
            skeleton_files: Step2ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«è¾æ›¸
            
        Returns:
            (success, logs, output_files dict) - çµ±ä¸€å‘½åè¦å‰‡æº–æ‹ ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        logs = ""
        try:
            start_time = time.time()
            self.logger.info(f"ğŸ”¥ Step3ã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨é–‹å§‹: ãƒ¢ãƒ‡ãƒ« '{model_name}'")
            self.logger.info(f"ğŸ”¥ é‡è¦: ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç‹¬è‡ªãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºå®Ÿè¡Œ: {original_file}")
            
            if not original_file.exists():
                error_msg = f"âŒ ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {original_file}"
                self.logger.error(error_msg)
                return False, logs, {
                    "skinned_fbx": "",
                    "skinning_npz": ""
                }

            # --- Step3å°‚ç”¨UniRigå‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™ ---
            unirig_model_processing_dir = self.unirig_processing_base_dir / model_name
            unirig_model_processing_dir.mkdir(parents=True, exist_ok=True)
            
            # --- Step3å°‚ç”¨ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ ---
            step3_mesh_dir = self.step_output_dir / "mesh_for_skinning"
            step3_mesh_dir.mkdir(parents=True, exist_ok=True)
            logs += f"âš™ï¸ Step3å°‚ç”¨ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™å®Œäº†: '{step3_mesh_dir}'\n"
            logs += f"âš™ï¸ Step3ç”¨UniRigå‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™å®Œäº†: '{unirig_model_processing_dir}'\n"

            # --- ğŸ”¥ åŠ¹ç‡åŒ–: æ—¢å­˜raw_data.npzç¢ºèª ---
            # dataset_inference_clean/{model_name}/ã«æ—¢ã«raw_data.npzãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            existing_raw_data = unirig_model_processing_dir / "raw_data.npz"
            if existing_raw_data.exists():
                logs += f"âœ… æ—¢å­˜ã®raw_data.npzã‚’ä½¿ç”¨: {existing_raw_data} (ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã‚¹ã‚­ãƒƒãƒ—)\n"
                success_extraction = True
                extraction_logs = f"ğŸ“‹ Step2ã§ç”Ÿæˆæ¸ˆã¿ã®raw_data.npzã‚’å†åˆ©ç”¨: {existing_raw_data}\n"
            else:
                # --- ğŸ”¥ é‡è¦: Step3ç‹¬è‡ªã®ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºå®Ÿè¡Œ ---
                success_extraction, extraction_logs = self._execute_skinning_specific_mesh_extraction(
                    original_file, unirig_model_processing_dir, model_name
                )
                
            logs += extraction_logs
            
            if not success_extraction:
                error_msg = f"âŒ Step3ç‹¬è‡ªãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºå¤±æ•—ã€‚"
                self.logger.error(error_msg)
                return False, logs, {
                    "skinned_fbx": "",
                    "skinning_npz": ""
                }

            # --- ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ•ã‚¡ã‚¤ãƒ«é…ç½® ---
            success_skeleton_setup, skeleton_setup_logs = self._setup_skeleton_files(
                unirig_model_processing_dir, skeleton_files, model_name
            )
            logs += skeleton_setup_logs
            
            if not success_skeleton_setup:
                error_msg = f"âŒ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ•ã‚¡ã‚¤ãƒ«é…ç½®å¤±æ•—ã€‚"
                self.logger.error(error_msg)
                return False, logs, {
                    "skinned_fbx": "",
                    "skinning_npz": ""
                }

            # --- UniRigã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†å®Ÿè¡Œ ---
            success_skinning, skinning_logs = self._execute_unirig_skinning_generation(
                model_name, unirig_model_processing_dir
            )
            logs += skinning_logs
            
            if not success_skinning:
                error_msg = f"âŒ UniRigã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†å¤±æ•—ã€‚"
                self.logger.error(error_msg)
                return False, logs, {
                    "skinned_fbx": "",
                    "skinning_npz": ""
                }
            
            # --- ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†ã¨çµ±ä¸€å‘½åè¦å‰‡å¯¾å¿œ ---
            success_output, output_logs, output_files = self._organize_step3_outputs(
                model_name, unirig_model_processing_dir
            )
            logs += output_logs
            
            if not success_output:
                error_msg = f"âŒ Step3å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†å¤±æ•—ã€‚"
                self.logger.error(error_msg)
                return False, logs, {
                    "skinned_fbx": "",
                    "skinning_npz": ""
                }
            
            # --- ğŸ” é‡è¦: ãƒãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ï¼ˆãƒœãƒ¼ãƒ³/ã‚¦ã‚§ã‚¤ãƒˆï¼‰æ¤œè¨¼å®Ÿè¡Œ ---
            if output_files.get("skinned_fbx") and Path(output_files["skinned_fbx"]).exists():
                validation_success, validation_logs = self._validate_vertex_groups_in_fbx(
                    Path(output_files["skinned_fbx"]), model_name
                )
                logs += validation_logs
                
                if not validation_success:
                    error_msg = f"âŒ Step3ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¤œè¨¼å¤±æ•—: ãƒãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ï¼ˆãƒœãƒ¼ãƒ³/ã‚¦ã‚§ã‚¤ãƒˆï¼‰ãŒæ­£ã—ãç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
                    self.logger.error(error_msg)
                    return False, logs, {
                        "skinned_fbx": "",
                        "skinning_npz": ""
                    }
                else:
                    self.logger.info("âœ… Step3ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¤œè¨¼æˆåŠŸ: ãƒãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ãŒæ­£å¸¸ã«ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã™ã€‚")
            else:
                error_msg = f"âŒ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ãƒãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—æ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚"
                self.logger.warning(error_msg)
                logs += error_msg + "\n"

            processing_time = time.time() - start_time
            output_files["processing_time_seconds"] = round(processing_time, 2)
            
            final_log_message = f"ğŸ”¥ Step3ã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨å®Œäº†:\n"
            final_log_message += f"- ãƒ¢ãƒ‡ãƒ«å: {model_name}\n"
            final_log_message += f"- å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’\n"
            if 'skinning_npz' in output_files:
                final_log_message += f"- çµ±ä¸€NPZ: {output_files.get('skinning_npz', '')}\n"
            else:
                final_log_message += f"- çµ±ä¸€NPZ: (ä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ)\n"
            final_log_message += f"- çµ±ä¸€FBX: {output_files.get('skinned_fbx', '')}\n"
            logs += "\n" + final_log_message
            
            self.logger.info(f"ğŸ”¥ Step3ã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨æ­£å¸¸å®Œäº†: '{output_files.get('skinned_fbx', '')}'")
            return True, logs, output_files
            
        except Exception as e:
            error_msg = f"âŒ Step3ã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {type(e).__name__} - {e}"
            self.logger.error(error_msg, exc_info=True)
            return False, logs, {
                    "skinned_fbx": "",
                    "skinning_npz": ""
                }
    
    def _execute_skinning_specific_mesh_extraction(self, original_file: Path, unirig_model_processing_dir: Path, model_name: str) -> Tuple[bool, str]:
        """
        ğŸ”¥ Step3ç‹¬è‡ªã®ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç‰¹åŒ–ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡º
        
        é‡è¦: åŸæµå‡¦ç†generate_skin.shç¬¬1æ®µéšå®Œå…¨äº’æ›
        ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç”Ÿæˆã«æœ€é©åŒ–ã•ã‚ŒãŸå‰å‡¦ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä½¿ç”¨
        
        Args:
            original_file: ã‚ªãƒªã‚¸ãƒŠãƒ«3Dãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«
            unirig_model_processing_dir: UniRigå‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            model_name: ãƒ¢ãƒ‡ãƒ«å
            
        Returns:
            (success, logs)
        """
        logs = ""
        try:
            # ãƒ‡ãƒ¼ã‚¿è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
            data_config = Path("/app/configs/data/quick_inference.yaml")
            if not data_config.exists():
                return False, f"âŒ ãƒ‡ãƒ¼ã‚¿è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨: {data_config}\n"
            
            logs += f"ğŸ”¥ Step3ç‹¬è‡ªãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºé–‹å§‹\n"
            logs += f"ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: {original_file}\n"
            logs += f"UniRigå‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {unirig_model_processing_dir}\n"
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ç”Ÿæˆ (åŸæµæ–¹å¼)
            time_str = time.strftime("%Y_%m_%d_%H_%M_%S")
            
            # ğŸ”¥ åŸæµå‡¦ç†generate_skin.shç¬¬1æ®µéšå®Œå…¨äº’æ›ã‚³ãƒãƒ³ãƒ‰
            extract_cmd = [
                sys.executable, "-m", "src.data.extract",
                "--config", str(data_config),
                "--force_override", "true",
                "--num_runs", "1",
                "--faces_target_count", "50000",  # ğŸ”¥ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ç‰¹åŒ–: è©³ç´°ãƒ¡ãƒƒã‚·ãƒ¥
                "--require_suffix", "obj,fbx,FBX,dae,glb,gltf,vrm",
                "--time", time_str,
                "--id", "0",
                "--input", str(original_file),  # ğŸ”¥ ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç›´æ¥æŒ‡å®š
                "--output_dir", str(unirig_model_processing_dir)
            ]
            
            logs += f"ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã‚³ãƒãƒ³ãƒ‰: {' '.join(extract_cmd)}\n"
            
            extract_start_time = time.time()
            result = subprocess.run(
                extract_cmd,
                cwd='/app',
                capture_output=True,
                text=True,
                timeout=600  # 10åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            )
            extract_execution_time = time.time() - extract_start_time
            logs += f"â±ï¸ ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºå®Ÿè¡Œæ™‚é–“: {extract_execution_time:.2f}ç§’\n"
            
            # ğŸ”¥ é‡è¦: Blenderã‚¯ãƒ©ãƒƒã‚·ãƒ¥(-11)ã§ã‚‚ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã•ã‚Œã¦ã„ã‚‹å ´åˆã¯æˆåŠŸã¨ã™ã‚‹
            # ãƒªã‚¿ãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰ã§ã¯ãªãã€å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ã‚’å„ªå…ˆã—ã¦ç¢ºèª
            possible_raw_data_locations = [
                # æŒ‡å®šå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç›´ä¸‹
                unirig_model_processing_dir / "raw_data.npz",
                # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸‹ã®ãƒ¢ãƒ‡ãƒ«åãƒ•ã‚©ãƒ«ãƒ€ï¼ˆå®Ÿéš›ã®å‡ºåŠ›å…ˆï¼‰
                original_file.parent / original_file.stem / "raw_data.npz", 
                # ãã®ä»–ã®å¯èƒ½æ€§
                unirig_model_processing_dir / "examples" / original_file.stem / "raw_data.npz",
                unirig_model_processing_dir / original_file.stem / "raw_data.npz"
            ]
            
            found_raw_data = None
            for possible_location in possible_raw_data_locations:
                if possible_location.exists():
                    found_raw_data = possible_location
                    break
            
            if found_raw_data:
                # ğŸ”¥ é‡è¦: è¦‹ã¤ã‹ã£ãŸraw_data.npzã‚’UniRigå‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼
                target_raw_data = unirig_model_processing_dir / "raw_data.npz"
                if found_raw_data != target_raw_data:
                    shutil.copy2(found_raw_data, target_raw_data)
                    logs += f"ğŸ“‹ raw_data.npzã‚’UniRigå‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼: {found_raw_data} â†’ {target_raw_data}\n"
                
                # ğŸ”¥ é‡è¦: Step3å°‚ç”¨ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚‚ã‚³ãƒ”ãƒ¼ï¼ˆæ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥ï¼‰
                step3_mesh_dir = self.step_output_dir / "mesh_for_skinning"
                step3_target_raw_data = step3_mesh_dir / "raw_data.npz"
                shutil.copy2(found_raw_data, step3_target_raw_data)
                logs += f"ğŸ“‹ raw_data.npzã‚’Step3å°‚ç”¨ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼: {found_raw_data} â†’ {step3_target_raw_data}\n"
                
                success_msg = f"âœ… Step3ç‹¬è‡ªãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºæˆåŠŸ (ãƒªã‚¿ãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰: {result.returncode}, Blenderã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã§ã‚‚ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆæ¸ˆã¿)\n"
                success_msg += f"ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«: {found_raw_data}\n"
                success_msg += f"UniRigå‡¦ç†ç”¨: {target_raw_data}\n"
                success_msg += f"Step3å°‚ç”¨ä¿å­˜: {step3_target_raw_data}\n"
                if result.stdout:
                    success_msg += f"STDOUT:\n{result.stdout}\n"
                logs += success_msg
                self.logger.info("Step3ç‹¬è‡ªãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºæˆåŠŸï¼ˆBlenderã‚¯ãƒ©ãƒƒã‚·ãƒ¥å¾Œã‚‚ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèªï¼‰ã€‚")
                return True, logs
            else:
                error_msg = f"âŒ raw_data.npzãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ (ãƒªã‚¿ãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰: {result.returncode})\n"
                error_msg += f"æ¤œç´¢å ´æ‰€: {[str(loc) for loc in possible_raw_data_locations]}\n"
                if result.stdout:
                    error_msg += f"STDOUT:\n{result.stdout}\n"
                if result.stderr:
                    error_msg += f"STDERR:\n{result.stderr}\n"
                self.logger.error(f"ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã‚¨ãƒ©ãƒ¼ã€‚Return code: {result.returncode}")
                logs += error_msg
                return False, logs
                
        except subprocess.TimeoutExpired:
            timeout_msg = "âŒ ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ (10åˆ†)\n"
            self.logger.error(timeout_msg)
            return False, logs + timeout_msg
        except Exception as e:
            exec_error_msg = f"âŒ ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {type(e).__name__} - {e}\n"
            self.logger.error(exec_error_msg, exc_info=True)
            return False, logs + exec_error_msg
    
    def _setup_skeleton_files(self, unirig_model_processing_dir: Path, skeleton_files: Dict[str, str], model_name: str) -> Tuple[bool, str]:
        """
        ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’UniRigå‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®
        
        Args:
            unirig_model_processing_dir: UniRigå‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            skeleton_files: Step2ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«è¾æ›¸
            model_name: ãƒ¢ãƒ‡ãƒ«å
            
        Returns:
            (success, logs)
        """
        logs = ""
        try:
            # predict_skeleton.npzé…ç½® (run.pyãŒæœŸå¾…ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å)
            skeleton_npz_path = skeleton_files.get("skeleton_npz") or skeleton_files.get("unified_skeleton_npz")
            if skeleton_npz_path and Path(skeleton_npz_path).exists():
                target_skeleton_npz = unirig_model_processing_dir / "predict_skeleton.npz"
                if not target_skeleton_npz.exists():
                    shutil.copy2(skeleton_npz_path, target_skeleton_npz)
                logs += f"âœ… ã‚¹ã‚±ãƒ«ãƒˆãƒ³NPZãƒ•ã‚¡ã‚¤ãƒ«é…ç½®: {target_skeleton_npz}\n"
            else:
                # ğŸš¨ å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨ã‚¨ãƒ©ãƒ¼ - Step3ã¯å¤±æ•—ã¨ã™ã‚‹
                error_msg = f"âŒ å¿…é ˆã‚¹ã‚±ãƒ«ãƒˆãƒ³NPZãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {skeleton_npz_path}"
                logs += f"{error_msg}\n"
                logs += f"ğŸ’¡ è§£æ±ºç­–: Step2ã®å®Ÿè¡Œã‚’å…ˆã«å®Œäº†ã—ã¦ãã ã•ã„\n"
                return False, logs
            
            # {model_name}.fbxé…ç½® (åŸæµäº’æ›å)
            skeleton_fbx_path = skeleton_files.get("skeleton_fbx") or skeleton_files.get("unified_skeleton_fbx")
            if skeleton_fbx_path and Path(skeleton_fbx_path).exists():
                target_skeleton_fbx = unirig_model_processing_dir / f"{model_name}.fbx"
                if not target_skeleton_fbx.exists():
                    shutil.copy2(skeleton_fbx_path, target_skeleton_fbx)
                logs += f"âœ… ã‚¹ã‚±ãƒ«ãƒˆãƒ³FBXãƒ•ã‚¡ã‚¤ãƒ«é…ç½®: {target_skeleton_fbx}\n"
            else:
                # ğŸš¨ å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨ã‚¨ãƒ©ãƒ¼ - Step3ã¯å¤±æ•—ã¨ã™ã‚‹
                error_msg = f"âŒ å¿…é ˆã‚¹ã‚±ãƒ«ãƒˆãƒ³FBXãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {skeleton_fbx_path}"
                logs += f"{error_msg}\n"
                logs += f"ğŸ’¡ è§£æ±ºç­–: Step2ã®å®Ÿè¡Œã‚’å…ˆã«å®Œäº†ã—ã¦ãã ã•ã„\n"
                return False, logs
                target_skeleton_fbx = unirig_model_processing_dir / f"{model_name}.fbx"
                if not target_skeleton_fbx.exists():
                    shutil.copy2(skeleton_fbx_path, target_skeleton_fbx)
                logs += f"ã‚¹ã‚±ãƒ«ãƒˆãƒ³FBXãƒ•ã‚¡ã‚¤ãƒ«é…ç½®: {target_skeleton_fbx}\n"
            
            return True, logs
            
        except Exception as e:
            error_msg = f"âŒ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ•ã‚¡ã‚¤ãƒ«é…ç½®ã‚¨ãƒ©ãƒ¼: {type(e).__name__} - {e}\n"
            self.logger.error(error_msg, exc_info=True)
            return False, logs + error_msg
    
    def _execute_unirig_skinning_generation(self, model_name: str, unirig_model_processing_dir: Path) -> Tuple[bool, str]:
        """
        UniRigã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†å®Ÿè¡Œ (åŸæµå‡¦ç†generate_skin.shç¬¬2æ®µéšå®Œå…¨äº’æ›)
        
        ğŸ”¥ é‡è¦ä¿®æ­£: run.py + YAMLè¨­å®šä½¿ç”¨ (åŸæµå‡¦ç†ã¨ã®å®Œå…¨ä¸€è‡´)
        
        Args:
            model_name: ãƒ¢ãƒ‡ãƒ«å
            unirig_model_processing_dir: UniRigå‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            
        Returns:
            (success, logs)
        """
        logs = ""
        try:
            # ã‚¹ã‚­ãƒ‹ãƒ³ã‚°è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
            skinning_config = Path("/app/configs/task/quick_inference_unirig_skin.yaml")
            if not skinning_config.exists():
                return False, f"âŒ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨: {skinning_config}\n"
            
            logs += f"ğŸ”¥ UniRigã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†å®Ÿè¡Œé–‹å§‹ (run.py + Lightningä½¿ç”¨)\n"
            logs += f"å‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {unirig_model_processing_dir}\n"
            logs += f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: {skinning_config}\n"
            
            # ğŸ”¥ æ±ºå®šçš„ä¿®æ­£: åŸæµå‡¦ç†generate_skin.shå®Œå…¨äº’æ› - dataset_inference_cleanä½¿ç”¨
            # é‡è¦: npz_dirã«ã¯ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡å®šã€data_nameã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆraw_data.npzï¼‰ã‚’ä½¿ç”¨
            skinning_cmd = [
                sys.executable, "run.py",
                "--task", str(skinning_config),
                "--seed", "12345",
                "--npz_dir", f"dataset_inference_clean/{model_name}",  # ğŸ”¥ ä¿®æ­£: ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæŒ‡å®š
                # data_nameã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆraw_data.npzï¼‰ã‚’ä½¿ç”¨ã€--data_nameãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯å‰Šé™¤
            ]
            
            logs += f"ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†ã‚³ãƒãƒ³ãƒ‰ (run.py + Lightning): {' '.join(skinning_cmd)}\n"
            
            skinning_start_time = time.time()
            result = subprocess.run(
                skinning_cmd,
                cwd='/app',
                capture_output=True,
                text=True,
                timeout=1800  # 30åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (Lightningå‡¦ç†ã®ãŸã‚å»¶é•·)
            )
            skinning_execution_time = time.time() - skinning_start_time
            logs += f"â±ï¸ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†å®Ÿè¡Œæ™‚é–“ (Lightning): {skinning_execution_time:.2f}ç§’\n"
            
            if result.returncode == 0:
                success_msg = f"âœ… UniRigã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†æˆåŠŸ (run.py + Lightning) (ãƒªã‚¿ãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰: {result.returncode})\n"
                if result.stdout:
                    success_msg += f"STDOUT:\n{result.stdout}\n"
                logs += success_msg
                self.logger.info("UniRigã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†æ­£å¸¸å®Œäº† (Lightningæœ€é©åŒ–)ã€‚")
                return True, logs
            else:
                error_msg = f"âŒ UniRigã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†å¤±æ•— (run.py + Lightning) (ãƒªã‚¿ãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰: {result.returncode})\n"
                if result.stdout:
                    error_msg += f"STDOUT:\n{result.stdout}\n"
                if result.stderr:
                    error_msg += f"STDERR:\n{result.stderr}\n"
                self.logger.error(f"ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†ã‚¨ãƒ©ãƒ¼ (Lightning)ã€‚Return code: {result.returncode}")
                logs += error_msg
                return False, logs
                
        except subprocess.TimeoutExpired:
            timeout_msg = "âŒ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ (15åˆ†)\n"
            self.logger.error(timeout_msg)
            return False, logs + timeout_msg
        except Exception as e:
            exec_error_msg = f"âŒ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {type(e).__name__} - {e}\n"
            self.logger.error(exec_error_msg, exc_info=True)
            return False, logs + exec_error_msg
    
    def _organize_step3_outputs(self, model_name: str, unirig_model_processing_dir: Path) -> Tuple[bool, str, Dict[str, Any]]:
        """
        Step3å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†ã¨çµ±ä¸€å‘½åè¦å‰‡å¯¾å¿œ
        
        Args:
            model_name: ãƒ¢ãƒ‡ãƒ«å
            unirig_model_processing_dir: UniRigå‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            
        Returns:
            (success, logs, output_files dict)
        """
        logs = ""
        output_files = {}
        
        try:
            logs += f"ğŸ”§ Step3å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†é–‹å§‹\n"
            
            # ğŸ”¥ é‡è¦: run.pyã«ã‚ˆã‚‹å®Ÿéš›ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç¢ºèª
            # åŸæµå‡¦ç†ã®å®Ÿéš›ã®å‡ºåŠ›ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãæ¤œç´¢
            possible_output_patterns = [
                # ğŸ¯ å®Ÿéš›ã®å‡ºåŠ›å ´æ‰€ã‚’è¿½åŠ ï¼ˆresults/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰
                Path("/app/results/skinned_model.fbx"),  # å®Ÿéš›ã®ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBX
                Path("/app/results/predict_skin.npz"),   # å®Ÿéš›ã®ã‚¹ã‚­ãƒ³ã‚¦ã‚§ã‚¤ãƒˆNPZ
                # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«åŸºã¥ãäºˆæƒ³å‡ºåŠ›å
                unirig_model_processing_dir / "result_fbx.fbx",
                unirig_model_processing_dir / f"{model_name}_skinned_unirig.fbx",
                unirig_model_processing_dir / "predict_skin.npz",
                unirig_model_processing_dir / f"{model_name}_skinning.npz",
                # ãã®ä»–ã®å¯èƒ½ãªå‡ºåŠ›ãƒ‘ã‚¿ãƒ¼ãƒ³
                unirig_model_processing_dir / "skinned.fbx",
                unirig_model_processing_dir / "output.fbx"
            ]
            
            # ç”Ÿæˆã•ã‚ŒãŸFBXãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            found_fbx = None
            found_npz = None
            
            for pattern in possible_output_patterns:
                if pattern.exists() and pattern.suffix == ".fbx":
                    found_fbx = pattern
                    logs += f"ğŸ“ ç”ŸæˆFBXãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {found_fbx}\n"
                    break
            
            for pattern in possible_output_patterns:
                if pattern.exists() and pattern.suffix == ".npz":
                    found_npz = pattern
                    logs += f"ğŸ“ ç”ŸæˆNPZãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {found_npz}\n"
                    break
            
            if not found_fbx:
                # æŒ‡å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã§è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨FBXã‚’æ¤œç´¢
                fbx_files = list(unirig_model_processing_dir.glob("*.fbx"))
                # ã‚¹ã‚±ãƒ«ãƒˆãƒ³FBXã‚’é™¤å¤–
                fbx_files = [f for f in fbx_files if f.name != f"{model_name}.fbx"]
                if fbx_files:
                    found_fbx = fbx_files[0]  # æœ€åˆã«è¦‹ã¤ã‹ã£ãŸã‚‚ã®ã‚’ä½¿ç”¨
                    logs += f"ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œç´¢ã§FBXãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {found_fbx}\n"
            
            if not found_npz:
                # æŒ‡å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã§è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨NPZã‚’æ¤œç´¢ï¼ˆraw_data.npz, predict_skeleton.npzã‚’é™¤å¤–ï¼‰
                npz_files = list(unirig_model_processing_dir.glob("*.npz"))
                npz_files = [f for f in npz_files if f.name not in ["raw_data.npz", "predict_skeleton.npz"]]
                if npz_files:
                    found_npz = npz_files[0]  # æœ€åˆã«è¦‹ã¤ã‹ã£ãŸã‚‚ã®ã‚’ä½¿ç”¨
                    logs += f"ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œç´¢ã§NPZãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {found_npz}\n"
            
            # ğŸ”¥ çµ±ä¸€å‘½åè¦å‰‡ã«åŸºã¥ãæœ€çµ‚å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«é…ç½®
            if found_fbx:
                unified_fbx_name = f"{model_name}_skinned.fbx"
                unified_fbx_path = self.step_output_dir / unified_fbx_name
                shutil.copy2(found_fbx, unified_fbx_path)
                output_files["skinned_fbx"] = str(unified_fbx_path)
                logs += f"âœ… çµ±ä¸€FBXç”Ÿæˆ: {unified_fbx_path}\n"
            else:
                return False, logs, {
                    "skinned_fbx": "",
                    "skinning_npz": ""
                }
            
            if found_npz:
                unified_npz_name = f"{model_name}_skinning.npz"
                unified_npz_path = self.step_output_dir / unified_npz_name
                shutil.copy2(found_npz, unified_npz_path)
                output_files["skinning_npz"] = str(unified_npz_path)
                logs += f"âœ… çµ±ä¸€NPZç”Ÿæˆ: {unified_npz_path}\n"
            else:
                # NPZãƒ•ã‚¡ã‚¤ãƒ«ã¯å¿…é ˆã§ã¯ãªã„å ´åˆãŒã‚ã‚‹ãŸã‚ã€è­¦å‘Šã®ã¿
                logs += f"âš ï¸ ã‚¹ã‚­ãƒ‹ãƒ³ã‚°NPZãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ï¼‰\n"
                output_files["skinning_npz"] = ""  # ç©ºæ–‡å­—ã§çµ±ä¸€
            
            # ğŸ”¥ æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥: mesh_for_skinning/raw_data.npzã‚’é…ç½®
            # dataset_inference_clean/{model_name}/raw_data.npzã‹ã‚‰æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼
            source_mesh_npz = Path(f"/app/dataset_inference_clean/{model_name}/raw_data.npz")
            target_mesh_dir = self.step_output_dir / "mesh_for_skinning"
            target_mesh_npz = target_mesh_dir / "raw_data.npz"
            
            # mesh_for_skinningãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆã¨raw_data.npzã‚³ãƒ”ãƒ¼
            target_mesh_dir.mkdir(parents=True, exist_ok=True)
            if source_mesh_npz.exists():
                shutil.copy2(source_mesh_npz, target_mesh_npz)
                logs += f"âœ… ãƒ¡ãƒƒã‚·ãƒ¥NPZãƒ•ã‚¡ã‚¤ãƒ«é…ç½®: {target_mesh_npz}\n"
                output_files["step3_mesh"] = str(target_mesh_npz)
            else:
                # ğŸš¨ å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨ã‚¨ãƒ©ãƒ¼ - Step3ã¯å¤±æ•—ã¨ã™ã‚‹
                error_msg = f"âŒ å¿…é ˆãƒ¡ãƒƒã‚·ãƒ¥NPZãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {source_mesh_npz}"
                logs += f"{error_msg}\n"
                logs += f"ğŸ’¡ è§£æ±ºç­–: Step1ã¾ãŸã¯Step2ã®å®Ÿè¡Œã‚’å…ˆã«å®Œäº†ã—ã¦ãã ã•ã„\n"
                return False, logs, {
                    "skinned_fbx": "",
                    "skinning_npz": "",
                    "step3_mesh": ""
                }
            
            # ğŸ”¥ æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥ã«åŸºã¥ãæœŸå¾…ãƒ•ã‚¡ã‚¤ãƒ«é…ç½®ç¢ºèª
            expected_files = {
                "skinned_fbx": self.step_output_dir / f"{model_name}_skinned.fbx",
                "skinning_npz": self.step_output_dir / f"{model_name}_skinning.npz"
            }
            
            all_expected_exist = True
            for file_type, file_path in expected_files.items():
                if file_path.exists():
                    logs += f"âœ… æœŸå¾…ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {file_type} -> {file_path}\n"
                    output_files[file_type] = str(file_path)
                else:
                    if file_type != "skinning_npz":  # NPZã¯ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«
                        logs += f"âŒ æœŸå¾…ãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨: {file_type} -> {file_path}\n"
                        all_expected_exist = False
                    else:
                        logs += f"âš ï¸ ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨: {file_type} -> {file_path}\n"
            
            # skinned_fbxã®å­˜åœ¨ç¢ºèªãŒæœ€é‡è¦ã€ãã®ä»–ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«
            if not output_files.get("skinned_fbx"):
                return False, logs, {
                    "skinned_fbx": "",
                    "skinning_npz": ""
                }
            
            # å¿…é ˆã‚­ãƒ¼ã®å­˜åœ¨ã‚’ä¿è¨¼
            if "skinning_npz" not in output_files:
                output_files["skinning_npz"] = ""
            if "skinned_fbx" not in output_files:
                output_files["skinned_fbx"] = ""
            
            return True, logs, output_files
            
        except Exception as e:
            error_msg = f"âŒ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {type(e).__name__} - {e}\n"
            self.logger.error(error_msg, exc_info=True)
            return False, logs, {
                    "skinned_fbx": "",
                    "skinning_npz": ""
                }
    
    def _validate_vertex_groups_in_fbx(self, fbx_file_path: Path, model_name: str) -> Tuple[bool, str]:
        """
        ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ãƒãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ï¼ˆãƒœãƒ¼ãƒ³/ã‚¦ã‚§ã‚¤ãƒˆï¼‰ã‚’æ¤œè¨¼
        
        Blenderã‚’ä½¿ç”¨ã—ã¦FBXãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ä»¥ä¸‹ã‚’ç¢ºèª:
        1. ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢ï¼ˆéª¨æ ¼ï¼‰ãŒå­˜åœ¨ã™ã‚‹ã‹
        2. ãƒ¡ãƒƒã‚·ãƒ¥ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ãƒãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ãŒå­˜åœ¨ã™ã‚‹ã‹
        3. ãƒãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ãŒã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢ã®ãƒœãƒ¼ãƒ³ã¨å¯¾å¿œã—ã¦ã„ã‚‹ã‹
        4. å®Ÿéš›ã«ã‚¦ã‚§ã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹
        
        Args:
            fbx_file_path: æ¤œè¨¼ã™ã‚‹FBXãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            model_name: ãƒ¢ãƒ‡ãƒ«åï¼ˆãƒ­ã‚°ç”¨ï¼‰
            
        Returns:
            (validation_success, detailed_logs)
        """
        logs = ""
        
        try:
            # Blenderã®Python APIã‚’ä½¿ç”¨ã—ã¦FBXãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œæŸ»
            # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ¢ãƒ¼ãƒ‰ã§å®‰å…¨ã«å®Ÿè¡Œ
            validation_script = f'''
import bpy
import sys
import json

def validate_vertex_groups():
    """FBXãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ãƒãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã‚’æ¤œè¨¼"""
    validation_result = {{
        "has_armature": False,
        "armature_name": "",
        "bone_count": 0,
        "meshes_with_vertex_groups": [],
        "meshes_without_vertex_groups": [],
        "vertex_group_details": {{}},
        "weight_data_exists": False,
        "validation_passed": False,
        "error_messages": []
    }}
    
    try:
        # å…¨ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç¢ºèª
        armatures = []
        meshes = []
        
        for obj in bpy.data.objects:
            if obj.type == 'ARMATURE':
                armatures.append(obj)
            elif obj.type == 'MESH':
                meshes.append(obj)
        
        # ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢å­˜åœ¨ç¢ºèª
        if not armatures:
            validation_result["error_messages"].append("âŒ ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢ï¼ˆéª¨æ ¼ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return validation_result
        
        armature = armatures[0]  # æœ€åˆã®ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢ã‚’ä½¿ç”¨
        validation_result["has_armature"] = True
        validation_result["armature_name"] = armature.name
        validation_result["bone_count"] = len(armature.data.bones)
        
        if validation_result["bone_count"] == 0:
            validation_result["error_messages"].append("âŒ ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢ã«ãƒœãƒ¼ãƒ³ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            return validation_result
        
        # å„ãƒ¡ãƒƒã‚·ãƒ¥ã®ãƒãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ç¢ºèª
        total_weighted_vertices = 0
        
        for mesh_obj in meshes:
            mesh_name = mesh_obj.name
            vertex_groups = mesh_obj.vertex_groups
            
            if len(vertex_groups) == 0:
                validation_result["meshes_without_vertex_groups"].append(mesh_name)
                validation_result["error_messages"].append("âŒ ãƒ¡ãƒƒã‚·ãƒ¥ '" + mesh_name + "' ã«ãƒãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            else:
                validation_result["meshes_with_vertex_groups"].append(mesh_name)
                
                # ãƒãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã®è©³ç´°ã‚’å–å¾—
                group_details = {{}}
                for vg in vertex_groups:
                    group_details[vg.name] = {{
                        "index": vg.index,
                        "vertex_count": len([v for v in mesh_obj.data.vertices if vg.index in [g.group for g in v.groups]])
                    }}
                
                validation_result["vertex_group_details"][mesh_name] = group_details
                
                # ã‚¦ã‚§ã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã®å­˜åœ¨ç¢ºèª
                for vertex in mesh_obj.data.vertices:
                    if len(vertex.groups) > 0:
                        total_weighted_vertices += 1
        
        validation_result["weight_data_exists"] = total_weighted_vertices > 0
        
        # ç·åˆåˆ¤å®š
        if (validation_result["has_armature"] and 
            validation_result["bone_count"] > 0 and 
            len(validation_result["meshes_with_vertex_groups"]) > 0 and
            validation_result["weight_data_exists"]):
            validation_result["validation_passed"] = True
        else:
            if not validation_result["weight_data_exists"]:
                validation_result["error_messages"].append("âŒ ãƒãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã«ã‚¦ã‚§ã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        return validation_result
        
    except Exception as e:
        validation_result["error_messages"].append("âŒ æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼: " + str(e))
        return validation_result

# ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
try:
    bpy.ops.wm.read_factory_settings(use_empty=True)
    bpy.ops.import_scene.fbx(filepath="{str(fbx_file_path)}")
    result = validate_vertex_groups()
    print("VALIDATION_RESULT_START")
    print(json.dumps(result, indent=2, ensure_ascii=False))
    print("VALIDATION_RESULT_END")
except Exception as e:
    error_result = {{
        "validation_passed": False,
        "error_messages": ["âŒ FBXãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: " + str(e)]
    }}
    print("VALIDATION_RESULT_START")
    print(json.dumps(error_result, indent=2, ensure_ascii=False))
    print("VALIDATION_RESULT_END")
    sys.exit(1)
'''

            # Blenderã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ
            logs += f"ğŸ” ãƒãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—æ¤œè¨¼é–‹å§‹: {fbx_file_path}\n"
            
            cmd = [
                "blender", "--background", "--python-text", validation_script
            ]
            
            # ä¸€æ™‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            import tempfile
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as temp_script:
                temp_script.write(validation_script)
                temp_script_path = temp_script.name
            
            try:
                # Blenderã‚³ãƒãƒ³ãƒ‰ã‚’ä¿®æ­£
                cmd = [
                    "blender", "--background", "--python", temp_script_path
                ]
                
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=120  # 2åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                )
                
                # æ¤œè¨¼çµæœã‚’ãƒ‘ãƒ¼ã‚¹
                stdout_text = result.stdout
                if "VALIDATION_RESULT_START" in stdout_text and "VALIDATION_RESULT_END" in stdout_text:
                    start_idx = stdout_text.find("VALIDATION_RESULT_START") + len("VALIDATION_RESULT_START")
                    end_idx = stdout_text.find("VALIDATION_RESULT_END")
                    json_text = stdout_text[start_idx:end_idx].strip()
                    
                    try:
                        import json
                        validation_data = json.loads(json_text)
                        
                        # çµæœã‚’è©³ç´°ã«ãƒ­ã‚°å‡ºåŠ›
                        logs += f"ğŸ“Š ãƒãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—æ¤œè¨¼çµæœ:\n"
                        logs += f"- ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢å­˜åœ¨: {validation_data.get('has_armature', False)}\n"
                        logs += f"- ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢å: {validation_data.get('armature_name', 'N/A')}\n"
                        logs += f"- ãƒœãƒ¼ãƒ³æ•°: {validation_data.get('bone_count', 0)}\n"
                        logs += f"- ãƒãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—æœ‰ã‚Šãƒ¡ãƒƒã‚·ãƒ¥: {validation_data.get('meshes_with_vertex_groups', [])}\n"
                        logs += f"- ãƒãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ç„¡ã—ãƒ¡ãƒƒã‚·ãƒ¥: {validation_data.get('meshes_without_vertex_groups', [])}\n"
                        logs += f"- ã‚¦ã‚§ã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿å­˜åœ¨: {validation_data.get('weight_data_exists', False)}\n"
                        
                        if validation_data.get('error_messages'):
                            logs += f"âš ï¸ ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:\n"
                            for error_msg in validation_data['error_messages']:
                                logs += f"  {error_msg}\n"
                        
                        if validation_data.get('validation_passed', False):
                            logs += f"âœ… ãƒãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—æ¤œè¨¼æˆåŠŸ: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒæ­£å¸¸ã«ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã™\n"
                            return True, logs
                        else:
                            logs += f"âŒ ãƒãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—æ¤œè¨¼å¤±æ•—: ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã«å•é¢˜ãŒã‚ã‚Šã¾ã™\n"
                            return False, logs
                            
                    except json.JSONDecodeError as e:
                        logs += f"âŒ æ¤œè¨¼çµæœã®JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}\n"
                        logs += f"ç”Ÿã®å‡ºåŠ›: {json_text}\n"
                        return False, logs
                else:
                    logs += f"âŒ Blenderæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å‡ºåŠ›å½¢å¼ãŒä¸æ­£ã§ã™\n"
                    logs += f"STDOUT: {result.stdout}\n"
                    logs += f"STDERR: {result.stderr}\n"
                    return False, logs
                    
            finally:
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                try:
                    os.unlink(temp_script_path)
                except:
                    pass
                    
        except subprocess.TimeoutExpired:
            logs += f"âŒ ãƒãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—æ¤œè¨¼ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ (2åˆ†)\n"
            return False, logs
        except Exception as e:
            logs += f"âŒ ãƒãƒ¼ãƒ†ãƒƒã‚¯ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—æ¤œè¨¼ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {type(e).__name__} - {e}\n"
            return False, logs

# --- äº’æ›æ€§ã®ãŸã‚ã®é–¢æ•°å®šç¾© ---
def apply_skinning_step3(model_name: str, mesh_file_path: str, skeleton_files: Dict[str, str], output_dir: str) -> Tuple[bool, str, Dict[str, Any]]:
    """
    Step3ã‚¹ã‚­ãƒ‹ãƒ³ã‚°é©ç”¨ã®äº’æ›æ€§é–¢æ•° (unified_pipeline_orchestrator.pyç”¨)
    
    Args:
        model_name: ãƒ¢ãƒ‡ãƒ«å
        mesh_file_path: Step1ãƒ¡ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆä½¿ç”¨ã—ãªã„ - åŸæµäº’æ›ã®ãŸã‚ï¼‰
        skeleton_files: Step2ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«è¾æ›¸
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        
    Returns:
        (success, logs, output_files)
    """
    # ğŸ”¥ é‡è¦: ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢
    # mesh_file_pathã¯ä½¿ç”¨ã›ãšã€ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å†æŠ½å‡ºã‚’è¡Œã†
    from fixed_directory_manager import FixedDirectoryManager
    
    logs = ""  # ãƒ­ã‚°åˆæœŸåŒ–
    
    # ãƒ¢ãƒ‡ãƒ«åã‹ã‚‰ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    fdm = FixedDirectoryManager(Path("/app/pipeline_work"), model_name)
    original_file = fdm.find_original_model_file()
    
    if not original_file:
        error_msg = f"âŒ ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ¢ãƒ‡ãƒ«å: {model_name}"
        logs += error_msg + "\n"
        return False, logs, {
                    "skinned_fbx": "",
                    "skinning_npz": ""
                }
    
    # Step3ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆã¨å®Ÿè¡Œ
    step3_instance = Step3Skinning(Path(output_dir))
    return step3_instance.apply_skinning(original_file, model_name, skeleton_files)
