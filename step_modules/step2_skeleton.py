"""
Step2 Module - ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ (æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥)
ğŸ”¥ é‡è¦: Step2ã¯å¿…ãšã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç‹¬è‡ªã®ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã‚’å®Ÿè¡Œ
åŸæµå‡¦ç†generate_skeleton.shå®Œå…¨äº’æ›å®Ÿè£…

è²¬å‹™: ã‚ªãƒªã‚¸ãƒŠãƒ«3Dãƒ¢ãƒ‡ãƒ« â†’ ã‚¹ã‚±ãƒ«ãƒˆãƒ³FBX + ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿
å‡ºåŠ›: {model_name}_skeleton.fbx, {model_name}_skeleton.npz
"""

import os
import sys
import subprocess
import shutil
import time
import logging
from pathlib import Path
from typing import Tuple, Dict, Any, Optional
import numpy as np

sys.path.insert(0, '/app')
sys.path.insert(0, '/app/src')

class Step2Skeleton:
    """Step2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥)"""
    
    def __init__(self, step_output_dir: Path, logger_instance: Optional[logging.Logger] = None):
        """
        Args:
            step_output_dir: Step2å°‚ç”¨å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ä¾‹: /app/pipeline_work/{model_name}/02_skeleton/)
            logger_instance: ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        self.step_output_dir = step_output_dir
        self.step_output_dir.mkdir(parents=True, exist_ok=True)
        self.logger = logger_instance if logger_instance else logging.getLogger(__name__)
        
        # UniRigå‡¦ç†ç”¨ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (run.pyãŒæœŸå¾…ã™ã‚‹æ§‹é€ )
        self.unirig_processing_base_dir = Path("/app/dataset_inference_clean")
        self.unirig_processing_base_dir.mkdir(parents=True, exist_ok=True)
    
    def generate_skeleton(self, 
                          original_file: Path, 
                          model_name: str, 
                          gender: str = "neutral"
                         ) -> Tuple[bool, str, Dict[str, Any]]:
        """
        ğŸ”¥ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ - ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç‹¬è‡ªãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºå®Ÿè¡Œ
        
        é‡è¦: Step1ã®çµæœã¯ä½¿ç”¨ã›ãšã€ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç‹¬è‡ªã«ãƒ¡ãƒƒã‚·ãƒ¥ã‚’å†æŠ½å‡º
        åŸæµå‡¦ç†generate_skeleton.shå®Œå…¨äº’æ›
        
        Args:
            original_file: ã‚ªãƒªã‚¸ãƒŠãƒ«3Dãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« (.glb, .fbx, .vrmç­‰)
            model_name: ãƒ¢ãƒ‡ãƒ«åï¼ˆçµ±ä¸€å‘½åè¦å‰‡ãƒ™ãƒ¼ã‚¹ï¼‰
            gender: æ€§åˆ¥è¨­å®š ("male", "female", "neutral")
            
        Returns:
            (success, logs, output_files dict) - çµ±ä¸€å‘½åè¦å‰‡æº–æ‹ ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        logs = ""
        try:
            start_time = time.time()
            self.logger.info(f"ğŸ”¥ Step2ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆé–‹å§‹: ãƒ¢ãƒ‡ãƒ« '{model_name}', æ€§åˆ¥ '{gender}'")
            self.logger.info(f"ğŸ”¥ é‡è¦: ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç‹¬è‡ªãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºå®Ÿè¡Œ: {original_file}")
            
            if not original_file.exists():
                error_msg = f"âŒ ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {original_file}"
                self.logger.error(error_msg)
                return False, error_msg, {}

            # --- Step2å°‚ç”¨UniRigå‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™ ---
            unirig_model_processing_dir = self.unirig_processing_base_dir / model_name
            unirig_model_processing_dir.mkdir(parents=True, exist_ok=True)
            
            # --- Step2å°‚ç”¨ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ ---
            step2_mesh_dir = self.step_output_dir / "mesh_for_skeleton"
            step2_mesh_dir.mkdir(parents=True, exist_ok=True)
            logs += f"âš™ï¸ Step2å°‚ç”¨ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™å®Œäº†: '{step2_mesh_dir}'\n"
            logs += f"âš™ï¸ Step2ç”¨UniRigå‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™å®Œäº†: '{unirig_model_processing_dir}'\n"

            # --- ğŸ”¥ é‡è¦: Step2ç‹¬è‡ªã®ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºå®Ÿè¡Œ ---
            success_extraction, extraction_logs = self._execute_skeleton_specific_mesh_extraction(
                original_file, unirig_model_processing_dir, model_name
            )
            logs += extraction_logs
            
            if not success_extraction:
                error_msg = f"âŒ Step2ç‹¬è‡ªãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºå¤±æ•—ã€‚"
                self.logger.error(error_msg)
                return False, logs, {}

            # --- UniRigã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå®Ÿè¡Œ ---
            success_skeleton, skeleton_logs = self._execute_unirig_skeleton_generation(
                model_name, unirig_model_processing_dir
            )
            logs += skeleton_logs
            
            if not success_skeleton:
                error_msg = f"âŒ UniRigã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå¤±æ•—ã€‚"
                self.logger.error(error_msg)
                return False, logs, {}
            
            # --- ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†ã¨çµ±ä¸€å‘½åè¦å‰‡å¯¾å¿œ ---
            success_output, output_logs, output_files = self._organize_step2_outputs(
                model_name, unirig_model_processing_dir
            )
            logs += output_logs
            
            if not success_output:
                error_msg = f"âŒ Step2å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†å¤±æ•—ã€‚"
                self.logger.error(error_msg)
                return False, logs, {}

            # å·¦å³å¯¾ç§°ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ã¯å‰Šé™¤ã•ã‚Œã¾ã—ãŸ
            
            processing_time = time.time() - start_time
            output_files["processing_time_seconds"] = round(processing_time, 2)
            
            final_log_message = f"ğŸ”¥ Step2ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå®Œäº†:\n"
            final_log_message += f"- ãƒ¢ãƒ‡ãƒ«å: {model_name}\n"
            final_log_message += f"- å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’\n"
            final_log_message += f"- çµ±ä¸€NPZ: {output_files.get('unified_skeleton_npz', 'N/A')}\n"
            final_log_message += f"- çµ±ä¸€FBX: {output_files.get('unified_skeleton_fbx', 'N/A')}\n"
            logs += "\n" + final_log_message
            
            self.logger.info(f"ğŸ”¥ Step2ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆæ­£å¸¸å®Œäº†: '{output_files['unified_skeleton_npz']}'")
            return True, logs, output_files
            
        except Exception as e:
            error_msg = f"âŒ Step2ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {type(e).__name__} - {e}"
            self.logger.error(error_msg, exc_info=True)
            return False, logs + error_msg + "\n", {}
    
    def _execute_skeleton_specific_mesh_extraction(self, original_file: Path, unirig_model_processing_dir: Path, model_name: str) -> Tuple[bool, str]:
        """
        ğŸ”¥ Step2ç‹¬è‡ªã®ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç‰¹åŒ–ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡º
        
        é‡è¦: åŸæµå‡¦ç†generate_skeleton.shç¬¬1æ®µéšå®Œå…¨äº’æ›
        faces_target_count=4000ã§ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”ŸæˆAIæœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä½¿ç”¨ 4000 â†’
        
        Args:
            original_file: ã‚ªãƒªã‚¸ãƒŠãƒ«3Dãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«
            unirig_model_processing_dir: UniRigå‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            model_name: ãƒ¢ãƒ‡ãƒ«å
            
        Returns:
            (success, logs)
        """
        logs = ""
        try:
            self.logger.info(f"ğŸ”¥ Step2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç‰¹åŒ–ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºé–‹å§‹ (faces_target_count=4000)")
            logs += f"ğŸ”¥ Step2: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç‰¹åŒ–ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºé–‹å§‹ (faces_target_count=4000)\n"

            # ãƒ‡ãƒ¼ã‚¿è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
            data_config = Path("/app/configs/data/quick_inference.yaml")
            if not data_config.exists():
                return False, f"âŒ ãƒ‡ãƒ¼ã‚¿è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨: {data_config}\n"
            
            logs += f"ğŸ”¥ Step2ç‹¬è‡ªãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºé–‹å§‹\n"
            logs += f"ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: {original_file}\n"
            logs += f"UniRigå‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {unirig_model_processing_dir}\n"
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ç”Ÿæˆ (åŸæµæ–¹å¼)
            time_str = time.strftime("%Y_%m_%d_%H_%M_%S")
            
            # ğŸ”¥ åŸæµå‡¦ç†generate_skeleton.shç¬¬1æ®µéšå®Œå…¨äº’æ›ã‚³ãƒãƒ³ãƒ‰
            extract_cmd = [
                sys.executable, "-m", "src.data.extract",
                "--config", str(data_config),
                "--force_override", "true",
                "--num_runs", "1",
                "--faces_target_count", "5000",  # ğŸ”¥ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç‰¹åŒ–: é¢æ•°æœ€é©åŒ–
                "--require_suffix", "obj,fbx,FBX,dae,glb,gltf,vrm",
                "--time", time_str,
                "--id", "0",
                "--input", str(original_file),  # ğŸ”¥ ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç›´æ¥æŒ‡å®š
                "--output_dir", str(unirig_model_processing_dir)
            ]
            
            logs += f"ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã‚³ãƒãƒ³ãƒ‰: {' '.join(extract_cmd)}\n"
            
            extract_start_time = time.time()
            result = subprocess.run(
                extract_cmd,
                cwd='/app',
                capture_output=True,
                text=True,
                timeout=600  # 10åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            )
            extract_execution_time = time.time() - extract_start_time
            logs += f"â±ï¸ ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºå®Ÿè¡Œæ™‚é–“: {extract_execution_time:.2f}ç§’\n"
            
            # ğŸ”¥ é‡è¦: Blenderã‚¯ãƒ©ãƒƒã‚·ãƒ¥(-11)ã§ã‚‚ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã•ã‚Œã¦ã„ã‚‹å ´åˆã¯æˆåŠŸã¨ã™ã‚‹
            # ãƒªã‚¿ãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰ã§ã¯ãªãã€å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ã‚’å„ªå…ˆã—ã¦ç¢ºèª
            # src.data.extractã®å®Ÿéš›ã®å‡ºåŠ›ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãæ¤œç´¢
            possible_raw_data_locations = [
                # æŒ‡å®šå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç›´ä¸‹
                unirig_model_processing_dir / "raw_data.npz",
                # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸‹ã®ãƒ¢ãƒ‡ãƒ«åãƒ•ã‚©ãƒ«ãƒ€ï¼ˆå®Ÿéš›ã®å‡ºåŠ›å…ˆï¼‰
                original_file.parent / original_file.stem / "raw_data.npz", 
                # ãã®ä»–ã®å¯èƒ½æ€§
                unirig_model_processing_dir / "examples" / original_file.stem / "raw_data.npz",
                unirig_model_processing_dir / original_file.stem / "raw_data.npz"
            ]
            
            found_raw_data = None
            for possible_location in possible_raw_data_locations:
                if possible_location.exists():
                    found_raw_data = possible_location
                    break
            
            if found_raw_data:
                # ğŸ”¥ é‡è¦: è¦‹ã¤ã‹ã£ãŸraw_data.npzã‚’UniRigå‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼
                target_raw_data = unirig_model_processing_dir / "raw_data.npz"
                if found_raw_data != target_raw_data:
                    shutil.copy2(found_raw_data, target_raw_data)
                    logs += f"ğŸ“‹ raw_data.npzã‚’UniRigå‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼: {found_raw_data} â†’ {target_raw_data}\n"
                
                # ğŸ”¥ é‡è¦: Step2å°‚ç”¨ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚‚ã‚³ãƒ”ãƒ¼ï¼ˆæ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥ï¼‰
                step2_mesh_dir = self.step_output_dir / "mesh_for_skeleton"
                step2_target_raw_data = step2_mesh_dir / "raw_data.npz"
                shutil.copy2(found_raw_data, step2_target_raw_data)
                logs += f"ğŸ“‹ raw_data.npzã‚’Step2å°‚ç”¨ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼: {found_raw_data} â†’ {step2_target_raw_data}\n"
                
                success_msg = f"âœ… Step2ç‹¬è‡ªãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºæˆåŠŸ (ãƒªã‚¿ãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰: {result.returncode}, Blenderã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã§ã‚‚ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆæ¸ˆã¿)\n"
                success_msg += f"ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«: {found_raw_data}\n"
                success_msg += f"UniRigå‡¦ç†ç”¨: {target_raw_data}\n"
                success_msg += f"Step2å°‚ç”¨ä¿å­˜: {step2_target_raw_data}\n"
                if result.stdout:
                    success_msg += f"STDOUT:\n{result.stdout}\n"
                logs += success_msg
                self.logger.info("Step2ç‹¬è‡ªãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºæˆåŠŸï¼ˆBlenderã‚¯ãƒ©ãƒƒã‚·ãƒ¥å¾Œã‚‚ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèªï¼‰ã€‚")
                return True, logs
            else:
                error_msg = f"âŒ raw_data.npzãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ (ãƒªã‚¿ãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰: {result.returncode})\n"
                error_msg += f"æ¤œç´¢å ´æ‰€: {[str(loc) for loc in possible_raw_data_locations]}\n"
                if result.stdout:
                    error_msg += f"STDOUT:\n{result.stdout}\n"
                if result.stderr:
                    error_msg += f"STDERR:\n{result.stderr}\n"
                self.logger.error(f"ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã‚¨ãƒ©ãƒ¼ã€‚Return code: {result.returncode}")
                logs += error_msg
                return False, logs
                
        except subprocess.TimeoutExpired:
            timeout_msg = "âŒ ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ (10åˆ†)\n"
            self.logger.error(timeout_msg)
            return False, logs + timeout_msg
        except Exception as e:
            exec_error_msg = f"âŒ ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {type(e).__name__} - {e}\n"
            self.logger.error(exec_error_msg, exc_info=True)
            return False, logs + exec_error_msg
    
    def _execute_unirig_skeleton_generation(self, model_name: str, unirig_model_processing_dir: Path) -> Tuple[bool, str]:
        """
        UniRigã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå®Ÿè¡Œ (åŸæµå‡¦ç†generate_skeleton.shç¬¬2æ®µéš)
        
        Args:
            model_name: ãƒ¢ãƒ‡ãƒ«å
            unirig_model_processing_dir: UniRigå‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (raw_data.npzé…ç½®æ¸ˆã¿)
            
        Returns:
            (success, logs)
        """
        logs = ""
        try:
            # ã‚¿ã‚¹ã‚¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
            task_config = Path("/app/configs/task/quick_inference_skeleton_articulationxl_ar_256.yaml")
            if not task_config.exists():
                return False, f"âŒ ã‚¿ã‚¹ã‚¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨: {task_config}\n"
            
            # raw_data.npzå­˜åœ¨ç¢ºèª
            raw_data_file = unirig_model_processing_dir / "raw_data.npz"
            if not raw_data_file.exists():
                return False, f"âŒ raw_data.npzä¸å­˜åœ¨: {raw_data_file}\n"
            
            logs += f"ğŸ”¥ UniRigã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆé–‹å§‹\n"
            logs += f"å…¥åŠ›: {raw_data_file}\n"
            logs += f"ã‚¿ã‚¹ã‚¯è¨­å®š: {task_config}\n"
            
            # ç’°å¢ƒå¤‰æ•°è¨­å®š
            env = os.environ.copy()
            env['PYTHONPATH'] = '/app:/app/src'
            
            # UniRigç”¨ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
            datalist_file_path = unirig_model_processing_dir / "inference_datalist.txt"
            with open(datalist_file_path, 'w') as f:
                f.write(model_name)
            logs += f"â„¹ï¸ UniRigç”¨ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: '{datalist_file_path}' (å†…å®¹: {model_name})\n"
            
            # ğŸ”¥ åŸæµå‡¦ç†generate_skeleton.shç¬¬2æ®µéšå®Œå…¨äº’æ›ã‚³ãƒãƒ³ãƒ‰
            skeleton_cmd = [
                sys.executable, "run.py",
                f"--task={task_config}",
                f"--seed=42",# ã‚‚ã¨ã‚‚ã¨ã¯12345ã€€ã—ã‹ã—ã€€generate_skeleton.shã§ã¯ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã‚’42ã«ã—ã¦ãŸ
                f"--npz_dir={str(unirig_model_processing_dir)}",  # raw_data.npzèª­ã¿è¾¼ã¿å…ƒ
                f"--output_dir={str(unirig_model_processing_dir)}"  # predict_skeleton.npzå‡ºåŠ›å…ˆ
            ]
            
            logs += f"ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆã‚³ãƒãƒ³ãƒ‰: {' '.join(skeleton_cmd)}\n"
            
            skeleton_start_time = time.time()
            result = subprocess.run(
                skeleton_cmd,
                cwd='/app',
                env=env,
                capture_output=True,
                text=True,
                timeout=1200  # 20åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            )
            skeleton_execution_time = time.time() - skeleton_start_time
            logs += f"â±ï¸ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå®Ÿè¡Œæ™‚é–“: {skeleton_execution_time:.2f}ç§’\n"
            
            # ğŸ”¥ é‡è¦: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆã§ã‚‚Blenderã‚¯ãƒ©ãƒƒã‚·ãƒ¥å¾Œãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèªå„ªå…ˆ
            possible_predict_skeleton_locations = [
                unirig_model_processing_dir / "predict_skeleton.npz",
                unirig_model_processing_dir / "examples" / model_name / "predict_skeleton.npz"
            ]
            
            found_predict_skeleton = None
            for possible_location in possible_predict_skeleton_locations:
                if possible_location.exists():
                    found_predict_skeleton = possible_location
                    break
            
            if found_predict_skeleton:
                success_msg = f"âœ… UniRigã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”ŸæˆæˆåŠŸ (ãƒªã‚¿ãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰: {result.returncode})\n"
                success_msg += f"ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«: {found_predict_skeleton}\n"
                if result.stdout:
                    success_msg += f"STDOUT:\n{result.stdout}\n"
                if result.stderr:  # æƒ…å ±ç”¨
                    success_msg += f"STDERR (æƒ…å ±ç”¨):\n{result.stderr}\n"
                logs += success_msg
                self.logger.info("UniRigã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”ŸæˆæˆåŠŸã€‚")
                return True, logs
            else:
                error_msg = f"âŒ predict_skeleton.npzãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ (ãƒªã‚¿ãƒ¼ãƒ³ã‚³ãƒ¼ãƒ‰: {result.returncode})\n"
                error_msg += f"æ¤œç´¢å ´æ‰€: {[str(loc) for loc in possible_predict_skeleton_locations]}\n"
                if result.stdout:
                    error_msg += f"STDOUT:\n{result.stdout}\n"
                if result.stderr:
                    error_msg += f"STDERR:\n{result.stderr}\n"
                self.logger.error(f"UniRigã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå¤±æ•—ã€‚Return code: {result.returncode}")
                self._debug_list_directory_contents(unirig_model_processing_dir)
                logs += error_msg
                return False, logs
                
        except subprocess.TimeoutExpired:
            timeout_msg = "âŒ UniRigã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”ŸæˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ (20åˆ†)\n"
            self.logger.error(timeout_msg)
            return False, logs + timeout_msg
        except Exception as e:
            exec_error_msg = f"âŒ UniRigã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {type(e).__name__} - {e}\n"
            self.logger.error(exec_error_msg, exc_info=True)
            return False, logs + exec_error_msg
    
    def _organize_step2_outputs(self, model_name: str, unirig_model_processing_dir: Path) -> Tuple[bool, str, Dict[str, Any]]:
        """
        Step2å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†ã¨çµ±ä¸€å‘½åè¦å‰‡å¯¾å¿œ (æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥)
        
        Args:
            model_name: ãƒ¢ãƒ‡ãƒ«å
            unirig_model_processing_dir: UniRigç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«æ ¼ç´ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            
        Returns:
            (success, logs, output_files)
        """
        logs = ""
        try:
            # UniRigãŒç”Ÿæˆã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
            generated_predict_skeleton = unirig_model_processing_dir / "predict_skeleton.npz"
            
            # ğŸš¨ å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨ã‚¨ãƒ©ãƒ¼ - Step2ã¯å¤±æ•—ã¨ã™ã‚‹
            if not generated_predict_skeleton.exists():
                error_msg = f"âŒ å¿…é ˆNPZãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ: {generated_predict_skeleton}\n"
                error_msg += f"ğŸ’¡ è§£æ±ºç­–: Step1ã®å®Ÿè¡Œã‚’å…ˆã«å®Œäº†ã—ã€ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„\n"
                self._debug_list_directory_contents(unirig_model_processing_dir)
                return False, logs + error_msg, {
                    "skeleton_fbx": "",
                    "skeleton_npz": "",
                    "unified_skeleton_fbx": "",
                    "unified_skeleton_npz": ""
                }
            
            logs += f"âœ… UniRigãŒNPZãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ: '{generated_predict_skeleton}'\n"
            
            # Step2å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«åŸºæœ¬ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼
            final_output_npz = self.step_output_dir / "predict_skeleton.npz"
            shutil.copy2(generated_predict_skeleton, final_output_npz)
            logs += f"ğŸ“‹ ç”Ÿæˆã•ã‚ŒãŸNPZã‚’Step2å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼: '{final_output_npz}'\n"
            
            # FBXãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ã¨ã‚³ãƒ”ãƒ¼
            skeleton_fbx_candidates = [
                unirig_model_processing_dir / "skeleton.fbx",
                unirig_model_processing_dir / "skeleton_model.fbx",
                unirig_model_processing_dir / f"{model_name}.fbx"
            ]
            
            final_output_fbx = None
            for candidate in skeleton_fbx_candidates:
                if candidate.exists():
                    final_output_fbx = self.step_output_dir / "skeleton.fbx"
                    shutil.copy2(candidate, final_output_fbx)
                    logs += f"ğŸ“‹ ç”Ÿæˆã•ã‚ŒãŸFBXã‚’Step2å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼: '{final_output_fbx}'\n"
                    break
            
            if not final_output_fbx:
                logs += f"âš ï¸ FBXãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚å€™è£œ: {skeleton_fbx_candidates}\n"
            
            # ğŸ¯ çµ±ä¸€å‘½åè¦å‰‡æº–æ‹ ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ (æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥)
            unified_skeleton_npz = self.step_output_dir / f"{model_name}_skeleton.npz"
            # ğŸ”¥ æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥æº–æ‹ : skeleton.fbx â†’ {model_name}_skeleton.fbx ã¸ã®çµ±ä¸€å‘½å
            unified_skeleton_fbx = self.step_output_dir / f"{model_name}_skeleton.fbx"
            
            # NPZãƒ•ã‚¡ã‚¤ãƒ«çµ±ä¸€å‘½å
            shutil.copy2(final_output_npz, unified_skeleton_npz)
            logs += f"ğŸ“ çµ±ä¸€NPZä½œæˆ: {unified_skeleton_npz}\n"
            
            # FBXãƒ•ã‚¡ã‚¤ãƒ«çµ±ä¸€å‘½å (åŸæµæº–æ‹ : skeleton.fbx â†’ {model_name}.fbx)
            if final_output_fbx:
                shutil.copy2(final_output_fbx, unified_skeleton_fbx)
                logs += f"ğŸ“ çµ±ä¸€FBXä½œæˆ (æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥): {unified_skeleton_fbx}\n"
            else:
                logs += f"âš ï¸ FBXãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„ãŸã‚ã€çµ±ä¸€FBXã¯ä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\n"
            
            # ãƒœãƒ¼ãƒ³éšå±¤ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
            bones_txt_path_str = self._generate_bones_txt_from_npz(final_output_npz, model_name)
            if bones_txt_path_str:
                logs += f"ğŸ“„ ãƒœãƒ¼ãƒ³éšå±¤ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ: '{bones_txt_path_str}'\n"
            
            # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±åé›†
            output_files: Dict[str, Any] = {
                "skeleton_npz": str(final_output_npz),
                "skeleton_fbx": str(final_output_fbx) if final_output_fbx else None,
                "unified_skeleton_npz": str(unified_skeleton_npz),
                "unified_skeleton_fbx": str(unified_skeleton_fbx) if final_output_fbx else None,
                "bones_txt": bones_txt_path_str,
                "bone_count": self._count_bones_in_npz_file(unified_skeleton_npz),
                "file_size_npz": unified_skeleton_npz.stat().st_size if unified_skeleton_npz.exists() else 0,
                "file_size_fbx": unified_skeleton_fbx.stat().st_size if unified_skeleton_fbx.exists() else 0
            }
            
            logs += f"âœ… Step2å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†å®Œäº† (æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥)\n"
            logs += f"åŸæµå‡¦ç†NPZ: {final_output_npz} ({output_files['file_size_npz']:,} bytes)\n"
            if final_output_fbx:
                logs += f"åŸæµå‡¦ç†FBX: {final_output_fbx} ({output_files['file_size_fbx']:,} bytes)\n"
            logs += f"çµ±ä¸€å‘½åNPZ: {unified_skeleton_npz}\n"
            logs += f"çµ±ä¸€å‘½åFBX: {unified_skeleton_fbx}\n"
            logs += f"ãƒœãƒ¼ãƒ³æ•° (æ¨å®š): {output_files['bone_count']}\n"
            
            return True, logs, output_files
            
        except Exception as e:
            error_msg = f"âŒ Step2å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {type(e).__name__} - {e}\n"
            self.logger.error(error_msg, exc_info=True)
            return False, logs + error_msg, {}
    
    def _debug_list_directory_contents(self, directory_path: Path):
        """ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šæŒ‡å®šã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å†…å®¹ã‚’ãƒ­ã‚°ã«å‡ºåŠ›"""
        if directory_path.exists() and directory_path.is_dir():
            try:
                files = os.listdir(directory_path)
                self.logger.debug(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{directory_path}' ã®å†…å®¹: {files}")
                for item in files:
                    item_path = directory_path / item
                    if item_path.is_dir():
                        sub_files = os.listdir(item_path)
                        self.logger.debug(f"  ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{item_path}' ã®å†…å®¹: {sub_files}")
            except Exception as e:
                self.logger.error(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼ '{directory_path}': {e}")
        else:
            self.logger.debug(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„ã‹ã€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã¯ã‚ã‚Šã¾ã›ã‚“: '{directory_path}'")
    
    def _generate_bones_txt_from_npz(self, npz_file_path: Path, model_name: str) -> Optional[str]:
        """NPZãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒœãƒ¼ãƒ³éšå±¤ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ"""
        if not npz_file_path.exists():
            self.logger.error(f"ãƒœãƒ¼ãƒ³éšå±¤ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆå¤±æ•—: NPZãƒ•ã‚¡ã‚¤ãƒ« '{npz_file_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return None
        
        bones_txt_output_path = npz_file_path.with_name(f"{model_name}_bones.txt")
        
        try:
            data = np.load(npz_file_path, allow_pickle=True)
            content = f"# Bone Hierarchy for {model_name}\n"
            content += f"# Generated from: {npz_file_path.name}\n\n"
            
            for key in data.files:
                array_data = data[key]
                content += f"Key: {key}\n"
                content += f"  Shape: {array_data.shape}\n"
                content += f"  Dtype: {array_data.dtype}\n"
                if hasattr(array_data, 'size'):
                    content += f"  Size: {array_data.size}\n"
                content += "\n"
            
            with open(bones_txt_output_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            self.logger.info(f"ãƒœãƒ¼ãƒ³éšå±¤ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ç”ŸæˆæˆåŠŸ: {bones_txt_output_path}")
            return str(bones_txt_output_path)
            
        except Exception as e:
            self.logger.error(f"ãƒœãƒ¼ãƒ³éšå±¤ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _count_bones_in_npz_file(self, npz_file_path: Path) -> int:
        """NPZãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒœãƒ¼ãƒ³æ•°æ¨å®š"""
        try:
            data = np.load(npz_file_path, allow_pickle=True)
            bone_count = 0
            for key in data.files:
                if 'joint' in key.lower() or 'bone' in key.lower():
                    array_data = data[key]
                    if len(array_data.shape) >= 1:
                        bone_count += array_data.shape[0]
            return bone_count if bone_count > 0 else len(data.files)
        except Exception as e:
            self.logger.error(f"ãƒœãƒ¼ãƒ³æ•°æ¨å®šã‚¨ãƒ©ãƒ¼: {e}")
            return 0
    
    # å·¦å³å¯¾ç§°ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ã¯å‰Šé™¤ã•ã‚Œã¾ã—ãŸ


# å¤–éƒ¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ (æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥å¯¾å¿œ)
def execute_step2(original_file: Path, model_name: str, step_output_dir: Path, logger: logging.Logger, gender: str = "neutral") -> Tuple[bool, str, Dict[str, Any]]:
    """
    Step2å¤–éƒ¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ - æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥å¯¾å¿œ
    
    ğŸ”¥ é‡è¦: ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç‹¬è‡ªãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºå®Ÿè¡Œ
    
    Args:
        original_file: ã‚ªãƒªã‚¸ãƒŠãƒ«3Dãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«
        model_name: ãƒ¢ãƒ‡ãƒ«å
        step_output_dir: Step2å°‚ç”¨å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        logger: ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        gender: æ€§åˆ¥è¨­å®š
        
    Returns:
        (success, logs, output_files dict)
    """
    try:
        step2 = Step2Skeleton(step_output_dir, logger)
        return step2.generate_skeleton(original_file, model_name, gender)
    except Exception as e:
        error_msg = f"Step2å¤–éƒ¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}"
        logger.error(error_msg, exc_info=True)
        return False, error_msg, {}


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³å®Ÿè¡Œ
    import argparse
    
    parser = argparse.ArgumentParser(description='Step2 ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆãƒ†ã‚¹ãƒˆ')
    parser.add_argument('--original_file', required=True, help='ã‚ªãƒªã‚¸ãƒŠãƒ«3Dãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    parser.add_argument('--model_name', required=True, help='ãƒ¢ãƒ‡ãƒ«å')
    parser.add_argument('--output_dir', default='/tmp/step2_test_output', help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--gender', default='neutral', choices=['neutral', 'male', 'female'], help='æ€§åˆ¥')
    
    args = parser.parse_args()
    
    # ãƒ­ã‚¬ãƒ¼è¨­å®š
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    logger = logging.getLogger('Step2Test')
    
    # Step2å®Ÿè¡Œ
    success, logs, output_files = execute_step2(
        Path(args.original_file),
        args.model_name,
        Path(args.output_dir),
        logger,
        args.gender
    )
    
    print(f"\n{'='*50}")
    print(f"Step2ãƒ†ã‚¹ãƒˆçµæœ: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±æ•—'}")
    print(f"{'='*50}")
    print(logs)
    if output_files:
        print(f"\nå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
        for key, value in output_files.items():
            print(f"  {key}: {value}")
