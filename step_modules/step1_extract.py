"""
Step 1 Module - ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º
ç‹¬ç«‹ã—ãŸå®Ÿè¡Œæ©Ÿèƒ½ã¨ã—ã¦ã€3Dãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º

è²¬å‹™: 3Dãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« â†’ ãƒ¡ãƒƒã‚·ãƒ¥NPZãƒ•ã‚¡ã‚¤ãƒ«
å…¥åŠ›: 3Dãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (.glb, .fbx, .objç­‰)
å‡ºåŠ›: ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (.npz)
"""

import os
import sys
import logging
import subprocess
import yaml # Not strictly used in current logic, but kept for potential future config use
from pathlib import Path
from typing import Tuple, Dict, Optional, Any
import json
import numpy as np # Not strictly used in current logic, but kept for potential future npz handling
import time
import shutil

# UniRigå®Ÿè¡Œãƒ‘ã‚¹è¨­å®š
sys.path.append('/app')

# Default logger setup if no logger is provided
logger = logging.getLogger(__name__)
if not logger.hasHandlers():
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

class Step1Extract:
    """Step 1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""
    
    def __init__(self, output_dir: Path, logger_instance: Optional[logging.Logger] = None):
        self.output_dir = output_dir # This is the step-specific output dir, e.g., /app/pipeline_work/model_name/01_extracted_mesh/
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.logger = logger_instance if logger_instance else logging.getLogger(__name__)
        
    def extract_mesh(self, input_file_path: Path, model_name: str, preserve_textures_in_step1: bool = False) -> Tuple[bool, str, Dict[str, Any]]:
        """
        å®Ÿéš›ã®ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºã®å®Ÿè¡Œ (UniRig src.data.extractä½¿ç”¨)
        
        Args:
            input_file_path: å…¥åŠ›3Dãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (çµ¶å¯¾ãƒ‘ã‚¹)
            model_name: ãƒ¢ãƒ‡ãƒ«åï¼ˆå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨ï¼‰
            preserve_textures_in_step1: ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ãƒ†ã‚¯ã‚¹ãƒãƒ£æƒ…å ±ã‚’åˆ¥é€”ä¿å­˜ã™ã‚‹ã‹ã€‚
                                     Step0ã§ã‚¢ã‚»ãƒƒãƒˆä¿å­˜ãŒè¡Œã‚ã‚Œã‚‹ãŸã‚ã€é€šå¸¸ã¯Falseã€‚
            
        Returns:
            (success, logs, output_files dict)
        """
        logs = ""
        try:
            self.logger.info(f"Step 1 é–‹å§‹: å…¥åŠ› '{input_file_path}', ãƒ¢ãƒ‡ãƒ«å '{model_name}'")
            
            if not input_file_path.exists():
                error_msg = f"âŒ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_file_path}"
                self.logger.error(error_msg)
                return False, error_msg, {}
            
            # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã®ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼ (src.data.extract ãŒç‰¹å®šã®å ´æ‰€ã‚’æœŸå¾…ã™ã‚‹å ´åˆãŒã‚ã‚‹ãŸã‚)
            # ã¾ãŸã€å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã«ãƒ¢ãƒ‡ãƒ«åã‚’å«ã‚ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒãƒƒã‚°æ™‚ã®è­˜åˆ¥ã‚’å®¹æ˜“ã«ã™ã‚‹
            persistent_input_file = self.output_dir / f"{model_name}{input_file_path.suffix}"
            if not persistent_input_file.exists() or persistent_input_file.stat().st_mtime < input_file_path.stat().st_mtime:
                shutil.copy2(input_file_path, persistent_input_file)
                logs += f"ğŸ“‹ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ« '{input_file_path.name}' ã‚’ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼: '{persistent_input_file}'\\n"
            else:
                logs += f"ğŸ“‹ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ« '{persistent_input_file.name}' ã¯ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚\\n"

            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹å®šç¾© (UniRigã®ã‚³ã‚¢ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒæœŸå¾…ã™ã‚‹å›ºå®šå)
            # ã“ã‚Œã‚‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ self.output_dir (ä¾‹: /app/pipeline_work/model_name/01_extracted_mesh/) ã«ç”Ÿæˆã•ã‚Œã‚‹
            output_npz_path = self.output_dir / "raw_data.npz"
            output_datalist_path = self.output_dir / "inference_datalist.txt"
            
            # UniRigã® src.data.extract ã‚¹ã‚¯ãƒªãƒ—ãƒˆç”¨ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            # ã“ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¯ãƒªãƒã‚¸ãƒˆãƒªã®å›ºå®šãƒ‘ã‚¹ã«ã‚ã‚‹ã¨ä»®å®š
            config_file_path = Path("/app/configs/data/quick_inference.yaml") # æŒ‡ç¤ºæ›¸ã«åŸºã¥ãä¿®æ­£
            if not config_file_path.exists():
                # Fallback or default config if specific one not found
                # For now, let's assume it must exist or try a more generic one if specified in docs.
                # Based on original script, it was /app/configs/extract_config.yaml
                # The original instructions mention configs/data/quick_inference.yaml for extract.sh
                # Let's stick to quick_inference.yaml as per the more detailed original script context.
                alt_config_path = Path("/app/configs/extract_config.yaml")
                if alt_config_path.exists():
                    config_file_path = alt_config_path
                    logs += f"âš ï¸ ãƒ¡ã‚¤ãƒ³è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« {config_file_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ä»£æ›¿ {alt_config_path} ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\\n"
                else:
                    error_msg = f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_file_path} ãŠã‚ˆã³ {alt_config_path}"
                    self.logger.error(error_msg)
                    return False, error_msg, {}
            
            logs += f"ğŸ” ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºé–‹å§‹: '{persistent_input_file.name}' ã‚’ä½¿ç”¨\\n"
            logs += f"âš™ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: '{config_file_path}'\\n"
            logs += f"ğŸ“ å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡º): '{self.output_dir}'\\n"
            
            # UniRig src.data.extract å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰
            cmd = [
                sys.executable, "-m", "src.data.extract",
                "--config", str(config_file_path),
                "--model_path", str(persistent_input_file), # ã‚³ãƒ”ãƒ¼ã•ã‚ŒãŸæ°¸ç¶šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
                "--output_dir", str(self.output_dir)      # ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            ]
            
            logs += f"ğŸš€ å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: {' '.join(cmd)}\\n"
            
            env = os.environ.copy()
            env['PYTHONPATH'] = f"/app:{env.get('PYTHONPATH', '')}"
            # env['GRADIO'] = '1' # GRADIOç’°å¢ƒå¤‰æ•°ã¯src.data.extractã«å½±éŸ¿ã—ãªã„å¯èƒ½æ€§ãŒé«˜ã„ã®ã§ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
            
            start_time = time.time()
            result = subprocess.run(
                cmd,
                cwd="/app", # UniRigã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ /app ã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹ã‚’æœŸå¾…ã™ã‚‹ã“ã¨ãŒã‚ã‚‹
                env=env,
                capture_output=True,
                text=True,
                timeout=300 # 5åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            )
            execution_time = time.time() - start_time
            logs += f"â±ï¸ æŠ½å‡ºã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’\\n"
            
            if result.returncode == 0:
                logs += "âœ… UniRigæŠ½å‡ºãƒ—ãƒ­ã‚»ã‚¹æ­£å¸¸çµ‚äº†\\n"
                if output_npz_path.exists():
                    file_size = output_npz_path.stat().st_size
                    logs += f"ğŸ“Š NPZãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ: '{output_npz_path.name}' ({file_size:,} bytes)\\n"
                    
                    output_files: Dict[str, Any] = {
                        "extracted_npz": str(output_npz_path), # Step2ãŒæœŸå¾…ã™ã‚‹ã‚­ãƒ¼å
                        "model_name": model_name,
                        "persistent_input_path_in_step_dir": str(persistent_input_file) # ã“ã®ã‚¹ãƒ†ãƒƒãƒ—å†…ã§ä½¿ç”¨ã—ãŸå…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
                    }
                    if output_datalist_path.exists():
                        logs += f"ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆç”Ÿæˆ: '{output_datalist_path.name}'\\n"
                        output_files["datalist"] = str(output_datalist_path)
                    else:
                        logs += f"âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« '{output_datalist_path.name}' ã¯ç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\\n"
                        output_files["datalist"] = None

                    # ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜å‡¦ç† (Step0ãŒä¸»æ‹…å½“ã ãŒã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¾ãŸã¯è¿½åŠ æƒ…å ±ã¨ã—ã¦)
                    if preserve_textures_in_step1:
                        texture_info = self._preserve_texture_metadata_in_step1(persistent_input_file, model_name)
                        output_files.update(texture_info)
                        logs += f"ğŸ¨ (Step1) ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜è©¦è¡Œå®Œäº†ã€‚çµæœ: {texture_info.get('texture_metadata')}\\n"
                    
                    logs += "âœ… Step 1: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå®Œäº†\\n"
                    return True, logs, output_files
                else:
                    error_msg = f"âŒ NPZãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ: {output_npz_path}\\nSTDOUT:\\n{result.stdout}\\nSTDERR:\\n{result.stderr}"
                    logs += error_msg
                    self.logger.error(error_msg)
                    return False, logs, {}
            else:
                error_msg = f"âŒ UniRigæŠ½å‡ºãƒ—ãƒ­ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼ (ã‚³ãƒ¼ãƒ‰: {result.returncode})\\nSTDOUT:\\n{result.stdout}\\nSTDERR:\\n{result.stderr}"
                logs += error_msg
                self.logger.error(error_msg)
                return False, logs, {}
                
        except subprocess.TimeoutExpired:
            error_msg = "âŒ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: ãƒ¡ãƒƒã‚·ãƒ¥æŠ½å‡ºå‡¦ç†ãŒ5åˆ†ã‚’è¶…éã—ã¾ã—ãŸ"
            logs += error_msg + "\\n"
            self.logger.error(error_msg)
            return False, logs, {}
        except Exception as e:
            error_msg = f"âŒ Step 1 å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {type(e).__name__} - {e}"
            logs += error_msg + "\\n"
            self.logger.error(error_msg, exc_info=True)
            return False, logs, {}
    
    def _preserve_texture_metadata_in_step1(self, source_model_file: Path, model_name: str) -> Dict[str, Optional[str]]:
        """
        ã“ã®ã‚¹ãƒ†ãƒƒãƒ—å†…ã§ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹ï¼ˆä¸»ã«Step0ã®è£œå®Œã¾ãŸã¯ãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰ã€‚
        Step0ãŒã‚¢ã‚»ãƒƒãƒˆä¿å­˜ã®ä¸»æ‹…å½“ã€‚
        """
        try:
            # ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (self.output_dir å†…)
            step1_texture_metadata_dir = self.output_dir / "step1_texture_info"
            step1_texture_metadata_dir.mkdir(exist_ok=True)
            
            metadata_file_path = step1_texture_metadata_dir / f"{model_name}_step1_texture_metadata.json"
            
            metadata = {
                "model_name": model_name,
                "source_model_in_step1_dir": str(source_model_file),
                "preserved_at_step1": time.time(),
                "info": "This metadata is a supplementary record from Step1. Primary asset preservation is handled by Step0."
                # ã“ã“ã«Blenderãªã©ã‚’ä½¿ã£ã¦å®Ÿéš›ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¿½åŠ å¯èƒ½
            }
            
            with open(metadata_file_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"(Step1) ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {metadata_file_path}")
            return {
                "step1_texture_metadata": str(metadata_file_path),
                "step1_texture_info_dir": str(step1_texture_metadata_dir)
            }
        except Exception as e:
            self.logger.warning(f"(Step1) ãƒ†ã‚¯ã‚¹ãƒãƒ£ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return {"step1_texture_metadata": None, "step1_texture_info_dir": None}

def execute_step1(
    input_file_path: Path, 
    model_name: str, 
    step_output_dir: Path, 
    logger_instance: logging.Logger,
    preserve_textures_in_step1: bool = False
) -> Tuple[bool, str, Dict[str, Any]]:
    """
    Step 1: 3Dãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¾ã™ã€‚

    Args:
        input_file_path: å…¥åŠ›3Dãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (çµ¶å¯¾ãƒ‘ã‚¹)
        model_name: ãƒ¢ãƒ‡ãƒ«å
        step_output_dir: ã“ã®ã‚¹ãƒ†ãƒƒãƒ—å°‚ç”¨ã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ (çµ¶å¯¾ãƒ‘ã‚¹)
        logger_instance: app.pyã‹ã‚‰æ¸¡ã•ã‚Œã‚‹ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        preserve_textures_in_step1: Step1å†…ã§è¿½åŠ ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£ä¿å­˜ã‚’è¡Œã†ã‹

    Returns:
        success: æˆåŠŸãƒ•ãƒ©ã‚° (True/False)
        logs: å®Ÿè¡Œãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        output_files: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«è¾æ›¸
    """
    try:
        extractor = Step1Extract(output_dir=step_output_dir, logger_instance=logger_instance)
        return extractor.extract_mesh(input_file_path, model_name, preserve_textures_in_step1)
    except Exception as e:
        error_message = f"Step 1 å®Ÿè¡Œæº–å‚™ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {type(e).__name__} - {e}"
        logger_instance.error(error_message, exc_info=True)
        return False, error_message, {}

if __name__ == '__main__':
    # --- ãƒ†ã‚¹ãƒˆè¨­å®š ---
    # ã“ã®ãƒ†ã‚¹ãƒˆã¯ã€ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒå˜ç‹¬ã§å®Ÿè¡Œã•ã‚ŒãŸå ´åˆã«ã®ã¿å‹•ä½œã—ã¾ã™ã€‚
    # å®Ÿéš›ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã¯app.pyã‹ã‚‰å‘¼ã³å‡ºã•ã‚Œã¾ã™ã€‚
    
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªãƒ†ã‚¹ãƒˆç”¨ãƒ­ã‚¬ãƒ¼è¨­å®š
    test_logger = logging.getLogger("Step1Extract_Test")
    test_logger.setLevel(logging.DEBUG)
    test_handler = logging.StreamHandler(sys.stdout)
    test_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
    test_logger.addHandler(test_handler)
    test_logger.propagate = False # è¦ªãƒ­ã‚¬ãƒ¼ã¸ã®ä¼æ’­ã‚’é˜²ã

    # ãƒ†ã‚¹ãƒˆç”¨ã®å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ¢ãƒ‡ãƒ«å
    # æ³¨æ„: /app/examples/bird.glb ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚
    # Dockerã‚³ãƒ³ãƒ†ãƒŠå†…ã«ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã¯ã€ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰ã‚³ãƒ”ãƒ¼ã™ã‚‹ã‹ã€
    # ãƒ€ãƒŸãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆãƒ­ã‚¸ãƒƒã‚¯ã‚’æœ‰åŠ¹ã«ã—ã¦ãã ã•ã„ã€‚
    test_input_model_filename = "bird.glb" # ã¾ãŸã¯ä»–ã®ãƒ†ã‚¹ãƒˆã—ãŸã„ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«
    test_input_file_original_location = Path(f"/app/examples/{test_input_model_filename}")
    test_model_name = "test_bird_model" # pipeline_work/{model_name} ã® {model_name} ã«å¯¾å¿œ

    # Step0 (Asset Preservation) ãŒä½œæˆã™ã‚‹ã§ã‚ã‚ã†æƒ³å®šã®å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    # ã“ã®ãƒ†ã‚¹ãƒˆã§ã¯ã€Step0ãŒå®Œäº†ã—ã€ãã®å‡ºåŠ›ãŒStep1ã®å…¥åŠ›ã«ãªã‚‹ã¨ä»®å®šã—ã¾ã™ã€‚
    # é€šå¸¸ã€Step0ã¯ /app/pipeline_work/{model_name}/00_asset_preservation/ ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚
    # Step1ã¯ãã®ä¸­ã«ã‚ã‚‹ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« (ä¾‹: preserved_model.glb) ã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚Šã¾ã™ã€‚
    # ã“ã“ã§ã¯ç°¡ç•¥åŒ–ã®ãŸã‚ã€examplesã«ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥ä½¿ã„ã¾ã™ãŒã€
    # FileManagerã«ã‚ˆã£ã¦è§£æ±ºã•ã‚ŒãŸãƒ‘ã‚¹ãŒæ¸¡ã•ã‚Œã‚‹ã“ã¨ã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚
    
    # ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (app.pyã®FileManagerãŒæ±ºå®šã™ã‚‹ãƒ‘ã‚¹ã‚’æ¨¡å€£)
    pipeline_base_dir = Path("/app/pipeline_work")
    step_specific_output_dir = pipeline_base_dir / test_model_name / "01_extracted_mesh"
    
    test_logger.info(f"--- Step1Extract ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆé–‹å§‹ ---")
    test_logger.info(f"ãƒ†ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«å: {test_model_name}")
    test_logger.info(f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ« (æƒ³å®š): {test_input_file_original_location}")
    test_logger.info(f"ã‚¹ãƒ†ãƒƒãƒ—å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {step_specific_output_dir}")

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå‰ã«å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— (ä»»æ„)
    if step_specific_output_dir.exists():
        test_logger.info(f"æ—¢å­˜ã®ãƒ†ã‚¹ãƒˆå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª {step_specific_output_dir} ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¾ã™ã€‚")
        try:
            shutil.rmtree(step_specific_output_dir)
        except OSError as e:
            test_logger.error(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¤±æ•—: {e}", exc_info=True)
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¤±æ•—æ™‚ã¯ãƒ†ã‚¹ãƒˆã‚’ä¸­æ­¢ã—ãŸæ–¹ãŒè‰¯ã„å ´åˆã‚‚ã‚ã‚‹
            # sys.exit(1) 
    step_specific_output_dir.mkdir(parents=True, exist_ok=True)

    # ãƒ€ãƒŸãƒ¼å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ (ã‚‚ã—examplesã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆ)
    created_dummy_input = False
    if not test_input_file_original_location.exists():
        test_logger.warning(f"ãƒ†ã‚¹ãƒˆç”¨å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ« {test_input_file_original_location} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        test_logger.warning("ä»£ã‚ã‚Šã«ãƒ€ãƒŸãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ãƒ†ã‚¹ãƒˆã‚’ç¶šè¡Œã—ã¾ã™ã€‚")
        # ãƒ€ãƒŸãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã¯ examples ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã¯ãªãã€ãƒ†ã‚¹ãƒˆç”¨ã®ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä½œæˆã—ãŸæ–¹ãŒè‰¯ã„ã‹ã‚‚ã—ã‚Œãªã„
        # ã“ã“ã§ã¯å…ƒã®ãƒ‘ã‚¹ã«ä½œæˆã™ã‚‹
        test_input_file_original_location.parent.mkdir(parents=True, exist_ok=True)
        with open(test_input_file_original_location, 'w') as f:
            f.write("dummy glb data for testing Step1Extract")
        created_dummy_input = True
        test_logger.info(f"ãƒ€ãƒŸãƒ¼å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ: {test_input_file_original_location}")

    # execute_step1 é–¢æ•°ã‚’å‘¼ã³å‡ºã—
    # preserve_textures_in_step1 ã¯é€šå¸¸Falseã ãŒã€ãƒ†ã‚¹ãƒˆã®ãŸã‚ã«Trueã«ã—ã¦ã¿ã‚‹ã“ã¨ã‚‚å¯èƒ½
    success, logs, files = execute_step1(
        input_file_path=test_input_file_original_location,
        model_name=test_model_name,
        step_output_dir=step_specific_output_dir,
        logger_instance=test_logger,
        preserve_textures_in_step1=True 
    )
    
    test_logger.info("\\n--- ãƒ†ã‚¹ãƒˆå®Ÿè¡Œçµæœ ---")
    test_logger.info(f"  æˆåŠŸ: {success}")
    test_logger.info(f"  ãƒ­ã‚°:\\n{logs}") # ãƒ­ã‚°ã¯è¤‡æ•°è¡Œã«ãªã‚‹ã“ã¨ãŒã‚ã‚‹ã®ã§æ”¹è¡Œã—ã¦è¡¨ç¤º
    test_logger.info(f"  å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±: {json.dumps(files, indent=2)}")

    if success:
        test_logger.info("ãƒ†ã‚¹ãƒˆæˆåŠŸã€‚ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        expected_npz = step_specific_output_dir / "raw_data.npz"
        if expected_npz.exists():
            test_logger.info(f"  âœ… NPZãƒ•ã‚¡ã‚¤ãƒ« '{expected_npz}' ãŒæœŸå¾…é€šã‚Šç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
        else:
            test_logger.error(f"  âŒ NPZãƒ•ã‚¡ã‚¤ãƒ« '{expected_npz}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    else:
        test_logger.error("ãƒ†ã‚¹ãƒˆå¤±æ•—ã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— (ç”Ÿæˆã•ã‚ŒãŸãƒ€ãƒŸãƒ¼å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿)
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯æ‰‹å‹•ã§ç¢ºèªãƒ»å‰Šé™¤ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨
    if created_dummy_input and test_input_file_original_location.exists():
        try:
            os.remove(test_input_file_original_location)
            test_logger.info(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: ãƒ€ãƒŸãƒ¼å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ« {test_input_file_original_location} ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
        except OSError as e:
            test_logger.error(f"ãƒ€ãƒŸãƒ¼å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã«å¤±æ•—: {e}")
            
    test_logger.info("--- Step1Extract ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆå®Œäº† ---")
