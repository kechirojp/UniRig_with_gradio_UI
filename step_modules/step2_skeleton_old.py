"""
Step2 Module - å›ºå®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª + çµ±ä¸€å‘½åè¦å‰‡å¯¾å¿œ
åŸæµå‡¦ç†äº’æ›ã®ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ
"""

import sys
import subprocess
import shutil
from pathlib import Path
from typing import Tuple, Dict, Any
import logging

sys.path.append('/app')

class Step2Skeleton:
    """å›ºå®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª + çµ±ä¸€å‘½åè¦å‰‡å¯¾å¿œã®Step2"""
    
    def __init__(self, output_dir: Path):
        self.output_dir = output_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.logger = logging.getLogger(__name__)
    
    def generate_skeleton(self, model_name: str, mesh_file: Path, gender: str = "neutral") -> Tuple[bool, str, Dict[str, Any]]:
        """
        å›ºå®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª + çµ±ä¸€å‘½åè¦å‰‡å¯¾å¿œã®ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ
        
        Args:
            model_name: ãƒ¢ãƒ‡ãƒ«å
            mesh_file: Step1ã§ç”Ÿæˆã•ã‚ŒãŸraw_data.npz
            gender: æ€§åˆ¥ (neutral/male/female)
            
        Returns:
            (success, logs, output_files)
        """
        logs = ""
        
        try:
            # å‰ææ¡ä»¶ç¢ºèª
            if not mesh_file.exists():
                return False, f"å…¥åŠ›ãƒ¡ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨: {mesh_file}\n", {}
            
            # åŸæµå‡¦ç†äº’æ›å®Ÿè¡Œ
            success, skeleton_logs = self._execute_original_skeleton(mesh_file, gender)
            logs += skeleton_logs
            
            if not success:
                return False, logs, {}
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
            return self._handle_output_files(model_name, logs)
            
        except Exception as e:
            error_msg = f"Step2å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}"
            return False, error_msg, {}
    
    def _execute_original_skeleton(self, mesh_file: Path, gender: str) -> Tuple[bool, str]:
        """åŸæµå‡¦ç†generate_skeleton.shäº’æ›å®Ÿè¡Œï¼ˆãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºå«ã‚€ï¼‰"""
        logs = ""
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
        task_config = Path("/app/configs/task/quick_inference_skeleton_articulationxl_ar_256.yaml")
        data_config = Path("/app/configs/data/quick_inference.yaml")
        
        if not task_config.exists():
            return False, f"ã‚¿ã‚¹ã‚¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨: {task_config}\n"
        if not data_config.exists():
            return False, f"ãƒ‡ãƒ¼ã‚¿è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨: {data_config}\n"
        
        # ğŸ”¥ åŸä½œã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆäº’æ›: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆç”¨ã«ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡º
        logs += "ğŸ”¥ åŸä½œäº’æ›: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆç”¨ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºé–‹å§‹\n"
        
        # 1. ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡º (åŸä½œã®generate_skeleton.shç¬¬1æ®µéš)
        import time as time_module
        time_str = time_module.strftime("%Y_%m_%d_%H_%M_%S")
        
        extract_cmd = [
            sys.executable, "-m", "src.data.extract",
            "--config", str(data_config),
            "--force_override", "true",
            "--num_runs", "1",
            "--target_count", "50000",
            "--faces_target_count", "50000",
            "--require_suffix", "obj,fbx,FBX,dae,glb,gltf,vrm",
            "--time", time_str,
            "--id", "0",
            "--output_dir", str(self.output_dir)
        ]
        
        # å…ƒã®ãƒ¡ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰inputæƒ…å ±ã‚’æ¨å®š
        if mesh_file.parent.name.endswith("_extracted_mesh"):
            # /app/pipeline_work/{model_name}/01_extracted_mesh/raw_data.npz
            # â†’ å…ƒã®input_dirã¯ /app/pipeline_work/{model_name}/00_preserved_assets/
            model_name = mesh_file.parent.parent.name
            input_dir = mesh_file.parent.parent / "00_asset_preservation"
            if input_dir.exists():
                extract_cmd.extend(["--input_dir", str(input_dir)])
                logs += f"å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¨å®š: {input_dir}\n"
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
                potential_input = mesh_file.parent.parent / "uploaded_model"
                if potential_input.exists():
                    # uploaded_modelãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
                    input_files = list(potential_input.glob("*"))
                    if input_files:
                        extract_cmd.extend(["--input", str(input_files[0])])
                        logs += f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ¨å®š: {input_files[0]}\n"
                else:
                    logs += f"âš ï¸ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\n"
        
        logs += f"ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã‚³ãƒãƒ³ãƒ‰: {' '.join(extract_cmd)}\n"
        
        try:
            extract_result = subprocess.run(
                extract_cmd,
                cwd="/app",
                capture_output=True,
                text=True,
                timeout=600,  # 10åˆ†
                check=True
            )
            
            logs += "âœ… ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºæˆåŠŸ\n"
            if extract_result.stdout:
                logs += f"å†æŠ½å‡ºstdout: {extract_result.stdout}\n"
                
        except subprocess.CalledProcessError as e:
            logs += f"âŒ ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºå¤±æ•—: {e}\n"
            if e.stderr:
                logs += f"å†æŠ½å‡ºstderr: {e.stderr}\n"
            return False, logs
        except subprocess.TimeoutExpired:
            logs += "âŒ ãƒ¡ãƒƒã‚·ãƒ¥å†æŠ½å‡ºã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (10åˆ†)\n"
            return False, logs
        
        # 2. ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆ (åŸä½œã®generate_skeleton.shç¬¬2æ®µéš)
        logs += "ğŸ”¥ åŸä½œäº’æ›: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆé–‹å§‹\n"
        
        skeleton_cmd = [
            sys.executable, "run.py",
            "--task", str(task_config),
            "--npz_dir", str(self.output_dir),
            "--output_dir", str(self.output_dir)
        ]
        
        logs += f"ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆã‚³ãƒãƒ³ãƒ‰: {' '.join(skeleton_cmd)}\n"
        
        try:
            skeleton_result = subprocess.run(
                skeleton_cmd,
                cwd="/app",
                capture_output=True,
                text=True,
                timeout=1200,  # 20åˆ†
                check=True
            )
            
            logs += "âœ… ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”ŸæˆæˆåŠŸ\n"
            if skeleton_result.stdout:
                logs += f"ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆstdout: {skeleton_result.stdout}\n"
            
            return True, logs
            
        except subprocess.CalledProcessError as e:
            logs += f"âŒ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆå¤±æ•—: {e}\n"
            if e.stderr:
                logs += f"ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆstderr: {e.stderr}\n"
            return False, logs
        except subprocess.TimeoutExpired:
            logs += "âŒ ã‚¹ã‚±ãƒ«ãƒˆãƒ³ç”Ÿæˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (20åˆ†)\n"
            return False, logs
    
    def _handle_output_files(self, model_name: str, logs: str) -> Tuple[bool, str, Dict[str, Any]]:
        """å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã¨çµ±ä¸€å‘½åè¦å‰‡å¯¾å¿œï¼ˆæ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥ï¼‰"""
        
        # run.pyã¯--output_dirã‚’ç„¡è¦–ã—ã¦--npz_dirã«å‡ºåŠ›ã™ã‚‹ãŸã‚ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ãƒ»ç§»å‹•
        input_dir = Path(f"/app/pipeline_work/{model_name}/01_extracted_mesh")  # å®Ÿéš›ã®å‡ºåŠ›å ´æ‰€
        
        # å®Ÿéš›ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        actual_predict_skeleton = input_dir / "predict_skeleton.npz"
        actual_skeleton_fbx = input_dir / "skeleton.fbx"
        
        if not actual_predict_skeleton.exists():
            return False, logs + f"âŒ å®Ÿéš›ã®å‡ºåŠ›ä¸å­˜åœ¨: {actual_predict_skeleton}\n", {}
        
        if not actual_skeleton_fbx.exists():
            return False, logs + f"âŒ å®Ÿéš›ã®å‡ºåŠ›ä¸å­˜åœ¨: {actual_skeleton_fbx}\n", {}
        
        logs += f"âœ… å®Ÿéš›ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹:\n"
        logs += f"  - NPZ: {actual_predict_skeleton}\n"
        logs += f"  - FBX: {actual_skeleton_fbx}\n"
        
        # æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æœŸå¾…å ´æ‰€ã«ç§»å‹•
        target_predict_skeleton = self.output_dir / "predict_skeleton.npz"
        target_skeleton_fbx = self.output_dir / "skeleton.fbx"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹•
        shutil.move(str(actual_predict_skeleton), str(target_predict_skeleton))
        shutil.move(str(actual_skeleton_fbx), str(target_skeleton_fbx))
        
        logs += f"âœ… æ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•å®Œäº†:\n"
        logs += f"  - NPZ: {target_predict_skeleton}\n"
        logs += f"  - FBX: {target_skeleton_fbx}\n"
        
        # çµ±ä¸€å‘½åè¦å‰‡ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        unified_skeleton_npz = self.output_dir / f"{model_name}_skeleton.npz"
        unified_skeleton_fbx = self.output_dir / f"{model_name}_skeleton.fbx"
        
        # NPZãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼
        if not unified_skeleton_npz.exists():
            shutil.copy2(target_predict_skeleton, unified_skeleton_npz)
            logs += f"âœ… çµ±ä¸€å‘½åNPZä½œæˆ: {unified_skeleton_npz}\n"
        
        # FBXãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼ï¼ˆåŸæµå‡¦ç†äº’æ›ã®ãŸã‚ã€{model_name}.fbxã‚‚ä½œæˆï¼‰
        original_compat_fbx = self.output_dir / f"{model_name}.fbx"
        if not original_compat_fbx.exists():
            shutil.copy2(target_skeleton_fbx, original_compat_fbx)
            logs += f"âœ… åŸæµå‡¦ç†äº’æ›FBXä½œæˆ: {original_compat_fbx}\n"
        
        if not unified_skeleton_fbx.exists():
            shutil.copy2(target_skeleton_fbx, unified_skeleton_fbx)
            logs += f"âœ… çµ±ä¸€å‘½åFBXä½œæˆ: {unified_skeleton_fbx}\n"
        
        # ä¸è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        cleanup_files = [
            input_dir / "skeleton.obj",
            input_dir / "skeleton_pred.txt"
        ]
        
        for cleanup_file in cleanup_files:
            if cleanup_file.exists():
                try:
                    cleanup_file.unlink()
                    logs += f"âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: {cleanup_file}\n"
                except Exception as e:
                    logs += f"âš ï¸ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¤±æ•— (ç„¡è¦–): {cleanup_file} - {e}\n"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
        npz_size = target_predict_skeleton.stat().st_size
        fbx_size = target_skeleton_fbx.stat().st_size
        
        logs += f"âœ… Step2å®Œäº†ï¼ˆæ±ºã‚æ‰“ã¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæˆ¦ç•¥ï¼‰\n"
        logs += f"åŸæµå‡¦ç†NPZ: {target_predict_skeleton} ({npz_size:,} bytes)\n"
        logs += f"åŸæµå‡¦ç†FBX: {target_skeleton_fbx} ({fbx_size:,} bytes)\n"
        logs += f"çµ±ä¸€å‘½åNPZ: {unified_skeleton_npz}\n"
        logs += f"çµ±ä¸€å‘½åFBX: {unified_skeleton_fbx}\n"
        
        return True, logs, {
            "skeleton_npz": str(target_predict_skeleton),      # åŸæµå‡¦ç†äº’æ›
            "skeleton_fbx": str(original_compat_fbx),          # åŸæµå‡¦ç†äº’æ› ({model_name}.fbx)
            "unified_skeleton_npz": str(unified_skeleton_npz), # çµ±ä¸€å‘½åè¦å‰‡
            "unified_skeleton_fbx": str(unified_skeleton_fbx)  # çµ±ä¸€å‘½åè¦å‰‡
        }

# å¤–éƒ¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
def generate_skeleton_step2(model_name: str, mesh_file_path: str, output_dir: str, gender: str = "neutral") -> Tuple[bool, str, Dict[str, Any]]:
    """Step2å¤–éƒ¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ - çµ±ä¸€å‘½åè¦å‰‡å¯¾å¿œ"""
    try:
        step2 = Step2Skeleton(Path(output_dir))
        return step2.generate_skeleton(model_name, Path(mesh_file_path), gender)
    except Exception as e:
        return False, f"Step2å¤–éƒ¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}", {}
