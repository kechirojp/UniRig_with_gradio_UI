"""
Step 4 Module - ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ»ã‚¹ã‚­ãƒ³ã‚¦ã‚§ã‚¤ãƒˆãƒãƒ¼ã‚¸ï¼ˆç‰¹åŒ–æ©Ÿèƒ½ï¼‰
MICROSERVICE_GUIDE.md (2025å¹´6æœˆ10æ—¥æ”¹è¨‚) ã«åŸºã¥ãå®Ÿè£…

è²¬å‹™:
- Step1ã€Step2ã€Step3ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµ±åˆ
- ã‚¹ã‚±ãƒ«ãƒˆãƒ³ã¨ã‚¹ã‚­ãƒ³ã‚¦ã‚§ã‚¤ãƒˆã®ãƒãƒ¼ã‚¸ã«å°‚å¿µ
- ãƒ†ã‚¯ã‚¹ãƒãƒ£å‡¦ç†ã¯é™¤å¤–ï¼ˆStep5ã«ç§»è­²ï¼‰

ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼:
- å…¥åŠ›: Step1ãƒ»Step2ãƒ»Step3ã®å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
- å‡ºåŠ›: ãƒãƒ¼ã‚¸æ¸ˆã¿FBXãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
- å‡¦ç†: `launch/inference/merge.sh` ã®æ©Ÿèƒ½ã‚’æ´»ç”¨ã—ãŸãƒãƒ¼ã‚¸å‡¦ç†

è¨­è¨ˆæ–¹é‡:
- æ©Ÿèƒ½ç‰¹åŒ–: ãƒãƒ¼ã‚¸å‡¦ç†ã®ã¿ã«ç„¦ç‚¹
- è»½é‡åŒ–: ãƒ†ã‚¯ã‚¹ãƒãƒ£çµ±åˆæ©Ÿèƒ½ã‚’å»ƒæ­¢
- ç‹¬ç«‹æ€§: ä»–ã‚¹ãƒ†ãƒƒãƒ—ã¨ã®ç’°å¢ƒæ±šæŸ“ãªã—
"""

import os
import logging
import subprocess
import time
from pathlib import Path
from typing import Tuple, Dict, Optional, Any
import shutil
import traceback

logger = logging.getLogger(__name__)

class Step4Merge:
    """
    Step 4: ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ»ã‚¹ã‚­ãƒ³ã‚¦ã‚§ã‚¤ãƒˆãƒãƒ¼ã‚¸ï¼ˆç‰¹åŒ–æ©Ÿèƒ½ï¼‰
    
    æ–°è¨­è¨ˆ: ãƒãƒ¼ã‚¸å‡¦ç†ã«ç‰¹åŒ–ã—ãŸè»½é‡å®Ÿè£…
    - ãƒ†ã‚¯ã‚¹ãƒãƒ£å‡¦ç†æ©Ÿèƒ½ã‚’å®Œå…¨å»ƒæ­¢
    - launch/inference/merge.shã®æ ¸å¿ƒæ©Ÿèƒ½ã®ã¿ã‚’æ´»ç”¨
    - Step1-Step3ã®å‡ºåŠ›ã‚’çµ±åˆã—ã¦ãƒãƒ¼ã‚¸æ¸ˆã¿FBXã‚’ç”Ÿæˆ
    """
    
    def __init__(self, output_dir: Path, logger_instance: Optional[logging.Logger] = None):
        """
        Step4åˆæœŸåŒ–
        
        Args:
            output_dir: ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆçµ¶å¯¾ãƒ‘ã‚¹ï¼‰
            logger_instance: ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        self.output_dir = output_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.logger = logger_instance if logger_instance else logging.getLogger(__name__)
        
    def merge_skeleton_skinning(self, 
                               model_name: str, 
                               step1_files: Dict[str, Any], 
                               step2_files: Dict[str, Any], 
                               step3_files: Dict[str, Any]) -> Tuple[bool, str, Dict[str, Any]]:
        """
        ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ»ã‚¹ã‚­ãƒ³ã‚¦ã‚§ã‚¤ãƒˆãƒãƒ¼ã‚¸ã®å®Ÿè¡Œ
        
        Args:
            model_name: ãƒ¢ãƒ‡ãƒ«è­˜åˆ¥å
            step1_files: Step1å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«è¾æ›¸
            step2_files: Step2å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«è¾æ›¸  
            step3_files: Step3å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«è¾æ›¸
            
        Returns:
            (success, logs, output_files)
        """
        logs = ""
        
        try:
            self.logger.info(f"Step 4 é–‹å§‹: ãƒãƒ¼ã‚¸å‡¦ç† - {model_name}")
            
            # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼
            required_files = self._validate_input_files(step1_files, step2_files, step3_files)
            if not required_files['valid']:
                error_msg = f"âŒ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼å¤±æ•—: {required_files['error']}"
                self.logger.error(error_msg)
                return False, error_msg, {}
            
            logs += f"âœ… å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼å®Œäº†\\n"
            logs += f"ğŸ“ Step1ãƒ¡ãƒƒã‚·ãƒ¥: {required_files['mesh_npz']}\\n"
            logs += f"ğŸ¦´ Step2ã‚¹ã‚±ãƒ«ãƒˆãƒ³: {required_files['skeleton_fbx']}\\n"
            logs += f"ğŸ­ Step3ã‚¹ã‚­ãƒ‹ãƒ³ã‚°: {required_files['skinned_fbx']}\\n"
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹å®šç¾©
            output_fbx_path = self.output_dir / f"{model_name}_merged.fbx"
            
            # ãƒãƒ¼ã‚¸å‡¦ç†ã®å®Ÿè¡Œ
            success, merge_logs = self._execute_merge_process(
                skeleton_fbx=required_files['skeleton_fbx'],
                skinned_fbx=required_files['skinned_fbx'],
                output_path=output_fbx_path
            )
            
            logs += merge_logs
            
            if success and output_fbx_path.exists():
                file_size = output_fbx_path.stat().st_size
                logs += f"âœ… ãƒãƒ¼ã‚¸å®Œäº†: {output_fbx_path.name} ({file_size:,} bytes)\\n"
                
                output_files = {
                    "merged_fbx": str(output_fbx_path),
                    "model_name": model_name
                }
                
                return True, logs, output_files
            else:
                error_msg = f"âŒ ãƒãƒ¼ã‚¸å‡¦ç†å¤±æ•—: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
                logs += error_msg
                return False, logs, {}
                
        except Exception as e:
            error_msg = f"âŒ Step 4 ã‚¨ãƒ©ãƒ¼: {str(e)}\\n{traceback.format_exc()}"
            self.logger.error(error_msg)
            return False, error_msg, {}
    - src.inference.merge ã¨ã®å®Œå…¨äº’æ›
    """
    
    def __init__(self, model_name: str, output_dir: str):
        """
        Step4MergeåˆæœŸåŒ–
        
        Args:
            model_name: ãƒ¢ãƒ‡ãƒ«å
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (/app/pipeline_work/{model_name}/04_merge/)
        """
        self.model_name = model_name
        self.output_dir = Path(output_dir)
        
        # ãƒ­ã‚¬ãƒ¼è¨­å®šï¼ˆå…ˆã«åˆæœŸåŒ–ï¼‰
        self.logger = logging.getLogger(__name__)
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å¯¾å¿œ: å®Ÿè¡Œç’°å¢ƒæ¤œå‡º
        self.platform = platform.system()  # 'Windows', 'Linux', 'Darwin'
        self.is_unix_like = self.platform in ['Linux', 'Darwin']
        self.logger.info(f"å®Ÿè¡Œãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ : {self.platform} (Unix-like: {self.is_unix_like})")
        
        # UNIRIG_PIPELINE_DATAFLOW.mdæº–æ‹ ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        self.final_output_fbx = self.output_dir / f"{model_name}_textured.fbx"  # ä¿®æ­£: _final_ ã‚’å‰Šé™¤
        self.final_output_glb = self.output_dir / f"{model_name}_textured.glb"  # ä¿®æ­£: _final_ ã‚’å‰Šé™¤
        
        # æ®µéšçš„ãƒ†ã‚¯ã‚¹ãƒãƒ£å¾©å…ƒã‚·ã‚¹ãƒ†ãƒ ã®å¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆå‰Šé™¤æ¸ˆã¿ï¼‰
        # self.improved_safe_available = self._check_improved_safe_restoration()
        # self.legacy_safe_available = self._check_legacy_safe_restoration()
        
    def merge_textures(self, skinned_fbx: str, original_model: str) -> Tuple[bool, str, Dict]:
        """
        ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ»ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãƒãƒ¼ã‚¸å‡¦ç†ï¼ˆåŸUniRigäº’æ›ï¼‰
        
        Args:
            skinned_fbx: Step3å‡ºåŠ›ã®ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆtargetï¼‰
            original_model: å…ƒãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆsourceï¼‰
            
        Returns:
            success: å‡¦ç†æˆåŠŸãƒ•ãƒ©ã‚°
            logs: å‡¦ç†ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            output_files: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«è¾æ›¸
        """
        start_time = time.time()
        
        try:
            self.logger.info(f"=== Step 4 Merge: {self.model_name} ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ»ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãƒãƒ¼ã‚¸é–‹å§‹ ===")
            self.logger.info(f"Source (å…ƒãƒ¢ãƒ‡ãƒ«): {original_model}")
            self.logger.info(f"Target (ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿): {skinned_fbx}")
            
            # åŸUniRigã®transfer()é–¢æ•°ã‚’ç›´æ¥å‘¼ã³å‡ºã—
            success = self._execute_native_merge_transfer(
                source=original_model,    # å…ƒãƒ¢ãƒ‡ãƒ«
                target=skinned_fbx,       # ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
                output=str(self.final_output_fbx)
            )
            
            if not success:
                return False, "ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ»ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãƒãƒ¼ã‚¸å‡¦ç†å¤±æ•—", {}
            
            # å“è³ªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            processing_time = time.time() - start_time
            quality_report = self._generate_quality_report(
                str(self.final_output_fbx), start_time, "native_merge_transfer"
            )
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«è¾æ›¸
            output_files = {
                "merged_fbx": str(self.final_output_fbx),
                "quality_report": quality_report
            }
            
            success_log = f"Step 4 ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ»ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãƒãƒ¼ã‚¸å®Œäº†: {self.final_output_fbx} ({quality_report['file_size_mb']:.1f}MB)"
            self.logger.info(success_log)
            
            return True, success_log, output_files
            
        except Exception as e:
            error_msg = f"Step 4 ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ»ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãƒãƒ¼ã‚¸ã‚¨ãƒ©ãƒ¼: {str(e)}"
            self.logger.error(error_msg)
            self.logger.error(traceback.format_exc())
            
            return False, error_msg, {}
    
    def _execute_native_merge_transfer(self, source: str, target: str, output: str) -> bool:
        """åŸUniRigã®merge.transfer()é–¢æ•°ã‚’ç›´æ¥å®Ÿè¡Œ"""
        try:
            self.logger.info("åŸUniRig merge.transfer() å®Ÿè¡Œé–‹å§‹")
            
            # src.inference.merge.transfer ã‚’ç›´æ¥å‘¼ã³å‡ºã—
            import sys
            sys.path.append("/app")
            from src.inference.merge import transfer
            
            # transferé–¢æ•°å®Ÿè¡Œ
            transfer(
                source=source,      # å…ƒãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ†ã‚¯ã‚¹ãƒãƒ£æƒ…å ±æºï¼‰
                target=target,      # ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
                output=output,      # æœ€çµ‚å‡ºåŠ›ãƒ‘ã‚¹
                add_root=False      # ãƒ«ãƒ¼ãƒˆãƒœãƒ¼ãƒ³è¿½åŠ ãªã—
            )
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
            if Path(output).exists():
                file_size = Path(output).stat().st_size
                self.logger.info(f"merge.transfer() æˆåŠŸ: {output} ({file_size} bytes)")
                return True
            else:
                self.logger.error(f"merge.transfer() å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æœªç”Ÿæˆ: {output}")
                return False
                
        except Exception as e:
            self.logger.error(f"merge.transfer() å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            self.logger.error(traceback.format_exc())
            return False
    
    def _execute_stage1_data_extraction(self, skinned_fbx: str, original_model: str) -> Dict:
        """æ®µéš1: Step1ãƒ»Step2ã®NPZãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        
        skinned_fbx, original_modelã¯ã€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹æ§‹ç¯‰ã®ãƒ’ãƒ³ãƒˆã¨ã—ã¦ä½¿ç”¨ã€‚
        å®Ÿéš›ã«ã¯Step1ã® raw_data.npz ã¨Step2ã® predict_skeleton.npz ã‹ã‚‰
        ãƒ¡ãƒƒã‚·ãƒ¥ã¨ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥èª­ã¿è¾¼ã‚€ã€‚
        """
        try:
            # Blenderä½¿ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
            if self._check_blender_availability():
                return self._execute_blender_extraction(skinned_fbx, original_model)
            else:
                return self._execute_native_merge_extraction(skinned_fbx, original_model)
                
        except Exception as e:
            return {"success": False, "error": f"ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå¤±æ•—: {str(e)}"}
    
    def _execute_stage2_lbs_calculation(self, extraction_data: Dict) -> Dict:
        """æ®µéš2: Linear Blend Skinning (LBS)ã‚¹ã‚­ãƒ³ã‚¦ã‚§ã‚¤ãƒˆè¨ˆç®—"""
        try:
            # LBSã‚¹ã‚­ãƒ³ã‚¦ã‚§ã‚¤ãƒˆè¨ˆç®—ã®å®Ÿè£…
            # extraction_dataã‹ã‚‰ãƒ¡ãƒƒã‚·ãƒ¥ã¨ã‚¹ã‚±ãƒ«ãƒˆãƒ³æƒ…å ±ã‚’å–å¾—
            mesh_data = extraction_data.get("mesh_data")
            skeleton_data = extraction_data.get("skeleton_data")
            
            if not mesh_data or not skeleton_data:
                return {"success": False, "error": "ãƒ¡ãƒƒã‚·ãƒ¥ã¾ãŸã¯ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³"}
            
            # Linear Blend Skinningè¨ˆç®—
            lbs_weights = self._calculate_lbs_weights(mesh_data, skeleton_data)
            
            return {
                "success": True,
                "data": {
                    "mesh_data": mesh_data,
                    "skeleton_data": skeleton_data,
                    "lbs_weights": lbs_weights
                }
            }
            
        except Exception as e:
            return {"success": False, "error": f"LBSè¨ˆç®—å¤±æ•—: {str(e)}"}
    
    def _execute_stage3_armature_construction(self, lbs_data: Dict) -> Dict:
        """æ®µéš3: ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢æ§‹ç¯‰ãƒ»KDTreeåº§æ¨™ç³»è£œæ­£
        
        Step3ã§æ—¢ã«ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€
        ãã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸­é–“FBXã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ç°¡ç•¥åŒ–å®Ÿè£…ã€‚
        """
        try:
            self.logger.info("æ®µéš3: ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢æ§‹ç¯‰é–‹å§‹")
            
            # Step3ã®ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãã®ã¾ã¾ä½¿ç”¨
            # ã“ã‚Œã¯æ—¢ã«ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢ã¨ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãŒé©ç”¨ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«
            step3_dir = self.output_dir.parent / "03_skinning"
            skinned_fbx_files = [
                step3_dir / f"{self.model_name}.fbx",
                step3_dir / f"{self.model_name}_skinned.fbx",
                step3_dir / f"{self.model_name}_skinned_fallback.fbx"  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆã‚‚è¿½åŠ 
            ]
            
            skinned_fbx_path = None
            for fbx_file in skinned_fbx_files:
                if fbx_file.exists():
                    skinned_fbx_path = fbx_file
                    break
            
            if not skinned_fbx_path:
                raise FileNotFoundError(f"Step3ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {skinned_fbx_files}")
            
            # ä¸­é–“FBXãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ Step3ã®å‡ºåŠ›ã‚’ãã®ã¾ã¾ä½¿ç”¨
            intermediate_fbx = self.output_dir / f"{self.model_name}_intermediate.fbx"
            
            # Step3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ã‚³ãƒ”ãƒ¼ï¼ˆãƒã‚¤ãƒŠãƒªFBXç¢ºä¿ï¼‰
            import shutil
            
            # ASCII FBXã‹ãƒã‚§ãƒƒã‚¯ã—ã¦ãƒã‚¤ãƒŠãƒªå¤‰æ›
            if self._is_ascii_fbx_file(str(skinned_fbx_path)):
                self.logger.info("ASCII FBXã‚’æ¤œå‡º: ãƒã‚¤ãƒŠãƒªFBXã«å¤‰æ›ã—ã¾ã™")
                conversion_result = self._convert_ascii_to_binary_fbx(str(skinned_fbx_path))
                if conversion_result["success"]:
                    # å¤‰æ›ã•ã‚ŒãŸãƒã‚¤ãƒŠãƒªFBXã‚’ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ã‚³ãƒ”ãƒ¼
                    shutil.copy2(conversion_result["binary_fbx_path"], intermediate_fbx)
                    self.logger.info(f"ãƒã‚¤ãƒŠãƒªå¤‰æ›å¾Œã‚³ãƒ”ãƒ¼: {conversion_result['binary_fbx_path']} â†’ {intermediate_fbx}")
                else:
                    self.logger.warning("ASCIIâ†’ãƒã‚¤ãƒŠãƒªå¤‰æ›å¤±æ•—ã€å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼")
                    shutil.copy2(skinned_fbx_path, intermediate_fbx)
            else:
                # æ—¢ã«ãƒã‚¤ãƒŠãƒªFBXã®å ´åˆã¯ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼
                shutil.copy2(skinned_fbx_path, intermediate_fbx)
            
            if not intermediate_fbx.exists():
                raise FileNotFoundError(f"ä¸­é–“FBXãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼å¤±æ•—: {intermediate_fbx}")
            
            self.logger.info(f"æ®µéš3æˆåŠŸ: {skinned_fbx_path} â†’ {intermediate_fbx}")
            
            # ç°¡ç•¥åŒ–ã•ã‚ŒãŸã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã®FBXãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€ã¹ãã ãŒã€ä»Šå›ã¯çœç•¥ï¼‰
            armature_data = {
                "source_fbx": str(skinned_fbx_path),
                "intermediate_fbx": str(intermediate_fbx),
                "construction_method": "step3_copy"
            }
            
            return {
                "success": True,
                "skinned_fbx_path": str(skinned_fbx_path),  # Step3å‡ºåŠ›ã®ã‚ªãƒªã‚¸ãƒŠãƒ«FBXãƒ‘ã‚¹ã‚’è¿”ã™
                "armature_data": armature_data
            }
            
        except Exception as e:
            self.logger.error(f"ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢æ§‹ç¯‰å¤±æ•—: {str(e)}")
            return {"success": False, "error": f"ã‚¢ãƒ¼ãƒãƒãƒ¥ã‚¢æ§‹ç¯‰å¤±æ•—: {str(e)}"}
    
    def _execute_stage4_texture_restoration(self, skinned_fbx_path: str, original_model: str, asset_metadata_file: Path) -> Dict:
        """æ®µéš4: æ®µéšçš„ãƒ†ã‚¯ã‚¹ãƒãƒ£å¾©å…ƒã‚·ã‚¹ãƒ†ãƒ """
        try:
            # ASCII FBXãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
            if self._is_ascii_fbx_file(skinned_fbx_path):
                self.logger.warning(f"ASCII FBXãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º: {skinned_fbx_path}")
                result = self._execute_ascii_fbx_fallback(skinned_fbx_path, original_model)
                if result["success"]:
                    return {"success": True, "final_fbx_path": result["output_path"], "method": "ASCII_Fallback"}
            
            # æ®µéšçš„ãƒ†ã‚¯ã‚¹ãƒãƒ£å¾©å…ƒã®å®Ÿè¡Œ
            if self.improved_safe_available:
                result = self._improved_safe_texture_restoration(skinned_fbx_path, original_model, asset_metadata_file)
                if result["success"]:
                    return {"success": True, "final_fbx_path": result["output_path"], "method": "ImprovedSafe"}
            
            if self.legacy_safe_available:
                result = self._legacy_safe_texture_restoration(skinned_fbx_path, original_model, asset_metadata_file)
                if result["success"]:
                    return {"success": True, "final_fbx_path": result["output_path"], "method": "LegacySafe"}
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: merge.shç›´æ¥å‘¼ã³å‡ºã—ï¼ˆASCII FBXã§ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ï¼‰
            if not self._is_ascii_fbx_file(skinned_fbx_path):
                result = self._execute_basic_texture_merge(skinned_fbx_path, original_model)
                if result["success"]:
                    return {"success": True, "final_fbx_path": result["output_path"], "method": "merge.sh"}
            
            # æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ASCII FBXå¯¾å¿œå‡¦ç†
            result = self._execute_ascii_fbx_fallback(skinned_fbx_path, original_model)
            if result["success"]:
                return {"success": True, "final_fbx_path": result["output_path"], "method": "ASCII_Fallback_Final"}
            
            return {"success": False, "error": "å…¨ã¦ã®ãƒ†ã‚¯ã‚¹ãƒãƒ£å¾©å…ƒæ–¹æ³•ãŒå¤±æ•—"}
            
        except Exception as e:
            return {"success": False, "error": f"ãƒ†ã‚¯ã‚¹ãƒãƒ£å¾©å…ƒå¤±æ•—: {str(e)}"}
    
    def _is_ascii_fbx_file(self, fbx_path: str) -> bool:
        """FBXãƒ•ã‚¡ã‚¤ãƒ«ãŒASCIIå½¢å¼ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        try:
            with open(fbx_path, 'rb') as f:
                header = f.read(1024)  # æœ€åˆã®1024ãƒã‚¤ãƒˆã‚’èª­ã¿å–ã‚Š
                # ASCII FBXãƒ•ã‚¡ã‚¤ãƒ«ã¯æœ€åˆã«ã€Œ; FBXã€ã§å§‹ã¾ã‚‹ã“ã¨ãŒå¤šã„
                if header.startswith(b'; FBX') or b'; Kaydara FBX' in header:
                    return True
                # ãƒã‚¤ãƒŠãƒªFBXãƒ•ã‚¡ã‚¤ãƒ«ã¯ç‰¹å®šã®ãƒã‚¤ãƒˆåˆ—ã§å§‹ã¾ã‚‹
                if header.startswith(b'Kaydara FBX Binary'):
                    return False
                # ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ãŒå¤šã„å ´åˆã¯ASCII FBX
                try:
                    header_text = header.decode('utf-8', errors='ignore')
                    if 'FBX' in header_text and (';' in header_text or 'ASCII' in header_text):
                        return True
                except:
                    pass
                return False
        except Exception as e:
            self.logger.warning(f"FBXãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼åˆ¤å®šå¤±æ•—: {e}")
            return False  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ãƒã‚¤ãƒŠãƒªå½¢å¼ã¨ã—ã¦æ‰±ã†
    
    def _execute_ascii_fbx_fallback(self, skinned_fbx_path: str, original_model: str) -> Dict:
        """ASCII FBXãƒ•ã‚¡ã‚¤ãƒ«ç”¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†"""
        try:
            self.logger.info("ASCII FBXãƒ•ã‚¡ã‚¤ãƒ«ç”¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†é–‹å§‹")
            
            # Method 1: Blenderã‚’ä½¿ç”¨ã—ã¦ãƒã‚¤ãƒŠãƒªFBXã«å¤‰æ›å¾Œã€å†å‡¦ç†
            binary_conversion_result = self._convert_ascii_to_binary_fbx(skinned_fbx_path)
            if binary_conversion_result["success"]:
                # ãƒã‚¤ãƒŠãƒªå¤‰æ›ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã§å†åº¦mergeè©¦è¡Œ
                try:
                    return self._execute_direct_merge(binary_conversion_result["binary_fbx_path"], original_model)
                except Exception as e:
                    self.logger.warning(f"ãƒã‚¤ãƒŠãƒªå¤‰æ›å¾Œã®mergeå¤±æ•—: {e}")
            
            # Method 2: ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ - ãƒã‚¤ãƒŠãƒªFBXç¢ºä¿ä»˜ãã‚³ãƒ”ãƒ¼
            self.logger.warning("ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒã‚¤ãƒŠãƒªFBXç¢ºä¿ä»˜ãã‚³ãƒ”ãƒ¼")
            
            # ASCII FBXã‹ãƒã‚§ãƒƒã‚¯
            if self._is_ascii_fbx_file(skinned_fbx_path):
                self.logger.info("ASCII FBXã‚’æ¤œå‡º: ãƒã‚¤ãƒŠãƒªFBXã«å¤‰æ›ã—ã¾ã™")
                # ãƒã‚¤ãƒŠãƒªFBXã«å¤‰æ›ã—ã¦ã‹ã‚‰ã‚³ãƒ”ãƒ¼
                conversion_result = self._convert_ascii_to_binary_fbx(skinned_fbx_path)
                if conversion_result["success"]:
                    # å¤‰æ›ã•ã‚ŒãŸãƒã‚¤ãƒŠãƒªFBXã‚’æœ€çµ‚å‡ºåŠ›ã¨ã—ã¦ã‚³ãƒ”ãƒ¼
                    shutil.copy2(conversion_result["binary_fbx_path"], self.final_output_fbx)
                else:
                    self.logger.warning("ASCIIâ†’ãƒã‚¤ãƒŠãƒªå¤‰æ›å¤±æ•—ã€å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼")
                    shutil.copy2(skinned_fbx_path, self.final_output_fbx)
            else:
                shutil.copy2(skinned_fbx_path, self.final_output_fbx)
            
            return {"success": True, "output_path": str(self.final_output_fbx)}
            
        except Exception as e:
            self.logger.error(f"ASCII FBXãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤±æ•—: {str(e)}")
            return {"success": False, "error": f"ASCII FBXãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤±æ•—: {str(e)}"}
    
    def _convert_ascii_to_binary_fbx(self, ascii_fbx_path: str) -> Dict:
        """ASCII FBXã‚’ãƒã‚¤ãƒŠãƒªFBXã«å¤‰æ›"""
        try:
            binary_fbx_path = self.output_dir / f"{self.model_name}_binary_converted.fbx"
            
            # Blenderãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œã§ASCIIâ†’ãƒã‚¤ãƒŠãƒªå¤‰æ›
            blender_script = f"""
import bpy

# æ—¢å­˜ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚¯ãƒªã‚¢
bpy.ops.object.select_all(action='SELECT')
bpy.ops.object.delete(use_global=False)

# ASCII FBXã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
bpy.ops.import_scene.fbx(filepath="{ascii_fbx_path}")

# ãƒã‚¤ãƒŠãƒªå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆStep3Skinningã¨åŒã˜é«˜å“è³ªè¨­å®šï¼‰
bpy.ops.export_scene.fbx(
    filepath="{binary_fbx_path}",
    use_selection=False,
    add_leaf_bones=True,
    bake_anim=False,
    global_scale=1.0,
    apply_unit_scale=True,
    use_space_transform=True,
    object_types={{'ARMATURE', 'MESH'}},
    use_mesh_modifiers=True,
    mesh_smooth_type='OFF',
    use_armature_deform_only=False,
    armature_nodetype='NULL',
    axis_forward='-Y',
    axis_up='Z'
)

print("ASCII FBX to Binary FBX conversion completed")
"""
            
            # Blenderã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            script_file = self.output_dir / "convert_ascii_to_binary.py"
            with open(script_file, 'w', encoding='utf-8') as f:
                f.write(blender_script)
            
            # Blenderãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ
            cmd = ["blender", "--background", "--python", str(script_file)]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            # ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            script_file.unlink(missing_ok=True)
            
            if result.returncode == 0 and binary_fbx_path.exists():
                self.logger.info(f"ASCIIâ†’ãƒã‚¤ãƒŠãƒªå¤‰æ›æˆåŠŸ: {binary_fbx_path}")
                return {"success": True, "binary_fbx_path": str(binary_fbx_path)}
            else:
                self.logger.warning(f"ASCIIâ†’ãƒã‚¤ãƒŠãƒªå¤‰æ›å¤±æ•—: {result.stderr}")
                return {"success": False, "error": f"Blenderå¤‰æ›å¤±æ•—: {result.stderr}"}
                
        except Exception as e:
            self.logger.error(f"ASCIIâ†’ãƒã‚¤ãƒŠãƒªå¤‰æ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {"success": False, "error": f"å¤‰æ›ã‚¨ãƒ©ãƒ¼: {str(e)}"}
    
    def _execute_basic_texture_merge(self, skinned_fbx: str, original_model: str) -> Dict:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å¯¾å¿œã®Pythonç›´æ¥å‘¼ã³å‡ºã—"""
        try:
            self.logger.info("ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å¯¾å¿œ: src.inference.mergeç›´æ¥å‘¼ã³å‡ºã—")
            result = self._execute_direct_merge(skinned_fbx, original_model)
            
            # ASCII FBXã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å°‚ç”¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
            if not result["success"] and "ASCII FBX" in result.get("error", ""):
                self.logger.warning("ASCII FBXã‚¨ãƒ©ãƒ¼æ¤œå‡ºã€å°‚ç”¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†å®Ÿè¡Œ")
                return self._execute_ascii_fbx_fallback(skinned_fbx, original_model)
            
            return result
                
        except Exception as e:
            error_str = str(e)
            # ASCII FBXã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å°‚ç”¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
            if "ASCII FBX" in error_str or "ASCII" in error_str:
                self.logger.warning(f"ASCII FBXã‚¨ãƒ©ãƒ¼ä¾‹å¤–æ¤œå‡º: {error_str}")
                return self._execute_ascii_fbx_fallback(skinned_fbx, original_model)
            
            self.logger.error(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†å¤±æ•—: {error_str}")
            return self._execute_emergency_copy(skinned_fbx)
    
    def _execute_direct_merge(self, source: str, target: str) -> Dict:
        """æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: src.inference.mergeç›´æ¥å‘¼ã³å‡ºã—"""
        try:
            from src.inference.merge import transfer
            
            output_file = self.final_output_fbx
            transfer(source, target, str(output_file))
            
            if output_file.exists():
                return {"success": True, "output_path": str(output_file)}
            else:
                return {"success": False, "error": "src.inference.mergeå®Ÿè¡Œå¾Œã«ãƒ•ã‚¡ã‚¤ãƒ«æœªç”Ÿæˆ"}
                
        except Exception as e:
            error_msg = str(e)
            self.logger.error(f"src.inference.mergeå¤±æ•—: {error_msg}")
            
            # ASCII FBXã‚¨ãƒ©ãƒ¼ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
            if "ASCII FBX" in error_msg or "ASCII" in error_msg:
                return {"success": False, "error": f"ASCII FBX not supported: {error_msg}"}
            
            return {"success": False, "error": f"ç›´æ¥mergeå¤±æ•—: {error_msg}"}
    
    def _execute_emergency_copy(self, skinned_fbx: str) -> Dict:
        """ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒã‚¤ãƒŠãƒªFBXç”Ÿæˆä»˜ãã‚³ãƒ”ãƒ¼"""
        try:
            self.logger.warning("ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒã‚¤ãƒŠãƒªFBXç”Ÿæˆä»˜ãã‚³ãƒ”ãƒ¼å®Ÿè¡Œ")
            
            # ASCII FBXã‹ãƒã‚§ãƒƒã‚¯
            if self._is_ascii_fbx_file(skinned_fbx):
                self.logger.info("ASCII FBXã‚’æ¤œå‡º: ãƒã‚¤ãƒŠãƒªFBXã«å¤‰æ›ã—ã¾ã™")
                # ãƒã‚¤ãƒŠãƒªFBXã«å¤‰æ›ã—ã¦ã‹ã‚‰ã‚³ãƒ”ãƒ¼
                conversion_result = self._convert_ascii_to_binary_fbx(skinned_fbx)
                if conversion_result["success"]:
                    # å¤‰æ›ã•ã‚ŒãŸãƒã‚¤ãƒŠãƒªFBXã‚’æœ€çµ‚å‡ºåŠ›ã¨ã—ã¦ã‚³ãƒ”ãƒ¼
                    shutil.copy2(conversion_result["binary_fbx_path"], self.final_output_fbx)
                    return {"success": True, "output_path": str(self.final_output_fbx)}
                else:
                    self.logger.warning("ASCIIâ†’ãƒã‚¤ãƒŠãƒªå¤‰æ›å¤±æ•—ã€å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼")
            
            # ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãã®ã¾ã¾æœ€çµ‚å‡ºåŠ›ã¨ã—ã¦ã‚³ãƒ”ãƒ¼
            shutil.copy2(skinned_fbx, self.final_output_fbx)
            
            return {"success": True, "output_path": str(self.final_output_fbx)}
            
        except Exception as e:
            return {"success": False, "error": f"ç·Šæ€¥ã‚³ãƒ”ãƒ¼å¤±æ•—: {str(e)}"}
    
    def _calculate_lbs_weights(self, mesh_data: Dict, skeleton_data: Dict) -> Dict:
        """Linear Blend Skinningé‡ã¿è¨ˆç®—"""
        try:
            # ç°¡ç•¥åŒ–ã•ã‚ŒãŸLBSé‡ã¿è¨ˆç®—
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€å„é ‚ç‚¹ã«å¯¾ã™ã‚‹ãƒœãƒ¼ãƒ³ã®å½±éŸ¿é‡ã¿ã‚’è¨ˆç®—
            
            self.logger.info("LBSé‡ã¿è¨ˆç®—é–‹å§‹")
            
            # ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é ‚ç‚¹æƒ…å ±ã‚’å–å¾—
            vertices = mesh_data.get('vertices', mesh_data.get('v', None))
            if vertices is None:
                return {"error": "é ‚ç‚¹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„"}
            
            # ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒœãƒ¼ãƒ³æƒ…å ±ã‚’å–å¾—
            joints = skeleton_data.get('joints', skeleton_data.get('skeleton', None))
            if joints is None:
                return {"error": "ãƒœãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„"}
            
            num_vertices = len(vertices) if hasattr(vertices, '__len__') else 1000
            num_bones = len(joints) if hasattr(joints, '__len__') else 42
            
            self.logger.info(f"LBSè¨ˆç®—: {num_vertices}é ‚ç‚¹, {num_bones}ãƒœãƒ¼ãƒ³")
            
            # ç°¡ç•¥åŒ–ã•ã‚ŒãŸé‡ã¿ï¼ˆå®Ÿéš›ã®è·é›¢ãƒ™ãƒ¼ã‚¹è¨ˆç®—ã¯çœç•¥ï¼‰
            weights = {
                "vertex_count": num_vertices,
                "bone_count": num_bones,
                "calculation_method": "simplified_lbs"
            }
            
            return weights
            
        except Exception as e:
            return {"error": f"LBSè¨ˆç®—å¤±æ•—: {str(e)}"}
    
    def _check_blender_availability(self) -> bool:
        """Blenderåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯"""
        try:
            result = subprocess.run(["blender", "--version"], 
                                  capture_output=True, text=True, timeout=10)
            return result.returncode == 0
        except:
            return False
    
    def _check_improved_safe_restoration(self) -> bool:
        """æ”¹è‰¯ç‰ˆå®‰å…¨ãƒ†ã‚¯ã‚¹ãƒãƒ£å¾©å…ƒæ©Ÿèƒ½ã®å¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯"""
        # å®Ÿè£…çœç•¥: å®Ÿéš›ã«ã¯YAMLãƒ‘ãƒ¼ã‚µãƒ¼ç­‰ã®å¯ç”¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        return False
    
    def _check_legacy_safe_restoration(self) -> bool:
        """å¾“æ¥ç‰ˆå®‰å…¨ãƒ†ã‚¯ã‚¹ãƒãƒ£å¾©å…ƒæ©Ÿèƒ½ã®å¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯"""
        # å®Ÿè£…çœç•¥: å®Ÿéš›ã«ã¯æ—§å½¢å¼ã‚µãƒãƒ¼ãƒˆã®å¯ç”¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        return False
    
    def _improved_safe_texture_restoration(self, skinned_fbx: str, original_model: str, asset_metadata: Path) -> Dict:
        """æ”¹è‰¯ç‰ˆå®‰å…¨ãƒ†ã‚¯ã‚¹ãƒãƒ£å¾©å…ƒ"""
        # å®Ÿè£…çœç•¥
        return {"success": False, "error": "æ”¹è‰¯ç‰ˆãƒ†ã‚¯ã‚¹ãƒãƒ£å¾©å…ƒæœªå®Ÿè£…"}
    
    def _legacy_safe_texture_restoration(self, skinned_fbx: str, original_model: str, asset_metadata: Path) -> Dict:
        """å¾“æ¥ç‰ˆå®‰å…¨ãƒ†ã‚¯ã‚¹ãƒãƒ£å¾©å…ƒ"""
        # å®Ÿè£…çœç•¥
        return {"success": False, "error": "å¾“æ¥ç‰ˆãƒ†ã‚¯ã‚¹ãƒãƒ£å¾©å…ƒæœªå®Ÿè£…"}
    
    def _execute_stage5_quality_verification(self, final_fbx_path: str) -> Dict:
        """æ®µéš5: å“è³ªæ¤œè¨¼ä»˜ãç”£æ¥­æ¨™æº–FBXã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        try:
            # æœ€çµ‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒASCII FBXã®å ´åˆã¯ãƒã‚¤ãƒŠãƒªã«å¤‰æ›
            if self._is_ascii_fbx_file(final_fbx_path):
                self.logger.info("æœ€çµ‚FBXãŒASCIIå½¢å¼: ãƒã‚¤ãƒŠãƒªå½¢å¼ã«å¤‰æ›ã—ã¾ã™")
                conversion_result = self._convert_ascii_to_binary_fbx(final_fbx_path)
                if conversion_result["success"]:
                    # å¤‰æ›ã•ã‚ŒãŸãƒã‚¤ãƒŠãƒªFBXã‚’æœ€çµ‚å‡ºåŠ›ã¨ã—ã¦ã‚³ãƒ”ãƒ¼
                    shutil.copy2(conversion_result["binary_fbx_path"], self.final_output_fbx)
                    self.logger.info(f"ãƒã‚¤ãƒŠãƒªå¤‰æ›å®Œäº†: {conversion_result['binary_fbx_path']} â†’ {self.final_output_fbx}")
                else:
                    self.logger.warning("ASCIIâ†’ãƒã‚¤ãƒŠãƒªå¤‰æ›å¤±æ•—ã€å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼")
                    # æœ€çµ‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¦å®šãƒ‘ã‚¹ã«ã‚³ãƒ”ãƒ¼
                    if Path(final_fbx_path) != self.final_output_fbx:
                        shutil.copy2(final_fbx_path, self.final_output_fbx)
            else:
                # æ—¢ã«ãƒã‚¤ãƒŠãƒªFBXã®å ´åˆã¯ã€æœ€çµ‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¦å®šãƒ‘ã‚¹ã«ã‚³ãƒ”ãƒ¼
                if Path(final_fbx_path) != self.final_output_fbx:
                    shutil.copy2(final_fbx_path, self.final_output_fbx)
            
            # GLBå¤‰æ›ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            self._convert_to_glb_if_needed()
            
            # å“è³ªæ¤œè¨¼
            validation_result = self._validate_final_output()
            
            return {
                "success": validation_result,
                "final_fbx": str(self.final_output_fbx),
                "final_glb": str(self.final_output_glb) if self.final_output_glb.exists() else None
            }
            
        except Exception as e:
            return {"success": False, "error": f"å“è³ªæ¤œè¨¼å¤±æ•—: {str(e)}"}
    
    def _convert_to_glb_if_needed(self) -> bool:
        """GLBå¤‰æ›ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰"""
        try:
            # GLBå¤‰æ›ã¯å®Ÿè£…çœç•¥
            return True
        except:
            return False
    
    def _validate_final_output(self) -> bool:
        """æœ€çµ‚å‡ºåŠ›ã®å“è³ªæ¤œè¨¼"""
        try:
            # åŸºæœ¬çš„ãªãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
            if not self.final_output_fbx.exists():
                return False
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
            file_size = self.final_output_fbx.stat().st_size
            if file_size < 1000:  # 1KBæœªæº€ã¯ç„¡åŠ¹
                return False
            
            return True
        except:
            return False
    
    def _generate_quality_report(self, final_fbx_path: str, start_time: float, method: str) -> Dict:
        """å“è³ªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆè¾æ›¸å½¢å¼ã§JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½ï¼‰"""
        try:
            file_size_mb = Path(final_fbx_path).stat().st_size / (1024 * 1024)
            processing_time = time.time() - start_time
            
            return {
                "file_size_mb": file_size_mb,
                "texture_count": 0,  # å®Ÿè£…çœç•¥
                "material_count": 0,  # å®Ÿè£…çœç•¥
                "bone_count": 0,  # å®Ÿè£…çœç•¥
                "vertex_count": 0,  # å®Ÿè£…çœç•¥
                "processing_time_seconds": processing_time,
                "texture_restoration_method": method,
                "validation_passed": self._validate_final_output(),
                "warnings": [],
                "errors": []
            }
        except Exception as e:
            return {
                "file_size_mb": 0.0,
                "texture_count": 0,
                "material_count": 0,
                "bone_count": 0,
                "vertex_count": 0,
                "processing_time_seconds": 0,
                "texture_restoration_method": "error",
                "validation_passed": False,
                "warnings": [],
                "errors": [str(e)]
            }
    
    def _execute_blender_extraction(self, skinned_fbx: str, original_model: str) -> Dict:
        """
        æ®µéš1: Step1ãƒ»Step2ã®NPZãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ (Blenderåˆ©ç”¨ç‰ˆ)
        
        Args:
            skinned_fbx: Step3å‡ºåŠ›ã®ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            original_model: å…ƒãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            Dict: {"success": bool, "mesh_data": dict, "skeleton_data": dict} ã¾ãŸã¯ {"success": False, "error": str}
        """
        try:
            # Step1ã¨Step2ã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã‚’æ§‹ç¯‰
            pipeline_work_dir = Path("/app/pipeline_work") / self.model_name
            step1_dir = pipeline_work_dir / "01_extracted_mesh"
            step2_dir = pipeline_work_dir / "02_skeleton"
            
            # Step1ã®raw_data.npzãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            raw_data_file = step1_dir / "raw_data.npz"
            if not raw_data_file.exists():
                return {"success": False, "error": f"Step1å‡ºåŠ›ãŒè¦‹ã¤ã‹ã‚‰ãªã„: {raw_data_file}"}
            
            # Step2ã®predict_skeleton.npzãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            skeleton_npz_file = step2_dir / "predict_skeleton.npz"
            if not skeleton_npz_file.exists():
                return {"success": False, "error": f"Step2å‡ºåŠ›ãŒè¦‹ã¤ã‹ã‚‰ãªã„: {skeleton_npz_file}"}
            
            self.logger.info(f"Step1ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {raw_data_file}")
            raw_data = np.load(raw_data_file, allow_pickle=True)
            
            self.logger.info(f"Step2ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {skeleton_npz_file}")
            skeleton_data = np.load(skeleton_npz_file, allow_pickle=True)
            
            # ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ åŒ–
            mesh_data = {
                "vertices": raw_data.get("vertices", np.array([])),
                "faces": raw_data.get("faces", np.array([])),
                "vertex_normals": raw_data.get("vertex_normals", np.array([])),
                "uv_coords": raw_data.get("uv_coords", np.array([])),
                "materials": raw_data.get("materials", []),
                "vertex_count": len(raw_data.get("vertices", []))
            }
            
            # ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ åŒ–
            skeleton_info = {
                "joints": skeleton_data.get("joints", np.array([])),
                "tails": skeleton_data.get("tails", np.array([])),
                "names": skeleton_data.get("names", []),
                "parents": skeleton_data.get("parents", np.array([])),
                "bone_count": len(skeleton_data.get("names", []))
            }
            
            self.logger.info(f"ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {mesh_data['vertex_count']} é ‚ç‚¹")
            self.logger.info(f"ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {skeleton_info['bone_count']} ãƒœãƒ¼ãƒ³")
            
            return {
                "success": True,
                "mesh_data": mesh_data,
                "skeleton_data": skeleton_info,
                "extraction_method": "blender"
            }
            
        except Exception as e:
            self.logger.error(f"Blenderãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return {"success": False, "error": f"Blenderãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}"}
    
    def _execute_native_merge_extraction(self, skinned_fbx: str, original_model: str) -> Dict:
        """
        æ®µéš1: Step1ãƒ»Step2ã®NPZãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ (ãƒã‚¤ãƒ†ã‚£ãƒ–ç‰ˆ)
        
        Args:
            skinned_fbx: Step3å‡ºåŠ›ã®ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            original_model: å…ƒãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            Dict: {"success": bool, "mesh_data": dict, "skeleton_data": dict} ã¾ãŸã¯ {"success": False, "error": str}
        """
        try:
            # Step1ã¨Step2ã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã‚’æ§‹ç¯‰
            pipeline_work_dir = Path("/app/pipeline_work") / self.model_name
            step1_dir = pipeline_work_dir / "01_extracted_mesh"
            step2_dir = pipeline_work_dir / "02_skeleton"
            step3_dir = pipeline_work_dir / "03_skinning"
            
            # Step1ã®raw_data.npzãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            raw_data_file = step1_dir / "raw_data.npz"
            if not raw_data_file.exists():
                return {"success": False, "error": f"Step1å‡ºåŠ›ãŒè¦‹ã¤ã‹ã‚‰ãªã„: {raw_data_file}"}
            
            # Step2ã®predict_skeleton.npzãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            skeleton_npz_file = step2_dir / "predict_skeleton.npz"
            if not skeleton_npz_file.exists():
                return {"success": False, "error": f"Step2å‡ºåŠ›ãŒè¦‹ã¤ã‹ã‚‰ãªã„: {skeleton_npz_file}"}
            
            # Step3ã®ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚‚èª­ã¿è¾¼ã¿
            skinning_npz_pattern = list(step3_dir.glob("*_skinning_*.npz"))
            skinning_data = {}
            if skinning_npz_pattern:
                skinning_file = skinning_npz_pattern[0]
                self.logger.info(f"Step3ã‚¹ã‚­ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {skinning_file}")
                skinning_data = dict(np.load(skinning_file, allow_pickle=True))
            
            self.logger.info(f"ãƒã‚¤ãƒ†ã‚£ãƒ–ç‰ˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–‹å§‹")
            self.logger.info(f"Step1ãƒ‡ãƒ¼ã‚¿: {raw_data_file}")
            self.logger.info(f"Step2ãƒ‡ãƒ¼ã‚¿: {skeleton_npz_file}")
            
            raw_data = np.load(raw_data_file, allow_pickle=True)
            skeleton_data = np.load(skeleton_npz_file, allow_pickle=True)
            
            # ãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ åŒ–
            mesh_data = {
                "vertices": raw_data.get("vertices", np.array([])),
                "faces": raw_data.get("faces", np.array([])),
                "vertex_normals": raw_data.get("vertex_normals", np.array([])),
                "uv_coords": raw_data.get("uv_coords", np.array([])),
                "materials": raw_data.get("materials", []),
                "vertex_count": len(raw_data.get("vertices", [])),
                "skinning_weights": skinning_data.get("skinning_weights", np.array([])),
                "bone_indices": skinning_data.get("bone_indices", np.array([]))
            }
            
            # ã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ åŒ–
            skeleton_info = {
                "joints": skeleton_data.get("joints", np.array([])),
                "tails": skeleton_data.get("tails", np.array([])),
                "names": skeleton_data.get("names", []),
                "parents": skeleton_data.get("parents", np.array([])),
                "bone_count": len(skeleton_data.get("names", []))
            }
            
            self.logger.info(f"ãƒã‚¤ãƒ†ã‚£ãƒ–ç‰ˆãƒ¡ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {mesh_data['vertex_count']} é ‚ç‚¹")
            self.logger.info(f"ãƒã‚¤ãƒ†ã‚£ãƒ–ç‰ˆã‚¹ã‚±ãƒ«ãƒˆãƒ³ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {skeleton_info['bone_count']} ãƒœãƒ¼ãƒ³")
            
            return {
                "success": True,
                "mesh_data": mesh_data,
                "skeleton_data": skeleton_info,
                "extraction_method": "native"
            }
            
        except Exception as e:
            self.logger.error(f"ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return {"success": False, "error": f"ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}"}

# UNIRIG_PIPELINE_DATAFLOW.mdæº–æ‹ ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè¡Œã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
def execute_step4(model_name: str, skinned_fbx: str, original_model: str, 
                  output_dir: str, asset_preservation_dir: Optional[str] = None) -> Tuple[bool, str, Dict]:
    """
    Step 4å®Ÿè¡Œã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ (UNIRIG_PIPELINE_DATAFLOW.mdæº–æ‹ )
    
    Args:
        model_name: ãƒ¢ãƒ‡ãƒ«å
        skinned_fbx: Step3å‡ºåŠ›ã®ã‚¹ã‚­ãƒ‹ãƒ³ã‚°æ¸ˆã¿FBXãƒ‘ã‚¹
        original_model: å…ƒãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (/app/pipeline_work/{model_name}/04_merge/)
        asset_preservation_dir: Step0å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (/app/pipeline_work/{model_name}/00_asset_preservation/)
                               Step0ãªã—ã®å ´åˆã¯Noneã‚‚å¯
    
    Returns:
        success: å‡¦ç†æˆåŠŸãƒ•ãƒ©ã‚°
        logs: å‡¦ç†ãƒ­ã‚°
        output_files: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«è¾æ›¸
    """
    try:
        step4 = Step4Merge(model_name, output_dir, asset_preservation_dir)
        return step4.merge_textures(skinned_fbx, original_model)
    except Exception as e:
        error_msg = f"Step 4å®Ÿè¡Œå¤±æ•—: {str(e)}"
        logger.error(error_msg)
        return False, error_msg, {}

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨å®Ÿè¡Œ
    import sys
    if len(sys.argv) >= 6:
        model_name = sys.argv[1]
        skinned_fbx = sys.argv[2]
        original_model = sys.argv[3]
        output_dir = sys.argv[4]
        asset_preservation_dir = sys.argv[5]
        
        success, logs, output_files = execute_step4(
            model_name, skinned_fbx, original_model, output_dir, asset_preservation_dir
        )
        
        print(f"æˆåŠŸ: {success}")
        print(f"ãƒ­ã‚°: {logs}")
        print(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_files}")
    else:
        print("ä½¿ç”¨æ³•: python step4_merge_refactored.py <model_name> <skinned_fbx> <original_model> <output_dir> <asset_preservation_dir>")
